# ğŸ¤ Redis AI Workshop â€” Speaker Script (Full Version)

> **Duration:** ~60â€“70 minutes (â‰ˆ5 minutes per slide)  
> **Goal:** Convince the audience that Redis is the essential real-time data & memory layer for AI systems.  
> **Tone:** Conversational, technical confidence, storytelling with business outcomes.

---

## ğŸŸ¥ Slide 1 â€” Redis AI Workshop: Applied Engineering Team

**Opening (1â€“2 min):**
> â€œHi everyone, and welcome to the Redis AI Workshop.  
Iâ€™m [Your Name], part of Redisâ€™s Applied Engineering Team.  
Our mission is to help companies operationalize AI â€” turning clever prototypes into scalable, real-time systems.â€

**Core Message:**
> â€œYou already know Redis as the fastest in-memory data platform.  
But today, weâ€™ll see Redis as something much more â€” the *real-time intelligence layer* for AI.  
Redis now powers **vector search**, **semantic caching**, **agent memory**, and **retrieval pipelines** â€” the backbone of modern GenAI systems.â€

**Framing:**
> â€œThe challenge today isnâ€™t just about making AI smarter â€” itâ€™s about making it *faster*, *cheaper*, and *more contextual*.  
Thatâ€™s what Redis does better than anyone.â€

**Transition:**
> â€œLetâ€™s take a look at what weâ€™ll cover today.â€

---

## ğŸŸ§ Slide 2 â€” Workshop Agenda

> â€œWeâ€™ll begin with an overview of *why Redis for AI* â€” the unique performance and data model advantages.  
Then weâ€™ll move into patterns and demos, including:â€

- Vector Search  
- Semantic Routing  
- Semantic Caching  
- AI Agents with Redis  

> â€œBy the end, youâ€™ll see that Redis is not just a caching system â€” itâ€™s a unified layer that accelerates and enriches *every* part of your AI stack.â€

**Key Message:**
> â€œIf youâ€™re using OpenAI, Anthropic, or any LLM provider, Redis is what turns those stateless models into *stateful intelligence systems*.â€

**Transition:**
> â€œLetâ€™s start with the big picture â€” the Redis advantage for AI.â€

---

## ğŸŸ¨ Slide 3 â€” Overview and Features

> â€œRedis is known for extreme performance â€” microsecond latency, horizontal scalability, and simplicity.  
But for AI, what matters is Redisâ€™s ability to connect memory, context, and computation.â€

**Explain the idea:**
> â€œAI apps need to *remember*, *retrieve*, and *react* â€” instantly.  
Redis does all three, serving as the data plane for real-time intelligence.â€

**Example narrative:**
> â€œThink of a virtual assistant â€” it has to recall what you said yesterday, find the right information, and respond within seconds.  
Redis handles each of those tasks â€” caching memory, retrieving knowledge, and feeding it back to the model.â€

**Transition:**
> â€œLetâ€™s see this visually â€” how Redis powers AI end to end.â€

---

## ğŸŸ¥ Slide 4 â€” Redis for AI

> â€œThis is where Redis shines.  
It unites vector search, semantic caching, feature storage, and memory â€” all in one high-performance platform.â€

**Key talking points:**
- **Redis Vector DB:** Stores embeddings for RAG, recommendations, search, and AI memory.  
- **Redis Cache:** Caches LLM responses and ML predictions for instant reuse.  
- **Feature Store:** Keeps features live for real-time inference.  
- **Session + Agent State:** Powers dynamic user sessions and multi-step reasoning.  
- **Fraud Detection:** Detects anomalies in real time using event streams and vector distances.

**Example:**
> â€œImagine an airline chatbot:  
Redis remembers your flight history, caches previous responses, and avoids repeated calls to the model.  
Everything happens in milliseconds.â€

**Tagline:**
> â€œFor a GenAI app, you only need *three components*:  
1ï¸âƒ£ An AI provider,  
2ï¸âƒ£ A UI,  
3ï¸âƒ£ Redis.â€

**Transition:**
> â€œLetâ€™s talk about how Redis fits into real-world AI workloads.â€

---

## ğŸŸ© Slide 5 â€” Fast for Every AI Use Case

> â€œRedis accelerates every class of AI application.â€

**Use Cases:**
- **RAG Chatbots / AI Assistants:** Ground LLMs in proprietary data.  
- **Recommenders:** Deliver instant personalization.  
- **Fraud Detection:** Flag anomalies in milliseconds.  
- **AI Agents:** Maintain state and long-term memory.  
- **AI Gateways:** Manage cost, routing, and compliance centrally.

**Example Story:**
> â€œOne financial customer used Redis to power both fraud detection *and* RAG chat â€” one system storing transaction embeddings, the other retrieving policy documents.  
Same Redis, two worlds: prevention and intelligence.â€

**Takeaway:**
> â€œRedis is the connective tissue across every AI function.â€

**Transition:**
> â€œBut whatâ€™s the real reason Redis is critical?  
It directly solves AIâ€™s three hardest problems.â€

---

## ğŸŸ¦ Slide 6 â€” Solving Key AI Pain Points

> â€œEvery enterprise faces the same AI bottlenecks: **speed, memory, and accuracy.**â€

### Speed
> â€œLLMs take seconds to generate â€” Redis reduces that to milliseconds by caching past outputs and managing workloads.â€

### Memory
> â€œModels forget. Redis provides persistent short- and long-term memory â€” so every conversation or task is context-aware.â€

### Accuracy
> â€œLLMs donâ€™t know your private data. Redis bridges that gap with vector search and contextual retrieval.â€

**Example:**
> â€œIn healthcare, Redis stores patient summaries as embeddings.  
When a doctor asks a question, the AI retrieves those embeddings â€” ensuring accurate, safe, contextual answers.â€

**Transition:**
> â€œLetâ€™s see how Redis fits into any AI stack â€” from dev tools to production environments.â€

---

## ğŸŸ§ Slide 7 â€” Built for Any Stack

> â€œRedis is engineered to work everywhere â€” from developer laptops to global-scale deployments.â€

**Architecture Layers:**
1. **Real-time Cache Engine:** Built on Redis Open Source, providing blazing-fast queries.  
2. **Hyperscale Layer:** Multi-tenant, active-active, 99.999% availability.  
3. **Global Deployment Layer:** Hybrid and multi-cloud with full security and automation.

**Developer Integrations:**
- LangChain  
- LlamaIndex  
- LangGraph  
- Redis Insight  
- Redis Data Integration (RDI)  

**Example:**
> â€œIf your team is building in LangChain, adding Redis as the retriever and memory module takes minutes â€” and you instantly get production-grade performance.â€

**Transition:**
> â€œLetâ€™s move from architecture to patterns â€” real AI workflows Redis enables.â€

---

## ğŸ§© Slide 9â€“11 â€” Vector Database

> â€œRedis isnâ€™t just fast â€” itâ€™s one of the *most advanced vector databases* available today.â€

**Highlights:**
- 62% faster than the next best DB across benchmarks.  
- Handles >1 billion vectors.  
- Supports **text, image, and audio embeddings.**  
- Uses algorithms like **HNSW** and **Vamana** for scalable similarity search.  
- Enables **hybrid queries**: text + numeric + vector in one operation.

**Example:**
> â€œImagine searching for â€˜cybersecurity reports similar to this PDF and published after 2023.â€™  
Redis handles that with one query.â€

**Takeaway:**
> â€œRedis makes unstructured data instantly searchable â€” the foundation for RAG and contextual AI.â€

**Transition:**
> â€œLetâ€™s explore how developers build these systems in practice.â€

---

## ğŸŸ¨ Slide 12 â€” Hands-on Example #1: Vector Search

> â€œHereâ€™s a practical example using RedisVL â€” our AI-native Python library.â€

**Steps:**
1. Create embeddings.  
2. Index vectors in Redis.  
3. Filter and search with hybrid queries.  
4. Retrieve context for your LLM in milliseconds.

**Story:**
> â€œA news company stores millions of article embeddings.  
When a user asks about â€˜AI regulations,â€™ Redis retrieves the 5 most relevant articles instantly â€” the model then summarizes them.â€

**Callout:**
> â€œYou can try this today on GitHub â€” no complex setup, just Redis and Python.â€

**Transition:**
> â€œNow letâ€™s look at how Redis cuts down cost and latency even further â€” through semantic caching.â€

---

## ğŸŸ§ Slide 13 â€” Semantic Caching

> â€œSemantic caching is like an intelligent memory for your LLM â€” it remembers *similar* questions, not just identical ones.â€

**Example:**
> â€œA user asks, â€˜Can I reset my password?â€™  
Another asks, â€˜How do I change my login credentials?â€™  
Redis detects that these are semantically the same â€” and reuses the cached answer.â€

**Impact:**
- 30â€“70% reduction in LLM inference calls.  
- Sub-millisecond response for repeated queries.  
- Massive cost savings and improved UX.

**Quote:**
> â€œOne customer cut their LLM costs by 65% after deploying Redis Semantic Cache in production.â€

**Transition:**
> â€œIf we can cache answers, we can also route queries intelligently â€” thatâ€™s semantic routing.â€

---

## ğŸŸ¦ Slide 14 â€” Semantic Routing: The Instant Classifier

> â€œSemantic Routing is Redis acting as your intelligent traffic director.â€

**Functions:**
- Classify incoming queries by meaning.  
- Route to the right LLM or microservice.  
- Apply guardrails and topic segregation.

**Example:**
> â€œA banking app routes â€˜check balanceâ€™ to a local endpoint,  
â€˜investing trendsâ€™ to a public model,  
and filters out â€˜account closureâ€™ for human review.â€

**Benefit:**
> â€œThis approach improves accuracy, ensures compliance, and reduces inference cost.â€

**Transition:**
> â€œNow letâ€™s see all of these ideas â€” caching, routing, memory â€” working together in a real AI agent architecture.â€

---

## ğŸŸ¥ Slide 16 â€” Putting It All Together: AI Agent Architecture

> â€œThis is the Redis-powered AI Agent pipeline.â€

**Flow:**
1. User sends a query.  
2. Redis checks **Semantic Cache** for similar past answers.  
3. If new, Redis runs **Semantic Routing** to the right model.  
4. It performs **RAG retrieval** from the vector DB.  
5. Calls the LLM only if needed.  
6. Redis stores the new interaction for future use.

**Example:**
> â€œA fintech chatbot using Redis can close an account, check balances, and run compliance checks â€” all within one agent workflow.â€

**Takeaway:**
> â€œRedis turns AI systems into self-improving networks â€” each request makes the system faster and cheaper.â€

**Transition:**
> â€œMemory is what makes this system intelligent â€” letâ€™s explore that next.â€

---

## ğŸŸ§ Slide 18 â€” Agent Memory

> â€œLLMs are smart, but forgetful. Redis gives them memory â€” both short-term and long-term.â€

**Short-term memory:**
> â€œHolds active context â€” the last few interactions or steps.â€

**Long-term memory:**
> â€œStores summaries, entities, and topics extracted automatically.â€

**Example:**
> â€œIn a healthcare chatbot, Redis remembers your last consultation, allergies, and prescriptions.  
Next time, it skips redundant questions and gives tailored advice.â€

**Technical Note:**
> â€œThe Agent Memory Server manages namespaces, summarization, and recall.  
This means one agent can handle thousands of conversations concurrently â€” without interference.â€

**Transition:**
> â€œAnd the best part â€” all of this is open-source and ready to use.â€

---

## ğŸŸ© Slide 19 â€” Supplemental Resources

> â€œEverything Iâ€™ve shown today is available to try.â€

- **RedisVL:** The AI-native Python client for vector operations.  
- **Redis AI Resources:** Dozens of live Jupyter notebooks.  
- **Redis Retrieval Optimizer:** Helps you select embeddings and index configs for your workload.

**Call to Action:**
> â€œYou can start building an enterprise-grade RAG or AI Agent in an afternoon.â€

**Transition:**
> â€œNow, letâ€™s see how Redis fits into full ML pipelines.â€

---

## ğŸŸ¦ Slides 21â€“23 â€” ML Inference, Anomaly Detection & Evaluation

> â€œRedis extends beyond LLMs â€” it powers ML pipelines end to end.â€

### ML Inference Pipeline
> â€œLoad pre-trained models into Redis for immediate serving, use JSON search as a feature store, and stream live events â€” no external infra needed.â€

### Anomaly Detection
> â€œUse vector distances to detect outliers â€” for example, fraudulent credit card transactions or machine sensor anomalies.â€

### Evaluation
> â€œRedis helps monitor retrieval performance with precision, recall, and F1 metrics â€” critical for production AI systems.â€

**Transition:**
> â€œRedis isnâ€™t just powerful â€” itâ€™s leading the market.â€

---

## ğŸŸ¥ Slide 24 â€” Market Leadership

> â€œRedis is the #1 data platform used by AI agents today â€” with 43% of developers relying on it, ahead of GitHub MCP and Supabase.â€

**Key Stats:**
- 8% year-over-year growth.  
- Top NoSQL database for AI developers.

**Message:**
> â€œThe worldâ€™s best AI systems already trust Redis â€” because it delivers predictable speed, reliability, and intelligence.â€

**Transition:**
> â€œLetâ€™s wrap up with how Redis integrates into agent frameworks like LangGraph.â€

---

## ğŸŸ© Slides 25â€“26 â€” LangGraph & RedisVL

> â€œRedis integrates directly with LangGraph to power agent memory and retrieval.â€

**Use Cases:**
- Vector store for RAG  
- Long-term memory  
- LLM cache  
- Short-term memory  

> â€œRedisVL, our Python client, provides an ergonomic API for indexing, vector search, and semantic caching.â€

**Example:**
> â€œIf youâ€™re building a support co-pilot, Redis handles memory, embeddings, and retrieval â€” while LangGraph orchestrates the flow.â€

**Transition:**
> â€œLetâ€™s end with how this looks in real-world production.â€

---

## ğŸŸ§ Slides 27â€“28 â€” Production Deployment Examples

> â€œHereâ€™s what Redis looks like in production.â€

**Example 1:**
> â€œA production AI agent running on Redis orchestrates retrieval, classification, and response generation through a single data layer.â€

**Example 2:**
> â€œIn AWS, Redis scales across clusters, automatically manages memory, and supports full observability through CloudWatch.â€

**Key Point:**
> â€œRedis isnâ€™t just theory â€” itâ€™s powering live systems in finance, retail, healthcare, and logistics today.â€

---

## ğŸ Closing â€” The Redis Value Proposition

> â€œSo to wrap up â€” Redis is more than a database.  
Itâ€™s the *real-time intelligence layer* for AI.â€

**Summarize:**
- Speed: Sub-millisecond retrieval and caching.  
- Memory: Long-term and short-term context persistence.  
- Accuracy: Vector-based RAG retrieval and classification.  
- Scale: Proven, cloud-native, and globally available.

> â€œRedis makes your AI systems *fast, stateful, and production-ready.*â€

> â€œThank you for joining the Redis AI Workshop â€” now letâ€™s go build AI that remembers, reasons, and reacts in real time.â€

---
