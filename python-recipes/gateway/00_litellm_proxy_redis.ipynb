{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "47c3fefa",
      "metadata": {
        "id": "47c3fefa"
      },
      "source": [
        "\n",
        "<div style=\"display: flex; justify-content: space-around; align-items: center;\">\n",
        "  <img src=\"https://redis.io/wp-content/uploads/2024/04/Logotype.svg\" width=\"150\" alt=\"Redis\">\n",
        "  <img src=\"https://awsmp-logos.s3.amazonaws.com/seller-xw5kijmvmzasy/c233c9ade2ccb5491072ae232c814942.png\" width=\"200\" alt=\"LiteLLM\">\n",
        "</div>\n",
        "\n",
        "# LiteLLM Proxy with Redis\n",
        "\n",
        "This notebook demonstrates how to use [LiteLLM](https://github.com/BerriAI/litellm) with Redis to build a powerful and efficient LLM proxy server backed by caching & rate limiting capabilities. LiteLLM provides a unified interface for accessing multiple LLM providers while Redis enhances performance of the application in several different ways.\n",
        "\n",
        "*This recipe will help you understand*:\n",
        "\n",
        "* **How** to set up LiteLLM as a proxy for different LLM endpoints\n",
        "* **Why** and **how** to implement exact and semantic caching for LLM calls\n",
        "\n",
        "**Open in Colab**\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/redis-developer/redis-ai-resources/blob/main/python-recipes/gateway/00_litellm_proxy_redis.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06c7b959",
      "metadata": {
        "id": "06c7b959"
      },
      "source": [
        "\n",
        "## 1 · Environment Setup  \n",
        "Before we begin, we need to make sure our environment is properly set up with all the necessary tools and resources.\n",
        "\n",
        "**Requirements**:\n",
        "* Python ≥ 3.9 with the below packages\n",
        "* OpenAI API key (set as `OPENAI_API_KEY` environment variable)\n",
        "\n",
        "\n",
        "### Install Python Dependencies\n",
        "\n",
        "First, let's install the required packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47246c48",
      "metadata": {
        "id": "47246c48"
      },
      "outputs": [],
      "source": [
        "%pip install \"litellm[proxy]==1.68.0\" \"redisvl==0.5.2\" requests openai"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "redis-setup",
      "metadata": {
        "id": "redis-setup"
      },
      "source": [
        "### Install Redis Stack\n",
        "\n",
        "\n",
        "#### For Colab\n",
        "Use the shell script below to download, extract, and install [Redis Stack](https://redis.io/docs/getting-started/install-stack/) directly from the Redis package archive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0db80601",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0db80601",
        "outputId": "e01d1a40-f412-4808-d5f0-4d34fb2204d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb jammy main\n",
            "Starting redis-stack-server, database path /var/lib/redis-stack\n"
          ]
        }
      ],
      "source": [
        "# NBVAL_SKIP\n",
        "%%sh\n",
        "curl -fsSL https://packages.redis.io/gpg | sudo gpg --dearmor -o /usr/share/keyrings/redis-archive-keyring.gpg\n",
        "echo \"deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/redis.list\n",
        "sudo apt-get update  > /dev/null 2>&1\n",
        "sudo apt-get install redis-stack-server  > /dev/null 2>&1\n",
        "redis-stack-server --daemonize yes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b750e779",
      "metadata": {
        "id": "b750e779"
      },
      "source": [
        "#### For Alternative Environments\n",
        "There are many ways to get the necessary redis-stack instance running\n",
        "1. On cloud, deploy a [FREE instance of Redis in the cloud](https://redis.io/try-free/). Or, if you have your\n",
        "own version of Redis Enterprise running, that works too!\n",
        "2. Per OS, [see the docs](https://redis.io/docs/latest/operate/oss_and_stack/install/install-stack/)\n",
        "3. With docker: `docker run -d --name redis-stack-server -p 6379:6379 redis/redis-stack-server:latest`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "177e9fe3",
      "metadata": {
        "id": "177e9fe3"
      },
      "source": [
        "### Define the Redis Connection URL\n",
        "\n",
        "By default this notebook connects to the local instance of Redis Stack. **If you have your own Redis Enterprise instance** - replace REDIS_PASSWORD, REDIS_HOST and REDIS_PORT values with your own."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "be77a1d3",
      "metadata": {
        "id": "be77a1d3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Replace values below with your own if using Redis Cloud instance\n",
        "REDIS_HOST = os.getenv(\"REDIS_HOST\", \"localhost\") # ex: \"redis-18374.c253.us-central1-1.gce.cloud.redislabs.com\"\n",
        "REDIS_PORT = os.getenv(\"REDIS_PORT\", \"6379\")      # ex: 18374\n",
        "REDIS_PASSWORD = os.getenv(\"REDIS_PASSWORD\", \"\")  # ex: \"1TNxTEdYRDgIDKM2gDfasupCADXXXX\"\n",
        "\n",
        "# If SSL is enabled on the endpoint, use rediss:// as the URL prefix\n",
        "REDIS_URL = f\"redis://:{REDIS_PASSWORD}@{REDIS_HOST}:{REDIS_PORT}\"\n",
        "os.environ[\"REDIS_URL\"] = REDIS_URL\n",
        "os.environ[\"REDIS_HOST\"] = REDIS_HOST\n",
        "os.environ[\"REDIS_PORT\"] = REDIS_PORT\n",
        "os.environ[\"REDIS_PASSWORD\"] = REDIS_PASSWORD"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "redis-connection",
      "metadata": {
        "id": "redis-connection"
      },
      "source": [
        "### Verify Redis Connection\n",
        "\n",
        "Let's test our Redis connection to make sure it's working properly:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "id": "f3ddcabf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3ddcabf",
        "outputId": "162846c8-4add-4de7-9ed6-69e8656ec102"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 132,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from redis import Redis\n",
        "\n",
        "client = Redis.from_url(REDIS_URL)\n",
        "client.ping()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "id": "AZmD8eR1lphs",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZmD8eR1lphs",
        "outputId": "0aaf4533-d239-4ad9-8853-e7192abf78d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 133,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "client.flushall()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce052678",
      "metadata": {
        "id": "ce052678"
      },
      "source": [
        "### Set OPENAI API Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e21ac07e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e21ac07e",
        "outputId": "3a6d5465-35e0-49af-ce1a-54df86898cee"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"LITELLM_LOG\"] = \"DEBUG\"\n",
        "\n",
        "def _set_env(key: str):\n",
        "    if key not in os.environ:\n",
        "        os.environ[key] = getpass.getpass(f\"{key}:\")\n",
        "\n",
        "_set_env(\"OPENAI_API_KEY\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5X9nFyFkPdkV",
      "metadata": {
        "id": "5X9nFyFkPdkV"
      },
      "source": [
        "## 2 · Running the LiteLLM Proxy\n",
        "First, we will define a LiteLLM config that contains:\n",
        "\n",
        "- a few supported model options\n",
        "- a semantic caching configuration using Redis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 234,
      "id": "pdeAixSUPxT7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdeAixSUPxT7",
        "outputId": "9cbff8c0-7fc8-431a-e93c-ba05698d217e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting litellm_redis.yml\n"
          ]
        }
      ],
      "source": [
        "%%writefile litellm_redis.yml\n",
        "model_list:\n",
        "- litellm_params:\n",
        "    api_key: os.environ/OPENAI_API_KEY\n",
        "    model: gpt-3.5-turbo\n",
        "    rpm: 30\n",
        "  model_name: gpt-3.5-turbo\n",
        "- litellm_params:\n",
        "    api_key: os.environ/OPENAI_API_KEY\n",
        "    model: gpt-4o-mini\n",
        "    rpm: 30\n",
        "  model_name: gpt-4o-mini\n",
        "- litellm_params:\n",
        "    api_key: os.environ/OPENAI_API_KEY\n",
        "    model: text-embedding-3-small\n",
        "  model_name: text-embedding-3-small\n",
        "\n",
        "litellm_settings:\n",
        "  cache: True\n",
        "  cache_params:\n",
        "    type: redis\n",
        "    host: os.environ/REDIS_HOST\n",
        "    port: os.environ/REDIS_PORT\n",
        "    password: os.environ/REDIS_PASSWORD\n",
        "    default_in_redis_ttl: 60"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4RqOqBoAHwVD",
      "metadata": {
        "id": "4RqOqBoAHwVD"
      },
      "source": [
        "Now for some helper code that will start/stop **LiteLLM** proxy as a background task here on the host machine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "id": "8mml7LhvPxWU",
      "metadata": {
        "id": "8mml7LhvPxWU"
      },
      "outputs": [],
      "source": [
        "import subprocess, atexit, os, signal, socket, time, pathlib, textwrap, sys\n",
        "\n",
        "\n",
        "_proxy_handle: subprocess.Popen | None = None\n",
        "\n",
        "\n",
        "def _is_port_open(port: int) -> bool:\n",
        "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
        "        s.settimeout(0.25)\n",
        "        return s.connect_ex((\"127.0.0.1\", port)) == 0\n",
        "\n",
        "def start_proxy(\n",
        "    config_path: str = \"litellm_redis.yml\",\n",
        "    port: int = 4000,\n",
        "    log_path: str = \"litellm_proxy.log\",\n",
        "    restart: bool = True,\n",
        "    timeout: float = 10.0,          # seconds we’re willing to wait\n",
        ") -> subprocess.Popen:\n",
        "\n",
        "    global _proxy_handle\n",
        "\n",
        "    # ── 1. stop running proxy we launched earlier ──\n",
        "    if _proxy_handle and _proxy_handle.poll() is None:\n",
        "        if restart:\n",
        "            _proxy_handle.terminate()\n",
        "            _proxy_handle.wait(timeout=3)\n",
        "            time.sleep(1)          # give the OS a breath\n",
        "        else:\n",
        "            print(f\"LiteLLM already running (PID {_proxy_handle.pid}) — reusing.\")\n",
        "            return _proxy_handle\n",
        "\n",
        "    # ── 2. ensure the port is free ──\n",
        "    if _is_port_open(port):\n",
        "        print(f\"Port {port} busy; trying to free it …\")\n",
        "        pids = os.popen(f\"lsof -ti tcp:{port}\").read().strip().splitlines()\n",
        "        for pid in pids:\n",
        "            try:\n",
        "                os.kill(int(pid), signal.SIGTERM)\n",
        "            except Exception:\n",
        "                pass\n",
        "        time.sleep(1)\n",
        "\n",
        "    # ── 3. launch proxy ──\n",
        "    log_file = open(log_path, \"w\")\n",
        "    cmd = [\"litellm\", \"--config\", config_path, \"--port\", str(port), \"--detailed_debug\"]\n",
        "    _proxy_handle = subprocess.Popen(cmd, stdout=log_file, stderr=subprocess.STDOUT)\n",
        "\n",
        "    atexit.register(lambda: _proxy_handle and _proxy_handle.terminate())\n",
        "\n",
        "    # ── 4. readiness loop with timeout & crash detection ──\n",
        "    deadline = time.time() + timeout\n",
        "    while time.time() < deadline:\n",
        "        if _is_port_open(port):\n",
        "            break\n",
        "        if _proxy_handle.poll() is not None:             # died early\n",
        "            last_lines = pathlib.Path(log_path).read_text().splitlines()[-20:]\n",
        "            raise RuntimeError(\n",
        "                \"LiteLLM exited before opening the port:\\n\" +\n",
        "                textwrap.indent(\"\\n\".join(last_lines), \"  \")\n",
        "            )\n",
        "        time.sleep(0.25)\n",
        "    else:\n",
        "        _proxy_handle.terminate()\n",
        "        raise RuntimeError(f\"LiteLLM proxy did not open port {port} within {timeout}s.\")\n",
        "\n",
        "    print(f\"✅ LiteLLM proxy on http://localhost:{port} (PID {_proxy_handle.pid})\")\n",
        "    print(f\"   Logs → {pathlib.Path(log_path).resolve()}\")\n",
        "    return _proxy_handle\n",
        "\n",
        "\n",
        "def stop_proxy() -> None:\n",
        "    global _proxy_handle\n",
        "    if _proxy_handle and _proxy_handle.poll() is None:\n",
        "        _proxy_handle.terminate()\n",
        "        _proxy_handle.wait(timeout=3)\n",
        "        print(\"LiteLLM proxy stopped.\")\n",
        "    _proxy_handle = None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8WSEon9JIRn8",
      "metadata": {
        "id": "8WSEon9JIRn8"
      },
      "source": [
        "Start up the LiteLLM proxy for the first time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "id": "jrw2Gu6uPxYr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrw2Gu6uPxYr",
        "outputId": "ae65f321-1d4e-49fe-9282-d418f324a5cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ LiteLLM proxy on http://localhost:4000 (PID 63464)\n",
            "   Logs → /content/litellm_proxy.log\n"
          ]
        }
      ],
      "source": [
        "_proxy_handle = start_proxy()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zzOSmL0_IzwF",
      "metadata": {
        "id": "zzOSmL0_IzwF"
      },
      "source": [
        "Now we will add a simple helper method to test out models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "id": "9rbN7PiMVAmA",
      "metadata": {
        "id": "9rbN7PiMVAmA"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "\n",
        "def call_model(text: str, model: str = \"gpt-4o-mini\"):\n",
        "  try:\n",
        "      t0 = time.time()\n",
        "      payload = {\n",
        "          \"model\": model,\n",
        "          \"messages\": [{\"role\": \"user\", \"content\": text}]\n",
        "      }\n",
        "      r = requests.post(\"http://localhost:4000/chat/completions\", json=payload, timeout=30)\n",
        "      r.raise_for_status()\n",
        "      print(r.json()[\"choices\"][0][\"message\"][\"content\"])\n",
        "      print(f\"{r.json()['id']} -- {r.json()['model']} -- latency: {time.time() - t0:.2f}s \\n\")\n",
        "      return r\n",
        "  except Exception as e:\n",
        "    print(str(e))\n",
        "    if \"error\" in r.json():\n",
        "      print(r.json()[\"error\"][\"message\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "id": "KEdfst47VdjN",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEdfst47VdjN",
        "outputId": "0898a5da-b907-4231-c171-ddf6a1043911"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello! I'm just a program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\n",
            "chatcmpl-BUdDxEetmH0k6yJkaDLeSshRZmGnz -- gpt-4o-mini-2024-07-18 -- latency: 0.90s \n",
            "\n"
          ]
        }
      ],
      "source": [
        "res = call_model(\"hello, how are you?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 239,
      "id": "XJnkyMUDI9xu",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJnkyMUDI9xu",
        "outputId": "bebbc826-60e8-4de9-8ddf-425d7c087cfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello! I'm just a computer program, so I don't have feelings, but I'm here to assist you. How can I help you today?\n",
            "chatcmpl-BUdDySZjzxB8tCTLkuYDTyPFfKo1P -- gpt-3.5-turbo-0125 -- latency: 0.65s \n",
            "\n"
          ]
        }
      ],
      "source": [
        "res = call_model(\"hello, how are you?\", model=\"gpt-3.5-turbo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "id": "79nkkD6cVii2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79nkkD6cVii2",
        "outputId": "c4ee9d21-3a81-4453-e412-2bd17d4a4372"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "400 Client Error: Bad Request for url: http://localhost:4000/chat/completions\n",
            "{'error': '/chat/completions: Invalid model name passed in model=claude. Call `/v1/models` to view available models for your key.'}\n"
          ]
        }
      ],
      "source": [
        "# Try a non-supported model!\n",
        "res = call_model(\"hello, how are you?\", model=\"claude\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc65bfdd",
      "metadata": {
        "id": "fc65bfdd"
      },
      "source": [
        "## 3 · Implement LLM caching with Redis\n",
        "\n",
        "LiteLLM Proxy with Redis provides two powerful caching capabilities that can significantly improve your LLM application performance and reliability:\n",
        "\n",
        "* **Exact cache (identical prompt)**: Pulls exact prompt/query matches from Redis with configurable TTL.\n",
        "* **Semantic cache (similar prompt)**: Uses Redis as a semantic cache powered by **vector search** to determine if a prompt/query is similar enough to a cached entry.\n",
        "\n",
        "### Why Use Caching for LLMs?\n",
        "\n",
        "1. **Cost Reduction**: Avoid redundant API calls for identical or similar prompts\n",
        "2. **Latency Improvement**: Cached responses return in milliseconds vs. seconds\n",
        "3. **Reliability**: Reduce dependency on external API availability\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 241,
      "id": "eup_Z0Z_Y493",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eup_Z0Z_Y493",
        "outputId": "d815413e-acc0-4108-8b47-87dfb35cd59f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The capital of France is Paris.\n",
            "chatcmpl-BUdDz7ZsNbR2PTGbnzgALezkkVvh8 -- gpt-4o-mini-2024-07-18 -- latency: 0.63s \n",
            "\n",
            "The capital of France is Paris.\n",
            "chatcmpl-BUdDz7ZsNbR2PTGbnzgALezkkVvh8 -- gpt-4o-mini-2024-07-18 -- latency: 0.02s \n",
            "\n",
            "The capital of France is Paris.\n",
            "chatcmpl-BUdDz7ZsNbR2PTGbnzgALezkkVvh8 -- gpt-4o-mini-2024-07-18 -- latency: 0.02s \n",
            "\n",
            "The capital of France is Paris.\n",
            "chatcmpl-BUdDz7ZsNbR2PTGbnzgALezkkVvh8 -- gpt-4o-mini-2024-07-18 -- latency: 0.02s \n",
            "\n",
            "The capital of France is Paris.\n",
            "chatcmpl-BUdDz7ZsNbR2PTGbnzgALezkkVvh8 -- gpt-4o-mini-2024-07-18 -- latency: 0.02s \n",
            "\n",
            "The capital of France is Paris.\n",
            "chatcmpl-BUdDz7ZsNbR2PTGbnzgALezkkVvh8 -- gpt-4o-mini-2024-07-18 -- latency: 0.03s \n",
            "\n",
            "The capital of France is Paris.\n",
            "chatcmpl-BUdDz7ZsNbR2PTGbnzgALezkkVvh8 -- gpt-4o-mini-2024-07-18 -- latency: 0.02s \n",
            "\n",
            "The capital of France is Paris.\n",
            "chatcmpl-BUdDz7ZsNbR2PTGbnzgALezkkVvh8 -- gpt-4o-mini-2024-07-18 -- latency: 0.02s \n",
            "\n",
            "18.6 ms ± 3.59 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "res = call_model(\"what is the capital of france?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GQRkOghoB9-Y",
      "metadata": {
        "id": "GQRkOghoB9-Y"
      },
      "source": [
        "Check response equivalence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 242,
      "id": "IbfUylGGUhP7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbfUylGGUhP7",
        "outputId": "e56853a1-61b0-4916-fb2b-c1695d922e8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The capital of France is Paris.\n",
            "chatcmpl-BUdDz7ZsNbR2PTGbnzgALezkkVvh8 -- gpt-4o-mini-2024-07-18 -- latency: 0.02s \n",
            "\n",
            "The capital of France is Paris.\n",
            "chatcmpl-BUdDz7ZsNbR2PTGbnzgALezkkVvh8 -- gpt-4o-mini-2024-07-18 -- latency: 0.02s \n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'id': 'chatcmpl-BUdDz7ZsNbR2PTGbnzgALezkkVvh8',\n",
              " 'created': 1746640319,\n",
              " 'model': 'gpt-4o-mini-2024-07-18',\n",
              " 'object': 'chat.completion',\n",
              " 'system_fingerprint': 'fp_129a36352a',\n",
              " 'choices': [{'finish_reason': 'stop',\n",
              "   'index': 0,\n",
              "   'message': {'content': 'The capital of France is Paris.',\n",
              "    'role': 'assistant',\n",
              "    'tool_calls': None,\n",
              "    'function_call': None,\n",
              "    'annotations': []}}],\n",
              " 'usage': {'completion_tokens': 8,\n",
              "  'prompt_tokens': 14,\n",
              "  'total_tokens': 22,\n",
              "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
              "   'audio_tokens': 0,\n",
              "   'reasoning_tokens': 0,\n",
              "   'rejected_prediction_tokens': 0},\n",
              "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
              " 'service_tier': 'default'}"
            ]
          },
          "execution_count": 242,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "res1 = call_model(\"what is the capital of france?\")\n",
        "res2 = call_model(\"what is the capital of france?\")\n",
        "\n",
        "assert res1.json() == res2.json()\n",
        "\n",
        "res1.json()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e121e215",
      "metadata": {
        "id": "e121e215"
      },
      "source": [
        "## 4 · Semantic caching\n",
        "\n",
        "Now we'll demonstrate semantic caching by sending similar prompts back to back. The first request should hit the LLM API, while future requests should be served from cache as long as they are similar enough. We'll see this reflected in the response times.\n",
        "\n",
        "First, we need to stop the running proxy and update the LiteLLM config."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 243,
      "id": "iX5F90uWCpuY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iX5F90uWCpuY",
        "outputId": "6ba29c04-a9f1-48f0-ae59-8fd059419fa7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-15"
            ]
          },
          "execution_count": 243,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Stop the proxy process\n",
        "_proxy_handle.terminate()\n",
        "_proxy_handle.wait(timeout=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "id": "MpcYlHdSCvQE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpcYlHdSCvQE",
        "outputId": "666254d5-4d3e-4af2-e003-60a0c70ae29c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting litellm_redis.yml\n"
          ]
        }
      ],
      "source": [
        "%%writefile litellm_redis.yml\n",
        "model_list:\n",
        "- litellm_params:\n",
        "    api_key: os.environ/OPENAI_API_KEY\n",
        "    model: gpt-3.5-turbo\n",
        "    rpm: 30\n",
        "  model_name: gpt-3.5-turbo\n",
        "- litellm_params:\n",
        "    api_key: os.environ/OPENAI_API_KEY\n",
        "    model: gpt-4o-mini\n",
        "    rpm: 30\n",
        "  model_name: gpt-4o-mini\n",
        "- litellm_params:\n",
        "    api_key: os.environ/OPENAI_API_KEY\n",
        "    model: text-embedding-3-small\n",
        "  model_name: text-embedding-3-small\n",
        "\n",
        "litellm_settings:\n",
        "  cache: True\n",
        "  set_verbose: True\n",
        "  cache_params:\n",
        "    type: redis-semantic\n",
        "    host: os.environ/REDIS_HOST\n",
        "    port: os.environ/REDIS_PORT\n",
        "    password: os.environ/REDIS_PASSWORD\n",
        "    ttl: 60\n",
        "    similarity_threshold: 0.90\n",
        "    redis_semantic_cache_embedding_model: text-embedding-3-small\n",
        "    redis_semantic_cache_index_name: llmcache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 245,
      "id": "9Ak-jWcXC6dq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ak-jWcXC6dq",
        "outputId": "eec709e6-075a-4c23-b6d4-c2ed59a4fd02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ LiteLLM proxy on http://localhost:4000 (PID 63528)\n",
            "   Logs → /content/litellm_proxy.log\n"
          ]
        }
      ],
      "source": [
        "_proxy_handle = start_proxy()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4sf49YkOnhww",
      "metadata": {
        "id": "4sf49YkOnhww"
      },
      "source": [
        "Semantic cache can handle exact match scenarios (where the characters/tokens are identical). This would happen more in a development environment or in cases where a programmatic user is providing input to an LLM call."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 246,
      "id": "c08699fc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c08699fc",
        "outputId": "1ef29ae8-6fd6-4cff-909f-0da1874dbe60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The capital city of the United States is Washington, D.C.\n",
            "chatcmpl-BUdE8A9yQyijCBN4Agg5QJxsrifUJ -- gpt-4o-mini-2024-07-18 -- latency: 1.35s \n",
            "\n",
            "The capital city of the United States is Washington, D.C.\n",
            "chatcmpl-BUdE8A9yQyijCBN4Agg5QJxsrifUJ -- gpt-4o-mini-2024-07-18 -- latency: 0.37s \n",
            "\n",
            "The capital city of the United States is Washington, D.C.\n",
            "chatcmpl-BUdE8A9yQyijCBN4Agg5QJxsrifUJ -- gpt-4o-mini-2024-07-18 -- latency: 0.53s \n",
            "\n",
            "The capital city of the United States is Washington, D.C.\n",
            "chatcmpl-BUdE8A9yQyijCBN4Agg5QJxsrifUJ -- gpt-4o-mini-2024-07-18 -- latency: 0.47s \n",
            "\n",
            "The capital city of the United States is Washington, D.C.\n",
            "chatcmpl-BUdE8A9yQyijCBN4Agg5QJxsrifUJ -- gpt-4o-mini-2024-07-18 -- latency: 0.36s \n",
            "\n",
            "The capital city of the United States is Washington, D.C.\n",
            "chatcmpl-BUdE8A9yQyijCBN4Agg5QJxsrifUJ -- gpt-4o-mini-2024-07-18 -- latency: 0.24s \n",
            "\n",
            "The capital city of the United States is Washington, D.C.\n",
            "chatcmpl-BUdE8A9yQyijCBN4Agg5QJxsrifUJ -- gpt-4o-mini-2024-07-18 -- latency: 0.39s \n",
            "\n",
            "The capital city of the United States is Washington, D.C.\n",
            "chatcmpl-BUdE8A9yQyijCBN4Agg5QJxsrifUJ -- gpt-4o-mini-2024-07-18 -- latency: 0.28s \n",
            "\n",
            "379 ms ± 94.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "\n",
        "call_model(\"what is the capital city of the United States?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mQTzCNvCFHRJ",
      "metadata": {
        "id": "mQTzCNvCFHRJ"
      },
      "source": [
        "Additional (or variable) latency here per check is due to using OpenAI embeddings which makes calls over the network. A more optimized solution would be to use a more scalable embedding inference system OR a localized model that doesn't require a network hop.\n",
        "\n",
        "The semantic cache can also be used for near exact matches (fuzzy caching) based on semantic meaning. Below are a few scenarios:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "id": "v5lkpxafr7ot",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5lkpxafr7ot",
        "outputId": "c00f3c88-e72d-4195-fd64-84bccf2ae185"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "As of my last update in October 2023, the President of France is Emmanuel Macron. He has been in office since May 14, 2017. However, please verify with a current source, as political positions can change.\n",
            "chatcmpl-BUdHNxLLb7HBmnTUUHRQpxWBVhGAI -- gpt-4o-mini-2024-07-18 -- latency: 2.37s \n",
            "\n",
            "As of my last knowledge update in October 2023, the President of France is Emmanuel Macron. He has been in office since May 14, 2017, and was re-elected for a second term in April 2022. Please verify with up-to-date sources, as political situations can change.\n",
            "chatcmpl-BUdHOz7UCsO4KKKcDfx8ZGv2LJ6dZ -- gpt-4o-mini-2024-07-18 -- latency: 1.38s \n",
            "\n",
            "As of my last update in October 2023, the President of France is Emmanuel Macron. He has been in office since May 14, 2017. However, please verify with a current source, as political positions can change.\n",
            "chatcmpl-BUdHNxLLb7HBmnTUUHRQpxWBVhGAI -- gpt-4o-mini-2024-07-18 -- latency: 0.65s \n",
            "\n",
            "As of my last update in October 2023, the President of France is Emmanuel Macron. He has been in office since May 14, 2017. However, please verify with a current source, as political positions can change.\n",
            "chatcmpl-BUdHNxLLb7HBmnTUUHRQpxWBVhGAI -- gpt-4o-mini-2024-07-18 -- latency: 0.60s \n",
            "\n"
          ]
        }
      ],
      "source": [
        "texts = [\n",
        "    \"who is the president of France?\",\n",
        "    \"who is the country president of France?\",\n",
        "    \"who is France's current presidet?\",\n",
        "    \"The current president of France is?\"\n",
        "]\n",
        "\n",
        "for text in texts:\n",
        "  res = call_model(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-akCGqYkqGVs",
      "metadata": {
        "id": "-akCGqYkqGVs"
      },
      "source": [
        "## 5 · Inspect Redis Index with RedisVL\n",
        "Use the `redisvl` helpers and CLI to investigate more about the underlying vector index that supports the checks within the LiteLLM proxy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 248,
      "id": "RntBqIlipyHA",
      "metadata": {
        "id": "RntBqIlipyHA"
      },
      "outputs": [],
      "source": [
        "from redisvl.index import SearchIndex\n",
        "\n",
        "idx = SearchIndex.from_existing(redis_client=client, name=\"llmcache\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 249,
      "id": "tHVIHkXCqU7V",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHVIHkXCqU7V",
        "outputId": "f68ad535-0f9d-4467-e0c7-bbf9ca271915"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 249,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "idx.exists()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 250,
      "id": "8mNvmr7op-B-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mNvmr7op-B-",
        "outputId": "ea0535f7-e6fa-490e-8a8d-288572d7170d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m17:52:13\u001b[0m \u001b[34m[RedisVL]\u001b[0m \u001b[1;30mINFO\u001b[0m   Using Redis address from environment variable, REDIS_URL\n",
            "\n",
            "\n",
            "Index Information:\n",
            "╭──────────────┬────────────────┬──────────────┬─────────────────┬────────────╮\n",
            "│ Index Name   │ Storage Type   │ Prefixes     │ Index Options   │   Indexing │\n",
            "├──────────────┼────────────────┼──────────────┼─────────────────┼────────────┤\n",
            "│ llmcache     │ HASH           │ ['llmcache'] │ []              │          0 │\n",
            "╰──────────────┴────────────────┴──────────────┴─────────────────┴────────────╯\n",
            "Index Fields:\n",
            "╭───────────────┬───────────────┬─────────┬────────────────┬────────────────┬────────────────┬────────────────┬────────────────┬────────────────┬─────────────────┬────────────────╮\n",
            "│ Name          │ Attribute     │ Type    │ Field Option   │ Option Value   │ Field Option   │ Option Value   │ Field Option   │   Option Value │ Field Option    │ Option Value   │\n",
            "├───────────────┼───────────────┼─────────┼────────────────┼────────────────┼────────────────┼────────────────┼────────────────┼────────────────┼─────────────────┼────────────────┤\n",
            "│ prompt        │ prompt        │ TEXT    │ WEIGHT         │ 1              │                │                │                │                │                 │                │\n",
            "│ response      │ response      │ TEXT    │ WEIGHT         │ 1              │                │                │                │                │                 │                │\n",
            "│ inserted_at   │ inserted_at   │ NUMERIC │                │                │                │                │                │                │                 │                │\n",
            "│ updated_at    │ updated_at    │ NUMERIC │                │                │                │                │                │                │                 │                │\n",
            "│ prompt_vector │ prompt_vector │ VECTOR  │ algorithm      │ FLAT           │ data_type      │ FLOAT32        │ dim            │           1536 │ distance_metric │ COSINE         │\n",
            "╰───────────────┴───────────────┴─────────┴────────────────┴────────────────┴────────────────┴────────────────┴────────────────┴────────────────┴─────────────────┴────────────────╯\n"
          ]
        }
      ],
      "source": [
        "!rvl index info -i llmcache"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00bd3fc6",
      "metadata": {
        "id": "00bd3fc6"
      },
      "source": [
        "### Examining the Cached Keys in Redis\n",
        "\n",
        "Let's look at the keys created in Redis for the cache and understand how LiteLLM structures them:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 251,
      "id": "46eb6aa5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46eb6aa5",
        "outputId": "bfae071a-b8c4-44bd-8672-0bbddc170027"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1 cache keys in Redis\n",
            "\n",
            "Example cache key: llmcache:e4e4faaeea347b9876d03c4f68b7d981234a3a7a4281590ab4bc0e70dbdaef9e\n",
            "TTL: 55 seconds remaining...\n",
            "{'response': '{\\'timestamp\\': 1746640328.978919, \\'response\\': \\'{\"id\":\"chatcmpl-BUdE8A9yQyijCBN4Agg5QJxsrifUJ\",\"created\":1746640328,\"model\":\"gpt-4o-mini-2024-07-18\",\"object\":\"chat.completion\",\"system_fingerprint\":\"fp_dbaca60df0\",\"choices\":[{\"finish_reason\":\"stop\",\"index\":0,\"message\":{\"content\":\"The capital city of the United States is Washington, D.C.\",\"role\":\"assistant\",\"tool_calls\":null,\"function_call\":null,\"annotations\":[]}}],\"usage\":{\"completion_tokens\":14,\"prompt_tokens\":17,\"total_tokens\":31,\"completion_tokens_details\":{\"accepted_prediction_tokens\":0,\"audio_tokens\":0,\"reasoning_tokens\":0,\"rejected_prediction_tokens\":0},\"prompt_tokens_details\":{\"audio_tokens\":0,\"cached_tokens\":0}},\"service_tier\":\"default\"}\\'}', 'prompt_vector': b'\\xccY/=\\xbf0\\x00\\xbdd\\x0f\\xa2=X\\xa5\\xc8=\\x1f\\t-\\xbc\\\\\\x1d\\x1b\\xbc^\\xda\\xdb\\xbc\\x02\\xfc<<t\\xb4\\x80;CI\\x1b\\xbc{(C\\xbc\\xa5^\\xe2<\\xdb?R\\xbdF\\xc5\\x17<\\r\\xa9\\xa2<\\xa4\\xe0\\x83\\xbcC\\xc9\\xc1\\xbc\\xa3!\\xc8;(\\xb8\\'=9\\xdb\\x97\\xbd\\x04\\xb7\\xe8\\xbb\\xd9\\x028\\xbc\\xc2*[\\xbc_\\x99\\x97<\\x05v\\xf1<\\r\\xa9\"=\\x0e\\xa7Z\\xbd\\x8a\\x0c\\xd1\\xbb\\xfe\\x81\\xd5\\xbc\\x96\\xf8\\x18=/\\xacC<\\x9d+\\x97\\xbc\\xe3\\xb1\\xb2\\xbc\\x0ef\\x16<\\x8d\\xc7|<\\x85\\x16\\xa0\\xba\\xf7\\xce0\\xbd\\x01~+\\xbd\\x0b\\xec\\xae;<\\xd5%<\\xc5\\xe5\\xb9<\\x15\\x9b)\\xbdp\\xfb\\xb6<F\\x84\\xed;7\\x1e$\\xbd\\xba\\xb8z;\\xa1%%\\xbdGC\\xa9\\xbc\\xde\\xb9\\xb9\\xbc\\xbe2\\xe2<\\xa9\\x17,\\xbc\\xc5&\\xb1<\\x04\\xf8\\x92<\\x9cn\\xa3<\\x06\\xf45\\xbc\\xa6\\x9b\\xfc\\xbco\\xbc\\x87<\\x7fa\\xb3:\\xc4gu=\\xf9\\xca\\x86<\\x1fH\\x0f=+s\\x86<Xd\\xd1;L\\xb93=#\\x01&<\\x8d\\x08t<+s\\x06=S\\xeeF=\\x9f)\\x02<\\xb9:\\xe99\\xf4\\x13\\x05;hH_=suk<\\xa0f\\x9c\\xbbA\\x8c\\xf4;yk\\x02=\\x0e\\xa7\\xda\\xbcL\\xfa*\\xbd\\x02|\\x96\\xbb\\x98\\xb5\\x8c\\xbcqy\\xc8\\xbc\\xd3\\xcd\\xa4\\xbc-\\xf1\\x97\\xbc\\xdc\\xbd\\xe3\\xbc$\\xc0\\xfb\\xbb\\xda\\x00\\xa3;\\xca\\xdd\\x7f=\\xead\\n;\\xf3T\\xc9<<\\xd5\\xf2\\xbc\\xd5\\n\\xbf\\xb9\\t\\xaf\\xe1;\\x15\\x1b\\x83\\xbbeN\\x84\\xbc\\xd7\\x06\\x15\\xbc\\xe4/D=\\x94\\xfc\\xc2<\\x14\\x9bv\\xbc\\xd1\\xd1N;DGS;\\x039W<\\x0b\\xec{\\xbc!\\x85)\\xbd\\x8eG\\x89<\\x02\\xbbE\\xbc}$f\\xbc\\xbb8\\x87\\xbc+s\\x86<%>@\\xbc\\xe8h\\xb4<\\xaf\\x8bn\\xbc\\x91Ad\\xbcP\\xf2\\xf0;}$\\xe6\\xbc\\xf2V\\x11\\xbdk\\x03>\\xbc\\xe6l\\x91\\xbd\\xaf\\xcc\\xe5\\xbc\\xaa\\x15\\x17<\\x90\\xc3\\x05\\xbc\\xb4\\x83\\xe7\\xb9\\t\\xaf\\x14=\\xe9\\'=\\xbc\\xc8\\xe1\\x0f<\\xf6P\\x1f\\xbb^\\xda\\x0e\\xbd\\x8c\\x8a\\xe2\\xb9\\xfb\\x07n;\\x7f\\xe1\\x8c\\xbcts\\x89=\\x95zT\\xbb&<\\xab\\xbb\\xe6l\\x11=h\\x89\\xd6\\xbc\\x9b\\xaf\\x9a<u\\xb2\\xb8<\\xf5\\x91\\xe3\\xbc\\xf8\\xcc\\x9b<\\xf2V\\x11\\xbd\\x18\\x15\\xde<~\"\\x04=\\x1eJq\\xbb\\xd6G\\x0c=\\\\^\\x12=\\x84W\\x97\\xbblB \\xbd\\x88\\x10\\xae;8]\\x86=\\xe3\\xb1\\xff\\xbc\\x95z\\xd4\\xbc\\xa8\\xd8\\xc9<\\x14\\x9b\\xf6<I?\\xcc;e\\xce\\xaa<,2\\x8f\\xbcVh{\\xbd\\xd4K\\xb6<\\xf6\\x0f\\xa8\\xbcV\\xe8\\x07\\xbd\\xae\\r]=\\xf3\\x15\\x9a\\xbc}\\xe3\\xee<\\x88\\x90\\x07\\xbc\\xde\\xfa0\\xbc\\xfb\\x07!\\xbcQp\\xb5<^\\xda\\x0e\\xbd\\xf7\\x8d9\\xbd\\xc5\\xe5\\xb9\\xbc\\x9a\\xf0^\\xbdE\\x06\\\\\\xbd,\\xf1\\xe4\\xbc\\xcdW\\xe7<\\xf8\\r\\x13\\xbcH\\x00\\x9d<\\xa8\\xd8\\xc9\\xbc\\x9d\\xab\\xbd\\xbc\\x12\\xe0J=i\\x07\\xe8<^\\xda[;\\xb3\\xc4\\xde;A\\xcdk\\xbd\\xee^\\x18<\\x8f\\x04J\\xbd0\\xeb%=e\\xce\\xf7<\\x8c\\x8a\\x95<\\x8d\\x08t\\xba=\\x94{\\xbc\\x07rG\\xbc\\x8cI\\x9e<\\xa6\\x9b|\\xba&\\xbcQ<\\xb0\\x8b\\xa1\\xbc\\x8f\\xc5\\x1a<\\xca]\\x0c<\\xf1X&<X\\xe4*\\xbd\\x01\\xbd\\r=\\xa3\\xa1\\xa1;\\xb3\\xc4\\xde\\xbcsu\\xeb<\\x03\\xfa\\'\\xbc\\xd0\\x92\\x1f<\\xcdW\\xe7\\xbc0\\xaa\\xae<I\\xbf\\xa5\\xbcv\\xf1\\x1a<\\xea\\xa5N\\xbb\\xc2k\\x05\\xbd\\xd9\\x02\\xb8\\xbc\\xc1\\xac\\xc9<\"\\xc4\\x8b\\xbd\\xc7\\xa2\\xad=\\x1f\\xc8\\xb5<\\x04\\xf8\\xdf<\\xea\\xa5\\x01\\xbd\\xb6@\\x0e=+s\\x06=)8\\x01=\\x8c\\x8ab<)8\\x01=\\xb5\\x01,=b\\xd2\\xd4;}$\\x99\\xbc\\x8f\\x84#=\\xb8\\xbcW<\\xd6\\x08\\xaa<\\x90\\xc3\\x05\\xbd{(\\xc3<Vh\\xfb<W\\xe6\\xbf\\xbc\\x1a\\x91\\x8d<\\xb3\\x05V<B\\x0c\\x81\\xbd]\\x1bS\\xbcgJ\\'<\\xd3\\x8cz\\xbc\\x82\\xdb\\xe7\\xbcd\\x0f\\xef<\\xd8\\x84\\xf3\\xbc\\xf7\\xce0\\xbb/\\xacC=\\xf0\\x99\\xea<B\\xcb\\t\\xbc\\xe23\\xa1;\\xdc\\xbd\\x96<J|\\xe6<GC\\xa9;\\xe4\\xf0\\x94=\\xf4\\x13\\xd2\\xbc\\xd1\\xd1\\xce\\xbc\\xf3TI<p\\xfb6<\\x8d\\xc7|\\xbcU\\xa9\\xf2<H\\x80C<E\\x06\\x0f=H\\xc1:=\\x17V\\x08<!\\xc6 \\xbdS-\\xa9\\xbc\\x0e\\xa7Z<\\xdc|\\xec\\xbc\\xf3TI\\xbdOt\\x128\\x039W:]\\xdc\\xa3\\xbct4\\xa7\\xbb\\nn\\x9d\\xbczi\\xba\\xbc..2=\\xc0o/\\xbdA\\x8ct\\xbc FG\\xbc5\\xe1\\xd6;|\\xa6\\x07\\xbd\\xe0\\xf6S;y\\xaa\\xfe:\\x12\\xe0J=\\xfeB&:\\x82\\x1c\\x12=\\\\^\\x12=\\x17\\xd6\\xae<&\\xbcQ\\xbdOt\\xdf<\\xc6cK;\\xc6$\\x9c<\\xb9{\\x13\\xbd/\\xacC\\xbcr8\\x04<\\x10\\xa30<\\x91\\x00\\xed\\xbc\\xf3\\x95@<\\xacR1=\\xcdW\\xe7<\\xb8\\xbc\\n\\xbd\\xe3p\\xbb\\xbc\\xc1\\xac\\xc9:h\\x89\\xd6\\xbb\\xbc\\xf5G\\xbc$@\\x08<l\\xc2\\xc6\\xbb\\xf1X\\xf3\\xbba\\x95\\xba;\\xdb?\\x85=\\x17\\x97\\xcc\\xbc\\x05v$=\\xe5n\\xa6<\\xaa\\xd4l<\\xd8\\xc5\\x9d\\xbd\\x08\\xf0X\\xbc\\x06\\xb5\\x06=G\\xc3\\x02\\xbd\\x91\\x00\\xa0\\xbb\\xe0\\xf6\\x06\\xbck\\x83\\x17\\xbde\\xcew\\xba\\xe3\\xb1\\xff\\xba\\xb7\\xbe\\x1f=\\xf6\\x0f(\\xbb\\xa4\\x9fY<\\x97\\xb7\\xa1<\\x15\\x1b\\x03\\xbdI\\xbf\\xa5\\xbcVh.=\\xb3\\x05\\xd6<.o)=g\\xca\\x00\\xbd<\\xd5%\\xbd\\x03zN:i\\x07\\x1b\\xbc?\\x90\\xd1\\xbc9[>\\xbb\\xfe\\x01/=\\xba\\xf9$\\xbdSn\\xa0\\xbb\\xad\\x8f\\xcb\\xb9\\xa7Z89\\xbds\\x0c<\\xa6\\xdcs<\\xf4\\x93+=v0\\xca\\xbb[\\xe0\\x00<\\xbf\\xb0s\\xbc1\\xa8\\xe6;\\xda\\x80\\xc9<q\\xf9\\xa1;\\x91A\\x97\\xbb\\xe6+\\x1a\\xbd\\xcf\\x944\\xbdE\\xc5\\xe4<BK}\\xbb\\xb2FM<]\\xdc#\\xbcx,m=\\x04\\xf8\\xdf;BK0\\xbd\\xbe\\xf1\\xea\\xbc\\xe6+\\x1a<z\\xe9\\x93<}\\xe3\\xa1\\xbbp:\\x19<\\x18\\x15^\\xbcS\\xad\\x02<\\x98\\xf4\\xbb\\xbb\\x87\\x92\\x1c\\xbdH\\x00\\x1d\\xbb\\xb3\\xc4\\xde<\\x83Y\\xac<g\\xca\\x80\\xbc\\rh\\xab\\xbc\\xe6+\\x9a<\\xdd\\xbb\\x81<\\xb6\\xc0\\xb4\\xb9\\x8cI\\xeb<\\t\\xaf\\xe1:\\xef\\\\\\x03<\\xca\\xdd2;5\\xa2\\xa7<\\xfc\\x85\\x7f\\xbc7\\x1e$\\xbc\\x95z\\xd4\\xb9\\x8b\\x8c\\xaa\\xbcI?\\xcc<\\xea%(=:\\xd9\\xcf=\\x1cN\\x01\\xbdv\\xefR\\xbc)w0\\xbb[\\x1f}=\\x13\\x1de\\xbc\\xd4\\xcb\\x8f=\\x07\\xb3\\xbe:\\xa0f\\x1c\\xbd\\xf7\\xce0;\\x89\\xcf\\xb6<\\x10\\xa3}=:\\xd9\\xcf\\xbb\\xaeN\\x87<?\\xd1H=\\x86\\x14X\\xbd\\x16X\\x1d<\\t\\xf0\\x0b\\xbdw\\xae\\xdb<\\xa3!\\xc8\\xbce\\x8d3\\xbb\\r\\xe8Q\\xbdJ\\xbd\\x10=9\\x1a\\xc7\\xbc\\\\\\x9dA=w\\xae\\xdb\\xbc\\x8f\\x84\\xa3\\xbb\\xac\\x91\\x13\\xbd\\xa6\\x9b\\xaf\\xbb\\x959]=\\x07rG=\\x05\\xb7\\x9b\\xbd]\\xdc#\\xbb/\\xed:\\xbcC\\xc9A=G\\xc3\\x02=\\x9d+\\x97\\xbc\\xfb\\x07\\xee<\\xbcu\\xa1\\xbc\\x15\\x9b)<\\x19\\x93o\\xba[\\x1f}<\\x17\\x17&\\xbc+s\\x06=\\x82\\x1c\\x12=\\xe9f\\x9f\\xbc\\x99\\xb3D=\\x0f\\xe4t=W\\xe6?\\xbb\\x16\\xd8\\xc3<(\\xb8t\\xba\\x99r\\xcd=\\xe8\\xe8\\r\\xbde\\x8d3\\xbd9\\x1c\\x0f\\xbb\\xca\\xdd2\\xbc\\xdd;\\xa8<\\xa1d\\x87\\xbcR\\xf0\\x8e\\xbdZ\\xe2\\x95;R/\\xbe<\\xf2\\xd67\\xbaY#\\xda\\xbb\\xea\\xa5\\x81=\\x9b\\xf0\\x11=\\xa8X\\xa3\\xbc\\x93\\xbd\\x93<J\\xbd\\x90\\xbcsu\\x9e\\xbc\\xf7\\xce}<\\xb7\\xfd\\xce<\\x17\\x97\\xcc<b\\x93%=\\x19\\xd4\\x19\\xbc\\x85\\x96F<\\xdb?\\x05=\\x07\\xf2\\xa0<\\x93\\xbd\\x13=j\\x85\\xf9\\xbb\\xcb\\x1aM<y\\xaa1=\\x03\\xfa\\'=0*U\\xbbs4\\xf4\\xbc5\"\\xce<\\x88\\x90\\x87<ts\\x89<\\xc5\\xa6\\n<+s\\x06<\\x85U\\xcf\\xbc\\xbcu\\xa1\\xbc\\x17V\\xd5<=\\x94\\xae<V\\xe8\\x07\\xbdz*\\x8b\\xbc\\x9c\\xad\\x85\\xbc\\xb9:\\x9c\\xbc\\x08\\xf0X=\\x84\\x185\\xbd]\\x1b\\xd3<\\xd7\\xc5j\\xbcf\\xcc\\x95\\xbc8\\xdd\\xac;\\x7f\\xa0\\x15=\\x01=\\xb4=\\xa5\\x1d\\x9e\\xbbGC)\\xbb\\xaa\\xd4\\xec\\xbb\\xe5-\\xaf<\\x9d\\xab=\\xbd\\x9f\\xa9(\\xbd{(\\xc3\\xbc[\\xe0\\x00\\xbd9[>\\xbd(\\xf9\\x1e<\\xb6\\xc04\\xbdSn ;\\x91A\\x97\\xbd\\xc1m\\x9a;\\xd2O`<\\xd8\\x84\\xa6:xmd<u\\xb2\\xb8\\xbb\\x10#\\x8a<(\\xf9\\x1e<]\\\\\\xca\\xbc?\\x10\\xab:\\x8aM\\xc8<\\xe8)\\x05\\xbdo\\xbc\\x07=Lz\\x04\\xbcT+\\x94\\xba\\xacR\\xb1;\\x959\\xdd\\xbcL\\xb93=k\\x03>=c\\x91\\x10\\xbc\\xe3\\xb1\\xff<A\\xcd\\x1e<\\x14\\x9bv<EG\\x06\\xbc\\xa6\\\\\\x80\\xbc$\\xc0{=,\\xf1\\xe4\\xbb\\x84\\xd7=\\xbb\\xad\\x0f%;j\\xc6\\xa3\\xbc\\xc4g(\\xbd\\xc9\\x1e*\\xbc\\x97\\xb7\\xa1<3\\xe53<1\\xa8f\\xbc\\xa2b?<j\\x85\\xf9\\xbb..\\xb2<`\\x97\\x02\\xbd\\x87Q\\xf2\\xbc\\x9a\\xf0\\xde\\xbc\\xa6\\x9b\\xaf\\xbcG\\x02\\xff\\xbc+\\xb4\\xca<\\x9a\\xf0^</\\xed\\xba\\xbcQ\\xb1y\\xbc\\xb7\\xfd\\xce\\xbca\\x95:=\\xf2\\xd67\\xbd\\xde9\\x93\\xbb\\xf9\\xca\\xd3<p{\\x90<\\x13\\x1d\\xe5\\xbc\\x0f\\xe4\\'\\xbd;W\\xe1;\\xca\\x9c;\\xbc\\x93~\\xb1<\\x9d\\xab\\xbd<A\\xcd\\x9e\\xbc\\xcfU\\x05<\\x0b\\xec\\xfb;_X\\xed<;W\\x94<\\x1eJ\\xf1<\\xf6Pl\\xbc\\x10#\\x8a;\\x0b+\\x91\\xbcr8\\x84<\\xb5\\x81\\x85<Z\\xa1\\xeb\\xbc\\xb7\\xfdN\\xbc\\xbbw\\xb6<\\x80\\x9e\\x80<\\xa0\\xa7\\x93\\xba\\x16\\xd8C\\xbc\\xc5\\xe59=\\xb9:\\xe9;\\x94|\\x1c=\\xce\\xd5\\xf8<\\xde\\xfa\\xfd\\xbc\\xc4g(\\xbd\\xd1\\xd1\\xce<-\\xf1\\x17\\xbcxm\\xe4;g\\xcaM\\xbc0*\\xd5\\xbc\\xde9\\x13\\xbd\\xdb?R=}$\\x99<\\x84\\x185<\\x0ef\\x16\\xbc\\x8d\\x88\\x80\\xbb\\xba\\xb8z\\xbb\\x86\\xd3`\\xbd\\xfaH\\x98\\xbc\\xc7\"\\x07<\\xc1\\xed\\xc0;\\xfc\\x852\\xbc\\xfe\\x81\\x88;I\\xfe\\xd4\\xbcO\\xb5\\xd6\\xbc\\xdf7\\xcb\\xbc[`\\'<Nv\\'\\xbb\\x8d\\x88\\x00=\\x8f\\x84\\xa3<s\\xb6\\x95<\\x89\\xcf6<\\xb0\\x8b\\xa1;\\xb2\\x07\\x1e=\\x93~1\\xbd?\\x90\\x84=\\x8a\\xcd!<|e\\x10=\\x081P;\\xfd\\xc4\\x14\\xbc\\x13\\x1d\\x18\\xbb\\xb1H\\x95;Z\\xa1\\x1e\\xbc\\x17\\xd6.<#\\x01\\xf3:\\x89\\x8e\\xbf<hH_\\xbd5\\xa2\\'=F\\x84m\\xbc\\xed`-\\xbcq8Q\\xba\\x90C,=\\x91\\x00m\\xba\\x8d\\xc7/;\\x96\\xf8\\x18\\xbc\\xf0\\xda\\xe1\\xbbk\\x83\\x97;\\xf2\\xd67<\\x993\\x9e\\xbc\\x8cIk\\xbb\\xdc\\xbdc=]\\xdc#\\xbb\\x8cIk\\xbd\\x8d\\x08\\xf4<\\x85U\\xcf;I?\\xcc<\\xae\\xce-<`V\\x8b<c\\x91\\x90\\xbc\\xc6\\xe3\\xa4\\xbb\\x02\\xfc<\\xba<\\x16j<\\xf9\\xca\\x86\\xbc\\xf8\\x0b\\xcb\\xbbG\\xc3\\x82<#B\\x9d\\xbc\\x91A\\xe4<\\xec`\\xfa:\\x1a\\x91\\x8d\\xbc!\\x05\\x83=\\xa4`*\\xbcq8Q;\\xf1\\x99\\x9d\\xbcL\\xfa\\xf7:a\\x15\\x94\\xbc\\xe0v\\xad\\xbbv\\xf1\\x9a\\xbb\\xd9\\x82\\x11;(\\xf9\\x1e=\\xb9{`=\\xd6\\x88\\x83\\xbd\\x07\\xb3><x,m\\xbb\\xd3\\x8c\\xfa;\\xed\\x9f\\x8f<!\\x05\\x83<,\\xf1d\\xbb\\x0e\\xa7Z\\xbd\\xb7\\xfd\\xce\\xbc\\xbfo|\\xbc\\x84\\x18\\xb5<\\xc0\\xae\\x91<9\\x1a\\xc7\\xbb\\xd5\\n?=\\xaf\\x8b\\xee\\xbb\\xf3\\x15\\x1a\\xbc\\x87\\x92\\xe9<\\x8b\\x0c\\x04=\\xea\\xa5\\xce;\\xa9V\\x0e=\\xf8\\r\\x93\\xbc\\xdb\\xfe\\xda;\\x88\\x10{<\\xd3\\xcdq=\\xbc\\xf5\\xc7<\\x88Q\\xa5\\xbcXdQ<\\xab\\x13\\x02\\xbc/\\xed:<\\x99\\xb3\\xc4:5\"\\x01\\xbdv0\\xca<\\xd4\\x0c\\x07<gJ\\'\\xbd?\\x10+\\xbaS\\xad\\x02; F\\xc7<v\\xf1\\x9a\\xbc\\xd6\\x88\\xd0;\\xcb\\x1aM\\xbc\\x19\\xd4\\x99<\\xdc\\xbd\\xe3\\xbc\\xc5e\\x93;\\x85\\x96F\\xbc\\\\^\\x92;\\xb2\\xc6&=B\\x8c\\xa7<_X\\xed\\xbc\\x0b\\xab7;\\x80\\x9e\\xcd\\xbb\\xdaA\\x1a<\\x1b\\x8fE\\xbc\\\\\\x9dA<F\\xc5\\x179J\\xfe\\x87;X\\xe4\\xaa;p:\\x99\\xbc\\x8a\\xcd!\\xbd\\xc0\\xef\\x08\\xbc\\xa7\\xda\\x91\\xbb5\"\\xce\\xba\"\\xc4\\x8b\\xbc\\x95z\\x07\\xbdHA\\x94<\\xa9\\x97R<n\\xff\\x13\\xbd\\':\\xe3:..2<\\xee^\\x98\\xbd\\x8cI\\x9e<\\x1bP\\x16\\xbd\\xa1d\\x87<\\xdf7\\xcb\\xbb@OZ;\\'{Z=]\\x9b\\xac<\\x16X\\x1d<\\x8b\\x8c\\xaa\\xbc\\xde\\xfa\\xfd\\xbbhH\\x92\\xbcG\\xc3\\x82\\xbd\\xc3\\xe9c;5\"\\x01:\\x93~\\xb1\\xbcY\\xe2\\xe2\\xbb]\\\\J;\\x86U\\x02=\\x1f\\tz;\\xde\\xfa\\xfd:\\xd1\\xd1\\x01\\xbb \\x87>\\xbc\\xc9\\x9e\\x03=\\xdfx\\xc2\\xbc\\x1d\\xcc\\x92\\xbaQ1\\x86<\\x88Q%\\xbc\\xaf\\xcc\\xe5:ts\\x89\\xbc\\xc9_!\\xbd\\x8c\\x8a\\xe2\\xbc\\x82\\xdb\\xe7\\xbc\\xa6\\x9b/=\\xe3p;\\xba\\xdf\\xf8\\x1b\\xbc\\xef\\x1bY\\xbb%\\xbe\\x99\\xbc\\x9f\\xa7`\\xbd\\xbd\\xb4\\x03<\\xb2\\xc6&\\xbdc\\xd2\\x87\\xbc\\xc2*[<\\x85UO<\\x18\\x15\\x91\\xbbL9\\x8d<\\xe9\\'\\xbd;aTC\\xbbN\\xf6M={\\xe7\\xcb\\xbc\\xf2\\x17\\xaf\\xbb\\x055z\\xbc@\\x0e\\x16<\\xb5B\\xf0<=\\x14\\x08\\xbcc\\x91\\x90\\xbcR\\xaf\\x97<\\x1a\\x114=\\x13^\\x0f=\\xdd|\\x1f\\xbd|\\xa6\\xd4\\xbc\\xfd\\xc4\\x14\\xbd\\xb4\\x83\\x9a\\xbcO\\xb5\\x89\\xba..2=\\':c\\xbc\\x96\\xf8\\xe5<\\xdc\\xfe\\x8d<\\xb9:i\\xbd\\x1b\\xd0<\\xbd`\\x97\\x82;\\xd0\\x92\\x1f;\\x03zN\\xbc+\\xf3\\xac\\xbb\\xe4\\xaf\\x9d;\\xeb#\\x93\\xbd\\x9f\\xa7`:\\xb1\\x89\\x0c\\xbd\\xa5^\\x15<=\\x94\\xae\\xbc\\xb3\\xc4\\xde<\\x1c\\rW<s\\xb6\\x95\\xbc\\xd6G\\x8c<\\r\\xa9\";\\xc2kR\\xbdC\\x8a\\x12=\\x93\\xfe\\n\\xbd|\\xa6\\x07=V\\xa9%=\\xcc\\x1a\\x80\\xbb\\x12\\x9f\\x06\\xbdU\\xa9\\xf2\\xb8\\xb1\\xc8\\xbb<\\x10#\\n\\xbcF\\x84 <\\xa7Z8\\xbb\\xe4/\\xc4\\xbcc\\xd2\\x87\\xbc/,\\x1d\\xbd\\xdd|\\x1f\\xbd\\xd0\\x12\\xc6\\xbb\\xbf0\\x80\\xbc\\x84\\x98\\x8e<\\xc9_\\xa1<\\x81]\\xd6\\xbc\\x10\\xa3\\xfd<\\xd3\\xcd\\xf1\\xbbwo,=\\xa7\\x1b\\x89<3&+\\xbbk\\x83\\x97\\xba\\xdd|\\x1f\\xbc\\xa4\\xe0P=\\x1d\\r\\n\\xbcn}\\xf2\\xbbU\\xeai:\\xa5\\x1d\\x9e;\\xad\\xd0B=\\x86U\\x02\\xbd@O\\x8d\\xbcA\\x8c\\xf4\\xbc\\\\\\xde\\xb8\\xbc\\x8b\\x0c\\x04<\\x1b\\xd0\\xbc\\xbc\\xf6\\x0fu<S\\xee\\xc6;=\\x94\\xfb;\\xe4\\xaf\\x9d\\xba\\x97\\xf6\\x83\\xbbU\\xea\\xe9\\xbc\\x8f\\x04\\xca;\\xa6\\xdc&\\xbc%>\\xc0<\\xb0\\xca\\x03<\\x9c-,=\\xc6\\xa4B\\xbc3e\\x8d<k\\xc4\\x8e\\xbc\\xd8C\\xfc\\xbbO\\xb5V<\\xed\\x1f6\\xbd?\\x90\\x04\\xbcBK\\xfd<I\\xbf%=l\\x81O<\\xd9\\x82\\x91\\xbbN\\xf6\\xcd\\xbc\\xe2\\xf2v\\xbc\\xd6G\\x0c<CI\\x9b\\xbc\\xfe\\x81\\x88;*69=*\\xf5A=cR.\\xbcr\\xb6b\\xbb\\xf1Xs\\xbbBK}\\xbc\\x17VU\\xbcF\\xc5\\x17=\\x90\\xc3\\x05\\xbd\\xe5n&:8\\x9c\\xb59\\x1cN\\xce\\xbb\\x18\\x15\\xde\\xbbA\\xcd\\xeb\\xbab\\xd4\\x1c;\\xc6\\xa4B:\\xfe\\xc2\\xcc\\xbb\\x97\\xb7\\xa1<\\xec\\xa1q\\xbc}$\\x19<i\\xc6p\\xbc\\xba\\xb8\\xfa\\xba\\xf6\\x8f\\x81<\\x8aMH\\xbc`\\xd6\\xfe<|\\xa6T\\xbc\\xf3\\x95@;\\x8f\\xc5\\x9a;\\x19Rx\\xbdG\\x02\\xff\\xbc\\x01\\xbd\\x8d\\xbc@O\\x8d<\\xb6\\xc04\\xbd\\xbc\\xf5\\xc7\\xbb#\\x01\\xf3;\\xd2\\x0e\\xe9<\\x8c\\x8a\\xe2\\xbc\\x80\\x9e\\x80=|&.\\xbc7\\x1e\\xa4;3\\xe53\\xbd\\x1c\\xce\\'<\"\\x83\\x94\\xbc\\x89\\x0e\\x99;W\\xa7\\x90\\xbb\\r\\xe8\\x04=p\\xfb\\xb6\\xbc\\xda\\x00#\\xbb\\xb0\\x8b!\\xbdBK}=\\xd6\\x88P\\xbc\\x9d+\\x17;\\xd4K\\xb6<\\xb5\\x81\\x05\\xbc\\xf8\\r\\x13<\\xe2r\\x83\\xbc\\xfa\\x89\\\\;\\xccY/\\xba\\xf7\\xce}<\\xdc\\xfe\\r;\\xe1\\xb5\\x0f\\xbd\\x91\\x00\\xed\\xbb\\xec\\xa1\\xa4\\xbc\\xfa\\x89\\x0f<\\xb5B#\\xbc\\x13\\x1d\\x18;\\xb1\\xc8\\xbb<w\\xae\\x8e;\\x8d\\xc7\\xfc;\\xce\\x16\\xa3\\xbcn\\xbe\\x9c\\xbb\\xa5^b\\xbc\\x8f\\x04\\xca\\xbc<\\x16\\x9d\\xbc^\\x99\\xe4:,2\\xdc;\\x14\\x9b\\xf6\\xbc\\xde\\xb9\\xb9<(\\xb8\\'=e\\xce\\xf7<\\xd5\\n\\xbf:\\r\\xe8\\x84<m\\xff\\xe0<\\xfd\\xc4\\x94<}\\xe3\\xa1\\xbc8]\\x06<\\xcd\\x98\\xde<\\xe6+\\xe7<hH\\x12\\xbb3\\xe53=\\xeb#\\x93<\\x93=\\xba;\\xbc\\xb6\\x98<z*\\x8b<\\xdd;(;\\x90\\xc3\\x85<\\xef\\\\P\\xbdOt\\x12=\\xaeNT<\\xb9:\\x1c;s4t=\\x86\\x14\\xd8<\\xd6\\x88\\x03=\\xd1\\x90\\xd7<\\xed\\xe0\\x86\\xbc\\xc8\\xa0\\xe5<\\x0b\\xec\\xfb\\xbaEG\\x06\\xbd\\x9dl\\x8e=\\n-\\xa6\\xbc\\xd2O\\xe0\\xbc\\x8f\\x84#=\\xaa\\x15\\x17<\\x9f)\\x02;\\xa7Z\\xb8;\\xb1\\x89\\x8c\\xbc\\xad\\x0f%\\xbd1\\xe9\\x90<A\\x8c\\xf4\\xbbaT\\xc3\\xbcQp5;\\x1d\\xcc\\x12\\xbd\\x93\\xfe\\n=J\\xfe\\x87<\\xb6\\xc0\\xb4\\xbcuqA\\xbcp\\xba?;[\\x1f\\xb0\\xba\\xa4\\x9f\\xd9\\xbc\\xd9C/\\xbb\\x16\\xd8C<i\\x07\\xe8\\xbc\\xea\\xa5N<v\\xef\\xd2<\\xb2F\\xcd\\xbb\\xaf\\xcce\\xbcI?L\\xbc\\xf4\\xd2Z<C\\n\\xb9\\xbbV\\xe8\\x07=\\xfc\\x85\\xb2;\\xed\\x1f6;\\xfe\\x81\\x88;dP\\x19;\\xc9\\x9e\\x83</\\xed\\xba<\\x1b\\x0f\\x9f<\\x7f\\xe1\\x0c<\\x01\\xbd\\x8d\\xbc>S\\xb7<\\xba\\xf9\\xf1\\xbb\\xe7\\xa9\\xf8<Y#Z;_X\\xed\\xbc\\x9f\\xe8W;\\xe0\\xb5\\xdc:\\\\\\x9d\\xc1\\xbc\\xbd4*=>\\x12@<L\\xfaw<\\xb9:\\x1c\\xbdg\\x0b\\xc5\\xbc\\x00\\xbf\\xef\\xba\\xe7\\xa9x\\xbc\\x8b\\x0c\\x04\\xbdY#Z\\xbc\\xd8\\x84&<g\\x0bE\\xbb\\x1bP\\x96\\xbb\\xb2FM\\xbc\\x9a1\\xd6<\\xb2\\x07\\x1e<su\\xeb\\xbc&\\xbc\\x04\\xbd\\xa5\\x1d\\x1e\\xbd\\x02;\\x9f\\xbc\\xc5\\xa6\\n\\xbc\\xd5I!<\\xadP\\x9c\\xbae\\xce*=H\\x80\\xc3\\xbadP\\x19<Q\\xb1y<?\\x90\\x04\\xbc\\xad\\x0f\\xa5\\xbc\\xb4\\xc4\\x91\\xbc\\xf1\\x99\\x9d\\xbc\\x0c\\xea\\x99\\xbbG\\x02\\xb2<J\\xbd\\x10=T+\\x14\\xbd\\xbb\\xf7\\x0f\\xbcy\\xeb\\xa8\\xbc\\xdf\\xf8\\x1b<\\xdd\\xbb\\x01\\xbd\\xaf\\xcc\\x18\\xbd\\x0bl\\x08<\\xcfU\\x05\\xbc\\x06\\xb5\\x86\\xbc\\x96\\xb7n\\xbczi\\xba<\\x049\\n<\\xcd\\x98\\x11<\\xd3\\xcd\\xf1\\xbc\\xaf\\xcce<ts\\x89;\\xd6\\x08*\\xbc\\xc1m\\x9a\\xba\\xde\\xfa0<s\\xb6\\x95<W\\xe6?\\xbb#B\\xea<\\xa1d\\x87<o}%<\\x19\\x93\\xef;W\\xa7\\x90\\xbb\\x1eJ\\xf1\\xbc\\xf7\\x8d9=\\x8e\\x06\\x12\\xbd\\xcb[\\xc4\\xbc{\\xa8\\x9c<\\xc5&1=\\xf3TI\\xbb\\x8d\\x88\\x00=\\xcb\\xdb\\x9d<\\x0cj\\xc0<\\x1eJ\\xa4<\\x16\\xd8\\xc3\\xbcJ\\xbd\\x10\\xbdE\\x06\\x0f=\\xc6cK;,2\\xdc\\xbc..2\\xbc\\xe9\\xe6\\xc5<\\xd5\\xc9G\\xbc&}\"\\xbc\\xd2O`\\xbcBK0\\xbd_X\\xa0\\xbc+\\xf3,\\xb9L9\\x8d<c\\x91];\\xa6\\\\\\x00\\xbd\\xb6@\\x0e\\xbdK|\\x19\\xbc\\xba\\xb8\\xad\\xbb\\xda\\x00#;+s\\x86;.o)\\xbc^\\xda\\xdb<\\xff\\xff\\xe6<\\xf3\\xd4\"<\\xef\\\\\\xd0\\xba1\\xe9\\xdd;\\xd1\\x90\\x8a<\\xd9\\xc3\\x88\\xbc\\xcb\\xdb\\x9d\\xbc\\x8f\\x04J=\\x00\\xbf\\xef\\xbc1*\\x08;\\xcd\\x98^<\\x93~1\\xbchH_\\xbb\\xd1\\xd1\\x01<\\xf4\\x93+;`\\x97\\x82<\\x9ar\\x00\\xbc\\xdd|\\x1f\\xbd\\x9b\\xaf\\x1a\\xbdn\\xff\\x93<\\xb9:\\x9c<\\xea%(<\\x11\\xa1\\x9b\\xbcA\\x8c\\xf4<.\\xae\\x8b\\xbc\\xb5\\x01,\\xbd\\xa9\\x97R\\xbd%>\\xc0;\\xb3F\\x00\\xbd-\\xb0\\xed\\xbbJ\\xbd\\xdd<0k\\xcc<\\x7f\\xe1\\x0c=\\xc2\\xeb+;_\\x99\\x97<\\x16X\\x9d<\\x83\\xd9\\x05\\xbd5\"\\xce\\xbb\\x87\\x92\\xe9\\xbc\\xd2\\x0e\\xe9<C\\n9:\\x0b\\xec{</\\xed:\\xbc\\x7f\\xe1\\x0c\\xbd\\x8b\\xcb\\xd9\\xbc\\'{Z9\\x82\\x9a\\xf0;u2\\x92\\xbc\\xe0v-<O\\xb5\\xd6\\xbcj\\x05\\x06\\xbd\\xda\\xc1@<\\x02\\xbb\\xc5\\xba\\x93\\xbd\\x93:1\\xe9\\xdd\\xbb\\x1eJ\\xf1<u2\\x12=g\\xca\\xcd\\xbc\\xf3T\\xc9;\\xa0\\xa7\\x13<\\xab\\x93\\xa8<\\rh+\\xbb9\\xdb\\x97\\xbbJ|\\xe6<\\xd4K\\xb6<\\xbf\\xb0s=p\\xba\\xbf:\\x83Y,=@\\x0e\\xe3<\\x0e\\xa7\\r\\xbd\\x0f%l<\\xc4&~\\xba\\xaf\\x8bn\\xbd\\x83Yy\\xbcP3h;~\\xa2\\xaa\\xbc\\x1b\\xd0<=\\x18\\xd4\\xe6;\\x93\\xfe\\n\\xbd\\xde\\xfa0\\xbc\\xf3\\x95\\xc0;\\xc9\\x1e\\xaa;\\xbe\\xf1j<e\\xce*\\xbc\\x19\\x93o;L\\xb93\\xbc\\x95zT=\\xa4\\x9f\\x0c\\xba\\x1bP\\x96;\\xd5\\n?<su\\xeb\\xbc\\x03z\\xce\\xbc\\xe9\\xe6E\\xbd\\xaa\\xd4\\xec<\\xd9\\xc3\\x08\\xbc~\\xa2w:\\x00\\xbf\"\\xbd1\\xe9\\xdd;j\\xc6#\\xbc2&x<\\x98\\xf4\\xbb<\\xcb[\\xc4<1\\xa8\\xe6<\\xfb\\xc6\\xf6\\xbcI\\xbf%;\\xf7\\xce\\xfd\\xbc\\xfc\\x05\\x8c;m@\\x0b\\xbcn\\xff\\x93<\\x8eE\\xc1\\xbc\\xc4gu\\xbc)w}\\xbc-\\xb0\\xed\\xbcQ\\xb1\\xf9\\xba\\xbbw6\\xbd FG\\xbcyk\\x82<p\\xba?\\xbc\\xb1H\\x95<8\\xdd,<g\\x8b\\x9e;\\x073\\x18=Xd\\xd1\\xbcg\\xcaM\\xbc+4$\\xbdt\\xf3\\xfc\\xbcB\\xcb\\t\\xbd\\x96\\xb7n\\xbcp{\\x10\\xbc\\xa7Z8<\\xf4\\x13\\xd2\\xbc\\x11!\\xc2:\\xe3\\xb12<\\xe4\\xf0\\x94<\\xc6$\\x1c\\xbc|e];B\\x0c\\x01\\xbd\\x1eJq=\\x15Z\\x7f<\\xdd;\\xa8<\\x1d\\r\\n=\\xd5\\xc9\\xc7\\xbc\\x1d\\xcc\\x12\\xbc\\x8e\\x86\\xb8;\\xe1te;k\\x03\\xbe\\xba\\xaeN\\x07=\\x10b\\xb9<\\xf0\\xda\\xe1;\\xb8\\xbc\\x8a<\\x8f\\xc5\\x1a\\xbdK;\"=\\xe31\\x8c\\xbc\\\\^\\x12<\\xdez\\n\\xbcd\\x0fo\\xbd\\x1d\\xcc\\x12\\xbc\\xb8\\xfd\\x01\\xbd\\x81\\x1c_\\xbc\\x10d\\x81\\xbc>S7=\\x8a\\xcd\\xa1<\\xf2\\x17/\\xbc\\x98\\xb5\\x0c=9\\x1a\\xc7;\\xacR1<C\\n\\xb9;\\x1d\\r\\n\\xbd\\xa6\\x9b/<\\xfe\\x01\\xaf\\xbc\\x84\\xd7=\\xbd\\x8c\\x8a\\xe2\\xb9\\xbe\\xf1\\xea\\xbb\\xd2O\\xe0<\\xaeNT\\xbd\\xbc\\xb6\\x18\\xbdb\\x13\\xcc\\xbaVh{<\\x065\\xad\\xbbQ1\\x86\\xbc\\x0e\\xa7\\x8d<\\x93~1=\\xe1\\xb5\\x0f<\\n-\\xa6\\xbb\\x85U\\xcf<\\x9a\\xf0^\\xbc\\xb9{\\xe0\\xbc1\\xe9\\xdd\\xbc\\xa6\\x9b\\xfc\\xbc\\xf0\\xda\\xe1\\xbc\\x85\\x96\\xc6<L\\xb9\\xb3<\\xec\\xe2\\x1b=\\x82\\xdb\\x9a<\\xe0\\xf6\\xd3\\xba\\r\\xe8\\xd1\\xbc\\x84\\x98\\x0e<Mx<<@O\\r\\xbd\\x1d\\x8b\\xe8\\xbc\\xf1\\x99\\x9d<\\xd4\\xcb\\x8f\\xbc$\\xc0\\xfb<\\xb8\\xbc\\xd7\\xbcp{\\x90\\xbc~\\xa2\\xf7\\xbc]\\xdc\\xa3\\xbc\\x85\\x96F=\\xeb#\\x13\\xbb\\x9bnp;#\\x01\\xf3:\\x12\\x1f\\xad\\xbc\\xa4`\\xaa<}$\\xe6\\xbb\\xca\\x9c\\xbb\\xbb\\xfd\\xc4\\x14=\\xb7\\xbe\\x9f\\xbc\\x081\\xd0<\\xd2\\x0e\\x1c\\xbcxm\\x17=\\xea%\\xa8:z\\xe9\\x93\\xbc\\x14\\x9b\\xf6:}\\xe3n\\xba|e]<\\xcd\\x98\\x919+s\\xd3:\\x19Rx\\xbc\\xbc\\xb6\\x98\\xbb\\xc8\\xa0e<\\xe1\\xb5\\x0f=\\x13^\\x0f\\xbd\\xc8\\xe1\\x8f;}$f\\xbc\\x1c\\xce\\xa7\\xbc\\xdfxB<\\x993\\x9e<o\\xbc\\x87\\xbcY\\xe2b\\xbc!\\x05P\\xbc\\t\\xaf\\x94\\xbc\\x06\\xf45\\xbc\\x11\\xe2\\x12=;\\x98\\x8b<p:\\x99\\xbc\\x84\\x18\\xb5<)w\\xb0\\xbb\\x92?\\x02\\xbb\\xeb\\xe2h<<\\xd5%\\xbc\\xa8X\\xa3;\\x17\\xd6\\xae<_\\x99\\x17\\xbc\\xad\\xd0B=\\xd4\\x8c\\xad;&}\"<\\x82\\xdb\\xe7<[\\x1f0<\\x9dl\\x0e9\\xe0\\xf6S\\xbd\\xff\\xff\\x19<\\xc6c\\xcb<@O\\xda<\\x8b\\x8c\\xaa<;\\x98\\x0b=su\\xeb;\\xec\\xe2\\x9b\\xbbo}%\\xbc;Wa<\\x80_\\x1e\\xbd>S\\xb7<\\xead\\x8a<n\\xbe\\x9c\\xbcQp5;\\xd2\\x0e\\x1c\\xbb\\xa0\\xa7\\x93\\xbc\\x88Q%<\\x97v\\xf7\\xbc/\\xed:<\\x02\\xbbE<\\x8d\\xc7\\xfc;\\x88\\x90\\x87;R\\xf0\\x8e\\xbc\\x8e\\x86\\xb8\\xbc\\xa1d\\x87<D\\x88J<\\xf2V\\x11\\xbd\\xca]\\x8c<N\\xb7\\x1e\\xbd\\x93~1\\xbc\\xe3\\xb1\\xb2:\\x18\\x15\\xde;\\x91\\x00m;\\xfd\\x83\\x9d\\xbb\\xad\\xd0\\xc2<*\\xb6\\x92\\xbc\\x90\\xc3\\x85<:\\xd9\\x02<\\xb7\\xff\\x16\\xbcG\\x82\\x0b\\xbd\\xee\\x1d!=\\x10#\\n\\xbc\\xa7Z\\xb8\\xbcJ~\\xae<\\xc7\\xe1\\\\;\\xdd|\\x1f=Lz\\x04\\xbdX\\xe4*\\xbc\\xb6\\xc04\\xbc\\xf7N\\x8a<!\\xc4\\xd8;\\x84\\xd7\\xbd\\xbbg\\xca\\x80\\xbb\\xe31\\x0c\\xbc@\\x0e\\xe3<xm\\x97;-\\xf1\\x97;\\xe23\\xee\\xbb\\xf3\\x15\\x1a;J\\xfe\\x87\\xbc\\xb3\\xc4\\xde<\\xb7\\xfdN:\\x01~\\xab\\xbc\\x15Z2=\\xdfx\\xc2:=\\x94{\\xbcS\\xad\\x82\\xbc\\x05\\xb7\\x1b;\\x17\\x17\\xa6<2\\xa8\\x99<su\\xeb\\xbb\\x10#\\n\\xbd\\x88Q\\xa5\\xbb!\\x85)=L\\xfa*<c\\x91\\x10\\xbc\\xd8\\x04\\x00\\xbc)w}<\\xfeB&;\\x9d\\xec\\xb4<EG\\x06\\xbd\\x1f\\x89\\x06=\\x9a1\\t\\xbd\\x1d\\x8bh\\xbd\\x85U\\xcf<\"\\xc4\\x8b\\xbbZ\\xa1\\x9e<\\xccY/=t\\xf3\\xaf<\\x08\\xf0X\\xbd\\x19\\x93\\xa2;;\\x98\\x0b<\\xe6l\\xde\\xbcfL<<\\x96\\xb7n\\xbbi\\x07\\x9b<\\xcfS\\xbd<\\x1d\\xcc_\\xbc\\x8f\\xc5\\x1a\\xbce\\xce*\\xbd+s\\xd3\\xba\\xd7\\x06b:xm\\x97\\xbcU\\xa9r<4\\xa4\\xbc<\\x993\\x9e<\\x9c-,\\xbd?\\x90\\xd1\\xbb\\xa3\\xe2\\x98:\\xa8\\x99\\x9a<\\x9c-\\xf9:\\xf2\\xd6\\xb7\\xbc\\x88\\x10{<\\x94;%<5\"\\xce\\xba\\xc0.\\xb8:K;\"=\\xe3p\\xbb<a\\x95\\xba\\xba\\xba\\xb8-=\\x1bP\\x16\\xbd/\\xac\\xc3<\\x0c)I;\\x081\\xd0\\xbbb\\xd4\\x1c<\\xc4&~\\xbc&\\xbcQ\\xbc\\xa6\\xdc&:\\xd4K\\xb6\\xbb`V\\x8b\\xbb^\\x1b\\x06<BK}\\xbb\\x11!B\\xbb\\xb2\\x87\\xc4<r\\xb6b\\xbbD\\xc7,<', 'entry_id': 'e4e4faaeea347b9876d03c4f68b7d981234a3a7a4281590ab4bc0e70dbdaef9e', 'inserted_at': '1746640329.2716022', 'updated_at': '1746640329.2716029', 'prompt': 'what is the capital city of the United States?'}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "from redisvl.redis.utils import convert_bytes\n",
        "from redisvl.query import FilterQuery\n",
        "\n",
        "# Get all keys related to LiteLLM cache\n",
        "cache_keys = list(idx.paginate(query=FilterQuery()))\n",
        "print(f\"Found {len(cache_keys)} cache keys in Redis\")\n",
        "\n",
        "if cache_keys:\n",
        "    # Look at the first key\n",
        "    first_key = cache_keys[0][0]['id']\n",
        "    print(f\"\\nExample cache key: {first_key}\")\n",
        "\n",
        "    # Get TTL for the key\n",
        "    ttl = client.ttl(first_key)\n",
        "    print(f\"TTL: {ttl} seconds remaining...\")\n",
        "\n",
        "    # Get the value (may be large, so limiting output)\n",
        "    value = client.hgetall(first_key)\n",
        "    if value:\n",
        "        v = convert_bytes(value)\n",
        "        print(v)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "implementation-alternatives",
      "metadata": {
        "id": "implementation-alternatives"
      },
      "source": [
        "## 6 · Implementation Options\n",
        "\n",
        "LiteLLM provides multiple ways to implement caching in your application:\n",
        "\n",
        "### Using LiteLLM Proxy (as shown)\n",
        "\n",
        "The proxy approach (demonstrated in this notebook) is recommended for production deployments because it:\n",
        "- Provides a unified API endpoint for all your models\n",
        "- Centralizes caching, rate-limiting, and fallback logic\n",
        "- Works with any client that uses the OpenAI API format\n",
        "- Supports multiple languages and frameworks\n",
        "\n",
        "### Direct Integration with LiteLLM Python SDK\n",
        "\n",
        "For Python applications, you can also integrate caching directly using the SDK. See the [LiteLLM Caching documentation](https://docs.litellm.ai/docs/caching/all_caches) for details."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6kEdjQG2ZQd",
      "metadata": {
        "id": "b6kEdjQG2ZQd"
      },
      "source": [
        "## 7 · Semantic caching with RedisVL directly\n",
        "In some cases you may want more control over your cache. No problem here! Use RedisVL semantic cache directly in your application code like below:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 252,
      "id": "Dl1_Ch8a078y",
      "metadata": {
        "id": "Dl1_Ch8a078y"
      },
      "outputs": [],
      "source": [
        "from redisvl.utils.vectorize import OpenAITextVectorizer\n",
        "from redisvl.extensions.llmcache import SemanticCache\n",
        "\n",
        "oai = OpenAITextVectorizer(\"text-embedding-3-small\")\n",
        "\n",
        "cache = SemanticCache(\n",
        "    redis_client=client,\n",
        "    distance_threshold=0.1,\n",
        "    overwrite=False,\n",
        "    vectorizer=oai,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 253,
      "id": "IwuC4Koi1cA4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "IwuC4Koi1cA4",
        "outputId": "a8fce92a-650b-44e3-d288-f79bb13a253a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'llmcache:e4e4faaeea347b9876d03c4f68b7d981234a3a7a4281590ab4bc0e70dbdaef9e'"
            ]
          },
          "execution_count": 253,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cache.store(\n",
        "    prompt=\"what is the capital city of the United States?\",\n",
        "    response=\"Washington DC is the capital of the USA.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 255,
      "id": "9dtoi8Yi2huX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dtoi8Yi2huX",
        "outputId": "c7cad081-f46a-4398-b479-ec13858491a2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'entry_id': 'e4e4faaeea347b9876d03c4f68b7d981234a3a7a4281590ab4bc0e70dbdaef9e',\n",
              "  'prompt': 'what is the capital city of the United States?',\n",
              "  'response': 'Washington DC is the capital of the USA.',\n",
              "  'vector_distance': 0.0600312948227,\n",
              "  'inserted_at': 1746640334.45,\n",
              "  'updated_at': 1746640334.45,\n",
              "  'key': 'llmcache:e4e4faaeea347b9876d03c4f68b7d981234a3a7a4281590ab4bc0e70dbdaef9e'}]"
            ]
          },
          "execution_count": 255,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cache.check(prompt=\"what is the capital of the United States of America?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FHQfig_e2waj",
      "metadata": {
        "id": "FHQfig_e2waj"
      },
      "source": [
        "Now we should NOT get any cache hits for these."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "id": "T-om1ofo166_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-om1ofo166_",
        "outputId": "f73bfaad-2d17-4f7b-d462-1cb9101cc786"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n",
            "[]\n",
            "[]\n",
            "[]\n"
          ]
        }
      ],
      "source": [
        "texts = [\n",
        "    \"who is the president of France?\",\n",
        "    \"who is the country president of France?\",\n",
        "    \"who is France's current presidet?\",\n",
        "    \"The current president of France is?\"\n",
        "]\n",
        "\n",
        "for text in texts:\n",
        "    print(cache.check(prompt=text))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "117e0229",
      "metadata": {
        "id": "117e0229"
      },
      "source": [
        "## 8 · Cleanup\n",
        "\n",
        "Let's stop the LiteLLM proxy server and clean up our environment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "id": "ta2U-r7CpKhi",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ta2U-r7CpKhi",
        "outputId": "f767ebc8-c721-4207-faf1-7d8bce49e0e0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 259,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "_proxy_handle.terminate()\n",
        "_proxy_handle.wait(timeout=4)\n",
        "cache.clear()\n",
        "client.flushall()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
