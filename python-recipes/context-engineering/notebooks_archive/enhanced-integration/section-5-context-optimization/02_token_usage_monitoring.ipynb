{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Redis](https://redis.io/wp-content/uploads/2024/04/Logotype.svg?auto=webp&quality=85,75&width=120)\n",
    "\n",
    "# Token Usage and Cost Monitoring\n",
    "\n",
    "## Why Token Monitoring Matters\n",
    "\n",
    "**The Problem:** LLM costs can spiral out of control without proper monitoring.\n",
    "\n",
    "**Real-World Horror Stories:**\n",
    "```\n",
    "Startup A: $50,000 OpenAI bill in first month\n",
    "Company B: 90% of costs from inefficient context\n",
    "Team C: 10x cost increase from memory leaks\n",
    "```\n",
    "\n",
    "**Why This Matters:**\n",
    "- ðŸ’° **Budget Control**: Prevent surprise bills\n",
    "- ðŸ“Š **Optimization**: Find inefficiencies\n",
    "- ðŸŽ¯ **Planning**: Predict scaling costs\n",
    "- ðŸš¨ **Alerts**: Catch problems early\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "You'll learn to:\n",
    "1. **Track token usage** - Monitor input/output tokens\n",
    "2. **Calculate costs** - Real-time cost tracking\n",
    "3. **Set budgets** - Prevent overspending\n",
    "4. **Analyze patterns** - Find optimization opportunities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Simple Token Tracking\n",
    "\n",
    "Let's build simple functions to track token usage and costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple token usage tracking - no classes needed\n",
    "import os\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Global usage tracking (in production, use Redis or database)\n",
    "usage_stats = {\n",
    "    'total_input_tokens': 0,\n",
    "    'total_output_tokens': 0,\n",
    "    'total_cost': 0.0,\n",
    "    'requests': 0,\n",
    "    'daily_usage': defaultdict(lambda: {'tokens': 0, 'cost': 0.0, 'requests': 0})\n",
    "}\n",
    "\n",
    "# Current pricing (as of 2024)\n",
    "PRICING = {\n",
    "    'gpt-3.5-turbo': {\n",
    "        'input': 0.0015,   # per 1K tokens\n",
    "        'output': 0.002    # per 1K tokens\n",
    "    },\n",
    "    'gpt-4': {\n",
    "        'input': 0.03,     # per 1K tokens\n",
    "        'output': 0.06     # per 1K tokens\n",
    "    },\n",
    "    'gpt-4-turbo': {\n",
    "        'input': 0.01,     # per 1K tokens\n",
    "        'output': 0.03     # per 1K tokens\n",
    "    }\n",
    "}\n",
    "\n",
    "def count_tokens(text: str) -> int:\n",
    "    \"\"\"Simple token counting\"\"\"\n",
    "    try:\n",
    "        import tiktoken\n",
    "        encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "        return len(encoding.encode(text))\n",
    "    except ImportError:\n",
    "        return len(text) // 4  # Rough approximation\n",
    "\n",
    "def calculate_cost(input_tokens: int, output_tokens: int, model: str = 'gpt-3.5-turbo') -> float:\n",
    "    \"\"\"Calculate cost for a request\"\"\"\n",
    "    if model not in PRICING:\n",
    "        model = 'gpt-3.5-turbo'  # Default fallback\n",
    "    \n",
    "    input_cost = (input_tokens / 1000) * PRICING[model]['input']\n",
    "    output_cost = (output_tokens / 1000) * PRICING[model]['output']\n",
    "    \n",
    "    return input_cost + output_cost\n",
    "\n",
    "def track_usage(input_text: str, output_text: str, model: str = 'gpt-3.5-turbo'):\n",
    "    \"\"\"Track token usage for a request\"\"\"\n",
    "    input_tokens = count_tokens(input_text)\n",
    "    output_tokens = count_tokens(output_text)\n",
    "    cost = calculate_cost(input_tokens, output_tokens, model)\n",
    "    \n",
    "    # Update global stats\n",
    "    usage_stats['total_input_tokens'] += input_tokens\n",
    "    usage_stats['total_output_tokens'] += output_tokens\n",
    "    usage_stats['total_cost'] += cost\n",
    "    usage_stats['requests'] += 1\n",
    "    \n",
    "    # Update daily stats\n",
    "    today = datetime.now().strftime('%Y-%m-%d')\n",
    "    usage_stats['daily_usage'][today]['tokens'] += input_tokens + output_tokens\n",
    "    usage_stats['daily_usage'][today]['cost'] += cost\n",
    "    usage_stats['daily_usage'][today]['requests'] += 1\n",
    "    \n",
    "    return {\n",
    "        'input_tokens': input_tokens,\n",
    "        'output_tokens': output_tokens,\n",
    "        'total_tokens': input_tokens + output_tokens,\n",
    "        'cost': cost,\n",
    "        'model': model\n",
    "    }\n",
    "\n",
    "# Test the tracking system\n",
    "print(\"ðŸ’° Token Usage Tracking System\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Simulate some requests\n",
    "sample_requests = [\n",
    "    (\"What machine learning courses are available?\", \"I found several ML courses: CS301, CS302, and CS401...\", 'gpt-3.5-turbo'),\n",
    "    (\"What are the prerequisites for CS301?\", \"CS301 requires CS101 and CS201 as prerequisites...\", 'gpt-3.5-turbo'),\n",
    "    (\"Can you explain neural networks in detail?\", \"Neural networks are computational models inspired by biological neural networks. They consist of layers of interconnected nodes...\", 'gpt-4')\n",
    "]\n",
    "\n",
    "for i, (input_text, output_text, model) in enumerate(sample_requests, 1):\n",
    "    result = track_usage(input_text, output_text, model)\n",
    "    print(f\"Request {i} ({model}):\")\n",
    "    print(f\"  Input: {result['input_tokens']} tokens\")\n",
    "    print(f\"  Output: {result['output_tokens']} tokens\")\n",
    "    print(f\"  Cost: ${result['cost']:.4f}\")\n",
    "    print()\n",
    "\n",
    "print(f\"ðŸ“Š Total Usage:\")\n",
    "print(f\"  Requests: {usage_stats['requests']}\")\n",
    "print(f\"  Input tokens: {usage_stats['total_input_tokens']:,}\")\n",
    "print(f\"  Output tokens: {usage_stats['total_output_tokens']:,}\")\n",
    "print(f\"  Total cost: ${usage_stats['total_cost']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept 1: Cost Analysis and Budgeting\n",
    "\n",
    "Let's analyze costs and set up simple budgeting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple budgeting and cost analysis\n",
    "def analyze_cost_breakdown():\n",
    "    \"\"\"Analyze where costs are coming from\"\"\"\n",
    "    total_tokens = usage_stats['total_input_tokens'] + usage_stats['total_output_tokens']\n",
    "    \n",
    "    if total_tokens == 0:\n",
    "        print(\"No usage data available\")\n",
    "        return\n",
    "    \n",
    "    input_percentage = (usage_stats['total_input_tokens'] / total_tokens) * 100\n",
    "    output_percentage = (usage_stats['total_output_tokens'] / total_tokens) * 100\n",
    "    \n",
    "    avg_tokens_per_request = total_tokens / usage_stats['requests']\n",
    "    avg_cost_per_request = usage_stats['total_cost'] / usage_stats['requests']\n",
    "    \n",
    "    print(\"ðŸ“ˆ Cost Breakdown Analysis:\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Input tokens: {input_percentage:.1f}% of total\")\n",
    "    print(f\"Output tokens: {output_percentage:.1f}% of total\")\n",
    "    print(f\"Average tokens per request: {avg_tokens_per_request:.0f}\")\n",
    "    print(f\"Average cost per request: ${avg_cost_per_request:.4f}\")\n",
    "    \n",
    "    # Scaling projections\n",
    "    print(f\"\\nðŸš€ Scaling Projections:\")\n",
    "    daily_cost = avg_cost_per_request * 1000  # 1000 requests/day\n",
    "    monthly_cost = daily_cost * 30\n",
    "    print(f\"1,000 requests/day: ${daily_cost:.2f}/day, ${monthly_cost:.2f}/month\")\n",
    "    \n",
    "    daily_cost_10k = avg_cost_per_request * 10000  # 10k requests/day\n",
    "    monthly_cost_10k = daily_cost_10k * 30\n",
    "    print(f\"10,000 requests/day: ${daily_cost_10k:.2f}/day, ${monthly_cost_10k:.2f}/month\")\n",
    "\n",
    "def check_budget(daily_budget: float = 10.0):\n",
    "    \"\"\"Simple budget checking\"\"\"\n",
    "    today = datetime.now().strftime('%Y-%m-%d')\n",
    "    today_usage = usage_stats['daily_usage'][today]\n",
    "    \n",
    "    print(f\"ðŸ’³ Budget Check for {today}:\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Daily budget: ${daily_budget:.2f}\")\n",
    "    print(f\"Used today: ${today_usage['cost']:.4f}\")\n",
    "    print(f\"Remaining: ${daily_budget - today_usage['cost']:.4f}\")\n",
    "    \n",
    "    usage_percentage = (today_usage['cost'] / daily_budget) * 100\n",
    "    print(f\"Budget used: {usage_percentage:.1f}%\")\n",
    "    \n",
    "    if usage_percentage > 80:\n",
    "        print(\"ðŸš¨ WARNING: Over 80% of daily budget used!\")\n",
    "    elif usage_percentage > 50:\n",
    "        print(\"âš ï¸  CAUTION: Over 50% of daily budget used\")\n",
    "    else:\n",
    "        print(\"âœ… Budget usage is healthy\")\n",
    "\n",
    "def suggest_optimizations():\n",
    "    \"\"\"Suggest ways to reduce costs\"\"\"\n",
    "    total_tokens = usage_stats['total_input_tokens'] + usage_stats['total_output_tokens']\n",
    "    avg_tokens = total_tokens / usage_stats['requests'] if usage_stats['requests'] > 0 else 0\n",
    "    \n",
    "    print(\"ðŸ’¡ Cost Optimization Suggestions:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    if avg_tokens > 2000:\n",
    "        print(\"ðŸ” HIGH TOKEN USAGE DETECTED:\")\n",
    "        print(\"   â€¢ Implement context compression\")\n",
    "        print(\"   â€¢ Use conversation summarization\")\n",
    "        print(\"   â€¢ Limit conversation history\")\n",
    "        \n",
    "        # Calculate potential savings\n",
    "        potential_savings = usage_stats['total_cost'] * 0.3  # 30% reduction\n",
    "        print(f\"   â€¢ Potential savings: ${potential_savings:.4f} (30% reduction)\")\n",
    "    \n",
    "    input_ratio = usage_stats['total_input_tokens'] / total_tokens if total_tokens > 0 else 0\n",
    "    if input_ratio > 0.8:\n",
    "        print(\"ðŸ“ HIGH INPUT TOKEN RATIO:\")\n",
    "        print(\"   â€¢ Reduce context size\")\n",
    "        print(\"   â€¢ Remove redundant information\")\n",
    "        print(\"   â€¢ Use more efficient prompts\")\n",
    "    \n",
    "    print(\"\\nðŸŽ¯ General Recommendations:\")\n",
    "    print(\"   â€¢ Use GPT-3.5-turbo for simple tasks\")\n",
    "    print(\"   â€¢ Reserve GPT-4 for complex reasoning\")\n",
    "    print(\"   â€¢ Implement caching for repeated queries\")\n",
    "    print(\"   â€¢ Set up usage alerts and budgets\")\n",
    "\n",
    "# Run the analysis\n",
    "analyze_cost_breakdown()\n",
    "print()\n",
    "check_budget(daily_budget=5.0)\n",
    "print()\n",
    "suggest_optimizations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept 2: Usage Patterns and Alerts\n",
    "\n",
    "Let's build simple monitoring and alerting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple usage monitoring and alerts\n",
    "def monitor_usage_patterns():\n",
    "    \"\"\"Analyze usage patterns for insights\"\"\"\n",
    "    print(\"ðŸ“Š Usage Pattern Analysis:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Analyze daily usage\n",
    "    if usage_stats['daily_usage']:\n",
    "        for date, daily_stats in usage_stats['daily_usage'].items():\n",
    "            avg_tokens_per_request = daily_stats['tokens'] / daily_stats['requests'] if daily_stats['requests'] > 0 else 0\n",
    "            avg_cost_per_request = daily_stats['cost'] / daily_stats['requests'] if daily_stats['requests'] > 0 else 0\n",
    "            \n",
    "            print(f\"Date: {date}\")\n",
    "            print(f\"  Requests: {daily_stats['requests']}\")\n",
    "            print(f\"  Total tokens: {daily_stats['tokens']:,}\")\n",
    "            print(f\"  Total cost: ${daily_stats['cost']:.4f}\")\n",
    "            print(f\"  Avg tokens/request: {avg_tokens_per_request:.0f}\")\n",
    "            print(f\"  Avg cost/request: ${avg_cost_per_request:.4f}\")\n",
    "            print()\n",
    "    \n",
    "    # Identify patterns\n",
    "    total_requests = usage_stats['requests']\n",
    "    if total_requests > 0:\n",
    "        avg_tokens_overall = (usage_stats['total_input_tokens'] + usage_stats['total_output_tokens']) / total_requests\n",
    "        \n",
    "        print(\"ðŸ” Pattern Insights:\")\n",
    "        if avg_tokens_overall > 1500:\n",
    "            print(\"   â€¢ High token usage per request - consider compression\")\n",
    "        elif avg_tokens_overall < 500:\n",
    "            print(\"   â€¢ Efficient token usage - good optimization\")\n",
    "        else:\n",
    "            print(\"   â€¢ Moderate token usage - room for optimization\")\n",
    "\n",
    "def setup_simple_alerts(cost_threshold: float = 1.0, token_threshold: int = 5000):\n",
    "    \"\"\"Simple alerting system\"\"\"\n",
    "    today = datetime.now().strftime('%Y-%m-%d')\n",
    "    today_usage = usage_stats['daily_usage'][today]\n",
    "    \n",
    "    alerts = []\n",
    "    \n",
    "    # Cost alerts\n",
    "    if today_usage['cost'] > cost_threshold:\n",
    "        alerts.append(f\"ðŸš¨ COST ALERT: Daily cost ${today_usage['cost']:.4f} exceeds threshold ${cost_threshold:.2f}\")\n",
    "    \n",
    "    # Token alerts\n",
    "    if today_usage['tokens'] > token_threshold:\n",
    "        alerts.append(f\"ðŸš¨ TOKEN ALERT: Daily tokens {today_usage['tokens']:,} exceeds threshold {token_threshold:,}\")\n",
    "    \n",
    "    # Request volume alerts\n",
    "    if today_usage['requests'] > 100:\n",
    "        alerts.append(f\"ðŸ“ˆ HIGH VOLUME: {today_usage['requests']} requests today\")\n",
    "    \n",
    "    print(\"ðŸ”” Alert System Status:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    if alerts:\n",
    "        for alert in alerts:\n",
    "            print(alert)\n",
    "    else:\n",
    "        print(\"âœ… All systems normal - no alerts\")\n",
    "    \n",
    "    print(f\"\\nðŸ“‹ Current Thresholds:\")\n",
    "    print(f\"   Daily cost: ${cost_threshold:.2f}\")\n",
    "    print(f\"   Daily tokens: {token_threshold:,}\")\n",
    "    print(f\"   Request volume: 100\")\n",
    "\n",
    "def generate_usage_report():\n",
    "    \"\"\"Generate a simple usage report\"\"\"\n",
    "    print(\"ðŸ“„ Usage Report\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Report generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"ðŸ“Š Summary Statistics:\")\n",
    "    print(f\"   Total requests: {usage_stats['requests']:,}\")\n",
    "    print(f\"   Total input tokens: {usage_stats['total_input_tokens']:,}\")\n",
    "    print(f\"   Total output tokens: {usage_stats['total_output_tokens']:,}\")\n",
    "    print(f\"   Total cost: ${usage_stats['total_cost']:.4f}\")\n",
    "    \n",
    "    if usage_stats['requests'] > 0:\n",
    "        avg_cost = usage_stats['total_cost'] / usage_stats['requests']\n",
    "        total_tokens = usage_stats['total_input_tokens'] + usage_stats['total_output_tokens']\n",
    "        avg_tokens = total_tokens / usage_stats['requests']\n",
    "        \n",
    "        print(f\"\\nðŸ“ˆ Averages:\")\n",
    "        print(f\"   Cost per request: ${avg_cost:.4f}\")\n",
    "        print(f\"   Tokens per request: {avg_tokens:.0f}\")\n",
    "        \n",
    "        # Efficiency metrics\n",
    "        cost_per_token = usage_stats['total_cost'] / total_tokens if total_tokens > 0 else 0\n",
    "        print(f\"   Cost per token: ${cost_per_token:.6f}\")\n",
    "    \n",
    "    print(f\"\\nðŸ’¡ Recommendations:\")\n",
    "    if usage_stats['total_cost'] > 0.1:\n",
    "        print(\"   â€¢ Consider implementing context compression\")\n",
    "        print(\"   â€¢ Monitor high-cost requests\")\n",
    "        print(\"   â€¢ Set up automated budgets\")\n",
    "    else:\n",
    "        print(\"   â€¢ Usage is currently low - good for testing\")\n",
    "        print(\"   â€¢ Prepare optimization strategies for scaling\")\n",
    "\n",
    "# Run monitoring and alerts\n",
    "monitor_usage_patterns()\n",
    "setup_simple_alerts(cost_threshold=0.01, token_threshold=1000)\n",
    "print()\n",
    "generate_usage_report()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
