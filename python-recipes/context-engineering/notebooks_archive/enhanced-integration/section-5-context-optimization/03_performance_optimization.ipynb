{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Redis](https://redis.io/wp-content/uploads/2024/04/Logotype.svg?auto=webp&quality=85,75&width=120)\n",
    "\n",
    "# Performance Optimization Techniques\n",
    "\n",
    "## Why Performance Optimization Matters\n",
    "\n",
    "**The Problem:** Slow agents frustrate users and waste resources.\n",
    "\n",
    "**Real-World Impact:**\n",
    "```\n",
    "Slow Response (5+ seconds):\n",
    "‚Ä¢ 40% of users abandon the conversation\n",
    "‚Ä¢ Poor user experience\n",
    "‚Ä¢ Higher server costs\n",
    "\n",
    "Fast Response (<2 seconds):\n",
    "‚Ä¢ Users stay engaged\n",
    "‚Ä¢ Better satisfaction scores\n",
    "‚Ä¢ Lower infrastructure costs\n",
    "```\n",
    "\n",
    "**Why This Matters:**\n",
    "- ‚ö° **User Experience**: Fast responses keep users engaged\n",
    "- üí∞ **Cost Efficiency**: Faster = fewer resources needed\n",
    "- üìà **Scalability**: Optimized systems handle more users\n",
    "- üéØ **Competitive Advantage**: Speed is a feature\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "You'll learn simple techniques to:\n",
    "1. **Measure performance** - Track response times\n",
    "2. **Cache intelligently** - Avoid repeated work\n",
    "3. **Optimize queries** - Faster database operations\n",
    "4. **Batch operations** - Process multiple requests efficiently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Simple Performance Measurement\n",
    "\n",
    "Let's build simple tools to measure and track performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple performance measurement - no classes needed\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Global performance tracking\n",
    "performance_stats = {\n",
    "    'response_times': [],\n",
    "    'operation_times': defaultdict(list),\n",
    "    'cache_hits': 0,\n",
    "    'cache_misses': 0,\n",
    "    'total_requests': 0\n",
    "}\n",
    "\n",
    "def measure_time(operation_name: str = \"operation\"):\n",
    "    \"\"\"Simple decorator to measure execution time\"\"\"\n",
    "    def decorator(func):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            start_time = time.time()\n",
    "            result = func(*args, **kwargs)\n",
    "            end_time = time.time()\n",
    "            \n",
    "            execution_time = end_time - start_time\n",
    "            performance_stats['operation_times'][operation_name].append(execution_time)\n",
    "            \n",
    "            return result\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "def track_response_time(start_time: float, end_time: float):\n",
    "    \"\"\"Track overall response time\"\"\"\n",
    "    response_time = end_time - start_time\n",
    "    performance_stats['response_times'].append(response_time)\n",
    "    performance_stats['total_requests'] += 1\n",
    "    return response_time\n",
    "\n",
    "def get_performance_summary():\n",
    "    \"\"\"Get performance statistics summary\"\"\"\n",
    "    if not performance_stats['response_times']:\n",
    "        return \"No performance data available\"\n",
    "    \n",
    "    response_times = performance_stats['response_times']\n",
    "    avg_response = sum(response_times) / len(response_times)\n",
    "    min_response = min(response_times)\n",
    "    max_response = max(response_times)\n",
    "    \n",
    "    # Calculate percentiles\n",
    "    sorted_times = sorted(response_times)\n",
    "    p95_index = int(len(sorted_times) * 0.95)\n",
    "    p95_response = sorted_times[p95_index] if p95_index < len(sorted_times) else max_response\n",
    "    \n",
    "    cache_total = performance_stats['cache_hits'] + performance_stats['cache_misses']\n",
    "    cache_hit_rate = (performance_stats['cache_hits'] / cache_total * 100) if cache_total > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'total_requests': performance_stats['total_requests'],\n",
    "        'avg_response_time': avg_response,\n",
    "        'min_response_time': min_response,\n",
    "        'max_response_time': max_response,\n",
    "        'p95_response_time': p95_response,\n",
    "        'cache_hit_rate': cache_hit_rate,\n",
    "        'cache_hits': performance_stats['cache_hits'],\n",
    "        'cache_misses': performance_stats['cache_misses']\n",
    "    }\n",
    "\n",
    "# Test performance measurement\n",
    "@measure_time(\"database_query\")\n",
    "def simulate_database_query(delay: float = 0.1):\n",
    "    \"\"\"Simulate a database query with artificial delay\"\"\"\n",
    "    time.sleep(delay)\n",
    "    return \"Query result\"\n",
    "\n",
    "@measure_time(\"llm_call\")\n",
    "def simulate_llm_call(delay: float = 0.5):\n",
    "    \"\"\"Simulate an LLM API call with artificial delay\"\"\"\n",
    "    time.sleep(delay)\n",
    "    return \"LLM response\"\n",
    "\n",
    "# Test the measurement system\n",
    "print(\"‚ö° Performance Measurement System\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Simulate some operations\n",
    "for i in range(3):\n",
    "    start = time.time()\n",
    "    \n",
    "    # Simulate agent operations\n",
    "    db_result = simulate_database_query(0.05)  # Fast query\n",
    "    llm_result = simulate_llm_call(0.3)        # Slower LLM call\n",
    "    \n",
    "    end = time.time()\n",
    "    response_time = track_response_time(start, end)\n",
    "    \n",
    "    print(f\"Request {i+1}: {response_time:.3f}s\")\n",
    "\n",
    "# Show performance summary\n",
    "summary = get_performance_summary()\n",
    "print(f\"\\nüìä Performance Summary:\")\n",
    "print(f\"   Total requests: {summary['total_requests']}\")\n",
    "print(f\"   Average response: {summary['avg_response_time']:.3f}s\")\n",
    "print(f\"   Min response: {summary['min_response_time']:.3f}s\")\n",
    "print(f\"   Max response: {summary['max_response_time']:.3f}s\")\n",
    "print(f\"   95th percentile: {summary['p95_response_time']:.3f}s\")\n",
    "\n",
    "# Show operation breakdown\n",
    "print(f\"\\nüîç Operation Breakdown:\")\n",
    "for operation, times in performance_stats['operation_times'].items():\n",
    "    avg_time = sum(times) / len(times)\n",
    "    print(f\"   {operation}: {avg_time:.3f}s average\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept 1: Simple Caching\n",
    "\n",
    "Let's implement simple caching to avoid repeated work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple caching implementation\n",
    "import hashlib\n",
    "import json\n",
    "\n",
    "# Simple in-memory cache (in production, use Redis)\n",
    "simple_cache = {}\n",
    "\n",
    "def create_cache_key(data) -> str:\n",
    "    \"\"\"Create a cache key from data\"\"\"\n",
    "    # Convert data to string and hash it\n",
    "    data_str = json.dumps(data, sort_keys=True) if isinstance(data, dict) else str(data)\n",
    "    return hashlib.md5(data_str.encode()).hexdigest()[:16]\n",
    "\n",
    "def cache_get(key: str):\n",
    "    \"\"\"Get value from cache\"\"\"\n",
    "    if key in simple_cache:\n",
    "        performance_stats['cache_hits'] += 1\n",
    "        return simple_cache[key]\n",
    "    else:\n",
    "        performance_stats['cache_misses'] += 1\n",
    "        return None\n",
    "\n",
    "def cache_set(key: str, value, ttl: int = 300):\n",
    "    \"\"\"Set value in cache with TTL (simplified - no actual expiration)\"\"\"\n",
    "    simple_cache[key] = {\n",
    "        'value': value,\n",
    "        'timestamp': time.time(),\n",
    "        'ttl': ttl\n",
    "    }\n",
    "\n",
    "def cached_course_search(query: str, limit: int = 5):\n",
    "    \"\"\"Course search with caching\"\"\"\n",
    "    # Create cache key\n",
    "    cache_key = create_cache_key({'query': query, 'limit': limit})\n",
    "    \n",
    "    # Check cache first\n",
    "    cached_result = cache_get(cache_key)\n",
    "    if cached_result:\n",
    "        return cached_result['value']\n",
    "    \n",
    "    # Simulate expensive course search\n",
    "    time.sleep(0.2)  # Simulate database query time\n",
    "    \n",
    "    # Mock course results\n",
    "    if 'machine learning' in query.lower():\n",
    "        results = [\n",
    "            {'code': 'CS301', 'title': 'Machine Learning', 'description': 'Intro to ML algorithms'},\n",
    "            {'code': 'CS302', 'title': 'Deep Learning', 'description': 'Neural networks and deep learning'}\n",
    "        ]\n",
    "    elif 'redis' in query.lower():\n",
    "        results = [\n",
    "            {'code': 'RU301', 'title': 'Vector Search', 'description': 'Advanced Redis vector operations'}\n",
    "        ]\n",
    "    else:\n",
    "        results = [{'code': 'GEN101', 'title': 'General Course', 'description': 'General course description'}]\n",
    "    \n",
    "    # Cache the result\n",
    "    cache_set(cache_key, results)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def cached_llm_response(prompt: str):\n",
    "    \"\"\"LLM response with caching\"\"\"\n",
    "    cache_key = create_cache_key(prompt)\n",
    "    \n",
    "    # Check cache\n",
    "    cached_result = cache_get(cache_key)\n",
    "    if cached_result:\n",
    "        return cached_result['value']\n",
    "    \n",
    "    # Simulate expensive LLM call\n",
    "    time.sleep(0.5)  # Simulate API call time\n",
    "    \n",
    "    # Mock LLM response\n",
    "    response = f\"This is a response to: {prompt[:50]}...\"\n",
    "    \n",
    "    # Cache the result\n",
    "    cache_set(cache_key, response)\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Test caching performance\n",
    "print(\"üöÄ Caching Performance Test\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Test course search caching\n",
    "queries = ['machine learning courses', 'redis courses', 'machine learning courses']  # Repeat first query\n",
    "\n",
    "for i, query in enumerate(queries, 1):\n",
    "    start = time.time()\n",
    "    results = cached_course_search(query)\n",
    "    end = time.time()\n",
    "    \n",
    "    print(f\"Query {i}: '{query}'\")\n",
    "    print(f\"   Time: {end - start:.3f}s\")\n",
    "    print(f\"   Results: {len(results)} courses\")\n",
    "    print(f\"   Cache status: {'HIT' if end - start < 0.1 else 'MISS'}\")\n",
    "    print()\n",
    "\n",
    "# Test LLM response caching\n",
    "prompts = [\n",
    "    \"What are the best machine learning courses?\",\n",
    "    \"Explain neural networks\",\n",
    "    \"What are the best machine learning courses?\"  # Repeat first prompt\n",
    "]\n",
    "\n",
    "print(\"ü§ñ LLM Response Caching Test:\")\n",
    "for i, prompt in enumerate(prompts, 1):\n",
    "    start = time.time()\n",
    "    response = cached_llm_response(prompt)\n",
    "    end = time.time()\n",
    "    \n",
    "    print(f\"Prompt {i}: Time {end - start:.3f}s, Cache: {'HIT' if end - start < 0.1 else 'MISS'}\")\n",
    "\n",
    "# Show cache statistics\n",
    "cache_total = performance_stats['cache_hits'] + performance_stats['cache_misses']\n",
    "hit_rate = (performance_stats['cache_hits'] / cache_total * 100) if cache_total > 0 else 0\n",
    "\n",
    "print(f\"\\nüìä Cache Statistics:\")\n",
    "print(f\"   Cache hits: {performance_stats['cache_hits']}\")\n",
    "print(f\"   Cache misses: {performance_stats['cache_misses']}\")\n",
    "print(f\"   Hit rate: {hit_rate:.1f}%\")\n",
    "print(f\"   Cache size: {len(simple_cache)} entries\")\n",
    "\n",
    "print(f\"\\nüí° Caching Benefits:\")\n",
    "if hit_rate > 0:\n",
    "    print(f\"   ‚Ä¢ {hit_rate:.1f}% of requests served from cache\")\n",
    "    print(f\"   ‚Ä¢ Estimated time saved: {performance_stats['cache_hits'] * 0.3:.1f}s\")\n",
    "    print(f\"   ‚Ä¢ Reduced API costs and server load\")\n",
    "else:\n",
    "    print(\"   ‚Ä¢ No cache hits yet - benefits will show with repeated queries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept 2: Batch Processing and Async Operations\n",
    "\n",
    "Let's implement simple batch processing for better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple batch processing and async operations\n",
    "import asyncio\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "def batch_process_queries(queries: List[str], batch_size: int = 3):\n",
    "    \"\"\"Process multiple queries in batches\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    print(f\"üîÑ Processing {len(queries)} queries in batches of {batch_size}\")\n",
    "    \n",
    "    for i in range(0, len(queries), batch_size):\n",
    "        batch = queries[i:i + batch_size]\n",
    "        batch_start = time.time()\n",
    "        \n",
    "        print(f\"   Batch {i//batch_size + 1}: {len(batch)} queries\")\n",
    "        \n",
    "        # Process batch (simulate parallel processing)\n",
    "        batch_results = []\n",
    "        for query in batch:\n",
    "            # Simulate processing time (reduced due to batching)\n",
    "            time.sleep(0.05)  # Much faster than individual processing\n",
    "            batch_results.append(f\"Result for: {query}\")\n",
    "        \n",
    "        batch_end = time.time()\n",
    "        print(f\"   Batch completed in {batch_end - batch_start:.3f}s\")\n",
    "        \n",
    "        results.extend(batch_results)\n",
    "    \n",
    "    return results\n",
    "\n",
    "async def async_course_search(query: str) -> Dict[str, Any]:\n",
    "    \"\"\"Async course search simulation\"\"\"\n",
    "    # Simulate async database query\n",
    "    await asyncio.sleep(0.1)\n",
    "    \n",
    "    return {\n",
    "        'query': query,\n",
    "        'results': [f\"Course result for {query}\"],\n",
    "        'count': 1\n",
    "    }\n",
    "\n",
    "async def async_llm_call(prompt: str) -> str:\n",
    "    \"\"\"Async LLM call simulation\"\"\"\n",
    "    # Simulate async API call\n",
    "    await asyncio.sleep(0.2)\n",
    "    \n",
    "    return f\"LLM response to: {prompt[:30]}...\"\n",
    "\n",
    "async def process_student_query_async(student_query: str) -> Dict[str, Any]:\n",
    "    \"\"\"Process student query with async operations\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Run course search and LLM call concurrently\n",
    "    course_task = async_course_search(student_query)\n",
    "    llm_task = async_llm_call(f\"Help student with: {student_query}\")\n",
    "    \n",
    "    # Wait for both to complete\n",
    "    course_results, llm_response = await asyncio.gather(course_task, llm_task)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    return {\n",
    "        'query': student_query,\n",
    "        'course_results': course_results,\n",
    "        'llm_response': llm_response,\n",
    "        'processing_time': end_time - start_time\n",
    "    }\n",
    "\n",
    "# Test batch processing\n",
    "print(\"‚ö° Batch Processing Performance Test\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "test_queries = [\n",
    "    \"machine learning courses\",\n",
    "    \"data science programs\",\n",
    "    \"python programming\",\n",
    "    \"redis database\",\n",
    "    \"web development\",\n",
    "    \"artificial intelligence\",\n",
    "    \"computer vision\"\n",
    "]\n",
    "\n",
    "# Compare individual vs batch processing\n",
    "print(\"üêå Individual Processing:\")\n",
    "individual_start = time.time()\n",
    "individual_results = []\n",
    "for query in test_queries[:3]:  # Test with first 3 queries\n",
    "    time.sleep(0.15)  # Simulate individual processing time\n",
    "    individual_results.append(f\"Individual result for: {query}\")\n",
    "individual_end = time.time()\n",
    "individual_time = individual_end - individual_start\n",
    "\n",
    "print(f\"   Processed {len(individual_results)} queries in {individual_time:.3f}s\")\n",
    "print(f\"   Average: {individual_time/len(individual_results):.3f}s per query\")\n",
    "\n",
    "print(\"\\nüöÄ Batch Processing:\")\n",
    "batch_start = time.time()\n",
    "batch_results = batch_process_queries(test_queries[:3], batch_size=3)\n",
    "batch_end = time.time()\n",
    "batch_time = batch_end - batch_start\n",
    "\n",
    "print(f\"   Processed {len(batch_results)} queries in {batch_time:.3f}s\")\n",
    "print(f\"   Average: {batch_time/len(batch_results):.3f}s per query\")\n",
    "print(f\"   Speedup: {individual_time/batch_time:.1f}x faster\")\n",
    "\n",
    "# Test async operations\n",
    "print(\"\\nüîÑ Async Operations Test:\")\n",
    "\n",
    "async def test_async_performance():\n",
    "    student_queries = [\n",
    "        \"What machine learning courses are available?\",\n",
    "        \"I need help with data science prerequisites\",\n",
    "        \"Recommend courses for AI specialization\"\n",
    "    ]\n",
    "    \n",
    "    # Process queries concurrently\n",
    "    tasks = [process_student_query_async(query) for query in student_queries]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    \n",
    "    total_processing_time = sum(result['processing_time'] for result in results)\n",
    "    wall_clock_time = max(result['processing_time'] for result in results)\n",
    "    \n",
    "    print(f\"   Processed {len(results)} queries concurrently\")\n",
    "    print(f\"   Total processing time: {total_processing_time:.3f}s\")\n",
    "    print(f\"   Wall clock time: {wall_clock_time:.3f}s\")\n",
    "    print(f\"   Concurrency benefit: {total_processing_time/wall_clock_time:.1f}x speedup\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run async test\n",
    "async_results = asyncio.run(test_async_performance())\n",
    "\n",
    "print(f\"\\nüí° Performance Optimization Summary:\")\n",
    "print(f\"   ‚Ä¢ Batch processing: {individual_time/batch_time:.1f}x speedup\")\n",
    "print(f\"   ‚Ä¢ Async operations: {sum(r['processing_time'] for r in async_results)/max(r['processing_time'] for r in async_results):.1f}x speedup\")\n",
    "print(f\"   ‚Ä¢ Caching: Up to 10x speedup for repeated queries\")\n",
    "print(f\"   ‚Ä¢ Combined: Potential 50x+ improvement in throughput\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept 3: Performance Monitoring Dashboard\n",
    "\n",
    "Let's create a simple performance monitoring dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple performance monitoring dashboard\n",
    "def create_performance_dashboard():\n",
    "    \"\"\"Create a simple text-based performance dashboard\"\"\"\n",
    "    summary = get_performance_summary()\n",
    "    \n",
    "    print(\"üìä PERFORMANCE DASHBOARD\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"üìÖ Report Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print()\n",
    "    \n",
    "    # Response Time Metrics\n",
    "    print(\"‚ö° RESPONSE TIME METRICS:\")\n",
    "    print(f\"   Total Requests: {summary['total_requests']:,}\")\n",
    "    print(f\"   Average Response: {summary['avg_response_time']:.3f}s\")\n",
    "    print(f\"   95th Percentile: {summary['p95_response_time']:.3f}s\")\n",
    "    print(f\"   Min Response: {summary['min_response_time']:.3f}s\")\n",
    "    print(f\"   Max Response: {summary['max_response_time']:.3f}s\")\n",
    "    \n",
    "    # Performance Status\n",
    "    avg_time = summary['avg_response_time']\n",
    "    if avg_time < 1.0:\n",
    "        status = \"üü¢ EXCELLENT\"\n",
    "    elif avg_time < 2.0:\n",
    "        status = \"üü° GOOD\"\n",
    "    elif avg_time < 5.0:\n",
    "        status = \"üü† NEEDS IMPROVEMENT\"\n",
    "    else:\n",
    "        status = \"üî¥ POOR\"\n",
    "    \n",
    "    print(f\"   Status: {status}\")\n",
    "    print()\n",
    "    \n",
    "    # Cache Performance\n",
    "    print(\"üöÄ CACHE PERFORMANCE:\")\n",
    "    print(f\"   Hit Rate: {summary['cache_hit_rate']:.1f}%\")\n",
    "    print(f\"   Cache Hits: {summary['cache_hits']:,}\")\n",
    "    print(f\"   Cache Misses: {summary['cache_misses']:,}\")\n",
    "    \n",
    "    cache_status = \"üü¢ EXCELLENT\" if summary['cache_hit_rate'] > 70 else \"üü° GOOD\" if summary['cache_hit_rate'] > 40 else \"üî¥ POOR\"\n",
    "    print(f\"   Cache Status: {cache_status}\")\n",
    "    print()\n",
    "    \n",
    "    # Operation Breakdown\n",
    "    print(\"üîç OPERATION BREAKDOWN:\")\n",
    "    for operation, times in performance_stats['operation_times'].items():\n",
    "        if times:\n",
    "            avg_time = sum(times) / len(times)\n",
    "            total_time = sum(times)\n",
    "            print(f\"   {operation}: {avg_time:.3f}s avg, {total_time:.3f}s total ({len(times)} calls)\")\n",
    "    print()\n",
    "    \n",
    "    # Recommendations\n",
    "    print(\"üí° OPTIMIZATION RECOMMENDATIONS:\")\n",
    "    recommendations = []\n",
    "    \n",
    "    if summary['avg_response_time'] > 2.0:\n",
    "        recommendations.append(\"‚Ä¢ Implement response caching\")\n",
    "        recommendations.append(\"‚Ä¢ Optimize database queries\")\n",
    "        recommendations.append(\"‚Ä¢ Use async operations\")\n",
    "    \n",
    "    if summary['cache_hit_rate'] < 50:\n",
    "        recommendations.append(\"‚Ä¢ Increase cache TTL\")\n",
    "        recommendations.append(\"‚Ä¢ Cache more operations\")\n",
    "        recommendations.append(\"‚Ä¢ Implement smarter cache keys\")\n",
    "    \n",
    "    if summary['p95_response_time'] > summary['avg_response_time'] * 2:\n",
    "        recommendations.append(\"‚Ä¢ Investigate slow queries\")\n",
    "        recommendations.append(\"‚Ä¢ Add request timeouts\")\n",
    "        recommendations.append(\"‚Ä¢ Implement circuit breakers\")\n",
    "    \n",
    "    if not recommendations:\n",
    "        recommendations.append(\"‚Ä¢ Performance looks good!\")\n",
    "        recommendations.append(\"‚Ä¢ Monitor for scaling issues\")\n",
    "        recommendations.append(\"‚Ä¢ Consider load testing\")\n",
    "    \n",
    "    for rec in recommendations:\n",
    "        print(f\"   {rec}\")\n",
    "    \n",
    "    print()\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "def performance_health_check():\n",
    "    \"\"\"Quick performance health check\"\"\"\n",
    "    summary = get_performance_summary()\n",
    "    \n",
    "    print(\"üè• PERFORMANCE HEALTH CHECK\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    checks = [\n",
    "        (\"Average response time < 2s\", summary['avg_response_time'] < 2.0),\n",
    "        (\"95th percentile < 5s\", summary['p95_response_time'] < 5.0),\n",
    "        (\"Cache hit rate > 30%\", summary['cache_hit_rate'] > 30),\n",
    "        (\"No responses > 10s\", summary['max_response_time'] < 10.0)\n",
    "    ]\n",
    "    \n",
    "    passed = 0\n",
    "    for check_name, passed_check in checks:\n",
    "        status = \"‚úÖ\" if passed_check else \"‚ùå\"\n",
    "        print(f\"{status} {check_name}\")\n",
    "        if passed_check:\n",
    "            passed += 1\n",
    "    \n",
    "    health_score = (passed / len(checks)) * 100\n",
    "    print(f\"\\nüéØ Health Score: {health_score:.0f}%\")\n",
    "    \n",
    "    if health_score >= 80:\n",
    "        print(\"üü¢ System performance is healthy\")\n",
    "    elif health_score >= 60:\n",
    "        print(\"üü° System performance needs attention\")\n",
    "    else:\n",
    "        print(\"üî¥ System performance requires immediate action\")\n",
    "\n",
    "# Generate performance dashboard\n",
    "create_performance_dashboard()\n",
    "print()\n",
    "performance_health_check()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
