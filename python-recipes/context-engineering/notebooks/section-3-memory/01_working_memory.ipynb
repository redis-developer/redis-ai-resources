{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Redis](https://redis.io/wp-content/uploads/2024/04/Logotype.svg?auto=webp&quality=85,75&width=120)\n",
    "\n",
    "# Working Memory\n",
    "\n",
    "## Why Agents Need Memory: The Grounding Problem\n",
    "\n",
    "Before diving into implementation, let's understand the fundamental problem that memory solves.\n",
    "\n",
    "### The Grounding Problem\n",
    "\n",
    "**Grounding** means understanding what users are referring to. Natural conversation is full of references:\n",
    "\n",
    "**Without Memory:**\n",
    "```\n",
    "User: \"Tell me about CS401\"\n",
    "Agent: \"CS401 is Machine Learning. It covers supervised learning...\"\n",
    "\n",
    "User: \"What are its prerequisites?\"\n",
    "Agent: âŒ \"What does 'its' refer to? Please specify which course.\"\n",
    "\n",
    "User: \"The course we just discussed!\"\n",
    "Agent: âŒ \"I don't have access to previous messages. Which course?\"\n",
    "```\n",
    "\n",
    "**This is a terrible user experience.**\n",
    "\n",
    "### Types of References That Need Grounding\n",
    "\n",
    "**Pronouns:**\n",
    "- \"it\", \"that course\", \"those\", \"this one\"\n",
    "- \"he\", \"she\", \"they\" (referring to people)\n",
    "\n",
    "**Descriptions:**\n",
    "- \"the easy one\", \"the online course\"\n",
    "- \"my advisor\", \"that professor\"\n",
    "\n",
    "**Implicit context:**\n",
    "- \"Can I take it?\" â†’ Take what?\n",
    "- \"When does it start?\" â†’ What starts?\n",
    "\n",
    "**Temporal references:**\n",
    "- \"you mentioned\", \"earlier\", \"last time\"\n",
    "\n",
    "### How Working Memory Provides Grounding\n",
    "\n",
    "**With Working Memory:**\n",
    "```\n",
    "User: \"Tell me about CS401\"\n",
    "Agent: \"CS401 is Machine Learning. It covers...\"\n",
    "[Stores: User asked about CS401]\n",
    "\n",
    "User: \"What are its prerequisites?\"\n",
    "Agent: [Checks memory: \"its\" = CS401]\n",
    "Agent: âœ… \"CS401 requires CS201 and MATH301\"\n",
    "\n",
    "User: \"Can I take it?\"\n",
    "Agent: [Checks memory: \"it\" = CS401]\n",
    "Agent: [Checks student transcript]\n",
    "Agent: âœ… \"You've completed CS201 but still need MATH301\"\n",
    "```\n",
    "\n",
    "**Now the conversation flows naturally!**\n",
    "\n",
    "### What Working Memory Stores\n",
    "\n",
    "Working memory maintains the **current conversation context**:\n",
    "\n",
    "```\n",
    "Session: session_123\n",
    "Messages:\n",
    "  1. User: \"Tell me about CS401\"\n",
    "  2. Agent: \"CS401 is Machine Learning...\"\n",
    "  3. User: \"What are its prerequisites?\"\n",
    "  4. Agent: \"CS401 requires CS201 and MATH301\"\n",
    "  5. User: \"Can I take it?\"\n",
    "  [Current turn - needs context from messages 1-4]\n",
    "```\n",
    "\n",
    "**Each message builds on previous messages.**\n",
    "\n",
    "### Without Memory: Every Message is Isolated\n",
    "\n",
    "```\n",
    "Turn 1: User asks about CS401\n",
    "        â†’ Agent responds\n",
    "        â†’ Agent forgets everything âŒ\n",
    "\n",
    "Turn 2: User asks \"What are its prerequisites?\"\n",
    "        â†’ Agent doesn't know what \"its\" refers to âŒ\n",
    "        â†’ Conversation breaks âŒ\n",
    "```\n",
    "\n",
    "### The Problem This Notebook Solves\n",
    "\n",
    "**Working memory** stores conversation messages so that:\n",
    "\n",
    "âœ… Pronouns can be resolved (\"it\" â†’ CS401)  \n",
    "âœ… Context carries forward (knows what was discussed)  \n",
    "âœ… Multi-turn conversations work naturally  \n",
    "âœ… Users don't repeat themselves  \n",
    "\n",
    "**Now let's implement this solution.**\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "- **Working Memory**: Session-scoped storage for conversation messages and context\n",
    "- **Session Scope**: Working memory is tied to a specific conversation session\n",
    "- **Message History**: The sequence of user and assistant messages that form the conversation\n",
    "- **Grounding**: Using stored context to understand what users are referring to\n",
    "\n",
    "### Technical Implementation\n",
    "\n",
    "Working memory solves the grounding problem by:\n",
    "- Storing conversation messages so the LLM can reference earlier parts of the conversation\n",
    "- Maintaining task-specific context (like current goals, preferences mentioned in this session)\n",
    "- Persisting this information across multiple turns of the conversation\n",
    "- Providing a foundation for extracting important information to long-term storage\n",
    "\n",
    "Because working memory stores messages, we can extract long-term data from it. When using the Agent Memory Server, extraction happens automatically in the background based on a configured strategy that controls what kind of information gets extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T20:32:31.983697Z",
     "start_time": "2025-10-03T20:32:28.032067Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install the Redis Context Course package\n",
    "%pip install -q -e ../../reference-agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-03T20:32:48.128143Z",
     "start_time": "2025-10-03T20:32:48.092640Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Environment variables loaded\n",
      "   REDIS_URL: redis://localhost:6379\n",
      "   AGENT_MEMORY_URL: http://localhost:8000\n",
      "   OPENAI_API_KEY: âœ“ Set\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Verify required environment variables are set\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    raise ValueError(\n",
    "        \"OPENAI_API_KEY not found. Please create a .env file with your OpenAI API key. \"\n",
    "        \"See SETUP.md for instructions.\"\n",
    "    )\n",
    "\n",
    "print(\"âœ… Environment variables loaded\")\n",
    "print(f\"   REDIS_URL: {os.getenv('REDIS_URL', 'redis://localhost:6379')}\")\n",
    "print(f\"   AGENT_MEMORY_URL: {os.getenv('AGENT_MEMORY_URL', 'http://localhost:8000')}\")\n",
    "print(f\"   OPENAI_API_KEY: {'âœ“ Set' if os.getenv('OPENAI_API_KEY') else 'âœ— Not set'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Working Memory Structure\n",
    "\n",
    "Working memory contains the essential context for the current conversation:\n",
    "\n",
    "- **Messages**: The conversation history (user and assistant messages)\n",
    "- **Session ID**: Identifies this specific conversation\n",
    "- **User ID**: Identifies the user across sessions\n",
    "- **Task Data**: Optional task-specific context (current goals, temporary state)\n",
    "\n",
    "This structure gives the LLM everything it needs to understand the current conversation context.\n",
    "\n",
    "Let's import the memory client to work with working memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T22:01:32.779633Z",
     "start_time": "2025-10-02T22:01:32.776671Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Memory server client imported successfully\n"
     ]
    }
   ],
   "source": [
    "from redis_context_course import MemoryClient\n",
    "\n",
    "print(\"âœ… Memory server client imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Storing and Retrieving Conversation Context\n",
    "\n",
    "Let's see how working memory stores and retrieves conversation context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T22:01:39.218627Z",
     "start_time": "2025-10-02T22:01:39.167246Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Memory client initialized successfully\n",
      "ðŸ“Š User ID: demo_student_working_memory\n",
      "ðŸ“Š Session ID: session_001\n",
      "\n",
      "Working memory will store conversation messages for this session.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from agent_memory_client import MemoryClientConfig\n",
    "\n",
    "# Initialize memory client for working memory\n",
    "student_id = \"demo_student_working_memory\"\n",
    "session_id = \"session_001\"\n",
    "config = MemoryClientConfig(\n",
    "    base_url=os.getenv(\"AGENT_MEMORY_URL\", \"http://localhost:8000\"),\n",
    "    default_namespace=\"redis_university\"\n",
    ")\n",
    "memory_client = MemoryClient(config=config)\n",
    "\n",
    "print(\"âœ… Memory client initialized successfully\")\n",
    "print(f\"ðŸ“Š User ID: {student_id}\")\n",
    "print(f\"ðŸ“Š Session ID: {session_id}\")\n",
    "print(\"\\nWorking memory will store conversation messages for this session.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T22:01:47.863402Z",
     "start_time": "2025-10-02T22:01:47.590762Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¬ Simulating Conversation with Working Memory\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "ConnectError",
     "evalue": "All connection attempts failed",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mConnectError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/redis-ai-resources/python-recipes/context-engineering/venv/lib/python3.12/site-packages/httpx/_transports/default.py:101\u001b[39m, in \u001b[36mmap_httpcore_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/redis-ai-resources/python-recipes/context-engineering/venv/lib/python3.12/site-packages/httpx/_transports/default.py:394\u001b[39m, in \u001b[36mAsyncHTTPTransport.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    393\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m394\u001b[39m     resp = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pool.handle_async_request(req)\n\u001b[32m    396\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.AsyncIterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/redis-ai-resources/python-recipes/context-engineering/venv/lib/python3.12/site-packages/httpcore/_async/connection_pool.py:256\u001b[39m, in \u001b[36mAsyncConnectionPool.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    255\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/redis-ai-resources/python-recipes/context-engineering/venv/lib/python3.12/site-packages/httpcore/_async/connection_pool.py:236\u001b[39m, in \u001b[36mAsyncConnectionPool.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m connection.handle_async_request(\n\u001b[32m    237\u001b[39m         pool_request.request\n\u001b[32m    238\u001b[39m     )\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/redis-ai-resources/python-recipes/context-engineering/venv/lib/python3.12/site-packages/httpcore/_async/connection.py:101\u001b[39m, in \u001b[36mAsyncHTTPConnection.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection.handle_async_request(request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/redis-ai-resources/python-recipes/context-engineering/venv/lib/python3.12/site-packages/httpcore/_async/connection.py:78\u001b[39m, in \u001b[36mAsyncHTTPConnection.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     stream = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connect(request)\n\u001b[32m     80\u001b[39m     ssl_object = stream.get_extra_info(\u001b[33m\"\u001b[39m\u001b[33mssl_object\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/redis-ai-resources/python-recipes/context-engineering/venv/lib/python3.12/site-packages/httpcore/_async/connection.py:124\u001b[39m, in \u001b[36mAsyncHTTPConnection._connect\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mconnect_tcp\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m     stream = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._network_backend.connect_tcp(**kwargs)\n\u001b[32m    125\u001b[39m     trace.return_value = stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/redis-ai-resources/python-recipes/context-engineering/venv/lib/python3.12/site-packages/httpcore/_backends/auto.py:31\u001b[39m, in \u001b[36mAutoBackend.connect_tcp\u001b[39m\u001b[34m(self, host, port, timeout, local_address, socket_options)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._init_backend()\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.connect_tcp(\n\u001b[32m     32\u001b[39m     host,\n\u001b[32m     33\u001b[39m     port,\n\u001b[32m     34\u001b[39m     timeout=timeout,\n\u001b[32m     35\u001b[39m     local_address=local_address,\n\u001b[32m     36\u001b[39m     socket_options=socket_options,\n\u001b[32m     37\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/redis-ai-resources/python-recipes/context-engineering/venv/lib/python3.12/site-packages/httpcore/_backends/anyio.py:113\u001b[39m, in \u001b[36mAnyIOBackend.connect_tcp\u001b[39m\u001b[34m(self, host, port, timeout, local_address, socket_options)\u001b[39m\n\u001b[32m    108\u001b[39m exc_map = {\n\u001b[32m    109\u001b[39m     \u001b[38;5;167;01mTimeoutError\u001b[39;00m: ConnectTimeout,\n\u001b[32m    110\u001b[39m     \u001b[38;5;167;01mOSError\u001b[39;00m: ConnectError,\n\u001b[32m    111\u001b[39m     anyio.BrokenResourceError: ConnectError,\n\u001b[32m    112\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m anyio.fail_after(timeout):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.6/lib/python3.12/contextlib.py:158\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    160\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    161\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/redis-ai-resources/python-recipes/context-engineering/venv/lib/python3.12/site-packages/httpcore/_exceptions.py:14\u001b[39m, in \u001b[36mmap_exceptions\u001b[39m\u001b[34m(map)\u001b[39m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mConnectError\u001b[39m: All connection attempts failed",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mConnectError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Create WorkingMemory object\u001b[39;00m\n\u001b[32m     22\u001b[39m working_memory = WorkingMemory(\n\u001b[32m     23\u001b[39m     session_id=session_id,\n\u001b[32m     24\u001b[39m     user_id=student_id,\n\u001b[32m   (...)\u001b[39m\u001b[32m     27\u001b[39m     data={}\n\u001b[32m     28\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m memory_client.put_working_memory(\n\u001b[32m     31\u001b[39m     session_id=session_id,\n\u001b[32m     32\u001b[39m     memory=working_memory,\n\u001b[32m     33\u001b[39m     user_id=student_id,\n\u001b[32m     34\u001b[39m     model_name=\u001b[33m\"\u001b[39m\u001b[33mgpt-4o\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     35\u001b[39m )\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… Conversation saved to working memory\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     38\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mðŸ“Š Messages: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(messages)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/redis-ai-resources/python-recipes/context-engineering/venv/lib/python3.12/site-packages/agent_memory_client/client.py:468\u001b[39m, in \u001b[36mMemoryAPIClient.put_working_memory\u001b[39m\u001b[34m(self, session_id, memory, user_id, model_name, context_window_max)\u001b[39m\n\u001b[32m    465\u001b[39m     params[\u001b[33m\"\u001b[39m\u001b[33mcontext_window_max\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mstr\u001b[39m(effective_context_window_max)\n\u001b[32m    467\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m468\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.put(\n\u001b[32m    469\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m/v1/working-memory/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msession_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    470\u001b[39m         json=memory.model_dump(exclude_none=\u001b[38;5;28;01mTrue\u001b[39;00m, mode=\u001b[33m\"\u001b[39m\u001b[33mjson\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    471\u001b[39m         params=params,\n\u001b[32m    472\u001b[39m     )\n\u001b[32m    473\u001b[39m     response.raise_for_status()\n\u001b[32m    474\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m WorkingMemoryResponse(**response.json())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/redis-ai-resources/python-recipes/context-engineering/venv/lib/python3.12/site-packages/httpx/_client.py:1896\u001b[39m, in \u001b[36mAsyncClient.put\u001b[39m\u001b[34m(self, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[39m\n\u001b[32m   1875\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mput\u001b[39m(\n\u001b[32m   1876\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1877\u001b[39m     url: URL | \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1889\u001b[39m     extensions: RequestExtensions | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1890\u001b[39m ) -> Response:\n\u001b[32m   1891\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1892\u001b[39m \u001b[33;03m    Send a `PUT` request.\u001b[39;00m\n\u001b[32m   1893\u001b[39m \n\u001b[32m   1894\u001b[39m \u001b[33;03m    **Parameters**: See `httpx.request`.\u001b[39;00m\n\u001b[32m   1895\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1896\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(\n\u001b[32m   1897\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPUT\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1898\u001b[39m         url,\n\u001b[32m   1899\u001b[39m         content=content,\n\u001b[32m   1900\u001b[39m         data=data,\n\u001b[32m   1901\u001b[39m         files=files,\n\u001b[32m   1902\u001b[39m         json=json,\n\u001b[32m   1903\u001b[39m         params=params,\n\u001b[32m   1904\u001b[39m         headers=headers,\n\u001b[32m   1905\u001b[39m         cookies=cookies,\n\u001b[32m   1906\u001b[39m         auth=auth,\n\u001b[32m   1907\u001b[39m         follow_redirects=follow_redirects,\n\u001b[32m   1908\u001b[39m         timeout=timeout,\n\u001b[32m   1909\u001b[39m         extensions=extensions,\n\u001b[32m   1910\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/redis-ai-resources/python-recipes/context-engineering/venv/lib/python3.12/site-packages/httpx/_client.py:1540\u001b[39m, in \u001b[36mAsyncClient.request\u001b[39m\u001b[34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[39m\n\u001b[32m   1525\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m   1527\u001b[39m request = \u001b[38;5;28mself\u001b[39m.build_request(\n\u001b[32m   1528\u001b[39m     method=method,\n\u001b[32m   1529\u001b[39m     url=url,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1538\u001b[39m     extensions=extensions,\n\u001b[32m   1539\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1540\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.send(request, auth=auth, follow_redirects=follow_redirects)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/redis-ai-resources/python-recipes/context-engineering/venv/lib/python3.12/site-packages/httpx/_client.py:1629\u001b[39m, in \u001b[36mAsyncClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m   1625\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m   1627\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m-> \u001b[39m\u001b[32m1629\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_handling_auth(\n\u001b[32m   1630\u001b[39m     request,\n\u001b[32m   1631\u001b[39m     auth=auth,\n\u001b[32m   1632\u001b[39m     follow_redirects=follow_redirects,\n\u001b[32m   1633\u001b[39m     history=[],\n\u001b[32m   1634\u001b[39m )\n\u001b[32m   1635\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1636\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/redis-ai-resources/python-recipes/context-engineering/venv/lib/python3.12/site-packages/httpx/_client.py:1657\u001b[39m, in \u001b[36mAsyncClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m   1654\u001b[39m request = \u001b[38;5;28;01mawait\u001b[39;00m auth_flow.\u001b[34m__anext__\u001b[39m()\n\u001b[32m   1656\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1657\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_handling_redirects(\n\u001b[32m   1658\u001b[39m         request,\n\u001b[32m   1659\u001b[39m         follow_redirects=follow_redirects,\n\u001b[32m   1660\u001b[39m         history=history,\n\u001b[32m   1661\u001b[39m     )\n\u001b[32m   1662\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1663\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/redis-ai-resources/python-recipes/context-engineering/venv/lib/python3.12/site-packages/httpx/_client.py:1694\u001b[39m, in \u001b[36mAsyncClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m   1691\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m   1692\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m hook(request)\n\u001b[32m-> \u001b[39m\u001b[32m1694\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_single_request(request)\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1696\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/redis-ai-resources/python-recipes/context-engineering/venv/lib/python3.12/site-packages/httpx/_client.py:1730\u001b[39m, in \u001b[36mAsyncClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1725\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1726\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an sync request with an AsyncClient instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1727\u001b[39m     )\n\u001b[32m   1729\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1730\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m transport.handle_async_request(request)\n\u001b[32m   1732\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, AsyncByteStream)\n\u001b[32m   1733\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/redis-ai-resources/python-recipes/context-engineering/venv/lib/python3.12/site-packages/httpx/_transports/default.py:393\u001b[39m, in \u001b[36mAsyncHTTPTransport.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhttpcore\u001b[39;00m\n\u001b[32m    381\u001b[39m req = httpcore.Request(\n\u001b[32m    382\u001b[39m     method=request.method,\n\u001b[32m    383\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    391\u001b[39m     extensions=request.extensions,\n\u001b[32m    392\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m    394\u001b[39m     resp = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pool.handle_async_request(req)\n\u001b[32m    396\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.AsyncIterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.6/lib/python3.12/contextlib.py:158\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    156\u001b[39m     value = typ()\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    160\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    161\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/redis-ai-resources/python-recipes/context-engineering/venv/lib/python3.12/site-packages/httpx/_transports/default.py:118\u001b[39m, in \u001b[36mmap_httpcore_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    117\u001b[39m message = \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mConnectError\u001b[39m: All connection attempts failed"
     ]
    }
   ],
   "source": [
    "# Simulate a conversation using working memory\n",
    "\n",
    "print(\"ðŸ’¬ Simulating Conversation with Working Memory\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create messages for the conversation\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"I prefer online courses because I work part-time\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"I understand you prefer online courses due to your work schedule.\"},\n",
    "    {\"role\": \"user\", \"content\": \"My goal is to specialize in machine learning\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Machine learning is an excellent specialization!\"},\n",
    "    {\"role\": \"user\", \"content\": \"What courses do you recommend?\"},\n",
    "]\n",
    "\n",
    "# Save to working memory\n",
    "from agent_memory_client.models import WorkingMemory, MemoryMessage\n",
    "\n",
    "# Convert messages to MemoryMessage format\n",
    "memory_messages = [MemoryMessage(**msg) for msg in messages]\n",
    "\n",
    "# Create WorkingMemory object\n",
    "working_memory = WorkingMemory(\n",
    "    session_id=session_id,\n",
    "    user_id=student_id,\n",
    "    messages=memory_messages,\n",
    "    memories=[],\n",
    "    data={}\n",
    ")\n",
    "\n",
    "await memory_client.put_working_memory(\n",
    "    session_id=session_id,\n",
    "    memory=working_memory,\n",
    "    user_id=student_id,\n",
    "    model_name=\"gpt-4o\"\n",
    ")\n",
    "\n",
    "print(\"âœ… Conversation saved to working memory\")\n",
    "print(f\"ðŸ“Š Messages: {len(messages)}\")\n",
    "print(\"\\nThese messages are now available as context for the LLM.\")\n",
    "print(\"The LLM can reference earlier parts of the conversation.\")\n",
    "\n",
    "# Retrieve working memory\n",
    "_, working_memory = await memory_client.get_or_create_working_memory(\n",
    "    session_id=session_id,\n",
    "    model_name=\"gpt-4o\",\n",
    "    user_id=student_id,\n",
    ")\n",
    "\n",
    "if working_memory:\n",
    "    print(f\"\\nðŸ“‹ Retrieved {len(working_memory.messages)} messages from working memory\")\n",
    "    print(\"This is the conversation context that would be provided to the LLM.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Automatic Extraction to Long-Term Memory\n",
    "\n",
    "Because working memory stores messages, we can extract important long-term information from it. When using the Agent Memory Server, this extraction happens automatically in the background.\n",
    "\n",
    "The extraction strategy controls what kind of information gets extracted:\n",
    "- User preferences (e.g., \"I prefer online courses\")\n",
    "- Goals (e.g., \"I want to specialize in machine learning\")\n",
    "- Important facts (e.g., \"I work part-time\")\n",
    "- Key decisions or outcomes from the conversation\n",
    "\n",
    "This extracted information becomes long-term memory that persists across sessions.\n",
    "\n",
    "Let's check what information was automatically extracted from our working memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what was extracted to long-term memory\n",
    "import asyncio\n",
    "from agent_memory_client import MemoryAPIClient as MemoryClient, MemoryClientConfig\n",
    "\n",
    "# Ensure memory_client is defined (in case cells are run out of order)\n",
    "if 'memory_client' not in globals():\n",
    "    # Initialize memory client with proper config\n",
    "    import os\n",
    "    config = MemoryClientConfig(\n",
    "        base_url=os.getenv(\"AGENT_MEMORY_URL\", \"http://localhost:8000\"),\n",
    "        default_namespace=\"redis_university\"\n",
    "    )\n",
    "    memory_client = MemoryClient(config=config)\n",
    "\n",
    "await asyncio.sleep(2)  # Give the extraction process time to complete\n",
    "\n",
    "# Search for extracted memories\n",
    "extracted_memories = await memory_client.search_long_term_memory(\n",
    "    text=\"preferences goals\",\n",
    "    limit=10\n",
    ")\n",
    "\n",
    "print(\"ðŸ§  Extracted to Long-term Memory\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if extracted_memories.memories:\n",
    "    for i, memory in enumerate(extracted_memories.memories, 1):\n",
    "        print(f\"{i}. {memory.text}\")\n",
    "        print(f\"   Type: {memory.memory_type} | Topics: {', '.join(memory.topics)}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"No memories extracted yet (extraction may take a moment)\")\n",
    "    print(\"\\nThe Agent Memory Server automatically extracts:\")\n",
    "    print(\"- User preferences (e.g., 'prefers online courses')\")\n",
    "    print(\"- Goals (e.g., 'wants to specialize in machine learning')\")\n",
    "    print(\"- Important facts (e.g., 'works part-time')\")\n",
    "    print(\"\\nThis happens in the background based on the configured extraction strategy.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Summary\n",
    "\n",
    "In this notebook, you learned:\n",
    "\n",
    "- âœ… **The Core Problem**: LLMs are stateless and need working memory to maintain conversation context\n",
    "- âœ… **Working Memory Solution**: Stores messages and task-specific context for the current session\n",
    "- âœ… **Message Storage**: Conversation history gives the LLM knowledge of what was said earlier\n",
    "- âœ… **Automatic Extraction**: Important information is extracted to long-term memory in the background\n",
    "- âœ… **Extraction Strategy**: Controls what kind of information gets extracted from working memory\n",
    "\n",
    "**Key API Methods:**\n",
    "```python\n",
    "# Save working memory (stores messages for this session)\n",
    "await memory_client.put_working_memory(session_id, memory, user_id, model_name)\n",
    "\n",
    "# Retrieve working memory (gets conversation context)\n",
    "_, working_memory = await memory_client.get_or_create_working_memory(\n",
    "    session_id, model_name, user_id\n",
    ")\n",
    "\n",
    "# Search long-term memories (extracted from working memory)\n",
    "memories = await memory_client.search_long_term_memory(text, limit)\n",
    "```\n",
    "\n",
    "**The Key Insight:**\n",
    "Working memory solves the fundamental problem of giving LLMs knowledge of the current conversation. Because it stores messages, we can also extract long-term data from it. The extraction strategy controls what gets extracted, and this happens automatically in the background when using the Agent Memory Server.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "See the next notebooks to learn about:\n",
    "- Long-term memory and how it persists across sessions\n",
    "- Memory tools that give LLMs explicit control over what gets remembered\n",
    "- Integrating working and long-term memory in your applications"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
