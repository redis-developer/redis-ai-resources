{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Redis](https://redis.io/wp-content/uploads/2024/04/Logotype.svg?auto=webp&quality=85,75&width=120)\n",
        "\n",
        "# Working Memory with Long-Term Extraction Strategies\n",
        "\n",
        "## Introduction\n",
        "\n",
        "This notebook demonstrates how to implement **working memory** with configurable **long-term extraction strategies** that inform memory management tools about when and how to extract important information from working memory to long-term storage.\n",
        "\n",
        "### Key Concepts\n",
        "\n",
        "- **Working Memory**: Persistent storage for task-focused context (conversation messages, task-related data)\n",
        "- **Long-term Memory**: Cross-session knowledge (user preferences, important facts learned over time)\n",
        "- **Long-Term Extraction Strategy**: Configurable logic for when/how to move important information from working to long-term memory\n",
        "- **Strategy-Aware Tools**: Memory tools that understand the extraction strategy and make intelligent decisions\n",
        "- **Context-Informed LLM**: The LLM receives information about the extraction strategy to make better memory management decisions\n",
        "\n",
        "### The Problem We're Solving\n",
        "\n",
        "Previously, memory tools like `add_memories_to_working_memory` and `create_memory` operated without knowledge of:\n",
        "- When memories should be extracted from working memory\n",
        "- What criteria determine memory importance\n",
        "- How the working memory's extraction strategy affects tool behavior\n",
        "\n",
        "This notebook shows how to solve this by making tools **extraction strategy aware**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install the Redis Context Course package\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Install the package in development mode\n",
        "package_path = \"../../reference-agent\"\n",
        "result = subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"-e\", package_path], \n",
        "                      capture_output=True, text=True)\n",
        "if result.returncode == 0:\n",
        "    print(\"✅ Package installed successfully\")\n",
        "else:\n",
        "    print(f\"❌ Package installation failed: {result.stderr}\")\n",
        "    raise RuntimeError(f\"Failed to install package: {result.stderr}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# Set up environment - handle both interactive and CI environments\n",
        "def _set_env(key: str):\n",
        "    if key not in os.environ:\n",
        "        # Check if we're in an interactive environment\n",
        "        if hasattr(sys.stdin, 'isatty') and sys.stdin.isatty():\n",
        "            import getpass\n",
        "            os.environ[key] = getpass.getpass(f\"{key}: \")\n",
        "        else:\n",
        "            # Non-interactive environment (like CI)\n",
        "            print(f\"⚠️  {key} not found in environment. Some features may not work.\")\n",
        "            pass  # Let it fail if key is actually needed\n",
        "\n",
        "_set_env(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Set Redis URL\n",
        "os.environ[\"REDIS_URL\"] = \"redis://localhost:6379\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Working Memory Components\n",
        "\n",
        "Let's explore the key components of our working memory system:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import memory components\n",
        "from redis_context_course import MemoryClient\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "\n",
        "print(\"✅ Memory components imported successfully\")\n",
        "print(\"\\nNote: This notebook demonstrates working memory concepts.\")\n",
        "print(\"The MemoryClient provides working memory via put_working_memory() and get_or_create_working_memory()\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Long-Term Extraction Strategies\n",
        "\n",
        "Extraction strategies define **when** and **how** memories should be moved from working memory to long-term storage:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Conceptual Example: Extraction Strategies**\n",
        "\n",
        "In a production system, you would define extraction strategies that determine when to move memories from working to long-term storage:\n",
        "\n",
        "```python\n",
        "# Strategy 1: Message Count Strategy\n",
        "strategy1 = MessageCountStrategy(message_threshold=5, min_importance=0.6)\n",
        "# Triggers extraction after 5 messages, only for memories with importance >= 0.6\n",
        "\n",
        "# Strategy 2: More aggressive extraction\n",
        "strategy2 = MessageCountStrategy(message_threshold=3, min_importance=0.4)\n",
        "# Triggers extraction after 3 messages, with lower importance threshold\n",
        "```\n",
        "\n",
        "**Importance Calculation Examples:**\n",
        "- \"I prefer online courses\" → importance: 0.85 (preference)\n",
        "- \"My goal is to become a data scientist\" → importance: 0.90 (goal)\n",
        "- \"What time is it?\" → importance: 0.10 (trivial)\n",
        "- \"I love machine learning and want to specialize in it\" → importance: 0.95 (strong preference + goal)\n",
        "- \"The weather is nice today\" → importance: 0.15 (small talk)\n",
        "\n",
        "The Agent Memory Server automatically handles this extraction when you save working memory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Working Memory in Action\n",
        "\n",
        "Let's see how working memory operates with an extraction strategy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize memory client for working memory\n",
        "student_id = \"demo_student_working_memory\"\n",
        "session_id = \"session_001\"\n",
        "\n",
        "# The MemoryClient handles working memory automatically\n",
        "# Initialize memory client with proper config\n",
        "import os\n",
        "config = MemoryClientConfig(\n",
        "    base_url=os.getenv(\"AGENT_MEMORY_URL\", \"http://localhost:8000\"),\n",
        "    default_namespace=\"redis_university\"\n",
        ")\n",
        "memory_client = MemoryClient(config=config)\n",
        "\n",
        "print(\"✅ Memory client initialized successfully\")\n",
        "print(f\"📊 User ID: {student_id}\")\n",
        "print(f\"📊 Session ID: {session_id}\")\n",
        "print(\"\\nThe Agent Memory Server automatically extracts important information\")\n",
        "print(\"from working memory to long-term storage.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simulate a conversation using working memory\n",
        "from agent_memory_client import MemoryAPIClient as MemoryClient, MemoryClientConfig\n",
        "\n",
        "# Ensure memory_client and session_id are defined (in case cells are run out of order)\n",
        "if 'memory_client' not in globals():\n",
        "    # Initialize memory client with proper config\n",
        "    import os\n",
        "    config = MemoryClientConfig(\n",
        "        base_url=os.getenv(\"AGENT_MEMORY_URL\", \"http://localhost:8000\"),\n",
        "        default_namespace=\"redis_university\"\n",
        "    )\n",
        "    memory_client = MemoryClient(config=config)\n",
        "if 'session_id' not in globals():\n",
        "    session_id = \"session_001\"\n",
        "\n",
        "print(\"💬 Simulating Conversation with Working Memory\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Create messages for the conversation\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"I prefer online courses because I work part-time\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"I understand you prefer online courses due to your work schedule.\"},\n",
        "    {\"role\": \"user\", \"content\": \"My goal is to specialize in machine learning\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"Machine learning is an excellent specialization!\"},\n",
        "    {\"role\": \"user\", \"content\": \"What courses do you recommend?\"},\n",
        "]\n",
        "\n",
        "# Save to working memory\n",
        "from agent_memory_client import WorkingMemory, MemoryMessage\n",
        "\n",
        "# Convert messages to MemoryMessage format\n",
        "memory_messages = [MemoryMessage(**msg) for msg in messages]\n",
        "\n",
        "# Create WorkingMemory object\n",
        "working_memory = WorkingMemory(\n",
        "    session_id=session_id,\n",
        "    user_id=\"demo_user\",\n",
        "    messages=memory_messages,\n",
        "    memories=[],\n",
        "    data={}\n",
        ")\n",
        "\n",
        "await memory_client.put_working_memory(\n",
        "    session_id=session_id,\n",
        "    memory=working_memory,\n",
        "    user_id=\"demo_user\",\n",
        "    model_name=\"gpt-4o\"\n",
        ")\n",
        "\n",
        "print(\"✅ Conversation saved to working memory\")\n",
        "print(f\"📊 Messages: {len(messages)}\")\n",
        "print(\"\\nThe Agent Memory Server will automatically extract important information\")\n",
        "print(\"like preferences and goals to long-term memory.\")\n",
        "\n",
        "# Retrieve working memory\n",
        "_, working_memory = await memory_client.get_or_create_working_memory(\n",
        "    session_id=session_id,\n",
        "    model_name=\"gpt-4o\"\n",
        ")\n",
        "\n",
        "if working_memory:\n",
        "    print(f\"\\n📋 Retrieved {len(working_memory.messages)} messages from working memory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Memory Tools with Agent Memory Server\n",
        "\n",
        "The Agent Memory Server provides tools for managing memories. You can use the built-in tools from the `redis_context_course` package:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import memory tools\n",
        "from redis_context_course import create_memory_tools, MemoryClient\n",
        "\n",
        "# Ensure memory_client is defined (in case cells are run out of order)\n",
        "if 'memory_client' not in globals():\n",
        "    # Initialize memory client with proper config\n",
        "    import os\n",
        "    config = MemoryClientConfig(\n",
        "        base_url=os.getenv(\"AGENT_MEMORY_URL\", \"http://localhost:8000\"),\n",
        "        default_namespace=\"redis_university\"\n",
        "    )\n",
        "    memory_client = MemoryClient(config=config)\n",
        "\n",
        "# Create memory tools for this user\n",
        "memory_tools = create_memory_tools(memory_client)\n",
        "\n",
        "print(\"🛠️  Available Memory Tools\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "for tool in memory_tools:\n",
        "    print(f\"📋 {tool.name}\")\n",
        "    print(f\"   Description: {tool.description.split('.')[0]}...\")\n",
        "    print()\n",
        "\n",
        "print(\"\\nThese tools allow the LLM to:\")\n",
        "print(\"- Store important information explicitly\")\n",
        "print(\"- Search for relevant memories\")\n",
        "print(\"- Control what gets remembered\")\n",
        "print(\"\\nSee notebook 04_memory_tools.ipynb for detailed examples.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Automatic Extraction by Agent Memory Server\n",
        "\n",
        "The Agent Memory Server automatically extracts important information from working memory to long-term storage. You don't need to manually configure extraction strategies - it's handled automatically based on the content and context of the conversation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check what was extracted to long-term memory\n",
        "import asyncio\n",
        "from agent_memory_client import MemoryAPIClient as MemoryClient, MemoryClientConfig\n",
        "\n",
        "# Ensure memory_client is defined (in case cells are run out of order)\n",
        "if 'memory_client' not in globals():\n",
        "    # Initialize memory client with proper config\n",
        "    import os\n",
        "    config = MemoryClientConfig(\n",
        "        base_url=os.getenv(\"AGENT_MEMORY_URL\", \"http://localhost:8000\"),\n",
        "        default_namespace=\"redis_university\"\n",
        "    )\n",
        "    memory_client = MemoryClient(config=config)\n",
        "\n",
        "await asyncio.sleep(2)  # Give the extraction process time to complete\n",
        "\n",
        "# Search for extracted memories\n",
        "extracted_memories = await memory_client.search_long_term_memory(\n",
        "    query=\"preferences goals\",\n",
        "    limit=10\n",
        ")\n",
        "\n",
        "print(\"🧠 Extracted to Long-term Memory\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "if extracted_memories.memories:\n",
        "    for i, memory in enumerate(extracted_memories.memories, 1):\n",
        "        print(f\"{i}. {memory.text}\")\n",
        "        print(f\"   Type: {memory.memory_type} | Topics: {', '.join(memory.topics)}\")\n",
        "        print()\n",
        "else:\n",
        "    print(\"No memories extracted yet (extraction may take a moment)\")\n",
        "    print(\"\\nThe Agent Memory Server extracts:\")\n",
        "    print(\"- User preferences (e.g., 'prefers online courses')\")\n",
        "    print(\"- Goals (e.g., 'wants to specialize in machine learning')\")\n",
        "    print(\"- Important facts (e.g., 'works part-time')\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Summary\n",
        "\n",
        "In this notebook, you learned:\n",
        "\n",
        "- ✅ Working memory stores session-scoped conversation context\n",
        "- ✅ The Agent Memory Server automatically extracts important information\n",
        "- ✅ Extraction happens asynchronously in the background\n",
        "- ✅ You can provide memory tools to give the LLM explicit control\n",
        "- ✅ The MemoryClient provides a simple API for working memory operations\n",
        "\n",
        "**Key API Methods:**\n",
        "```python\n",
        "# Save working memory\n",
        "await memory_client.save_working_memory(session_id, messages)\n",
        "\n",
        "# Retrieve working memory\n",
        "working_memory = await memory_client.get_working_memory(session_id, model_name)\n",
        "\n",
        "# Search long-term memories\n",
        "memories = await memory_client.search_memories(query, limit)\n",
        "```\n",
        "\n",
        "See the next notebooks for more on long-term memory and memory integration!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Benefits\n",
        "\n",
        "### ✅ **Strategy Awareness**\n",
        "- Memory tools understand the current extraction strategy\n",
        "- Tools can make intelligent decisions about memory placement\n",
        "- LLM receives context about when extraction will happen\n",
        "\n",
        "### ✅ **Intelligent Memory Management**\n",
        "- High-importance memories can bypass working memory\n",
        "- Extraction happens automatically based on configurable triggers\n",
        "- Memory tools coordinate with extraction strategy\n",
        "\n",
        "### ✅ **Configurable Behavior**\n",
        "- Different extraction strategies for different use cases\n",
        "- Importance calculation can be customized\n",
        "- Trigger conditions are flexible and extensible\n",
        "\n",
        "### ✅ **Context-Informed Decisions**\n",
        "- Tools include strategy context in their descriptions\n",
        "- LLM can make better decisions about memory management\n",
        "- System prompt includes working memory status\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "This working memory system with extraction strategy awareness provides a foundation for:\n",
        "\n",
        "1. **Custom Extraction Strategies**: Implement time-based, importance-threshold, or conversation-end strategies\n",
        "2. **Advanced Importance Calculation**: Use NLP techniques for better importance scoring\n",
        "3. **Multi-Modal Memory**: Extend to handle different types of content (text, images, etc.)\n",
        "4. **Memory Hierarchies**: Implement multiple levels of memory with different retention policies\n",
        "\n",
        "The key insight is that **memory tools should be aware of the memory management strategy** to make intelligent decisions about when and how to store information."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
