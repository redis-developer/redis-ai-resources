{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Memory Integration: Combining Working and Long-term Memory\n",
        "\n",
        "## Introduction\n",
        "\n",
        "In this notebook, you'll learn how to integrate working memory and long-term memory to create a complete memory system for your agent. You'll see how these two types of memory work together to provide both conversation context and persistent knowledge.\n",
        "\n",
        "### What You'll Learn\n",
        "\n",
        "- How working and long-term memory complement each other\n",
        "- When to use each type of memory\n",
        "- How to build a complete memory flow\n",
        "- How automatic extraction works\n",
        "- How to test multi-session conversations\n",
        "\n",
        "### Prerequisites\n",
        "\n",
        "- Completed `01_working_memory_with_extraction_strategies.ipynb`\n",
        "- Completed `02_long_term_memory.ipynb`\n",
        "- Redis 8 running locally\n",
        "- Agent Memory Server running\n",
        "- OpenAI API key set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Concepts: Memory Integration\n",
        "\n",
        "### The Complete Memory Architecture\n",
        "\n",
        "A production agent needs both types of memory:\n",
        "\n",
        "```\n",
        "┌─────────────────────────────────────────────────┐\n",
        "│              User Query                         │\n",
        "└─────────────────────────────────────────────────┘\n",
        "                      ↓\n",
        "┌─────────────────────────────────────────────────┐\n",
        "│  1. Load Working Memory (current conversation)  │\n",
        "└─────────────────────────────────────────────────┘\n",
        "                      ↓\n",
        "┌─────────────────────────────────────────────────┐\n",
        "│  2. Search Long-term Memory (relevant facts)    │\n",
        "└─────────────────────────────────────────────────┘\n",
        "                      ↓\n",
        "┌─────────────────────────────────────────────────┐\n",
        "│  3. Agent Processes with Full Context           │\n",
        "└─────────────────────────────────────────────────┘\n",
        "                      ↓\n",
        "┌─────────────────────────────────────────────────┐\n",
        "│  4. Save Working Memory (with new messages)     │\n",
        "│     → Automatic extraction to long-term         │\n",
        "└─────────────────────────────────────────────────┘\n",
        "```\n",
        "\n",
        "### Memory Flow in Detail\n",
        "\n",
        "**Turn 1:**\n",
        "1. Load working memory (empty)\n",
        "2. Search long-term memory (empty)\n",
        "3. Process query\n",
        "4. Save working memory\n",
        "5. Extract important facts → long-term memory\n",
        "\n",
        "**Turn 2 (same session):**\n",
        "1. Load working memory (has Turn 1 messages)\n",
        "2. Search long-term memory (has extracted facts)\n",
        "3. Process query with full context\n",
        "4. Save working memory (Turn 1 + Turn 2)\n",
        "5. Extract new facts → long-term memory\n",
        "\n",
        "**Turn 3 (new session, same user):**\n",
        "1. Load working memory (empty - new session)\n",
        "2. Search long-term memory (has all extracted facts)\n",
        "3. Process query with long-term context\n",
        "4. Save working memory (Turn 3 only)\n",
        "5. Extract facts → long-term memory\n",
        "\n",
        "### When to Use Each Memory Type\n",
        "\n",
        "| Scenario | Working Memory | Long-term Memory |\n",
        "|----------|----------------|------------------|\n",
        "| Current conversation | ✅ Always | ❌ No |\n",
        "| User preferences | ❌ No | ✅ Yes |\n",
        "| Recent context | ✅ Yes | ❌ No |\n",
        "| Important facts | ❌ No | ✅ Yes |\n",
        "| Cross-session data | ❌ No | ✅ Yes |\n",
        "| Temporary info | ✅ Yes | ❌ No |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import asyncio\n",
        "from datetime import datetime\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
        "from agent_memory_client import MemoryAPIClient as MemoryClient, MemoryClientConfig\n",
        "\n",
        "# Initialize\n",
        "student_id = \"student_456\"\n",
        "session_id_1 = \"session_001\"\n",
        "session_id_2 = \"session_002\"\n",
        "\n",
        "# Initialize memory client with proper config\n",
        "import os\n",
        "config = MemoryClientConfig(\n",
        "    base_url=os.getenv(\"AGENT_MEMORY_URL\", \"http://localhost:8000\"),\n",
        "    default_namespace=\"redis_university\"\n",
        ")\n",
        "memory_client = MemoryClient(config=config)\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.7)\n",
        "\n",
        "print(f\"✅ Setup complete for {student_id}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hands-on: Building Complete Memory Flow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Session 1, Turn 1: First Interaction\n",
        "\n",
        "Let's simulate the first turn of a conversation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 80)\n",
        "print(\"SESSION 1, TURN 1\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Step 1: Load working memory (empty for first turn)\n",
        "print(\"\\n1. Loading working memory...\")\n",
        "_, working_memory = await memory_client.get_or_create_working_memory(\n",
        "    session_id=session_id_1,\n",
        "    model_name=\"gpt-4o\"\n",
        ")\n",
        "print(f\"   Messages in working memory: {len(working_memory.messages) if working_memory else 0}\")\n",
        "\n",
        "# Step 2: Search long-term memory (empty for first interaction)\n",
        "print(\"\\n2. Searching long-term memory...\")\n",
        "user_query = \"Hi! I'm interested in learning about databases.\"\n",
        "long_term_memories = await memory_client.search_long_term_memory(\n",
        "    query=user_query,\n",
        "    limit=3\n",
        ")\n",
        "print(f\"   Relevant memories found: {len(long_term_memories)}\")\n",
        "\n",
        "# Step 3: Process with LLM\n",
        "print(\"\\n3. Processing with LLM...\")\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are a helpful class scheduling agent for Redis University.\"),\n",
        "    HumanMessage(content=user_query)\n",
        "]\n",
        "response = llm.invoke(messages)\n",
        "print(f\"\\n   User: {user_query}\")\n",
        "print(f\"   Agent: {response.content}\")\n",
        "\n",
        "# Step 4: Save working memory\n",
        "print(\"\\n4. Saving working memory...\")\n",
        "from agent_memory_client import WorkingMemory, MemoryMessage\n",
        "\n",
        "# Convert messages to MemoryMessage format\n",
        "memory_messages = [MemoryMessage(**msg) for msg in []\n",
        "\n",
        "# Create WorkingMemory object\n",
        "working_memory = WorkingMemory(\n",
        "    session_id=session_id_1,\n",
        "    user_id=\"demo_user\",\n",
        "    messages=memory_messages,\n",
        "    memories=[],\n",
        "    data={}\n",
        ")\n",
        "\n",
        "await memory_client.put_working_memory(\n",
        "    session_id=session_id_1,\n",
        "    memory=working_memory,\n",
        "    user_id=\"demo_user\",\n",
        "    model_name=\"gpt-4o\"\n",
        ")\n",
        "print(\"   ✅ Working memory saved\")\n",
        "print(\"   ✅ Agent Memory Server will automatically extract important facts to long-term memory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Session 1, Turn 2: Continuing the Conversation\n",
        "\n",
        "Let's continue the conversation in the same session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"SESSION 1, TURN 2\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Step 1: Load working memory (now has Turn 1)\n",
        "print(\"\\n1. Loading working memory...\")\n",
        "_, working_memory = await memory_client.get_or_create_working_memory(\n",
        "    session_id=session_id_1,\n",
        "    model_name=\"gpt-4o\"\n",
        ")\n",
        "print(f\"   Messages in working memory: {len(working_memory.messages)}\")\n",
        "print(\"   Previous context available: ✅\")\n",
        "\n",
        "# Step 2: Search long-term memory\n",
        "print(\"\\n2. Searching long-term memory...\")\n",
        "user_query_2 = \"I prefer online courses and morning classes.\"\n",
        "long_term_memories = await memory_client.search_long_term_memory(\n",
        "    query=user_query_2,\n",
        "    limit=3\n",
        ")\n",
        "print(f\"   Relevant memories found: {len(long_term_memories)}\")\n",
        "\n",
        "# Step 3: Process with LLM (with conversation history)\n",
        "print(\"\\n3. Processing with LLM...\")\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are a helpful class scheduling agent for Redis University.\"),\n",
        "]\n",
        "\n",
        "# Add working memory messages\n",
        "for msg in working_memory.messages:\n",
        "    if msg.role == \"user\":\n",
        "        messages.append(HumanMessage(content=msg.content))\n",
        "    elif msg.role == \"assistant\":\n",
        "        messages.append(AIMessage(content=msg.content))\n",
        "\n",
        "# Add new query\n",
        "messages.append(HumanMessage(content=user_query_2))\n",
        "\n",
        "response = llm.invoke(messages)\n",
        "print(f\"\\n   User: {user_query_2}\")\n",
        "print(f\"   Agent: {response.content}\")\n",
        "\n",
        "# Step 4: Save working memory (with both turns)\n",
        "print(\"\\n4. Saving working memory...\")\n",
        "all_messages = [\n",
        "    {\"role\": msg.role, \"content\": msg.content}\n",
        "    for msg in working_memory.messages\n",
        "]\n",
        "all_messages.extend([\n",
        "    {\"role\": \"user\", \"content\": user_query_2},\n",
        "    {\"role\": \"assistant\", \"content\": response.content}\n",
        "])\n",
        "\n",
        "from agent_memory_client import WorkingMemory, MemoryMessage\n",
        "\n",
        "# Convert messages to MemoryMessage format\n",
        "memory_messages = [MemoryMessage(**msg) for msg in all_messages]\n",
        "\n",
        "# Create WorkingMemory object\n",
        "working_memory = WorkingMemory(\n",
        "    session_id=session_id_1,\n",
        "    user_id=\"demo_user\",\n",
        "    messages=memory_messages,\n",
        "    memories=[],\n",
        "    data={}\n",
        ")\n",
        "\n",
        "await memory_client.put_working_memory(\n",
        "    session_id=session_id_1,\n",
        "    memory=working_memory,\n",
        "    user_id=\"demo_user\",\n",
        "    model_name=\"gpt-4o\"\n",
        ")\n",
        "print(\"   ✅ Working memory saved with both turns\")\n",
        "print(\"   ✅ Preferences will be extracted to long-term memory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Verify Automatic Extraction\n",
        "\n",
        "Let's check if the Agent Memory Server extracted facts to long-term memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Wait a moment for extraction to complete\n",
        "print(\"Waiting for automatic extraction...\")\n",
        "await asyncio.sleep(2)\n",
        "\n",
        "# Search for extracted memories\n",
        "print(\"\\nSearching for extracted memories...\\n\")\n",
        "memories = await memory_client.search_long_term_memory(\n",
        "    query=\"student preferences\",\n",
        "    limit=5\n",
        ")\n",
        "\n",
        "if memories:\n",
        "    print(\"✅ Extracted memories found:\\n\")\n",
        "    for i, memory in enumerate(memories, 1):\n",
        "        print(f\"{i}. {memory.text}\")\n",
        "        print(f\"   Type: {memory.memory_type} | Topics: {', '.join(memory.topics)}\")\n",
        "        print()\n",
        "else:\n",
        "    print(\"⏳ No memories extracted yet (extraction may take a moment)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Session 2: New Session, Same User\n",
        "\n",
        "Now let's start a completely new session with the same user. Working memory will be empty, but long-term memory persists."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"SESSION 2, TURN 1 (New Session, Same User)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Step 1: Load working memory (empty - new session)\n",
        "print(\"\\n1. Loading working memory...\")\n",
        "_, working_memory = await memory_client.get_or_create_working_memory(\n",
        "    session_id=session_id_2,\n",
        "    model_name=\"gpt-4o\"\n",
        ")\n",
        "print(f\"   Messages in working memory: {len(working_memory.messages) if working_memory else 0}\")\n",
        "print(\"   (Empty - this is a new session)\")\n",
        "\n",
        "# Step 2: Search long-term memory (has data from Session 1)\n",
        "print(\"\\n2. Searching long-term memory...\")\n",
        "user_query_3 = \"What database courses do you recommend for me?\"\n",
        "long_term_memories = await memory_client.search_long_term_memory(\n",
        "    query=user_query_3,\n",
        "    limit=5\n",
        ")\n",
        "print(f\"   Relevant memories found: {len(long_term_memories)}\")\n",
        "if long_term_memories:\n",
        "    print(\"\\n   Retrieved memories:\")\n",
        "    for memory in long_term_memories:\n",
        "        print(f\"   - {memory.text}\")\n",
        "\n",
        "# Step 3: Process with LLM (with long-term context)\n",
        "print(\"\\n3. Processing with LLM...\")\n",
        "context = \"\\n\".join([f\"- {m.text}\" for m in long_term_memories])\n",
        "system_prompt = f\"\"\"You are a helpful class scheduling agent for Redis University.\n",
        "\n",
        "What you know about this student:\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=system_prompt),\n",
        "    HumanMessage(content=user_query_3)\n",
        "]\n",
        "\n",
        "response = llm.invoke(messages)\n",
        "print(f\"\\n   User: {user_query_3}\")\n",
        "print(f\"   Agent: {response.content}\")\n",
        "print(\"\\n   ✅ Agent used long-term memory to personalize response!\")\n",
        "\n",
        "# Step 4: Save working memory\n",
        "print(\"\\n4. Saving working memory...\")\n",
        "from agent_memory_client import WorkingMemory, MemoryMessage\n",
        "\n",
        "# Convert messages to MemoryMessage format\n",
        "memory_messages = [MemoryMessage(**msg) for msg in []\n",
        "\n",
        "# Create WorkingMemory object\n",
        "working_memory = WorkingMemory(\n",
        "    session_id=session_id_2,\n",
        "    user_id=\"demo_user\",\n",
        "    messages=memory_messages,\n",
        "    memories=[],\n",
        "    data={}\n",
        ")\n",
        "\n",
        "await memory_client.put_working_memory(\n",
        "    session_id=session_id_2,\n",
        "    memory=working_memory,\n",
        "    user_id=\"demo_user\",\n",
        "    model_name=\"gpt-4o\"\n",
        ")\n",
        "print(\"   ✅ Working memory saved for new session\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Testing: Memory Consolidation\n",
        "\n",
        "Let's verify that both sessions' data is consolidated in long-term memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"MEMORY CONSOLIDATION CHECK\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Check all memories about the student\n",
        "print(\"\\nAll memories about this student:\\n\")\n",
        "all_memories = await memory_client.search_long_term_memory(\n",
        "    query=\"\",  # Empty query returns all\n",
        "    limit=20\n",
        ")\n",
        "\n",
        "semantic_memories = [m for m in all_memories if m.memory_type == \"semantic\"].memories\n",
        "episodic_memories = [m for m in all_memories if m.memory_type == \"episodic\"].memories\n",
        "\n",
        "print(f\"Semantic memories (facts): {len(semantic_memories)}\")\n",
        "for memory in semantic_memories.memories:\n",
        "    print(f\"  - {memory.text}\")\n",
        "\n",
        "print(f\"\\nEpisodic memories (events): {len(episodic_memories)}\")\n",
        "for memory in episodic_memories:\n",
        "    print(f\"  - {memory.text}\")\n",
        "\n",
        "print(\"\\n✅ All memories from both sessions are consolidated in long-term memory!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Takeaways\n",
        "\n",
        "### Memory Integration Pattern\n",
        "\n",
        "**Every conversation turn:**\n",
        "1. Load working memory (conversation history)\n",
        "2. Search long-term memory (relevant facts)\n",
        "3. Process with full context\n",
        "4. Save working memory (triggers extraction)\n",
        "\n",
        "### Automatic Extraction\n",
        "\n",
        "The Agent Memory Server automatically:\n",
        "- ✅ Analyzes conversations\n",
        "- ✅ Extracts important facts\n",
        "- ✅ Stores in long-term memory\n",
        "- ✅ Deduplicates similar memories\n",
        "- ✅ Organizes by type and topics\n",
        "\n",
        "### Memory Lifecycle\n",
        "\n",
        "```\n",
        "User says something\n",
        "       ↓\n",
        "Stored in working memory (session-scoped)\n",
        "       ↓\n",
        "Automatic extraction analyzes importance\n",
        "       ↓\n",
        "Important facts → long-term memory (user-scoped)\n",
        "       ↓\n",
        "Available in future sessions\n",
        "```\n",
        "\n",
        "### Best Practices\n",
        "\n",
        "1. **Always load working memory first** - Get conversation context\n",
        "2. **Search long-term memory for relevant facts** - Use semantic search\n",
        "3. **Combine both in system prompt** - Give LLM full context\n",
        "4. **Save working memory after each turn** - Enable extraction\n",
        "5. **Trust automatic extraction** - Don't manually extract everything"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercises\n",
        "\n",
        "1. **Multi-turn conversation**: Have a 5-turn conversation about course planning. Verify memories are extracted.\n",
        "\n",
        "2. **Cross-session test**: Start a new session and ask \"What do you know about me?\" Does the agent remember?\n",
        "\n",
        "3. **Memory search**: Try different search queries to find specific memories. How does semantic search perform?\n",
        "\n",
        "4. **Extraction timing**: How long does automatic extraction take? Test with different conversation lengths."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "In this notebook, you learned:\n",
        "\n",
        "- ✅ Working and long-term memory work together for complete context\n",
        "- ✅ Load working memory → search long-term → process → save working memory\n",
        "- ✅ Automatic extraction moves important facts to long-term memory\n",
        "- ✅ Long-term memory persists across sessions\n",
        "- ✅ This pattern enables truly personalized, context-aware agents\n",
        "\n",
        "**Next:** In Section 4, we'll explore optimizations like context window management, retrieval strategies, and grounding techniques."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
