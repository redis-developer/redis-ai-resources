{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f38f7a74133d584d",
   "metadata": {},
   "source": [
    "![Redis](https://redis.io/wp-content/uploads/2024/04/Logotype.svg?auto=webp&quality=85,75&width=120)\n",
    "\n",
    "# Engineering Retrieved Context with RAG\n",
    "\n",
    "## From Context Engineering to Retrieval-Augmented Generation\n",
    "\n",
    "In Section 1, you learned about the four core context types:\n",
    "1. **System Context** - The AI's role and domain knowledge\n",
    "2. **User Context** - Personal profiles and preferences  \n",
    "3. **Conversation Context** - Dialogue history and flow\n",
    "4. **Retrieved Context** - Dynamic information from external sources\n",
    "\n",
    "This notebook focuses on **Retrieved Context** - the most powerful and complex context type. You'll learn how to build a production-ready RAG (Retrieval-Augmented Generation) system that dynamically fetches relevant information to enhance AI responses.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "**RAG Fundamentals:**\n",
    "- What RAG is and why it's essential for context engineering\n",
    "- How vector embeddings enable semantic search\n",
    "- Building a complete RAG pipeline with LangChain and Redis\n",
    "\n",
    "**Practical Implementation:**\n",
    "- Generate and ingest course data using existing utilities\n",
    "- Set up Redis vector store for semantic search\n",
    "- Implement retrieval and generation workflows\n",
    "- Combine retrieved context with user and system context\n",
    "\n",
    "**Foundation for Advanced Topics:**\n",
    "- This RAG system becomes the base for Section 3 (Memory Systems for Context Engineering)\n",
    "- You'll add LangGraph state management and tools in later sections\n",
    "- Focus here is purely on retrieval ‚Üí context assembly ‚Üí generation\n",
    "\n",
    "**Time to complete:** 45-50 minutes\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32f737633a8079d",
   "metadata": {},
   "source": [
    "## Why RAG Matters for Context Engineering\n",
    "\n",
    "### The Challenge: Static vs. Dynamic Knowledge\n",
    "\n",
    "In Section 1, we used **hardcoded** course information in the system context:\n",
    "\n",
    "```python\n",
    "system_context = \"\"\"You are a Redis University course advisor.\n",
    "\n",
    "Available Courses:\n",
    "- RU101: Introduction to Redis (Beginner, 4-6 hours)\n",
    "- RU201: Redis for Python (Intermediate, 6-8 hours)\n",
    "...\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "**Problems with this approach:**\n",
    "- ‚ùå **Doesn't scale** - Can't hardcode thousands of courses\n",
    "- ‚ùå **Wastes tokens** - Includes irrelevant courses in every request\n",
    "- ‚ùå **Hard to update** - Requires code changes to add/modify courses\n",
    "- ‚ùå **No personalization** - Same courses shown to everyone\n",
    "\n",
    "### The Solution: Retrieval-Augmented Generation (RAG)\n",
    "\n",
    "RAG solves these problems by **dynamically retrieving** only the most relevant information:\n",
    "\n",
    "```\n",
    "User Query: \"I want to learn about vector search\"\n",
    "     ‚Üì\n",
    "Semantic Search: Find courses matching \"vector search\"\n",
    "     ‚Üì\n",
    "Retrieved Context: RU301 - Vector Similarity Search with Redis\n",
    "     ‚Üì\n",
    "LLM Generation: Personalized recommendation using retrieved context\n",
    "```\n",
    "\n",
    "**Benefits:**\n",
    "- ‚úÖ **Scales infinitely** - Store millions of documents\n",
    "- ‚úÖ **Token efficient** - Only retrieve what's relevant\n",
    "- ‚úÖ **Easy to update** - Add/modify data without code changes\n",
    "- ‚úÖ **Personalized** - Different results for different queries\n",
    "\n",
    "### RAG as \"Retrieved Context\" from Section 1\n",
    "\n",
    "Remember the four context types? RAG is how we implement **Retrieved Context** in production:\n",
    "\n",
    "| Context Type | Storage | Retrieval Method | Example |\n",
    "|--------------|---------|------------------|---------|\n",
    "| System Context | Hardcoded | Always included | AI role, instructions |\n",
    "| User Context | Database | User ID lookup | Student profile |\n",
    "| Conversation Context | Session store | Session ID lookup | Chat history |\n",
    "| **Retrieved Context** | **Vector DB** | **Search** | **Relevant courses** |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6199337174405d39",
   "metadata": {},
   "source": [
    "## Setup and Environment\n",
    "\n",
    "Let's prepare our environment with the necessary dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b8643051fbc09a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T02:54:53.258252Z",
     "iopub.status.busy": "2025-11-05T02:54:53.257978Z",
     "iopub.status.idle": "2025-11-05T02:54:53.273856Z",
     "shell.execute_reply": "2025-11-05T02:54:53.273159Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment variables loaded\n",
      "   REDIS_URL: redis://localhost:6379\n",
      "   OPENAI_API_KEY: ‚úì Set\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Verify required environment variables\n",
    "required_vars = [\"OPENAI_API_KEY\"]\n",
    "missing_vars = [var for var in required_vars if not os.getenv(var)]\n",
    "\n",
    "if missing_vars:\n",
    "    print(\n",
    "        f\"\"\"\n",
    "‚ö†Ô∏è  Missing required environment variables: {', '.join(missing_vars)}\n",
    "\n",
    "Please create a .env file with:\n",
    "OPENAI_API_KEY=your_openai_api_key\n",
    "REDIS_URL=redis://localhost:6379\n",
    "\n",
    "For Redis setup:\n",
    "- Local: docker run -d -p 6379:6379 redis/redis-stack-server:latest\n",
    "- Cloud: https://redis.com/try-free/\n",
    "\"\"\"\n",
    "    )\n",
    "    sys.exit(1)\n",
    "REDIS_URL = \"redis://localhost:6379\"\n",
    "print(\"‚úÖ Environment variables loaded\")\n",
    "print(f\"   REDIS_URL: {REDIS_URL}\")\n",
    "print(f\"   OPENAI_API_KEY: {'‚úì Set' if os.getenv('OPENAI_API_KEY') else '‚úó Not set'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c09c113f31cc9237",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T02:54:53.275793Z",
     "iopub.status.busy": "2025-11-05T02:54:53.275635Z",
     "iopub.status.idle": "2025-11-05T02:54:53.278225Z",
     "shell.execute_reply": "2025-11-05T02:54:53.277783Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Utility functions loaded\n"
     ]
    }
   ],
   "source": [
    "# Utility: Token counter\n",
    "def count_tokens(text: str, model: str = \"gpt-4o\") -> int:\n",
    "    \"\"\"Count tokens in text using tiktoken.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "print(\"‚úÖ Utility functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a604197ba5bed3c",
   "metadata": {},
   "source": [
    "### Install Dependencies\n",
    "\n",
    "We'll use LangChain for RAG orchestration and Redis for vector storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa253a5a5fea56a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T02:54:53.279773Z",
     "iopub.status.busy": "2025-11-05T02:54:53.279658Z",
     "iopub.status.idle": "2025-11-05T02:54:53.281620Z",
     "shell.execute_reply": "2025-11-05T02:54:53.281223Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dependencies ready\n"
     ]
    }
   ],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# %pip install -q langchain langchain-openai langchain-redis redisvl redis python-dotenv\n",
    "\n",
    "print(\"‚úÖ Dependencies ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78bfe047e37e3fe",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Step 1: Understanding Vector Embeddings\n",
    "\n",
    "Before building our RAG system, let's understand the core concept: **vector embeddings**.\n",
    "\n",
    "### What Are Embeddings?\n",
    "\n",
    "Embeddings convert text into numerical vectors that capture semantic meaning:\n",
    "\n",
    "```\n",
    "Text: \"Introduction to Redis\"\n",
    "  ‚Üì (embedding model)\n",
    "Vector: [0.23, -0.45, 0.67, ..., 0.12]  # 1536 dimensions for OpenAI\n",
    "```\n",
    "\n",
    "**Key insight:** Similar texts have similar vectors (measured by cosine similarity).\n",
    "\n",
    "### Why Embeddings Enable Semantic Search\n",
    "\n",
    "Traditional keyword search:\n",
    "- Query: \"machine learning courses\" \n",
    "- Matches: Only documents containing exact words \"machine learning\"\n",
    "- Misses: \"AI courses\", \"neural network classes\", \"deep learning programs\"\n",
    "\n",
    "Semantic search with embeddings:\n",
    "- Query: \"machine learning courses\"\n",
    "- Matches: All semantically similar content (AI, neural networks, deep learning, etc.)\n",
    "- Works across synonyms, related concepts, and different phrasings\n",
    "\n",
    "Let's see this in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8987e7214633221",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T02:54:53.283237Z",
     "iopub.status.busy": "2025-11-05T02:54:53.283110Z",
     "iopub.status.idle": "2025-11-05T02:54:55.250728Z",
     "shell.execute_reply": "2025-11-05T02:54:55.250182Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Generated embeddings for 3 texts\n",
      "   Vector dimensions: 1536\n",
      "   First vector preview: [-0.030, -0.013, 0.001, ...]\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Initialize embedding model\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Generate embeddings for similar and different texts\n",
    "texts = [\n",
    "    \"Introduction to machine learning and neural networks\",\n",
    "    \"Learn about AI and deep learning fundamentals\",\n",
    "    \"Database administration and SQL queries\",\n",
    "]\n",
    "\n",
    "# Get embeddings (this calls OpenAI API)\n",
    "vectors = embeddings.embed_documents(texts)\n",
    "\n",
    "print(f\"‚úÖ Generated embeddings for {len(texts)} texts\")\n",
    "print(f\"   Vector dimensions: {len(vectors[0])}\")\n",
    "print(\n",
    "    f\"   First vector preview: [{vectors[0][0]:.3f}, {vectors[0][1]:.3f}, {vectors[0][2]:.3f}, ...]\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7963a05e261c914c",
   "metadata": {},
   "source": [
    "### Measuring Semantic Similarity\n",
    "\n",
    "Let's calculate cosine similarity to see which texts are semantically related:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "830004ddb2bd656b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T02:54:55.252285Z",
     "iopub.status.busy": "2025-11-05T02:54:55.252177Z",
     "iopub.status.idle": "2025-11-05T02:54:55.255175Z",
     "shell.execute_reply": "2025-11-05T02:54:55.254836Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Similarity Scores (0=unrelated, 1=identical):\n",
      "   ML vs AI:       0.623 ‚Üê High similarity (related topics)\n",
      "   ML vs Database: 0.171 ‚Üê Low similarity (different topics)\n",
      "   AI vs Database: 0.177 ‚Üê Low similarity (different topics)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"Calculate cosine similarity between two vectors.\"\"\"\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "\n",
    "# Compare similarities\n",
    "sim_1_2 = cosine_similarity(vectors[0], vectors[1])  # ML vs AI (related)\n",
    "sim_1_3 = cosine_similarity(vectors[0], vectors[2])  # ML vs Database (unrelated)\n",
    "sim_2_3 = cosine_similarity(vectors[1], vectors[2])  # AI vs Database (unrelated)\n",
    "\n",
    "print(\"Semantic Similarity Scores (0=unrelated, 1=identical):\")\n",
    "print(f\"   ML vs AI:       {sim_1_2:.3f} ‚Üê High similarity (related topics)\")\n",
    "print(f\"   ML vs Database: {sim_1_3:.3f} ‚Üê Low similarity (different topics)\")\n",
    "print(f\"   AI vs Database: {sim_2_3:.3f} ‚Üê Low similarity (different topics)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be16970c9b44fcec",
   "metadata": {},
   "source": [
    "**üí° Key Takeaway:** Embeddings capture semantic meaning, allowing us to find relevant information even when exact keywords don't match.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63e217969956023",
   "metadata": {},
   "source": [
    "## üìö Step 2: Generate Course Data\n",
    "\n",
    "Now let's create realistic course data for our RAG system. We'll use the existing utilities from the reference agent.\n",
    "\n",
    "### Understanding the Course Generation Script\n",
    "\n",
    "The `generate_courses.py` script creates realistic course data with:\n",
    "- Multiple majors (CS, Data Science, Math, Business, Psychology)\n",
    "- Course templates with descriptions, prerequisites, schedules\n",
    "- Realistic metadata (instructors, enrollment, difficulty levels)\n",
    "\n",
    "Let's generate our course catalog:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e95cd4b02364b072",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T02:54:55.256620Z",
     "iopub.status.busy": "2025-11-05T02:54:55.256532Z",
     "iopub.status.idle": "2025-11-05T02:54:55.443392Z",
     "shell.execute_reply": "2025-11-05T02:54:55.442907Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Generating course catalog...\n",
      "\n",
      "‚úÖ Generated 5 majors:\n",
      "   - Computer Science (CS)\n",
      "   - Data Science (DS)\n",
      "   - Mathematics (MATH)\n",
      "   - Business Administration (BUS)\n",
      "   - Psychology (PSY)\n",
      "\n",
      "‚úÖ Generated 50 courses\n",
      "\n",
      "Sample Course:\n",
      "   Code: CS001\n",
      "   Title: Introduction to Programming\n",
      "   Department: Computer Science\n",
      "   Difficulty: beginner\n",
      "   Credits: 3\n",
      "   Description: Fundamental programming concepts using Python. Variables, control structures, functions, and basic d...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# IGNORE: Add reference-agent to Python path because I installed reference-agent with pip\n",
    "# IGNORE: sys.path.insert(0, os.path.join(os.getcwd(), 'python-recipes/context-engineering/reference-agent'))\n",
    "\n",
    "# Initialize generator with a seed for reproducibility\n",
    "import random\n",
    "\n",
    "from redis_context_course.scripts.generate_courses import CourseGenerator\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# Create generator\n",
    "generator = CourseGenerator()\n",
    "\n",
    "print(\"üìö Generating course catalog...\")\n",
    "print()\n",
    "\n",
    "# Generate majors\n",
    "majors = generator.generate_majors()\n",
    "print(f\"‚úÖ Generated {len(majors)} majors:\")\n",
    "for major in majors:\n",
    "    print(f\"   - {major.name} ({major.code})\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Generate courses (10 per major)\n",
    "courses = generator.generate_courses(courses_per_major=10)\n",
    "print(f\"‚úÖ Generated {len(courses)} courses\")\n",
    "\n",
    "# Show a sample course\n",
    "sample_course = courses[0]\n",
    "print(\n",
    "    f\"\"\"\n",
    "Sample Course:\n",
    "   Code: {sample_course.course_code}\n",
    "   Title: {sample_course.title}\n",
    "   Department: {sample_course.department}\n",
    "   Difficulty: {sample_course.difficulty_level.value}\n",
    "   Credits: {sample_course.credits}\n",
    "   Description: {sample_course.description[:100]}...\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35eb083f18863411",
   "metadata": {},
   "source": [
    "### Save Course Catalog to JSON\n",
    "\n",
    "Let's save this data so we can ingest it into Redis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c15d309043a79486",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T02:54:55.444714Z",
     "iopub.status.busy": "2025-11-05T02:54:55.444632Z",
     "iopub.status.idle": "2025-11-05T02:54:55.448049Z",
     "shell.execute_reply": "2025-11-05T02:54:55.447647Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 5 majors and 50 courses\n",
      "Data saved to course_catalog_section2.json\n",
      "‚úÖ Course catalog saved to course_catalog_section2.json\n",
      "   Ready for ingestion into Redis vector store\n"
     ]
    }
   ],
   "source": [
    "catalog_file = \"course_catalog_section2.json\"\n",
    "generator.save_to_json(catalog_file)\n",
    "\n",
    "print(f\"‚úÖ Course catalog saved to {catalog_file}\")\n",
    "print(f\"   Ready for ingestion into Redis vector store\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429acdaadabaa392",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîß Step 3: Set Up Redis Vector Store\n",
    "\n",
    "Now we'll configure Redis to store our course embeddings and enable semantic search.\n",
    "\n",
    "### Understanding Redis Vector Search\n",
    "\n",
    "Redis Stack provides vector similarity search capabilities:\n",
    "- **Storage:** Courses stored as Redis hashes with vector fields\n",
    "- **Indexing:** Vector index for fast similarity search (HNSW algorithm)\n",
    "- **Search:** Find top-k most similar courses to a query vector using cosine similarity\n",
    "\n",
    "### Using the Reference Agent Utilities\n",
    "\n",
    "Instead of configuring Redis from scratch, we'll use the **production-ready utilities** from the reference agent. These utilities are already configured and tested, allowing you to focus on context engineering concepts rather than Redis configuration details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b05a2a034da925",
   "metadata": {},
   "source": [
    "### Import Redis Configuration\n",
    "\n",
    "Let's import the pre-configured Redis setup:\n",
    "\n",
    "What we're importing:\n",
    " - redis_config: A global singleton that manages all Redis connections\n",
    "\n",
    "What it provides (lazy-initialized properties):\n",
    " - redis_config.redis_client: Redis connection for data storage\n",
    " - redis_config.embeddings: OpenAI embeddings (text-embedding-3-small)\n",
    " - redis_config.vector_index: RedisVL SearchIndex with pre-configured schema\n",
    " - redis_config.checkpointer: RedisSaver for LangGraph (used in Section 3)\n",
    "\n",
    "Why use this:\n",
    " - Production-ready configuration (same as reference agent)\n",
    " - Proper schema with all course metadata fields\n",
    " - Vector field: 1536 dims, cosine distance, HNSW algorithm\n",
    " - No boilerplate - just import and use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93784287e000173d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T02:54:55.449086Z",
     "iopub.status.busy": "2025-11-05T02:54:55.449024Z",
     "iopub.status.idle": "2025-11-05T02:54:55.450663Z",
     "shell.execute_reply": "2025-11-05T02:54:55.450326Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Redis configuration imported\n",
      "   Redis URL: redis://localhost:6379\n",
      "   Vector index name: course_catalog\n"
     ]
    }
   ],
   "source": [
    "from redis_context_course.redis_config import redis_config\n",
    "\n",
    "print(\"‚úÖ Redis configuration imported\")\n",
    "print(f\"   Redis URL: {redis_config.redis_url}\")\n",
    "print(f\"   Vector index name: {redis_config.vector_index_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2f11887561871f",
   "metadata": {},
   "source": [
    "### Test Redis Connection\n",
    "\n",
    "Let's verify Redis is running and accessible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "154a875022180c9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T02:54:55.451591Z",
     "iopub.status.busy": "2025-11-05T02:54:55.451531Z",
     "iopub.status.idle": "2025-11-05T02:54:55.455913Z",
     "shell.execute_reply": "2025-11-05T02:54:55.455503Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Connected to Redis\n",
      "   Redis is healthy and ready\n"
     ]
    }
   ],
   "source": [
    "# Test connection using built-in health check\n",
    "if redis_config.health_check():\n",
    "    print(\"‚úÖ Connected to Redis\")\n",
    "    print(f\"   Redis is healthy and ready\")\n",
    "else:\n",
    "    print(\"‚ùå Redis connection failed\")\n",
    "    print(\"   Make sure Redis is running:\")\n",
    "    print(\"   - Local: docker run -d -p 6379:6379 redis/redis-stack-server:latest\")\n",
    "    print(\"   - Cloud: https://redis.com/try-free/\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89de1e20794eda1",
   "metadata": {},
   "source": [
    "### Initialize Course Manager\n",
    "\n",
    "Now let's import the `CourseManager` - this handles all course operations, such as storage, retrieval, and search:\n",
    "\n",
    "What it provides:\n",
    " - store_course(): Store a course with vector embedding\n",
    " - search_courses(): Semantic search with filters\n",
    " - get_course(): Retrieve course by ID\n",
    " - get_course_by_code(): Retrieve course by course code\n",
    " - recommend_courses(): Generate personalized recommendations\n",
    "\n",
    "How it works:\n",
    " - Uses redis_config for connections (redis_client, vector_index, embeddings)\n",
    " - Automatically generates embeddings from course content\n",
    " - Uses RedisVL's VectorQuery for semantic search\n",
    " - Supports metadata filters (department, difficulty, format, etc.)\n",
    "\n",
    "Why use this:\n",
    " - Encapsulates all Redis/RedisVL complexity\n",
    " - Same code used in reference agent (Sections 3 & 4)\n",
    " - Focus on RAG concepts, not Redis implementation details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa59e20137321967",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T02:54:55.456958Z",
     "iopub.status.busy": "2025-11-05T02:54:55.456893Z",
     "iopub.status.idle": "2025-11-05T02:54:55.467286Z",
     "shell.execute_reply": "2025-11-05T02:54:55.466848Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:54:55 redisvl.index.index INFO   Index already exists, not overwriting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Course manager initialized\n",
      "   Ready for course storage and search\n",
      "   Using RedisVL for vector operations\n"
     ]
    }
   ],
   "source": [
    "from redis_context_course.course_manager import CourseManager\n",
    "\n",
    "# Initialize course manager\n",
    "course_manager = CourseManager()\n",
    "\n",
    "print(\"‚úÖ Course manager initialized\")\n",
    "print(f\"   Ready for course storage and search\")\n",
    "print(f\"   Using RedisVL for vector operations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ccf2cb80ad5e05",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "---\n",
    "\n",
    "## üì• Step 4: Ingest Courses into Redis\n",
    "\n",
    "Now we'll load our course catalog into Redis with vector embeddings for semantic search.\n",
    "\n",
    "### Understanding the Ingestion Process\n",
    "\n",
    "The ingestion pipeline:\n",
    "1. **Load** course data from JSON\n",
    "2. **Generate embeddings** for each course (title + description + tags)\n",
    "3. **Store** in Redis with metadata for filtering\n",
    "4. **Index** vectors for fast similarity search\n",
    "\n",
    "Let's use the existing ingestion utilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da9f4e00dcc39387",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T02:54:55.468321Z",
     "iopub.status.busy": "2025-11-05T02:54:55.468255Z",
     "iopub.status.idle": "2025-11-05T02:55:09.000931Z",
     "shell.execute_reply": "2025-11-05T02:55:09.000238Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting course ingestion...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">üöÄ Starting Course Catalog Ingestion</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34müöÄ Starting Course Catalog Ingestion\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">‚úÖ Redis connection successful</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m‚úÖ Redis connection successful\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">üßπ Clearing existing data...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33müßπ Clearing existing data\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Cleared <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span> course records\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   Cleared \u001b[1;36m50\u001b[0m course records\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Cleared <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> major records\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   Cleared \u001b[1;36m5\u001b[0m major records\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">‚úÖ Data cleared successfully</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m‚úÖ Data cleared successfully\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">‚úÖ Loaded catalog from course_catalog_section2.json</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m‚úÖ Loaded catalog from course_catalog_section2.json\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Majors: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   Majors: \u001b[1;36m5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Courses: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   Courses: \u001b[1;36m50\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e245e292de4b39a25d44303bc8d1ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">‚úÖ Ingested </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">5</span><span style=\"color: #008000; text-decoration-color: #008000\"> majors</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m‚úÖ Ingested \u001b[0m\u001b[1;32m5\u001b[0m\u001b[32m majors\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93e09c8c24bb44b2959274577cab1d3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:54:55 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:54:56 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:54:57 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:54:57 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:54:57 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:54:57 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:54:57 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:54:57 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:54:58 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:54:58 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:54:58 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:54:59 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:54:59 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:54:59 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:54:59 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:00 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:00 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:00 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:00 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:01 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:01 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:01 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:01 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:02 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:02 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:02 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:03 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:03 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:03 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:04 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:04 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:04 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:05 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:05 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:05 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:05 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:05 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:05 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:06 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:06 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:06 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:06 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:07 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:07 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:07 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:07 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:08 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:08 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:08 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:08 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">‚úÖ Ingested </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">50</span><span style=\"color: #008000; text-decoration-color: #008000\"> courses</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m‚úÖ Ingested \u001b[0m\u001b[1;32m50\u001b[0m\u001b[32m courses\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">üìä Verification - Courses: </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">50</span><span style=\"color: #000080; text-decoration-color: #000080\">, Majors: </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34müìä Verification - Courses: \u001b[0m\u001b[1;34m50\u001b[0m\u001b[34m, Majors: \u001b[0m\u001b[1;34m5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">üéâ Ingestion completed successfully!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32müéâ Ingestion completed successfully!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Course ingestion complete!\n",
      "   Courses in Redis: 50\n",
      "   Majors in Redis: 5\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "from redis_context_course.scripts.ingest_courses import CourseIngestionPipeline\n",
    "\n",
    "# What we're importing:\n",
    "# - CourseIngestionPipeline: Handles bulk ingestion of course data\n",
    "#\n",
    "# What it does:\n",
    "# - Loads course catalog from JSON file\n",
    "# - For each course: generates embedding + stores in Redis\n",
    "# - Uses CourseManager internally for storage\n",
    "# - Provides progress tracking and verification\n",
    "#\n",
    "# Why use this:\n",
    "# - Handles batch ingestion efficiently\n",
    "# - Same utility used to populate reference agent\n",
    "# - Includes error handling and progress reporting\n",
    "\n",
    "# Initialize ingestion pipeline\n",
    "pipeline = CourseIngestionPipeline()\n",
    "\n",
    "print(\"üöÄ Starting course ingestion...\")\n",
    "print()\n",
    "\n",
    "# Run ingestion (clear existing data first)\n",
    "success = await pipeline.run_ingestion(catalog_file=catalog_file, clear_existing=True)\n",
    "\n",
    "if success:\n",
    "    print()\n",
    "    print(\"‚úÖ Course ingestion complete!\")\n",
    "\n",
    "    # Verify what was ingested\n",
    "    verification = pipeline.verify_ingestion()\n",
    "    print(f\"   Courses in Redis: {verification['courses']}\")\n",
    "    print(f\"   Majors in Redis: {verification['majors']}\")\n",
    "else:\n",
    "    print(\"‚ùå Ingestion failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4d3d17c5c3cdae",
   "metadata": {},
   "source": [
    "### What Just Happened?\n",
    "\n",
    "For each course, the ingestion pipeline:\n",
    "\n",
    "1. **Created searchable content:**\n",
    "   ```python\n",
    "   content = f\"{course.title} {course.description} {course.department} {' '.join(course.tags)}\"\n",
    "   ```\n",
    "\n",
    "2. **Generated embedding vector:**\n",
    "   ```python\n",
    "   embedding = await embeddings.aembed_query(content)  # 1536-dim vector\n",
    "   ```\n",
    "\n",
    "3. **Stored in Redis:**\n",
    "   ```python\n",
    "   redis_client.hset(f\"course_idx:{course.id}\", mapping={\n",
    "       \"course_code\": \"CS001\",\n",
    "       \"title\": \"Introduction to Programming\",\n",
    "       \"description\": \"...\",\n",
    "       \"content_vector\": embedding.tobytes()  # Binary vector\n",
    "   })\n",
    "   ```\n",
    "\n",
    "4. **Indexed for search:**\n",
    "   - Redis automatically indexes the vector field\n",
    "   - Enables fast k-NN (k-nearest neighbors) search\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19cebdedbaec6a0",
   "metadata": {},
   "source": [
    "## üîç Step 5: Semantic Search - Finding Relevant Courses\n",
    "\n",
    "Now comes the magic: semantic search. Let's query our vector store to find relevant courses.\n",
    "\n",
    "### Basic Semantic Search\n",
    "\n",
    "Let's search for courses related to \"machine learning\".\n",
    "\n",
    "When this is called:\n",
    "```python\n",
    "await course_manager.search_courses(\n",
    "    query=query,\n",
    "    limit=3  # top_k parameter\n",
    ")\n",
    "```\n",
    "It is performing semantic search under the hood:\n",
    "1. Generates embedding for the query using OpenAI\n",
    "2. Performs vector similarity search in Redis (cosine distance)\n",
    "3. Returns top-k most similar courses\n",
    "4. Uses RedisVL's VectorQuery under the hood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bd46b1b7a140f91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T02:55:09.074805Z",
     "iopub.status.busy": "2025-11-05T02:55:09.074744Z",
     "iopub.status.idle": "2025-11-05T02:55:09.406101Z",
     "shell.execute_reply": "2025-11-05T02:55:09.405341Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Searching for: 'machine learning and artificial intelligence'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:09 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 3 relevant courses:\n",
      "\n",
      "1. CS007: Machine Learning\n",
      "   Department: Computer Science\n",
      "   Difficulty: advanced\n",
      "   Description: Introduction to machine learning algorithms and applications. Supervised and unsupervised learning, ...\n",
      "\n",
      "2. DS012: Statistics for Data Science\n",
      "   Department: Data Science\n",
      "   Difficulty: intermediate\n",
      "   Description: Statistical methods and probability theory for data analysis. Hypothesis testing, regression, and st...\n",
      "\n",
      "3. DS014: Statistics for Data Science\n",
      "   Department: Data Science\n",
      "   Difficulty: intermediate\n",
      "   Description: Statistical methods and probability theory for data analysis. Hypothesis testing, regression, and st...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We already initialized course_manager in Step 3\n",
    "# It's ready to use for semantic search\n",
    "\n",
    "# Search for machine learning courses\n",
    "query = \"machine learning and artificial intelligence\"\n",
    "print(f\"üîç Searching for: '{query}'\\n\")\n",
    "\n",
    "# Perform semantic search (returns top 3 most similar courses)\n",
    "results = await course_manager.search_courses(query=query, limit=3)  # top_k parameter\n",
    "\n",
    "print(f\"‚úÖ Found {len(results)} relevant courses:\\n\")\n",
    "\n",
    "for i, course in enumerate(results, 1):\n",
    "    print(f\"{i}. {course.course_code}: {course.title}\")\n",
    "    print(f\"   Department: {course.department}\")\n",
    "    print(f\"   Difficulty: {course.difficulty_level.value}\")\n",
    "    print(f\"   Description: {course.description[:100]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e81b08ef0b24e1",
   "metadata": {},
   "source": [
    "### Search with Filters\n",
    "\n",
    "We can combine semantic search with metadata filters for more precise results:\n",
    "\n",
    "How filters work:\n",
    "\n",
    "```python\n",
    "results = await course_manager.search_courses(\n",
    "    query=query,\n",
    "    limit=3,\n",
    "    filters=filters\n",
    ")\n",
    "```\n",
    " - CourseManager._build_filters() converts dict to RedisVL filter expressions\n",
    " - Uses Tag filters for categorical fields (difficulty_level, format, department)\n",
    " - Uses Num filters for numeric fields (credits, year)\n",
    " - Combines filters with AND logic\n",
    " - Applied to vector search results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c9406198195f5c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T02:55:09.408519Z",
     "iopub.status.busy": "2025-11-05T02:55:09.408358Z",
     "iopub.status.idle": "2025-11-05T02:55:09.710312Z",
     "shell.execute_reply": "2025-11-05T02:55:09.709564Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Searching for: 'machine learning'\n",
      "   Filters: {'difficulty_level': 'beginner', 'format': 'online'}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:09 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 3 matching courses:\n",
      "1. DS020: Data Visualization\n",
      "   Format: online, Difficulty: beginner\n",
      "\n",
      "2. PSY043: Introduction to Psychology\n",
      "   Format: online, Difficulty: beginner\n",
      "\n",
      "3. PSY049: Introduction to Psychology\n",
      "   Format: online, Difficulty: beginner\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Search for beginner-level machine learning courses\n",
    "query = \"machine learning\"\n",
    "filters = {\"difficulty_level\": \"beginner\", \"format\": \"online\"}\n",
    "\n",
    "print(f\"üîç Searching for: '{query}'\\n   Filters: {filters}\\n\")\n",
    "# How filters work:\n",
    "# - CourseManager._build_filters() converts dict to RedisVL filter expressions\n",
    "# - Uses Tag filters for categorical fields (difficulty_level, format, department)\n",
    "# - Uses Num filters for numeric fields (credits, year)\n",
    "# - Combines filters with AND logic\n",
    "# - Applied to vector search results\n",
    "results = await course_manager.search_courses(query=query, limit=3, filters=filters)\n",
    "\n",
    "print(f\"‚úÖ Found {len(results)} matching courses:\")\n",
    "for i, course in enumerate(results, 1):\n",
    "    print(f\"{i}. {course.course_code}: {course.title}\")\n",
    "    print(\n",
    "        f\"   Format: {course.format.value}, Difficulty: {course.difficulty_level.value}\"\n",
    "    )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d2fedcf3efb590",
   "metadata": {},
   "source": [
    "**üí° Key Insight:** We can combine:\n",
    "- **Semantic search** (find courses about \"machine learning\")\n",
    "- **Metadata filters** (only beginner, online courses)\n",
    "\n",
    "This gives us precise, relevant results for any query. This will be a useful tool to build context for our RAG pipeline.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38da21b55f381ab",
   "metadata": {},
   "source": [
    "## üîó Step 6: Building the RAG Pipeline\n",
    "\n",
    "Now let's combine everything into a complete RAG pipeline: Retrieval ‚Üí Context Assembly ‚Üí Generation.\n",
    "\n",
    "### The RAG Flow\n",
    "\n",
    "```\n",
    "User Query\n",
    "    ‚Üì\n",
    "1. Semantic Search (retrieve relevant courses)\n",
    "    ‚Üì\n",
    "2. Context Assembly (combine system + user + retrieved context)\n",
    "    ‚Üì\n",
    "3. LLM Generation (create personalized response)\n",
    "```\n",
    "\n",
    "Let's implement each step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a3289098af7058a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T02:55:09.712768Z",
     "iopub.status.busy": "2025-11-05T02:55:09.712594Z",
     "iopub.status.idle": "2025-11-05T02:55:09.732104Z",
     "shell.execute_reply": "2025-11-05T02:55:09.731491Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LLM initialized (gpt-4o-mini)\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "\n",
    "print(\"‚úÖ LLM initialized (gpt-4o-mini)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1206c431ffb4292",
   "metadata": {},
   "source": [
    "### Step 6.1: Retrieval Function\n",
    "\n",
    "First, let's create a function to retrieve relevant courses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef03683be57faf95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T02:55:09.733563Z",
     "iopub.status.busy": "2025-11-05T02:55:09.733450Z",
     "iopub.status.idle": "2025-11-05T02:55:09.896481Z",
     "shell.execute_reply": "2025-11-05T02:55:09.895322Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:09 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Retrieved 3 courses for: 'I want to learn about data structures'\n",
      "   - CS009: Data Structures and Algorithms\n",
      "   - CS001: Introduction to Programming\n",
      "   - CS005: Introduction to Programming\n"
     ]
    }
   ],
   "source": [
    "async def retrieve_courses(query: str, limit: int = 3, filters: dict = None):\n",
    "    \"\"\"\n",
    "    Retrieve relevant courses using semantic search.\n",
    "\n",
    "    Args:\n",
    "        query: User's search query\n",
    "        limit: Number of courses to retrieve\n",
    "        filters: Optional metadata filters\n",
    "\n",
    "    Returns:\n",
    "        List of relevant courses\n",
    "    \"\"\"\n",
    "    results = await course_manager.search_courses(\n",
    "        query=query, limit=limit, filters=filters\n",
    "    )\n",
    "    return results\n",
    "\n",
    "\n",
    "# Test retrieval\n",
    "test_query = \"I want to learn about data structures\"\n",
    "retrieved_courses = await retrieve_courses(test_query, limit=3)\n",
    "\n",
    "print(f\"üîç Retrieved {len(retrieved_courses)} courses for: '{test_query}'\")\n",
    "for course in retrieved_courses:\n",
    "    print(f\"   - {course.course_code}: {course.title}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a068ffa458f850f",
   "metadata": {},
   "source": [
    "### Step 6.2: Context Assembly Function\n",
    "\n",
    "Now let's assemble context from multiple sources (system + user + retrieved):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16d6089b-7fe2-451d-b57d-436c49259216",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T02:55:09.899767Z",
     "iopub.status.busy": "2025-11-05T02:55:09.899500Z",
     "iopub.status.idle": "2025-11-05T02:55:09.906168Z",
     "shell.execute_reply": "2025-11-05T02:55:09.905393Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Context assembled\n",
      "   Total length: 1537 characters\n",
      "   Includes: System + User + Retrieved context\n"
     ]
    }
   ],
   "source": [
    "def assemble_context(\n",
    "    user_query: str, retrieved_courses: list, user_profile: dict = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Assemble context from multiple sources for the LLM.\n",
    "\n",
    "    This implements the context engineering principles from Section 1:\n",
    "    - System Context: AI role and instructions\n",
    "    - User Context: Student profile and preferences\n",
    "    - Retrieved Context: Relevant courses from vector search\n",
    "    \"\"\"\n",
    "\n",
    "    # System Context: Define the AI's role\n",
    "    system_context = \"\"\"You are a Redis University course advisor.\n",
    "\n",
    "Your role:\n",
    "- Help students find courses that match their interests and goals\n",
    "- Provide personalized recommendations based on student profiles\n",
    "- Explain course prerequisites and learning paths\n",
    "- Be encouraging and supportive\n",
    "\n",
    "Guidelines:\n",
    "- Only recommend courses from the provided course list\n",
    "- Consider student's difficulty level preferences\n",
    "- Explain your reasoning for recommendations\n",
    "- Be concise but informative\n",
    "\"\"\"\n",
    "\n",
    "    # User Context: Student profile (if provided)\n",
    "    user_context = \"\"\n",
    "    if user_profile:\n",
    "        user_context = f\"\"\"\n",
    "Student Profile:\n",
    "- Name: {user_profile.get('name', 'Student')}\n",
    "- Major: {user_profile.get('major', 'Undeclared')}\n",
    "- Year: {user_profile.get('year', 'N/A')}\n",
    "- Interests: {', '.join(user_profile.get('interests', []))}\n",
    "- Preferred Difficulty: {user_profile.get('preferred_difficulty', 'any')}\n",
    "- Preferred Format: {user_profile.get('preferred_format', 'any')}\n",
    "\"\"\"\n",
    "\n",
    "    # Retrieved Context: Relevant courses from semantic search\n",
    "    retrieved_context = \"\\nRelevant Courses:\\n\"\n",
    "    for i, course in enumerate(retrieved_courses, 1):\n",
    "        retrieved_context += f\"\"\"\n",
    "{i}. {course.course_code}: {course.title}\n",
    "   Department: {course.department}\n",
    "   Difficulty: {course.difficulty_level.value}\n",
    "   Format: {course.format.value}\n",
    "   Credits: {course.credits}\n",
    "   Description: {course.description}\n",
    "   Prerequisites: {len(course.prerequisites)} required\n",
    "\"\"\"\n",
    "\n",
    "    # Combine all context\n",
    "    full_context = system_context\n",
    "    if user_context:\n",
    "        full_context += user_context\n",
    "    full_context += retrieved_context\n",
    "\n",
    "    return full_context\n",
    "\n",
    "\n",
    "# Test context assembly\n",
    "test_profile = {\n",
    "    \"name\": \"Sarah Chen\",\n",
    "    \"major\": \"Computer Science\",\n",
    "    \"year\": \"Junior\",\n",
    "    \"interests\": [\"machine learning\", \"data science\"],\n",
    "    \"preferred_difficulty\": \"intermediate\",\n",
    "    \"preferred_format\": \"online\",\n",
    "}\n",
    "\n",
    "assembled_context = assemble_context(\n",
    "    user_query=test_query,\n",
    "    retrieved_courses=retrieved_courses,\n",
    "    user_profile=test_profile,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Context assembled\")\n",
    "print(f\"   Total length: {len(assembled_context)} characters\")\n",
    "print(f\"   Includes: System + User + Retrieved context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9800d8dd-38ea-482f-9486-fc32ba9f1799",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T02:55:09.907866Z",
     "iopub.status.busy": "2025-11-05T02:55:09.907713Z",
     "iopub.status.idle": "2025-11-05T02:55:09.910247Z",
     "shell.execute_reply": "2025-11-05T02:55:09.909584Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observe the assembled context: \n",
      "\n",
      "You are a Redis University course advisor.\n",
      "\n",
      "Your role:\n",
      "- Help students find courses that match their interests and goals\n",
      "- Provide personalized recommendations based on student profiles\n",
      "- Explain course prerequisites and learning paths\n",
      "- Be encouraging and supportive\n",
      "\n",
      "Guidelines:\n",
      "- Only recommend courses from the provided course list\n",
      "- Consider student's difficulty level preferences\n",
      "- Explain your reasoning for recommendations\n",
      "- Be concise but informative\n",
      "\n",
      "Student Profile:\n",
      "- Name: Sarah Chen\n",
      "- Major: Computer Science\n",
      "- Year: Junior\n",
      "- Interests: machine learning, data science\n",
      "- Preferred Difficulty: intermediate\n",
      "- Preferred Format: online\n",
      "\n",
      "Relevant Courses:\n",
      "\n",
      "1. CS009: Data Structures and Algorithms\n",
      "   Department: Computer Science\n",
      "   Difficulty: intermediate\n",
      "   Format: in_person\n",
      "   Credits: 4\n",
      "   Description: Study of fundamental data structures and algorithms. Arrays, linked lists, trees, graphs, sorting, and searching.\n",
      "   Prerequisites: 2 required\n",
      "\n",
      "2. CS001: Introduction to Programming\n",
      "   Department: Computer Science\n",
      "   Difficulty: beginner\n",
      "   Format: hybrid\n",
      "   Credits: 3\n",
      "   Description: Fundamental programming concepts using Python. Variables, control structures, functions, and basic data structures.\n",
      "   Prerequisites: 0 required\n",
      "\n",
      "3. CS005: Introduction to Programming\n",
      "   Department: Computer Science\n",
      "   Difficulty: beginner\n",
      "   Format: hybrid\n",
      "   Credits: 3\n",
      "   Description: Fundamental programming concepts using Python. Variables, control structures, functions, and basic data structures.\n",
      "   Prerequisites: 0 required\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Observe the assembled context: \\n\\n{assembled_context}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f28151926c3be5",
   "metadata": {},
   "source": [
    "**üéÅ Bonus:** Can you identify the different parts of the context from what we learned in section 1 from above?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c1be78f7cd3e20",
   "metadata": {},
   "source": [
    "**‚úÖ Answer:** Yes! Looking at the assembled context above, we can identify all three context types from Section 1:\n",
    "\n",
    "1. **System Context** (Static)\n",
    "   - The first section: \"You are a Redis University course advisor...\"\n",
    "   - Defines the AI's role, responsibilities, and guidelines\n",
    "   - Remains the same for all queries\n",
    "   - Sets behavioral instructions and constraints\n",
    "\n",
    "2. **User Context** (Dynamic, User-Specific)\n",
    "   - The \"Student Profile\" section\n",
    "   - Contains Sarah Chen's personal information: major, year, interests, preferences\n",
    "   - Changes based on who is asking the question\n",
    "   - Enables personalized recommendations\n",
    "\n",
    "3. **Retrieved Context** (Dynamic, Query-Specific)\n",
    "   - The \"Relevant Courses\" section\n",
    "   - Lists the 3 courses found via semantic search for \"data structures\"\n",
    "   - Changes based on the specific query\n",
    "   - Provides the factual information the LLM needs to answer\n",
    "\n",
    "Notice how all three work together: System Context tells the AI **how to behave**, User Context tells it **who it's helping**, and Retrieved Context provides **what information is relevant**. This is RAG in action!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e27332f-83d5-475f-9fcc-405525a25c9f",
   "metadata": {},
   "source": [
    "### Step 6.3: Generation Function\n",
    "\n",
    "Finally, let's generate a response using the assembled context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cba9e518ee7581c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T02:55:09.911917Z",
     "iopub.status.busy": "2025-11-05T02:55:09.911779Z",
     "iopub.status.idle": "2025-11-05T02:55:14.220960Z",
     "shell.execute_reply": "2025-11-05T02:55:14.220255Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:14 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Generated Response:\n",
      "\n",
      "Hi Sarah! It's great to hear that you're interested in learning about data structures, especially since you are a Computer Science major.\n",
      "\n",
      "The course that fits your interest is **CS009: Data Structures and Algorithms**. Here's a bit more about it:\n",
      "\n",
      "- **Difficulty**: Intermediate\n",
      "- **Format**: In-person (please note that it may not match your preference for online)\n",
      "- **Credits**: 4\n",
      "- **Description**: This course covers fundamental data structures and algorithms, including arrays, linked lists, trees, graphs, sorting, and searching. \n",
      "- **Prerequisites**: There are 2 required prerequisites, which means you should check if you meet those before enrolling.\n",
      "\n",
      "Since you're a junior and interested in machine learning and data science, understanding data structures will be crucial for optimizing algorithms and managing data efficiently.\n",
      "\n",
      "Unfortunately, since this course is in-person, it may not fit your preferred format. If you're open to considering other online courses in the future or adjusting your preferences, I can help you find more options.\n",
      "\n",
      "Let me know if you have any questions or need further assistance!\n"
     ]
    }
   ],
   "source": [
    "async def generate_response(user_query: str, context: str):\n",
    "    \"\"\"\n",
    "    Generate LLM response using assembled context.\n",
    "\n",
    "    Args:\n",
    "        user_query: User's question\n",
    "        context: Assembled context (system + user + retrieved)\n",
    "\n",
    "    Returns:\n",
    "        LLM response string\n",
    "    \"\"\"\n",
    "    messages = [SystemMessage(content=context), HumanMessage(content=user_query)]\n",
    "\n",
    "    response = await llm.ainvoke(messages)\n",
    "    return response.content\n",
    "\n",
    "\n",
    "# Test generation\n",
    "response = await generate_response(test_query, assembled_context)\n",
    "\n",
    "print(\"\\nü§ñ Generated Response:\\n\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29793f2405eba89f",
   "metadata": {},
   "source": [
    "### üéØ Understanding the Generated Response\n",
    "\n",
    "Notice how the LLM's response demonstrates effective context engineering:\n",
    "\n",
    "**üë§ Personalization from User Context:**\n",
    "- Addresses Sarah by name\n",
    "- References her intermediate difficulty preference\n",
    "- Acknowledges her online format preference (even though the course is in-person)\n",
    "- Connects to her interests (machine learning and data science)\n",
    "\n",
    "**üìö Accuracy from Retrieved Context:**\n",
    "- Recommends CS009 (which was in the retrieved courses)\n",
    "- Provides correct course details (difficulty, format, credits, description)\n",
    "- Mentions prerequisites accurately (2 required)\n",
    "\n",
    "**ü§ñ Guidance from System Context:**\n",
    "- Acts as a supportive advisor (\"I'm here to help you succeed!\")\n",
    "- Explains reasoning for the recommendation\n",
    "- Acknowledges the format mismatch honestly\n",
    "- Stays within the provided course list\n",
    "\n",
    "This is the power of RAG: the LLM generates a response that is **personalized** (User Context), **accurate** (Retrieved Context), and **helpful** (System Context). Without RAG, the LLM would either hallucinate course details or provide generic advice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dff6ee-0f65-4875-b0ee-469a2afd26b0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚ú® Step 7: Complete RAG Function\n",
    "\n",
    "Let's combine all three steps into a single, reusable RAG function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4a079374b0fe92c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T02:55:14.222912Z",
     "iopub.status.busy": "2025-11-05T02:55:14.222743Z",
     "iopub.status.idle": "2025-11-05T02:55:19.846336Z",
     "shell.execute_reply": "2025-11-05T02:55:19.845635Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "COMPLETE RAG PIPELINE TEST\n",
      "============================================================\n",
      "\n",
      "Query: I'm interested in learning about databases and data management\n",
      "\n",
      "Student: Alex Johnson (Data Science, Sophomore)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:14 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:19 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Courses:\n",
      "   1. CS004: Database Systems\n",
      "   2. CS009: Data Structures and Algorithms\n",
      "   3. CS007: Machine Learning\n",
      "\n",
      "AI Response:\n",
      "Hi Alex! It's great to hear that you're interested in databases and data management, especially considering your major in Data Science. Based on your profile, I recommend the following course:\n",
      "\n",
      "**CS004: Database Systems**\n",
      "- **Difficulty**: Intermediate\n",
      "- **Format**: Online\n",
      "- **Credits**: 3\n",
      "- **Description**: This course covers the design and implementation of database systems, including SQL, normalization, transactions, and database administration.\n",
      "- **Prerequisites**: None\n",
      "\n",
      "This course aligns well with your interests in databases and SQL, and being at an intermediate level, it should match your current skill set nicely. Although it's fully online, it will provide you with a solid foundation in database management which is crucial for your field.\n",
      "\n",
      "If you're open to considering more advanced topics in the future, you might also look into **CS007: Machine Learning** once you're ready to tackle more challenging material, as it could complement your data analysis skills.\n",
      "\n",
      "Feel free to ask if you have any questions or need further guidance!\n"
     ]
    }
   ],
   "source": [
    "async def rag_query(\n",
    "    user_query: str, user_profile: dict = None, limit: int = 3, filters: dict = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Complete RAG pipeline: Retrieve ‚Üí Assemble ‚Üí Generate\n",
    "\n",
    "    Args:\n",
    "        user_query: User's question\n",
    "        user_profile: Optional student profile\n",
    "        limit: Number of courses to retrieve\n",
    "        filters: Optional metadata filters\n",
    "\n",
    "    Returns:\n",
    "        LLM response string\n",
    "    \"\"\"\n",
    "    # Step 1: Retrieve relevant courses\n",
    "    retrieved_courses = await retrieve_courses(user_query, limit, filters)\n",
    "\n",
    "    # Step 2: Assemble context\n",
    "    context = assemble_context(user_query, retrieved_courses, user_profile)\n",
    "\n",
    "    # Step 3: Generate response\n",
    "    response = await generate_response(user_query, context)\n",
    "\n",
    "    return response, retrieved_courses\n",
    "\n",
    "\n",
    "# Test the complete RAG pipeline\n",
    "print(\"=\" * 60)\n",
    "print(\"COMPLETE RAG PIPELINE TEST\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "query = \"I'm interested in learning about databases and data management\"\n",
    "profile = {\n",
    "    \"name\": \"Alex Johnson\",\n",
    "    \"major\": \"Data Science\",\n",
    "    \"year\": \"Sophomore\",\n",
    "    \"interests\": [\"databases\", \"data analysis\", \"SQL\"],\n",
    "    \"preferred_difficulty\": \"intermediate\",\n",
    "    \"preferred_format\": \"hybrid\",\n",
    "}\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print()\n",
    "print(f\"Student: {profile['name']} ({profile['major']}, {profile['year']})\")\n",
    "print()\n",
    "\n",
    "response, courses = await rag_query(query, profile, limit=3)\n",
    "\n",
    "print(\"Retrieved Courses:\")\n",
    "for i, course in enumerate(courses, 1):\n",
    "    print(f\"   {i}. {course.course_code}: {course.title}\")\n",
    "print()\n",
    "\n",
    "print(\"AI Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f126f77dd7242ddb",
   "metadata": {},
   "source": [
    "### üéØ Why This Complete RAG Function Matters\n",
    "\n",
    "The `rag_query()` function encapsulates the entire RAG pipeline in a single, reusable interface. This is important because:\n",
    "\n",
    "**1. Simplicity:** One function call handles retrieval ‚Üí assembly ‚Üí generation\n",
    "- No need to manually orchestrate the three steps\n",
    "- Clean API for building applications\n",
    "\n",
    "**2. Consistency:** Every query follows the same pattern\n",
    "- Ensures all three context types are always included\n",
    "- Reduces errors from missing context\n",
    "\n",
    "**3. Flexibility:** Easy to customize behavior\n",
    "- Adjust `top_k` for more/fewer retrieved courses\n",
    "- Add/remove user profile information\n",
    "- Modify filters for specific use cases\n",
    "\n",
    "**4. Production-Ready:** This pattern scales to real applications\n",
    "- In Section 3, we'll add memory (conversation history)\n",
    "- In Section 4, we'll add tools (course enrollment, prerequisites checking)\n",
    "- The core RAG pattern remains the same\n",
    "\n",
    "This is the foundation you'll build on throughout the rest of the course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d63b2d5a412a8d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üß™ Step 8: Try Different Queries\n",
    "\n",
    "Let's test our RAG system with various queries to see how it handles different scenarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6d543a2d75022b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T02:55:19.849709Z",
     "iopub.status.busy": "2025-11-05T02:55:19.849459Z",
     "iopub.status.idle": "2025-11-05T02:55:27.018643Z",
     "shell.execute_reply": "2025-11-05T02:55:27.017535Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 1: Beginner Programming\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:20 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:27 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: I'm new to programming and want to start learning\n",
      "\n",
      "\n",
      "AI Response:\n",
      "\n",
      "Hi Maria! It's great to hear that you're interested in starting your programming journey. Since you're a beginner and looking for online courses, I recommend considering the following:\n",
      "\n",
      "1. **CS001: Introduction to Programming**\n",
      "   - **Department:** Computer Science\n",
      "   - **Difficulty:** Beginner\n",
      "   - **Format:** Hybrid (note: while it's not fully online, it may still offer some online components)\n",
      "   - **Credits:** 3\n",
      "   - **Description:** This course covers fundamental programming concepts using Python, including variables, control structures, functions, and basic data structures.\n",
      "   - **Prerequisites:** None required.\n",
      "\n",
      "2. **CS005: Introduction to Programming**\n",
      "   - **Department:** Computer Science\n",
      "   - **Difficulty:** Beginner\n",
      "   - **Format:** Hybrid (similar note on format)\n",
      "   - **Credits:** 3\n",
      "   - **Description:** This course also focuses on fundamental programming concepts using Python, covering the same material as CS001.\n",
      "   - **Prerequisites:** None required.\n",
      "\n",
      "Both courses are excellent starting points for anyone new to programming, and they cover the basics of Python, which is a great language for beginners. \n",
      "\n",
      "If you're specifically looking for a fully online option, it might be worth checking if there are any upcoming offerings for these courses in an online format or discussing with your academic advisor about potential alternatives.\n",
      "\n",
      "I encourage you to take the plunge into programming‚Äîit's a valuable skill that can open many doors in technology! Let me know if you have any questions or need further assistance!\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Beginner looking for programming courses\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 1: Beginner Programming\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "query1 = \"I'm new to programming and want to start learning\"\n",
    "profile1 = {\n",
    "    \"name\": \"Maria Garcia\",\n",
    "    \"major\": \"Undeclared\",\n",
    "    \"year\": \"Freshman\",\n",
    "    \"interests\": [\"programming\", \"technology\"],\n",
    "    \"preferred_difficulty\": \"beginner\",\n",
    "    \"preferred_format\": \"online\",\n",
    "}\n",
    "\n",
    "response1, courses1 = await rag_query(query1, profile1, limit=2)\n",
    "print(f\"\\nQuery: {query1}\\n\")\n",
    "print(\"\\nAI Response:\\n\")\n",
    "print(response1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6430f264bc17b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T02:55:27.020674Z",
     "iopub.status.busy": "2025-11-05T02:55:27.020529Z",
     "iopub.status.idle": "2025-11-05T02:55:31.114946Z",
     "shell.execute_reply": "2025-11-05T02:55:31.113887Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 2: Advanced Machine Learning\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:27 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:31 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: I want advanced courses in machine learning and AI\n",
      "\n",
      "\n",
      "AI Response:\n",
      "\n",
      "Hi David! Based on your interests in machine learning and AI, I recommend taking CS007: Machine Learning. \n",
      "\n",
      "Here's why it aligns with your profile:\n",
      "\n",
      "- **Difficulty Level**: CS007 is classified as advanced, matching your preference for more challenging coursework.\n",
      "- **Content**: The course covers essential topics such as supervised and unsupervised learning and neural networks, which are crucial in both machine learning and AI research.\n",
      "- **Format**: Although it is offered in a hybrid format, it still provides a strong foundation for advanced concepts in the field.\n",
      "\n",
      "Unfortunately, the available courses do not specifically cover AI or advanced machine learning beyond CS007. However, CS007 is a solid choice to deepen your knowledge in machine learning, which is integral to AI.\n",
      "\n",
      "If you have any other questions or need further assistance, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Advanced student looking for specialized courses\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 2: Advanced Machine Learning\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "query2 = \"I want advanced courses in machine learning and AI\"\n",
    "profile2 = {\n",
    "    \"name\": \"David Kim\",\n",
    "    \"major\": \"Computer Science\",\n",
    "    \"year\": \"Senior\",\n",
    "    \"interests\": [\"machine learning\", \"AI\", \"research\"],\n",
    "    \"preferred_difficulty\": \"advanced\",\n",
    "    \"preferred_format\": \"in-person\",\n",
    "}\n",
    "\n",
    "response2, courses2 = await rag_query(query2, profile2, limit=2)\n",
    "print(f\"\\nQuery: {query2}\\n\")\n",
    "print(\"\\nAI Response:\\n\")\n",
    "print(response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38103b67a0624eb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T02:55:31.117387Z",
     "iopub.status.busy": "2025-11-05T02:55:31.117212Z",
     "iopub.status.idle": "2025-11-05T02:55:35.643787Z",
     "shell.execute_reply": "2025-11-05T02:55:35.642878Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 3: Business Analytics\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:31 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:35 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: What courses can help me with business analytics and decision making?\n",
      "\n",
      "\n",
      "\n",
      "AI Response:\n",
      "\n",
      "Hi Jennifer! It's great to see your interest in business analytics and decision making. However, based on the course list provided, I don't see any specific courses that directly focus on business analytics or decision-making strategies.\n",
      "\n",
      "The courses listed, such as BUS032 and BUS034, focus on marketing strategy, which may touch upon aspects of analytics in terms of market analysis and consumer behavior, but they do not specifically cater to business analytics or decision-making.\n",
      "\n",
      "Given your major in Business Administration and your interests, I recommend considering courses in data analytics or management strategy if they are available in the future. For now, if you are open to exploring marketing strategy, either BUS032 or BUS034 could still provide valuable insights into strategic decision-making processes.\n",
      "\n",
      "If you have any other specific interests or questions, feel free to ask! I'm here to help you achieve your academic goals.\n"
     ]
    }
   ],
   "source": [
    "# Test 3: Business student looking for relevant courses\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 3: Business Analytics\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "query3 = \"What courses can help me with business analytics and decision making?\"\n",
    "profile3 = {\n",
    "    \"name\": \"Jennifer Lee\",\n",
    "    \"major\": \"Business Administration\",\n",
    "    \"year\": \"Junior\",\n",
    "    \"interests\": [\"analytics\", \"management\", \"strategy\"],\n",
    "    \"preferred_difficulty\": \"intermediate\",\n",
    "    \"preferred_format\": \"hybrid\",\n",
    "}\n",
    "\n",
    "response3, courses3 = await rag_query(query3, profile3, limit=2)\n",
    "print(f\"\\nQuery: {query3}\\n\")\n",
    "print()\n",
    "print(\"\\nAI Response:\\n\")\n",
    "print(response3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6994c097a695afdb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéì Key Takeaways\n",
    "\n",
    "### What You've Learned\n",
    "\n",
    "**1. RAG Fundamentals**\n",
    "- RAG dynamically retrieves relevant information instead of hardcoding knowledge\n",
    "- Vector embeddings enable semantic search (meaning-based, not keyword-based)\n",
    "- RAG solves the scalability and token efficiency problems of static context\n",
    "\n",
    "**2. The RAG Pipeline**\n",
    "```\n",
    "User Query ‚Üí Semantic Search ‚Üí Context Assembly ‚Üí LLM Generation\n",
    "```\n",
    "- **Retrieval:** Find relevant documents using vector similarity\n",
    "- **Assembly:** Combine system + user + retrieved context\n",
    "- **Generation:** LLM creates personalized response with full context\n",
    "\n",
    "**3. Context Engineering in Practice**\n",
    "- **System Context:** AI role and instructions (static)\n",
    "- **User Context:** Student profile and preferences (dynamic, user-specific)\n",
    "- **Retrieved Context:** Relevant courses from vector search (dynamic, query-specific)\n",
    "- **Integration:** All three context types work together\n",
    "\n",
    "**4. Technical Implementation with Reference Agent Utilities**\n",
    "- **redis_config**: Production-ready Redis configuration (RedisVL + LangChain)\n",
    "  - Manages connections, embeddings, vector index, checkpointer\n",
    "  - Same configuration used in reference agent\n",
    "- **CourseManager**: Handles all course operations\n",
    "  - Uses RedisVL's VectorQuery for semantic search\n",
    "  - Supports metadata filters with Tag and Num classes\n",
    "  - Automatically generates embeddings and stores courses\n",
    "- **CourseIngestionPipeline**: Bulk data ingestion\n",
    "  - Loads JSON, generates embeddings, stores in Redis\n",
    "  - Progress tracking and verification\n",
    "- **Benefits**: Focus on RAG concepts, not Redis implementation details\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "**Retrieval:**\n",
    "- Retrieve only what's needed (top-k results)\n",
    "- Use metadata filters to narrow results\n",
    "- Balance between too few (missing info) and too many (wasting tokens) results\n",
    "- **üí° Research Insight:** Context Rot research shows that distractors (similar-but-wrong information) have amplified negative impact in long contexts. Precision in retrieval matters more than recall. ([Context Rot paper](https://research.trychroma.com/context-rot))\n",
    "\n",
    "**Context Assembly:**\n",
    "- Structure context clearly (system ‚Üí user ‚Üí retrieved)\n",
    "- Include only relevant metadata\n",
    "- Keep descriptions concise but informative\n",
    "\n",
    "**Generation:**\n",
    "- Use appropriate temperature (0.7 for creative, 0.0 for factual)\n",
    "- Provide clear instructions in system context\n",
    "- Let the LLM explain its reasoning\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f445a3359501a4",
   "metadata": {},
   "source": [
    "## Part 4: Context Quality Matters\n",
    "\n",
    "### Why Quality Engineering is Essential\n",
    "\n",
    "You've built a working RAG system - congratulations! But there's a critical question: **What makes context \"good\"?**\n",
    "\n",
    "In the next notebook, you'll learn that context engineering is real engineering - it requires the same rigor, analysis, and deliberate decision-making as any other engineering discipline. Let's preview why this matters with a concrete example.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9b8641f068666b",
   "metadata": {},
   "source": [
    "### Example: The Impact of Poor vs. Well-Engineered Context\n",
    "\n",
    "Let's see what happens when we don't engineer our context properly.\n",
    "\n",
    "**Scenario:** A student asks about machine learning courses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38e31170-962f-4fe9-9209-a48f23a33400",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T02:55:35.646750Z",
     "iopub.status.busy": "2025-11-05T02:55:35.646588Z",
     "iopub.status.idle": "2025-11-05T02:55:35.954126Z",
     "shell.execute_reply": "2025-11-05T02:55:35.953652Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:35 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå POOR CONTEXT (Naive Approach):\n",
      "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
      "Courses: 10 (unfiltered - may not be relevant)\n",
      "Tokens: 1,257\n",
      "Format: Raw JSON with all fields (including internal IDs)\n",
      "\n",
      "Sample:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"course_catalog:01K98Z0MEGD61VQMAV074C6NHD\",\n",
      "    \"course_code\": \"MATH027\",\n",
      "    \"title\": \"Calculus I\",\n",
      "    \"description\": \"Differential calculus including limits, derivatives, and applications. Foundation for advanced mathematics.\",\n",
      "    \"department\": \"Mathematics\",\n",
      "    \"credits\": 4,\n",
      " ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Poor context: Raw JSON dump (what we might do naively)\n",
    "# Get first 10 courses using a broad search\n",
    "poor_context_courses = await course_manager.search_courses(\"course\", limit=10)\n",
    "\n",
    "poor_context = json.dumps(\n",
    "    [\n",
    "        {\n",
    "            \"id\": c.id,\n",
    "            \"course_code\": c.course_code,\n",
    "            \"title\": c.title,\n",
    "            \"description\": c.description,\n",
    "            \"department\": c.department,\n",
    "            \"credits\": c.credits,\n",
    "            \"difficulty_level\": c.difficulty_level.value,\n",
    "            \"format\": c.format.value,\n",
    "            \"instructor\": c.instructor,\n",
    "            \"prerequisites\": (\n",
    "                [p.course_code for p in c.prerequisites] if c.prerequisites else []\n",
    "            ),\n",
    "        }\n",
    "        for c in poor_context_courses\n",
    "    ],\n",
    "    indent=2,\n",
    ")\n",
    "\n",
    "poor_tokens = count_tokens(poor_context)\n",
    "\n",
    "print(\n",
    "    f\"\"\"‚ùå POOR CONTEXT (Naive Approach):\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "Courses: {len(poor_context_courses)} (unfiltered - may not be relevant)\n",
    "Tokens: {poor_tokens:,}\n",
    "Format: Raw JSON with all fields (including internal IDs)\n",
    "\n",
    "Sample:\n",
    "{poor_context[:300]}...\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e77ef9355ce3d7",
   "metadata": {},
   "source": [
    "Now let's compare with well-engineered context using our RAG system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "742185aabf47db4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T02:55:35.955359Z",
     "iopub.status.busy": "2025-11-05T02:55:35.955285Z",
     "iopub.status.idle": "2025-11-05T02:55:36.343123Z",
     "shell.execute_reply": "2025-11-05T02:55:36.342015Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:36 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ WELL-ENGINEERED CONTEXT (RAG + Optimization):\n",
      "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
      "Courses: 3 (filtered by semantic relevance)\n",
      "Tokens: 147\n",
      "Format: LLM-optimized text (no internal fields, clean formatting)\n",
      "\n",
      "Context:\n",
      "CS007: Machine Learning (advanced)\n",
      "Description: Introduction to machine learning algorithms and applications. Supervised and unsupervised learning, neural networks.\n",
      "Department: Computer Science | Credits: 4 | Format: hybrid\n",
      "Prerequisites: None\n",
      "\n",
      "MATH026: Linear Algebra (intermediate)\n",
      "Description: Vector spaces, matrices, eigenvalues, and linear transformations. Essential for data science and engineering.\n",
      "Department: Mathematics | Credits: 3 | Format: in_person\n",
      "Prerequisites: None\n",
      "\n",
      "MATH022: Linear Algebra (intermediate)\n",
      "Description: Vector spaces, matrices, eigenvalues, and linear transformations. Essential for data science and engineering.\n",
      "Department: Mathematics | Credits: 3 | Format: in_person\n",
      "Prerequisites: None\n",
      "\n",
      "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
      "Token Reduction: 1,110 tokens (88.3% reduction)\n",
      "Cost Savings: $0.0028 per request\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Well-engineered context: Filtered + Optimized\n",
    "query = \"What machine learning courses are available?\"\n",
    "\n",
    "# Use our RAG system to get relevant courses\n",
    "relevant_courses = await course_manager.search_courses(query, limit=3)\n",
    "\n",
    "# Transform to LLM-friendly format (not raw JSON)\n",
    "well_engineered_context = \"\\n\\n\".join(\n",
    "    [\n",
    "        f\"\"\"{course.course_code}: {course.title} ({course.difficulty_level.value})\n",
    "Description: {course.description}\n",
    "Department: {course.department} | Credits: {course.credits} | Format: {course.format.value}\n",
    "Prerequisites: {', '.join([p.course_code for p in course.prerequisites]) if course.prerequisites else 'None'}\"\"\"\n",
    "        for course in relevant_courses\n",
    "    ]\n",
    ")\n",
    "\n",
    "good_tokens = count_tokens(well_engineered_context)\n",
    "\n",
    "print(\n",
    "    f\"\"\"‚úÖ WELL-ENGINEERED CONTEXT (RAG + Optimization):\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "Courses: {len(relevant_courses)} (filtered by semantic relevance)\n",
    "Tokens: {good_tokens:,}\n",
    "Format: LLM-optimized text (no internal fields, clean formatting)\n",
    "\n",
    "Context:\n",
    "{well_engineered_context}\n",
    "\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "Token Reduction: {poor_tokens - good_tokens:,} tokens ({((poor_tokens - good_tokens) / poor_tokens * 100):.1f}% reduction)\n",
    "Cost Savings: ${((poor_tokens - good_tokens) / 1_000_000) * 2.50:.4f} per request\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df48bc4771c49ee",
   "metadata": {},
   "source": [
    "### The Difference in LLM Responses\n",
    "\n",
    "Let's see how context quality affects the actual responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49a4d41f673b11a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T02:55:36.345636Z",
     "iopub.status.busy": "2025-11-05T02:55:36.345452Z",
     "iopub.status.idle": "2025-11-05T02:55:42.887153Z",
     "shell.execute_reply": "2025-11-05T02:55:42.885839Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:42 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå RESPONSE WITH POOR CONTEXT:\n",
      "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
      "Currently, there are no specific machine learning courses listed in the available course catalog. If you're interested in related topics, you might want to consider courses such as \"Statistics for Data Science,\" which covers statistical methods and probability theory that are foundational for understanding machine learning concepts. \n",
      "\n",
      "Here are the relevant options:\n",
      "\n",
      "1. **Statistics for Data Science (Hybrid)**\n",
      "   - Instructor: Chris Flores\n",
      "   - Credits: 4\n",
      "   - Description: Statistical methods and probability theory for data analysis. Hypothesis testing, regression, and statistical inference.\n",
      "\n",
      "2. **Statistics for Data Science (In-person)**\n",
      "   - Instructor: Rhonda Rodriguez\n",
      "   - Credits: 4\n",
      "   - Description: Statistical methods and probability theory for data analysis. Hypothesis testing, regression, and statistical inference.\n",
      "\n",
      "3. **Statistics for Data Science (Hybrid)**\n",
      "   - Instructor: Joshua Stone\n",
      "   - Credits: 4\n",
      "   - Description: Statistical methods and probability theory for data analysis. Hypothesis testing, regression, and statistical inference.\n",
      "\n",
      "4. **Statistics for Data Science (Online)**\n",
      "   - Instructor: Alex Long\n",
      "   - Credits: 4\n",
      "   - Description: Statistical methods and probability theory for data analysis. Hypothesis testing, regression, and statistical inference.\n",
      "\n",
      "If you're looking for further courses specifically in machine learning, I recommend checking back later or looking for related programs that may include machine learning topics.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test with poor context\n",
    "messages_poor = [\n",
    "    SystemMessage(\n",
    "        content=f\"\"\"You are a Redis University course advisor.\n",
    "\n",
    "Available Courses:\n",
    "{poor_context}\n",
    "\n",
    "Help students find relevant courses.\"\"\"\n",
    "    ),\n",
    "    HumanMessage(content=query),\n",
    "]\n",
    "\n",
    "response_poor = llm.invoke(messages_poor)\n",
    "\n",
    "print(\n",
    "    f\"\"\"‚ùå RESPONSE WITH POOR CONTEXT:\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "{response_poor.content}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1d43f264c681b61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-05T02:55:42.890398Z",
     "iopub.status.busy": "2025-11-05T02:55:42.890181Z",
     "iopub.status.idle": "2025-11-05T02:55:46.212033Z",
     "shell.execute_reply": "2025-11-05T02:55:46.211019Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:55:46 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ RESPONSE WITH WELL-ENGINEERED CONTEXT:\n",
      "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
      "The available machine learning course is:\n",
      "\n",
      "**CS007: Machine Learning (advanced)**\n",
      "- **Description:** Introduction to machine learning algorithms and applications. Covers supervised and unsupervised learning, and neural networks.\n",
      "- **Department:** Computer Science\n",
      "- **Credits:** 4\n",
      "- **Format:** Hybrid\n",
      "- **Prerequisites:** None\n",
      "\n",
      "This course is suitable for students interested in gaining a deeper understanding of machine learning concepts and applications.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test with well-engineered context\n",
    "messages_good = [\n",
    "    SystemMessage(\n",
    "        content=f\"\"\"You are a Redis University course advisor.\n",
    "\n",
    "Relevant Courses:\n",
    "{well_engineered_context}\n",
    "\n",
    "Help students find the best course for their needs.\"\"\"\n",
    "    ),\n",
    "    HumanMessage(content=query),\n",
    "]\n",
    "\n",
    "response_good = llm.invoke(messages_good)\n",
    "\n",
    "print(\n",
    "    f\"\"\"‚úÖ RESPONSE WITH WELL-ENGINEERED CONTEXT:\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "{response_good.content}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b99887a7d40e67",
   "metadata": {},
   "source": [
    "### Key Takeaways: Why Context Engineering Matters\n",
    "\n",
    "From this example, you can see that well-engineered context:\n",
    "\n",
    "1. **Reduces Token Usage** - 50-70% fewer tokens through filtering and optimization\n",
    "2. **Improves Relevance** - Semantic search finds the right courses\n",
    "3. **Enhances Response Quality** - LLM can focus on relevant information\n",
    "4. **Saves Money** - Fewer tokens = lower API costs\n",
    "5. **Scales Better** - Works with thousands of courses, not just 10\n",
    "\n",
    "**The Engineering Mindset:**\n",
    "- Context is data that requires engineering discipline\n",
    "- Raw data ‚â† Good context\n",
    "- Systematic transformation: Extract ‚Üí Clean ‚Üí Transform ‚Üí Optimize ‚Üí Store\n",
    "- Quality metrics: Relevance, Completeness, Efficiency, Accuracy\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48a057aaae7e8ab",
   "metadata": {},
   "source": [
    "### What You'll Learn in the Next Notebook\n",
    "\n",
    "In **Notebook 2: Engineering Context for Production**, you'll dive deep into:\n",
    "\n",
    "**Data Engineering for Context:**\n",
    "- Systematic transformation pipeline (Extract ‚Üí Clean ‚Üí Transform ‚Üí Optimize ‚Üí Store)\n",
    "- Three engineering approaches: RAG, Structured Views, Hybrid\n",
    "- When to use each approach based on your requirements\n",
    "\n",
    "**Chunking Strategies:**\n",
    "- When does your data need chunking? (Critical first question)\n",
    "- Four different chunking strategies with LangChain integration\n",
    "- How to choose based on your data characteristics\n",
    "\n",
    "**Production Pipelines:**\n",
    "- Three pipeline architectures (Request-Time, Batch, Event-Driven)\n",
    "- Building production-ready context preparation workflows\n",
    "- Quality optimization and testing\n",
    "\n",
    "**You'll learn to engineer context with the same rigor as any other data engineering problem.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5da886e31e5b50",
   "metadata": {},
   "source": [
    "## üöÄ What's Next?\n",
    "\n",
    "### üìä Section 2, Notebook 2: Engineering Context for Production\n",
    "\n",
    "Now that you understand RAG fundamentals and why context quality matters, the next notebook teaches you to engineer context with production-level rigor:\n",
    "- Master data engineering workflows for context preparation\n",
    "- Learn chunking strategies and when to use them\n",
    "- Build production-ready context pipelines\n",
    "- Optimize context quality with systematic approaches\n",
    "\n",
    "### üß† Section 3: Memory Systems for Context Engineering\n",
    "\n",
    "In this section, you built a RAG system that retrieves relevant information for each query. But there's a problem: **it doesn't remember previous conversations**.\n",
    "\n",
    "In Section 3, you'll add memory to your RAG system:\n",
    "- **Working Memory:** Track conversation history within a session\n",
    "- **Long-term Memory:** Remember user preferences across sessions\n",
    "- **LangGraph Integration:** Manage stateful workflows with checkpointing\n",
    "- **Redis Agent Memory Server:** Automatic memory extraction and retrieval\n",
    "\n",
    "### ü§ñ Section 4: Tool Use and Agents\n",
    "\n",
    "After adding memory, you'll transform your RAG system into a full agent:\n",
    "- **Tool Calling:** Let the AI use functions (search, enroll, check prerequisites)\n",
    "- **LangGraph State Management:** Orchestrate complex multi-step workflows\n",
    "- **Agent Reasoning:** Plan and execute multi-step tasks\n",
    "- **Production Patterns:** Error handling, retries, and monitoring\n",
    "\n",
    "### The Journey\n",
    "\n",
    "```\n",
    "Section 1: Context Engineering Fundamentals\n",
    "    ‚Üì\n",
    "Section 2, NB1: RAG Fundamentals ‚Üê You are here\n",
    "    ‚Üì\n",
    "Section 2, NB2: Engineering Context for Production ‚Üê Next\n",
    "    ‚Üì\n",
    "Section 3: Memory Systems for Context Engineering\n",
    "    ‚Üì\n",
    "Section 4: Tool Use and Agents (Complete System)\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb63ec59713eebcf",
   "metadata": {},
   "source": [
    "## üí™ Practice Exercises\n",
    "\n",
    "Try these exercises to deepen your understanding:\n",
    "\n",
    "**Exercise 1: Custom Filters**\n",
    "- Modify the RAG query to filter by specific departments\n",
    "- Try combining multiple filters (difficulty + format + department)\n",
    "\n",
    "**Exercise 2: Adjust Retrieval**\n",
    "- Experiment with different `top_k` values (1, 3, 5, 10)\n",
    "- Observe how response quality changes with more/fewer retrieved courses\n",
    "\n",
    "**Exercise 3: Context Optimization**\n",
    "- Modify the `assemble_context` function to include more/less detail\n",
    "- Measure token usage and response quality trade-offs\n",
    "\n",
    "**Exercise 4: Different Domains**\n",
    "- Generate courses for a different domain (e.g., healthcare, finance)\n",
    "- Ingest and test RAG with your custom data\n",
    "\n",
    "**Exercise 5: Evaluation**\n",
    "- Create test queries with expected results\n",
    "- Measure retrieval accuracy (are the right courses retrieved?)\n",
    "- Measure generation quality (are responses helpful and accurate?)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b2ee5474515589",
   "metadata": {},
   "source": [
    "## üìù Summary\n",
    "\n",
    "You've built a complete RAG system that:\n",
    "- ‚úÖ Generates and ingests course data with vector embeddings\n",
    "- ‚úÖ Performs semantic search to find relevant courses\n",
    "- ‚úÖ Assembles context from multiple sources (system + user + retrieved)\n",
    "- ‚úÖ Generates personalized responses using LLMs\n",
    "- ‚úÖ Handles different query types and user profiles\n",
    "\n",
    "This RAG system is the foundation for the advanced topics in Sections 3 and 4. You'll build on this exact code to add memory, tools, and full agent capabilities.\n",
    "\n",
    "**Great work!** You've mastered Retrieved Context and built a production-ready RAG pipeline. üéâ\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Additional Resources\n",
    "\n",
    "### **RAG and Vector Search**\n",
    "- [Retrieval-Augmented Generation Paper](https://arxiv.org/abs/2005.11401) - Original RAG paper by Facebook AI\n",
    "- [Redis Vector Similarity Search](https://redis.io/docs/stack/search/reference/vectors/) - Official Redis VSS documentation\n",
    "- [RedisVL Documentation](https://redisvl.com/) - Redis Vector Library for Python\n",
    "- [LangChain RAG Tutorial](https://python.langchain.com/docs/tutorials/rag/) - Building RAG applications\n",
    "\n",
    "### **Embeddings and Semantic Search**\n",
    "- [OpenAI Embeddings Guide](https://platform.openai.com/docs/guides/embeddings) - Understanding text embeddings\n",
    "- [Sentence Transformers](https://www.sbert.net/) - Open-source embedding models\n",
    "- [HNSW Algorithm](https://arxiv.org/abs/1603.09320) - Hierarchical Navigable Small World graphs\n",
    "\n",
    "### **LangChain and Redis Integration**\n",
    "- [LangChain Documentation](https://python.langchain.com/docs/get_started/introduction) - Framework overview\n",
    "- [LangChain Redis Integration](https://python.langchain.com/docs/integrations/vectorstores/redis/) - Using Redis with LangChain\n",
    "- [Redis Python Client](https://redis-py.readthedocs.io/) - redis-py documentation\n",
    "\n",
    "### **Advanced RAG Techniques**\n",
    "- [Advanced RAG Patterns](https://blog.langchain.dev/deconstructing-rag/) - LangChain blog on RAG optimization\n",
    "- [Advanced Search with RedisVL](https://docs.redisvl.com/en/latest/user_guide/11_advanced_queries.html) - Vector, Hybrid, Text, and Keyword Search\n",
    "- [RAG Evaluation](https://arxiv.org/abs/2309.15217) - Measuring RAG system performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff96707ebbaf4026",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "102ccbbc1bcd464b8aae6e800427aa58": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "91e245e292de4b39a25d44303bc8d1ef": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_ec112180a1364704bebb872d6f26266b",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">Ingesting majors...</span> <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ</span> <span style=\"color: #800080; text-decoration-color: #800080\">  0%</span> <span style=\"color: #008080; text-decoration-color: #008080\">-:--:--</span>\n</pre>\n",
          "text/plain": "\u001b[34mIngesting majors...\u001b[0m \u001b[38;5;237m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[35m  0%\u001b[0m \u001b[36m-:--:--\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "93e09c8c24bb44b2959274577cab1d3a": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_102ccbbc1bcd464b8aae6e800427aa58",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Ingesting courses...</span> <span style=\"color: #f92672; text-decoration-color: #f92672\">‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">‚ï∫</span> <span style=\"color: #800080; text-decoration-color: #800080\"> 98%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:01</span>\n</pre>\n",
          "text/plain": "\u001b[32mIngesting courses...\u001b[0m \u001b[38;2;249;38;114m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[38;5;237m‚ï∫\u001b[0m \u001b[35m 98%\u001b[0m \u001b[36m0:00:01\u001b[0m\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     },
     "ec112180a1364704bebb872d6f26266b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
