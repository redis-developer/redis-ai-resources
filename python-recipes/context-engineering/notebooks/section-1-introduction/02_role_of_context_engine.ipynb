{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Redis](https://redis.io/wp-content/uploads/2024/04/Logotype.svg?auto=webp&quality=85,75&width=120)\n",
    "\n",
    "# The Role of a Context Engine\n",
    "\n",
    "## Introduction\n",
    "\n",
    "A **Context Engine** is the technical infrastructure that powers context engineering. It's the system responsible for storing, retrieving, managing, and serving contextual information to AI agents and applications.\n",
    "\n",
    "Think of a context engine as the \"brain's memory system\" - it handles both the storage of information and the intelligent retrieval of relevant context when needed. Just as human memory involves complex processes of encoding, storage, and retrieval, a context engine manages these same processes for AI systems.\n",
    "\n",
    "## What Makes a Context Engine?\n",
    "\n",
    "A context engine typically consists of several key components:\n",
    "\n",
    "### üóÑÔ∏è **Storage Layer**\n",
    "- **Vector databases** for semantic similarity search\n",
    "- **Traditional databases** for structured data\n",
    "- **Cache systems** for fast access to frequently used context\n",
    "- **File systems** for large documents and media\n",
    "\n",
    "### üîç **Retrieval Layer**\n",
    "- **Semantic search** using embeddings and vector similarity\n",
    "- **Keyword search** for exact matches and structured queries\n",
    "- **Hybrid search** combining multiple retrieval methods\n",
    "- **Ranking algorithms** to prioritize relevant results\n",
    "\n",
    "### üß† **Memory Management**\n",
    "- **Working memory** for active conversations, sessions, and task-related data (persistent)\n",
    "- **Long-term memory** for knowledge learned across sessions (user preferences, important facts)\n",
    "- **Memory consolidation** for moving important information from working to long-term memory\n",
    "\n",
    "### üîÑ **Integration Layer**\n",
    "- **APIs** for connecting with AI models and applications\n",
    "- **Streaming interfaces** for real-time context updates\n",
    "- **Batch processing** for large-scale context ingestion\n",
    "- **Event systems** for reactive context management\n",
    "\n",
    "## Redis as a Context Engine\n",
    "\n",
    "Redis is uniquely positioned to serve as a context engine because it provides:\n",
    "\n",
    "- **Vector Search**: Native support for semantic similarity search\n",
    "- **Multiple Data Types**: JSON documents, strings, hashes, lists, sets, streams, and more\n",
    "- **High Performance**: In-memory processing with sub-millisecond latency\n",
    "- **Persistence**: Durable storage with various persistence options\n",
    "- **Scalability**: Horizontal scaling with Redis Cluster\n",
    "- **Rich Ecosystem**: Integrations with AI frameworks and tools\n",
    "\n",
    "Let's explore how Redis functions as a context engine in our university class agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the Redis Context Course package\n",
    "%pip install -q -e ../../reference-agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import sys\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# Set up environment - handle both interactive and CI environments\n",
    "def _set_env(key: str):\n",
    "    if key not in os.environ:\n",
    "        # Check if we're in an interactive environment\n",
    "        if hasattr(sys.stdin, 'isatty') and sys.stdin.isatty():\n",
    "            import getpass\n",
    "            os.environ[key] = getpass.getpass(f\"{key}: \")\n",
    "        else:\n",
    "            # Non-interactive environment (like CI) - use a dummy key\n",
    "            print(f\"‚ö†Ô∏è  Non-interactive environment detected. Using dummy {key} for demonstration.\")\n",
    "            os.environ[key] = \"sk-dummy-key-for-testing-purposes-only\"\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "os.environ[\"REDIS_URL\"] = \"redis://localhost:6379\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context Engine Architecture\n",
    "\n",
    "Let's examine the architecture of our Redis-based context engine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Redis Context Course components with error handling\n",
    "try:\n",
    "    from redis_context_course.redis_config import redis_config\n",
    "    from redis_context_course import MemoryClient\n",
    "    from redis_context_course.course_manager import CourseManager\n",
    "    import redis\n",
    "    \n",
    "    PACKAGE_AVAILABLE = True\n",
    "    print(\"‚úÖ Redis Context Course package imported successfully\")\n",
    "    \n",
    "    # Check Redis connection\n",
    "    redis_healthy = redis_config.health_check()\n",
    "    print(f\"üì° Redis Connection: {'‚úÖ Healthy' if redis_healthy else '‚ùå Failed'}\")\n",
    "    \n",
    "    if redis_healthy:\n",
    "        # Show Redis info\n",
    "        redis_info = redis_config.redis_client.info()\n",
    "        print(f\"üìä Redis Version: {redis_info.get('redis_version', 'Unknown')}\")\n",
    "        print(f\"üíæ Memory Usage: {redis_info.get('used_memory_human', 'Unknown')}\")\n",
    "        print(f\"üîó Connected Clients: {redis_info.get('connected_clients', 'Unknown')}\")\n",
    "        \n",
    "        # Show configured indexes\n",
    "        print(f\"\\nüóÇÔ∏è Vector Indexes:\")\n",
    "        print(f\"  ‚Ä¢ Course Catalog: {redis_config.vector_index_name}\")\n",
    "        print(f\"  ‚Ä¢ Agent Memory: Managed by Agent Memory Server\")\n",
    "        \n",
    "        # Show data types in use\n",
    "        print(f\"\\nüìã Data Types in Use:\")\n",
    "        print(f\"  ‚Ä¢ Hashes: Course storage\")\n",
    "        print(f\"  ‚Ä¢ Vectors: Semantic embeddings (1536 dimensions)\")\n",
    "        print(f\"  ‚Ä¢ Strings: Simple key-value pairs\")\n",
    "        print(f\"  ‚Ä¢ Sets: Tags and categories\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è  Package not available: {e}\")\n",
    "    print(\"üìù This is expected in CI environments. Creating mock objects for demonstration...\")\n",
    "    \n",
    "    # Create mock classes\n",
    "    class MockRedisConfig:\n",
    "        def __init__(self):\n",
    "            self.vector_index_name = \"course_catalog_index\"\n",
    "        \n",
    "        def health_check(self):\n",
    "            return False  # Simulate Redis not available in CI\n",
    "    \n",
    "    class MemoryClient:\n",
    "        def __init__(self, student_id: str):\n",
    "            self.student_id = student_id\n",
    "            print(f\"üìù Mock MemoryClient created for {student_id}\")\n",
    "        \n",
    "        async def store_memory(self, content: str, memory_type: str, importance: float = 0.5, metadata: dict = None):\n",
    "            return \"mock-memory-id-12345\"\n",
    "        \n",
    "        async def retrieve_memories(self, query: str, limit: int = 5):\n",
    "            class MockMemory:\n",
    "                def __init__(self, content: str, memory_type: str):\n",
    "                    self.content = content\n",
    "                    self.memory_type = memory_type\n",
    "            \n",
    "            return [\n",
    "                MockMemory(\"Student prefers online courses\", \"preference\"),\n",
    "                MockMemory(\"Goal: AI specialization\", \"goal\"),\n",
    "                MockMemory(\"Strong programming background\", \"academic_performance\")\n",
    "            ]\n",
    "        \n",
    "        async def get_student_context(self, query: str):\n",
    "            return {\n",
    "                \"preferences\": [\"online courses\", \"flexible schedule\"],\n",
    "                \"goals\": [\"machine learning specialization\"],\n",
    "                \"general_memories\": [\"programming experience\"],\n",
    "                \"recent_conversations\": [\"course planning session\"]\n",
    "            }\n",
    "    \n",
    "    class CourseManager:\n",
    "        def __init__(self):\n",
    "            print(\"üìù Mock CourseManager created\")\n",
    "    \n",
    "    redis_config = MockRedisConfig()\n",
    "    redis_healthy = False\n",
    "    PACKAGE_AVAILABLE = False\n",
    "    print(\"‚úÖ Mock objects created for demonstration\")\n",
    "\n",
    "# Initialize our context engine components\n",
    "print(\"\\nüèóÔ∏è Context Engine Architecture\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"üì° Redis Connection: {'‚úÖ Healthy' if redis_healthy else '‚ùå Failed (using mock data)'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storage Layer Deep Dive\n",
    "\n",
    "Let's explore how different types of context are stored in Redis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate different storage patterns\n",
    "print(\"üíæ Storage Layer Patterns\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# 1. Structured Data Storage (Hashes)\n",
    "print(\"\\n1Ô∏è‚É£ Structured Data (Redis Hashes)\")\n",
    "sample_course_data = {\n",
    "    \"course_code\": \"CS101\",\n",
    "    \"title\": \"Introduction to Programming\",\n",
    "    \"credits\": \"3\",\n",
    "    \"department\": \"Computer Science\",\n",
    "    \"difficulty_level\": \"beginner\",\n",
    "    \"format\": \"online\"\n",
    "}\n",
    "\n",
    "print(\"Course data stored as hash:\")\n",
    "for key, value in sample_course_data.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# 2. Vector Storage for Semantic Search\n",
    "print(\"\\n2Ô∏è‚É£ Vector Embeddings (1536-dimensional)\")\n",
    "print(\"Sample embedding vector (first 10 dimensions):\")\n",
    "sample_embedding = np.random.rand(10)  # Simulated embedding\n",
    "print(f\"  [{', '.join([f'{x:.4f}' for x in sample_embedding])}...]\")\n",
    "print(f\"  Full vector: 1536 dimensions, stored as binary data\")\n",
    "\n",
    "# 3. Memory Storage Patterns\n",
    "print(\"\\n3Ô∏è‚É£ Memory Storage (Timestamped Records)\")\n",
    "sample_memory = {\n",
    "    \"id\": \"mem_12345\",\n",
    "    \"student_id\": \"student_alex\",\n",
    "    \"content\": \"Student prefers online courses due to work schedule\",\n",
    "    \"memory_type\": \"preference\",\n",
    "    \"importance\": \"0.9\",\n",
    "    \"created_at\": \"1703123456.789\",\n",
    "    \"metadata\": '{\"context\": \"course_planning\"}'\n",
    "}\n",
    "\n",
    "print(\"Memory record structure:\")\n",
    "for key, value in sample_memory.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval Layer in Action\n",
    "\n",
    "The retrieval layer is where the magic happens - turning queries into relevant context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate different retrieval methods\n",
    "print(\"üîç Retrieval Layer Methods\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Initialize managers\n",
    "import os\n",
    "from agent_memory_client import MemoryClientConfig\n",
    "\n",
    "config = MemoryClientConfig(\n",
    "    base_url=os.getenv(\"AGENT_MEMORY_URL\", \"http://localhost:8000\"),\n",
    "    default_namespace=\"redis_university\"\n",
    ")\n",
    "memory_client = MemoryClient(config=config)\n",
    "course_manager = CourseManager()\n",
    "\n",
    "async def demonstrate_retrieval_methods():\n",
    "    # 1. Exact Match Retrieval\n",
    "    print(\"\\n1Ô∏è‚É£ Exact Match Retrieval\")\n",
    "    print(\"Query: Find course with code 'CS101'\")\n",
    "    print(\"Method: Direct key lookup or tag filter\")\n",
    "    print(\"Use case: Looking up specific courses, IDs, or codes\")\n",
    "    \n",
    "    # 2. Semantic Similarity Search\n",
    "    print(\"\\n2Ô∏è‚É£ Semantic Similarity Search\")\n",
    "    print(\"Query: 'I want to learn machine learning'\")\n",
    "    print(\"Process:\")\n",
    "    print(\"  1. Convert query to embedding vector\")\n",
    "    print(\"  2. Calculate cosine similarity with stored vectors\")\n",
    "    print(\"  3. Return top-k most similar results\")\n",
    "    print(\"  4. Apply similarity threshold filtering\")\n",
    "    \n",
    "    # Simulate semantic search process\n",
    "    query = \"machine learning courses\"\n",
    "    print(f\"\\nüîç Simulating semantic search for: '{query}'\")\n",
    "    \n",
    "    # This would normally generate an actual embedding\n",
    "    print(\"  Step 1: Generate query embedding... ‚úÖ\")\n",
    "    print(\"  Step 2: Search vector index... ‚úÖ\")\n",
    "    print(\"  Step 3: Calculate similarities... ‚úÖ\")\n",
    "    print(\"  Step 4: Rank and filter results... ‚úÖ\")\n",
    "    \n",
    "    # 3. Hybrid Search\n",
    "    print(\"\\n3Ô∏è‚É£ Hybrid Search (Semantic + Filters)\")\n",
    "    print(\"Query: 'online programming courses for beginners'\")\n",
    "    print(\"Process:\")\n",
    "    print(\"  1. Semantic search: 'programming courses'\")\n",
    "    print(\"  2. Apply filters: format='online', difficulty='beginner'\")\n",
    "    print(\"  3. Combine and rank results\")\n",
    "    \n",
    "    # 4. Memory Retrieval\n",
    "    print(\"\\n4Ô∏è‚É£ Memory Retrieval\")\n",
    "    print(\"Query: 'What are my course preferences?'\")\n",
    "    print(\"Process:\")\n",
    "    print(\"  1. Semantic search in memory index\")\n",
    "    print(\"  2. Filter by memory_type='preference'\")\n",
    "    print(\"  3. Sort by importance and recency\")\n",
    "    print(\"  4. Return relevant memories\")\n",
    "\n",
    "await demonstrate_retrieval_methods()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Management System\n",
    "\n",
    "Let's explore how the context engine manages different types of memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate memory management\n",
    "print(\"üß† Memory Management System\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "async def demonstrate_memory_management():\n",
    "    # Working Memory (Task-Focused Context)\n",
    "    print(\"\\nüìù Working Memory (Persistent Task Context)\")\n",
    "    print(\"Purpose: Maintain conversation flow and task-related data\")\n",
    "    print(\"Storage: Redis Streams and Hashes (LangGraph Checkpointer)\")\n",
    "    print(\"Lifecycle: Persistent during task, can span multiple sessions\")\n",
    "    print(\"Example data:\")\n",
    "    print(\"  ‚Ä¢ Current conversation messages\")\n",
    "    print(\"  ‚Ä¢ Agent state and workflow position\")\n",
    "    print(\"  ‚Ä¢ Task-related variables and computations\")\n",
    "    print(\"  ‚Ä¢ Tool call results and intermediate steps\")\n",
    "    print(\"  ‚Ä¢ Search results being processed\")\n",
    "    print(\"  ‚Ä¢ Cached embeddings for current task\")\n",
    "    \n",
    "    # Long-term Memory (Cross-Session Knowledge)\n",
    "    print(\"\\nüóÑÔ∏è Long-term Memory (Cross-Session Knowledge)\")\n",
    "    print(\"Purpose: Store knowledge learned across sessions\")\n",
    "    print(\"Storage: Redis Vector Index with embeddings\")\n",
    "    print(\"Lifecycle: Persistent across all sessions\")\n",
    "    print(\"Example data:\")\n",
    "    \n",
    "    # Store some example memories\n",
    "    memory_examples = [\n",
    "        (\"preference\", \"Student prefers online courses\", 0.9),\n",
    "        (\"goal\", \"Wants to specialize in AI and machine learning\", 1.0),\n",
    "        (\"experience\", \"Struggled with calculus but excelled in programming\", 0.8),\n",
    "        (\"context\", \"Works part-time, needs flexible schedule\", 0.7)\n",
    "    ]\n",
    "    \n",
    "    for memory_type, content, importance in memory_examples:\n",
    "        print(f\"  ‚Ä¢ [{memory_type.upper()}] {content} (importance: {importance})\")\n",
    "    \n",
    "    # Memory Consolidation\n",
    "    print(\"\\nüîÑ Memory Consolidation Process\")\n",
    "    print(\"Purpose: Move important information from working to long-term memory\")\n",
    "    print(\"Triggers:\")\n",
    "    print(\"  ‚Ä¢ Conversation length exceeds threshold (20+ messages)\")\n",
    "    print(\"  ‚Ä¢ Important preferences or goals mentioned\")\n",
    "    print(\"  ‚Ä¢ Significant events or decisions made\")\n",
    "    print(\"  ‚Ä¢ End of session or explicit save commands\")\n",
    "    \n",
    "    print(\"\\nüìä Memory Status (Conceptual):\")\n",
    "    print(f\"  ‚Ä¢ Preferences stored: 1 (online courses)\")\n",
    "    print(f\"  ‚Ä¢ Goals stored: 1 (AI/ML specialization)\")\n",
    "    print(f\"  ‚Ä¢ General memories: 2 (calculus struggle, part-time work)\")\n",
    "    print(f\"  ‚Ä¢ Conversation summaries: 0 (new session)\")\n",
    "    print(\"\\nNote: See Section 3 notebooks for actual memory implementation.\")\n",
    "\n",
    "await demonstrate_memory_management()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration Layer: Connecting Everything\n",
    "\n",
    "The integration layer is how the context engine connects with AI models and applications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate integration patterns\n",
    "print(\"üîÑ Integration Layer Patterns\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# 1. LangGraph Integration\n",
    "print(\"\\n1Ô∏è‚É£ LangGraph Integration (Checkpointer)\")\n",
    "print(\"Purpose: Persistent agent state and conversation history\")\n",
    "print(\"Pattern: Redis as state store for workflow nodes\")\n",
    "print(\"Benefits:\")\n",
    "print(\"  ‚Ä¢ Automatic state persistence\")\n",
    "print(\"  ‚Ä¢ Resume conversations across sessions\")\n",
    "print(\"  ‚Ä¢ Parallel execution support\")\n",
    "print(\"  ‚Ä¢ Built-in error recovery\")\n",
    "\n",
    "# Show checkpointer configuration\n",
    "checkpointer_config = {\n",
    "    \"redis_client\": \"Connected Redis instance\",\n",
    "    \"namespace\": \"class_agent\",\n",
    "    \"serialization\": \"JSON with binary support\",\n",
    "    \"key_pattern\": \"namespace:thread_id:checkpoint_id\"\n",
    "}\n",
    "\n",
    "print(\"\\nCheckpointer Configuration:\")\n",
    "for key, value in checkpointer_config.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# 2. OpenAI Integration\n",
    "print(\"\\n2Ô∏è‚É£ OpenAI Integration (Embeddings & Chat)\")\n",
    "print(\"Purpose: Generate embeddings and chat completions\")\n",
    "print(\"Pattern: Context engine provides relevant information to LLM\")\n",
    "print(\"Flow:\")\n",
    "print(\"  1. User query ‚Üí Context engine retrieval\")\n",
    "print(\"  2. Retrieved context ‚Üí System prompt construction\")\n",
    "print(\"  3. Enhanced prompt ‚Üí OpenAI API\")\n",
    "print(\"  4. LLM response ‚Üí Context engine storage\")\n",
    "\n",
    "# 3. Tool Integration\n",
    "print(\"\\n3Ô∏è‚É£ Tool Integration (LangChain Tools)\")\n",
    "print(\"Purpose: Expose context engine capabilities as agent tools\")\n",
    "print(\"Available tools:\")\n",
    "tools_info = [\n",
    "    (\"search_courses_tool\", \"Semantic search in course catalog\"),\n",
    "    (\"get_recommendations_tool\", \"Personalized course recommendations\"),\n",
    "    (\"store_preference_tool\", \"Save user preferences to memory\"),\n",
    "    (\"store_goal_tool\", \"Save user goals to memory\"),\n",
    "    (\"get_student_context_tool\", \"Retrieve relevant user context\")\n",
    "]\n",
    "\n",
    "for tool_name, description in tools_info:\n",
    "    print(f\"  ‚Ä¢ {tool_name}: {description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Characteristics\n",
    "\n",
    "Let's examine the performance characteristics of our Redis-based context engine:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conceptual Example (not executable in this notebook)**\n",
    "\n",
    "```python\n",
    "import time\n",
    "import asyncio\n",
    "\n",
    "# Performance benchmarking\n",
    "print(\"‚ö° Performance Characteristics\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "async def benchmark_context_engine():\n",
    "    # 1. Memory Storage Performance\n",
    "    print(\"\\nüìù Memory Storage Performance\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Store multiple memories\n",
    "    memory_tasks = []\n",
    "    for i in range(10):\n",
    "#         task = memory_manager.store_memory(\n",
    "            f\"Test memory {i} for performance benchmarking\",\n",
    "            \"benchmark\",\n",
    "            importance=0.5\n",
    "        )\n",
    "        memory_tasks.append(task)\n",
    "    \n",
    "    await asyncio.gather(*memory_tasks)\n",
    "    storage_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"  Stored 10 memories in {storage_time:.3f} seconds\")\n",
    "    print(f\"  Average: {(storage_time/10)*1000:.1f} ms per memory\")\n",
    "    \n",
    "    # 2. Memory Retrieval Performance\n",
    "    print(\"\\nüîç Memory Retrieval Performance\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Perform multiple retrievals\n",
    "    retrieval_tasks = []\n",
    "    for i in range(5):\n",
    "#         task = memory_manager.retrieve_memories(\n",
    "            f\"performance test query {i}\",\n",
    "            limit=5\n",
    "        )\n",
    "        retrieval_tasks.append(task)\n",
    "    \n",
    "    results = await asyncio.gather(*retrieval_tasks)\n",
    "    retrieval_time = time.time() - start_time\n",
    "    \n",
    "    total_results = sum(len(result) for result in results)\n",
    "    print(f\"  Retrieved {total_results} memories in {retrieval_time:.3f} seconds\")\n",
    "    print(f\"  Average: {(retrieval_time/5)*1000:.1f} ms per query\")\n",
    "    \n",
    "    # 3. Context Integration Performance\n",
    "    print(\"\\nüß† Context Integration Performance\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Get comprehensive student context\n",
    "#     context = await memory_manager.get_student_context(\n",
    "        \"comprehensive context for performance testing\"\n",
    "    )\n",
    "    \n",
    "    integration_time = time.time() - start_time\n",
    "    context_size = len(str(context))\n",
    "    \n",
    "    print(f\"  Integrated context in {integration_time:.3f} seconds\")\n",
    "    print(f\"  Context size: {context_size} characters\")\n",
    "    print(f\"  Throughput: {context_size/integration_time:.0f} chars/second\")\n",
    "\n",
    "# Run performance benchmark\n",
    "if redis_config.health_check():\n",
    "    await benchmark_context_engine()\n",
    "else:\n",
    "    print(\"‚ùå Redis not available for performance testing\")",
    "```\n",
    "\n",
    "*Note: This demonstrates the concept. See Section 3 notebooks for actual memory implementation using MemoryClient.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context Engine Best Practices\n",
    "\n",
    "Based on our implementation, here are key best practices for building context engines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best practices demonstration\n",
    "print(\"üí° Context Engine Best Practices\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\n1Ô∏è‚É£ **Data Organization**\")\n",
    "print(\"‚úÖ Use consistent naming conventions for keys\")\n",
    "print(\"‚úÖ Separate different data types into different indexes\")\n",
    "print(\"‚úÖ Include metadata for filtering and sorting\")\n",
    "print(\"‚úÖ Use appropriate data structures for each use case\")\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£ **Memory Management**\")\n",
    "print(\"‚úÖ Implement memory consolidation strategies\")\n",
    "print(\"‚úÖ Use importance scoring for memory prioritization\")\n",
    "print(\"‚úÖ Distinguish between working memory (task-focused) and long-term memory (cross-session)\")\n",
    "print(\"‚úÖ Monitor memory usage and implement cleanup\")\n",
    "\n",
    "print(\"\\n3Ô∏è‚É£ **Search Optimization**\")\n",
    "print(\"‚úÖ Use appropriate similarity thresholds\")\n",
    "print(\"‚úÖ Combine semantic and keyword search when needed\")\n",
    "print(\"‚úÖ Implement result ranking and filtering\")\n",
    "print(\"‚úÖ Cache frequently accessed embeddings\")\n",
    "\n",
    "print(\"\\n4Ô∏è‚É£ **Performance Optimization**\")\n",
    "print(\"‚úÖ Use connection pooling for Redis clients\")\n",
    "print(\"‚úÖ Batch operations when possible\")\n",
    "print(\"‚úÖ Implement async operations for I/O\")\n",
    "print(\"‚úÖ Monitor and optimize query performance\")\n",
    "\n",
    "print(\"\\n5Ô∏è‚É£ **Error Handling**\")\n",
    "print(\"‚úÖ Implement graceful degradation\")\n",
    "print(\"‚úÖ Use circuit breakers for external services\")\n",
    "print(\"‚úÖ Log errors with sufficient context\")\n",
    "print(\"‚úÖ Provide fallback mechanisms\")\n",
    "\n",
    "print(\"\\n6Ô∏è‚É£ **Security & Privacy**\")\n",
    "print(\"‚úÖ Encrypt sensitive data at rest\")\n",
    "print(\"‚úÖ Use secure connections (TLS)\")\n",
    "print(\"‚úÖ Implement proper access controls\")\n",
    "print(\"‚úÖ Anonymize or pseudonymize personal data\")\n",
    "\n",
    "# Show example of good key naming\n",
    "print(\"\\nüìù Example: Good Key Naming Convention\")\n",
    "key_examples = [\n",
    "    \"course_catalog:CS101\",\n",
    "    \"agent_memory:student_alex:preference:mem_12345\",\n",
    "    \"session:thread_abc123:checkpoint:step_5\",\n",
    "    \"cache:embedding:query_hash_xyz789\"\n",
    "]\n",
    "\n",
    "for key in key_examples:\n",
    "    print(f\"  {key}\")\n",
    "    \n",
    "print(\"\\nPattern: namespace:entity:type:identifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-World Context Engine Example\n",
    "\n",
    "Let's see our context engine in action with a realistic scenario:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conceptual Example (not executable in this notebook)**\n",
    "\n",
    "```python\n",
    "# Real-world scenario demonstration\n",
    "print(\"üåç Real-World Context Engine Scenario\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "async def realistic_scenario():\n",
    "    print(\"\\nüìö Scenario: Student Planning Next Semester\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Step 1: Student context retrieval\n",
    "    print(\"\\n1Ô∏è‚É£ Context Retrieval Phase\")\n",
    "    query = \"I need help planning my courses for next semester\"\n",
    "    print(f\"Student Query: '{query}'\")\n",
    "    \n",
    "    # Simulate context retrieval\n",
    "    print(\"\\nüîç Context Engine Processing:\")\n",
    "    print(\"  ‚Ä¢ Retrieving student profile...\")\n",
    "    print(\"  ‚Ä¢ Searching relevant memories...\")\n",
    "    print(\"  ‚Ä¢ Loading academic history...\")\n",
    "    print(\"  ‚Ä¢ Checking preferences and goals...\")\n",
    "    \n",
    "    # Get actual context\n",
    "#     context = await memory_manager.get_student_context(query)\n",
    "    \n",
    "    print(\"\\nüìã Retrieved Context:\")\n",
    "    print(f\"  ‚Ä¢ Preferences: {len(context.get('preferences', []))} stored\")\n",
    "    print(f\"  ‚Ä¢ Goals: {len(context.get('goals', []))} stored\")\n",
    "    print(f\"  ‚Ä¢ Conversation history: {len(context.get('recent_conversations', []))} summaries\")\n",
    "    \n",
    "    # Step 2: Context integration\n",
    "    print(\"\\n2Ô∏è‚É£ Context Integration Phase\")\n",
    "    print(\"üß† Integrating multiple context sources:\")\n",
    "    \n",
    "    integrated_context = {\n",
    "        \"student_profile\": {\n",
    "            \"major\": \"Computer Science\",\n",
    "            \"year\": 2,\n",
    "            \"completed_credits\": 45,\n",
    "            \"gpa\": 3.7\n",
    "        },\n",
    "        \"preferences\": [\n",
    "            \"Prefers online courses due to work schedule\",\n",
    "            \"Interested in machine learning and AI\",\n",
    "            \"Wants hands-on programming experience\"\n",
    "        ],\n",
    "        \"constraints\": [\n",
    "            \"Maximum 15 credits per semester\",\n",
    "            \"Must complete CS201 prerequisite\",\n",
    "            \"Available Tuesday/Thursday evenings\"\n",
    "        ],\n",
    "        \"goals\": [\n",
    "            \"Graduate in 4 years\",\n",
    "            \"Specialize in AI/ML\",\n",
    "            \"Maintain 3.5+ GPA\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    for category, items in integrated_context.items():\n",
    "        print(f\"  ‚Ä¢ {category.title()}: {len(items) if isinstance(items, list) else 'Profile loaded'}\")\n",
    "    \n",
    "    # Step 3: Intelligent response generation\n",
    "    print(\"\\n3Ô∏è‚É£ Response Generation Phase\")\n",
    "    print(\"ü§ñ Context-aware response:\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    response = f\"\"\"\n",
    "Based on your profile and our previous conversations, here's my recommendation for next semester:\n",
    "\n",
    "üéØ **Personalized Plan for CS Year 2 Student:**\n",
    "\n",
    "**Recommended Courses (12 credits):**\n",
    "1. **CS301: Machine Learning Fundamentals** (4 credits, Online)\n",
    "   ‚Üí Aligns with your AI specialization goal\n",
    "   ‚Üí Available Tuesday evenings (fits your schedule)\n",
    "   ‚Üí Prerequisite CS201 will be completed this semester\n",
    "\n",
    "2. **CS250: Database Systems** (4 credits, Hybrid)\n",
    "   ‚Üí Essential for CS major requirements\n",
    "   ‚Üí Practical skills valuable for internships\n",
    "   ‚Üí Thursday evening lab sessions\n",
    "\n",
    "3. **MATH301: Statistics** (4 credits, Online)\n",
    "   ‚Üí Required for ML specialization\n",
    "   ‚Üí Fully online (matches your preference)\n",
    "   ‚Üí Self-paced with flexible deadlines\n",
    "\n",
    "**Why this plan works:**\n",
    "‚úÖ Stays within your 15-credit limit\n",
    "‚úÖ All courses available in preferred formats\n",
    "‚úÖ Fits your Tuesday/Thursday availability\n",
    "‚úÖ Advances your AI/ML specialization goal\n",
    "‚úÖ Maintains manageable workload for 3.5+ GPA\n",
    "\n",
    "**Next steps:**\n",
    "1. Verify CS201 completion this semester\n",
    "2. Check for any schedule conflicts\n",
    "3. Register early - these courses fill up quickly!\n",
    "\n",
    "Would you like me to help you explore any of these courses in more detail?\n",
    "\"\"\"\n",
    "    \n",
    "    print(response)\n",
    "    \n",
    "    # Step 4: Memory consolidation\n",
    "    print(\"\\n4Ô∏è‚É£ Memory Consolidation Phase\")\n",
    "    print(\"üíæ Storing interaction for future reference:\")\n",
    "    \n",
    "    # Store the planning session as a memory\n",
    "#     planning_memory = await memory_manager.store_memory(\n",
    "        \"Student requested semester planning help. Recommended CS301, CS250, MATH301 based on AI/ML goals and schedule constraints.\",\n",
    "        \"planning_session\",\n",
    "        importance=0.9,\n",
    "        metadata={\"semester\": \"Spring 2024\", \"credits_planned\": 12}\n",
    "    )\n",
    "    \n",
    "    print(f\"  ‚úÖ Planning session stored (ID: {planning_memory[:8]}...)\")\n",
    "    print(\"  ‚úÖ Course preferences updated\")\n",
    "    print(\"  ‚úÖ Academic goals reinforced\")\n",
    "    print(\"  ‚úÖ Context ready for future interactions\")\n",
    "\n",
    "# Run the realistic scenario\n",
    "if redis_config.health_check():\n",
    "    await realistic_scenario()\n",
    "else:\n",
    "    print(\"‚ùå Redis not available for scenario demonstration\")",
    "```\n",
    "\n",
    "*Note: This demonstrates the concept. See Section 3 notebooks for actual memory implementation using MemoryClient.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "From our exploration of context engines, several important principles emerge:\n",
    "\n",
    "### 1. **Multi-Layer Architecture**\n",
    "- **Storage Layer**: Handles different data types and access patterns\n",
    "- **Retrieval Layer**: Provides intelligent search and ranking\n",
    "- **Memory Management**: Orchestrates working memory (task-focused) and long-term memory (cross-session)\n",
    "- **Integration Layer**: Connects with AI models and applications\n",
    "\n",
    "### 2. **Performance is Critical**\n",
    "- Context retrieval must be fast (< 100ms for good UX)\n",
    "- Memory storage should be efficient and scalable\n",
    "- Caching strategies are essential for frequently accessed data\n",
    "- Async operations prevent blocking in AI workflows\n",
    "\n",
    "### 3. **Context Quality Matters**\n",
    "- Relevant context improves AI responses dramatically\n",
    "- Irrelevant context can confuse or mislead AI models\n",
    "- Context ranking and filtering are as important as retrieval\n",
    "- Memory consolidation helps maintain context quality by moving important information to long-term storage\n",
    "\n",
    "### 4. **Integration is Key**\n",
    "- Context engines must integrate seamlessly with AI frameworks\n",
    "- Tool-based integration provides flexibility and modularity\n",
    "- State management integration enables persistent conversations\n",
    "- API design affects ease of use and adoption\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "In the next section, we'll dive into **Setting up System Context** - how to define what your AI agent should know about itself, its capabilities, and its operating environment. We'll cover:\n",
    "\n",
    "- System prompt engineering\n",
    "- Tool definition and management\n",
    "- Capability boundaries and constraints\n",
    "- Domain knowledge integration\n",
    "\n",
    "## Try It Yourself\n",
    "\n",
    "Experiment with the context engine concepts:\n",
    "\n",
    "1. **Modify retrieval parameters** - Change similarity thresholds and see how it affects results\n",
    "2. **Add new memory types** - Create custom memory categories for your use case\n",
    "3. **Experiment with context integration** - Try different ways of combining context sources\n",
    "4. **Measure performance** - Benchmark different operations and optimize bottlenecks\n",
    "\n",
    "The context engine is the foundation that makes sophisticated AI agents possible. Understanding its architecture and capabilities is essential for building effective context engineering solutions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
