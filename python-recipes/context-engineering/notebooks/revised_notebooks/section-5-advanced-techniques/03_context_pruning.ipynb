{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Redis](https://redis.io/wp-content/uploads/2024/04/Logotype.svg?auto=webp&quality=85,75&width=120)\n",
    "\n",
    "# Context Pruning: Intelligent Memory Cleanup\n",
    "\n",
    "## Learning Objectives (30 minutes)\n",
    "By the end of this notebook, you will be able to:\n",
    "1. **Understand** why context accumulates \"cruft\" and degrades performance\n",
    "2. **Implement** relevance scoring for memory records and conversations\n",
    "3. **Create** intelligent pruning strategies for different types of context\n",
    "4. **Design** automated cleanup processes for your Agent Memory Server\n",
    "5. **Measure** the impact of pruning on agent performance and accuracy\n",
    "\n",
    "## Prerequisites\n",
    "- Completed previous notebooks in Section 5\n",
    "- Understanding of Agent Memory Server and Redis\n",
    "- Familiarity with your Redis University Class Agent\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "**Context Pruning** is the practice of intelligently removing irrelevant, outdated, or redundant information from your agent's memory to maintain optimal context quality. Like pruning a garden, removing the dead branches helps the healthy parts flourish.\n",
    "\n",
    "### The Context Accumulation Problem\n",
    "\n",
    "Over time, agents accumulate \"context cruft\":\n",
    "- **Outdated preferences**: \"I prefer morning classes\" (from 2 semesters ago)\n",
    "- **Irrelevant conversations**: Course browsing mixed with career planning\n",
    "- **Redundant information**: Multiple similar course searches\n",
    "- **Stale data**: Old course availability or requirements\n",
    "\n",
    "### Our Solution: Intelligent Pruning\n",
    "\n",
    "We'll implement:\n",
    "1. **Relevance scoring** for memory records\n",
    "2. **Time-based decay** for aging information\n",
    "3. **Semantic deduplication** for redundant content\n",
    "4. **Context health monitoring** for proactive cleanup\n",
    "\n",
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment setup\n",
    "import os\n",
    "import asyncio\n",
    "import json\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime, timedelta\n",
    "from enum import Enum\n",
    "import math\n",
    "import hashlib\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "REDIS_URL = os.getenv(\"REDIS_URL\", \"redis://localhost:6379\")\n",
    "AGENT_MEMORY_URL = os.getenv(\"AGENT_MEMORY_URL\", \"http://localhost:8088\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "print(\"🔧 Environment Setup\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"Redis URL: {REDIS_URL}\")\n",
    "print(f\"Agent Memory URL: {AGENT_MEMORY_URL}\")\n",
    "print(f\"OpenAI API Key: {'✅ Set' if OPENAI_API_KEY else '❌ Not set'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "try:\n",
    "    import redis\n",
    "    from redis_context_course.models import StudentProfile\n",
    "    from redis_context_course.course_manager import CourseManager\n",
    "    from redis_context_course.redis_config import redis_config\n",
    "    \n",
    "    # Redis connection\n",
    "    redis_client = redis.from_url(REDIS_URL)\n",
    "    if redis_config.health_check():\n",
    "        print(\"✅ Redis connection healthy\")\n",
    "    else:\n",
    "        print(\"❌ Redis connection failed\")\n",
    "    \n",
    "    print(\"✅ Core modules imported successfully\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"❌ Import failed: {e}\")\n",
    "    print(\"Please ensure you've completed the setup from previous sections.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Record and Relevance Framework\n",
    "\n",
    "Let's create a framework for tracking and scoring memory relevance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryType(Enum):\n",
    "    \"\"\"Types of memory records.\"\"\"\n",
    "    CONVERSATION = \"conversation\"\n",
    "    PREFERENCE = \"preference\"\n",
    "    COURSE_INTERACTION = \"course_interaction\"\n",
    "    ACADEMIC_PROGRESS = \"academic_progress\"\n",
    "    CAREER_INTEREST = \"career_interest\"\n",
    "    SEARCH_HISTORY = \"search_history\"\n",
    "\n",
    "@dataclass\n",
    "class MemoryRecord:\n",
    "    \"\"\"Represents a memory record with relevance metadata.\"\"\"\n",
    "    id: str\n",
    "    memory_type: MemoryType\n",
    "    content: str\n",
    "    timestamp: datetime\n",
    "    student_id: str\n",
    "    namespace: str = \"default\"\n",
    "    \n",
    "    # Relevance scoring factors\n",
    "    access_count: int = 0\n",
    "    last_accessed: Optional[datetime] = None\n",
    "    relevance_score: float = 1.0\n",
    "    importance_weight: float = 1.0\n",
    "    \n",
    "    # Content metadata\n",
    "    content_hash: Optional[str] = None\n",
    "    related_records: List[str] = field(default_factory=list)\n",
    "    tags: List[str] = field(default_factory=list)\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.content_hash is None:\n",
    "            self.content_hash = self._calculate_content_hash()\n",
    "        if self.last_accessed is None:\n",
    "            self.last_accessed = self.timestamp\n",
    "    \n",
    "    def _calculate_content_hash(self) -> str:\n",
    "        \"\"\"Calculate hash for content deduplication.\"\"\"\n",
    "        content_normalized = self.content.lower().strip()\n",
    "        return hashlib.md5(content_normalized.encode()).hexdigest()[:16]\n",
    "    \n",
    "    def update_access(self):\n",
    "        \"\"\"Update access tracking.\"\"\"\n",
    "        self.access_count += 1\n",
    "        self.last_accessed = datetime.now()\n",
    "    \n",
    "    def age_in_days(self) -> float:\n",
    "        \"\"\"Calculate age of record in days.\"\"\"\n",
    "        return (datetime.now() - self.timestamp).total_seconds() / 86400\n",
    "    \n",
    "    def days_since_access(self) -> float:\n",
    "        \"\"\"Calculate days since last access.\"\"\"\n",
    "        if self.last_accessed:\n",
    "            return (datetime.now() - self.last_accessed).total_seconds() / 86400\n",
    "        return self.age_in_days()\n",
    "\n",
    "class RelevanceScorer:\n",
    "    \"\"\"Calculates relevance scores for memory records.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Scoring weights for different factors\n",
    "        self.weights = {\n",
    "            \"recency\": 0.3,      # How recent is the memory?\n",
    "            \"frequency\": 0.25,   # How often is it accessed?\n",
    "            \"importance\": 0.25,  # How important is the content type?\n",
    "            \"relevance\": 0.2     # How relevant to current context?\n",
    "        }\n",
    "        \n",
    "        # Importance weights by memory type\n",
    "        self.type_importance = {\n",
    "            MemoryType.ACADEMIC_PROGRESS: 1.0,\n",
    "            MemoryType.PREFERENCE: 0.8,\n",
    "            MemoryType.CAREER_INTEREST: 0.7,\n",
    "            MemoryType.COURSE_INTERACTION: 0.6,\n",
    "            MemoryType.CONVERSATION: 0.4,\n",
    "            MemoryType.SEARCH_HISTORY: 0.3\n",
    "        }\n",
    "    \n",
    "    def calculate_relevance_score(self, record: MemoryRecord, current_context: Optional[str] = None) -> float:\n",
    "        \"\"\"Calculate overall relevance score for a memory record.\"\"\"\n",
    "        \n",
    "        # 1. Recency score (exponential decay)\n",
    "        age_days = record.age_in_days()\n",
    "        recency_score = math.exp(-age_days / 30)  # 30-day half-life\n",
    "        \n",
    "        # 2. Frequency score (logarithmic)\n",
    "        frequency_score = math.log(record.access_count + 1) / math.log(10)  # Log base 10\n",
    "        frequency_score = min(frequency_score, 1.0)  # Cap at 1.0\n",
    "        \n",
    "        # 3. Importance score (by type)\n",
    "        importance_score = self.type_importance.get(record.memory_type, 0.5)\n",
    "        importance_score *= record.importance_weight\n",
    "        \n",
    "        # 4. Context relevance score\n",
    "        context_score = self._calculate_context_relevance(record, current_context)\n",
    "        \n",
    "        # Combine scores\n",
    "        total_score = (\n",
    "            self.weights[\"recency\"] * recency_score +\n",
    "            self.weights[\"frequency\"] * frequency_score +\n",
    "            self.weights[\"importance\"] * importance_score +\n",
    "            self.weights[\"relevance\"] * context_score\n",
    "        )\n",
    "        \n",
    "        return min(total_score, 1.0)  # Cap at 1.0\n",
    "    \n",
    "    def _calculate_context_relevance(self, record: MemoryRecord, current_context: Optional[str]) -> float:\n",
    "        \"\"\"Calculate relevance to current context.\"\"\"\n",
    "        if not current_context:\n",
    "            return 0.5  # Neutral score\n",
    "        \n",
    "        # Simple keyword matching (in real implementation, use embeddings)\n",
    "        context_words = set(current_context.lower().split())\n",
    "        record_words = set(record.content.lower().split())\n",
    "        \n",
    "        if not context_words or not record_words:\n",
    "            return 0.5\n",
    "        \n",
    "        # Calculate Jaccard similarity\n",
    "        intersection = len(context_words & record_words)\n",
    "        union = len(context_words | record_words)\n",
    "        \n",
    "        return intersection / union if union > 0 else 0.0\n",
    "\n",
    "# Initialize the relevance scorer\n",
    "relevance_scorer = RelevanceScorer()\n",
    "\n",
    "print(\"✅ Memory record and relevance framework initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context Pruning Engine\n",
    "\n",
    "Now let's create the main pruning engine that implements different cleanup strategies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PruningStrategy(Enum):\n",
    "    \"\"\"Different pruning strategies.\"\"\"\n",
    "    RELEVANCE_THRESHOLD = \"relevance_threshold\"  # Remove below threshold\n",
    "    TOP_K_RETENTION = \"top_k_retention\"          # Keep only top K records\n",
    "    TIME_BASED = \"time_based\"                    # Remove older than X days\n",
    "    DEDUPLICATION = \"deduplication\"              # Remove duplicate content\n",
    "    HYBRID = \"hybrid\"                            # Combination of strategies\n",
    "\n",
    "@dataclass\n",
    "class PruningConfig:\n",
    "    \"\"\"Configuration for pruning operations.\"\"\"\n",
    "    strategy: PruningStrategy\n",
    "    relevance_threshold: float = 0.3\n",
    "    max_records_per_type: int = 100\n",
    "    max_age_days: int = 90\n",
    "    enable_deduplication: bool = True\n",
    "    preserve_important: bool = True\n",
    "\n",
    "class ContextPruner:\n",
    "    \"\"\"Intelligent context pruning engine.\"\"\"\n",
    "    \n",
    "    def __init__(self, relevance_scorer: RelevanceScorer):\n",
    "        self.relevance_scorer = relevance_scorer\n",
    "        self.pruning_stats = {\n",
    "            \"total_pruned\": 0,\n",
    "            \"by_strategy\": {},\n",
    "            \"by_type\": {}\n",
    "        }\n",
    "    \n",
    "    async def prune_memory_records(self, \n",
    "                                 records: List[MemoryRecord], \n",
    "                                 config: PruningConfig,\n",
    "                                 current_context: Optional[str] = None) -> Tuple[List[MemoryRecord], Dict[str, Any]]:\n",
    "        \"\"\"Prune memory records based on configuration.\"\"\"\n",
    "        \n",
    "        original_count = len(records)\n",
    "        pruned_records = records.copy()\n",
    "        pruning_report = {\n",
    "            \"original_count\": original_count,\n",
    "            \"strategy\": config.strategy.value,\n",
    "            \"operations\": []\n",
    "        }\n",
    "        \n",
    "        # Update relevance scores\n",
    "        for record in pruned_records:\n",
    "            record.relevance_score = self.relevance_scorer.calculate_relevance_score(record, current_context)\n",
    "        \n",
    "        # Apply pruning strategy\n",
    "        if config.strategy == PruningStrategy.RELEVANCE_THRESHOLD:\n",
    "            pruned_records, operation_report = self._prune_by_relevance(pruned_records, config)\n",
    "            pruning_report[\"operations\"].append(operation_report)\n",
    "        \n",
    "        elif config.strategy == PruningStrategy.TOP_K_RETENTION:\n",
    "            pruned_records, operation_report = self._prune_by_top_k(pruned_records, config)\n",
    "            pruning_report[\"operations\"].append(operation_report)\n",
    "        \n",
    "        elif config.strategy == PruningStrategy.TIME_BASED:\n",
    "            pruned_records, operation_report = self._prune_by_age(pruned_records, config)\n",
    "            pruning_report[\"operations\"].append(operation_report)\n",
    "        \n",
    "        elif config.strategy == PruningStrategy.DEDUPLICATION:\n",
    "            pruned_records, operation_report = self._prune_duplicates(pruned_records, config)\n",
    "            pruning_report[\"operations\"].append(operation_report)\n",
    "        \n",
    "        elif config.strategy == PruningStrategy.HYBRID:\n",
    "            # Apply multiple strategies in sequence\n",
    "            strategies = [\n",
    "                (self._prune_duplicates, \"deduplication\"),\n",
    "                (self._prune_by_age, \"time_based\"),\n",
    "                (self._prune_by_relevance, \"relevance_threshold\")\n",
    "            ]\n",
    "            \n",
    "            for prune_func, strategy_name in strategies:\n",
    "                pruned_records, operation_report = prune_func(pruned_records, config)\n",
    "                operation_report[\"strategy\"] = strategy_name\n",
    "                pruning_report[\"operations\"].append(operation_report)\n",
    "        \n",
    "        # Final statistics\n",
    "        final_count = len(pruned_records)\n",
    "        pruning_report[\"final_count\"] = final_count\n",
    "        pruning_report[\"pruned_count\"] = original_count - final_count\n",
    "        pruning_report[\"retention_rate\"] = final_count / original_count if original_count > 0 else 1.0\n",
    "        \n",
    "        # Update global stats\n",
    "        self.pruning_stats[\"total_pruned\"] += pruning_report[\"pruned_count\"]\n",
    "        \n",
    "        return pruned_records, pruning_report\n",
    "    \n",
    "    def _prune_by_relevance(self, records: List[MemoryRecord], config: PruningConfig) -> Tuple[List[MemoryRecord], Dict[str, Any]]:\n",
    "        \"\"\"Prune records below relevance threshold.\"\"\"\n",
    "        original_count = len(records)\n",
    "        \n",
    "        # Keep records above threshold or marked as important\n",
    "        kept_records = [\n",
    "            record for record in records\n",
    "            if record.relevance_score >= config.relevance_threshold or \n",
    "               (config.preserve_important and record.importance_weight > 0.8)\n",
    "        ]\n",
    "        \n",
    "        return kept_records, {\n",
    "            \"operation\": \"relevance_threshold\",\n",
    "            \"threshold\": config.relevance_threshold,\n",
    "            \"original_count\": original_count,\n",
    "            \"kept_count\": len(kept_records),\n",
    "            \"pruned_count\": original_count - len(kept_records)\n",
    "        }\n",
    "    \n",
    "    def _prune_by_top_k(self, records: List[MemoryRecord], config: PruningConfig) -> Tuple[List[MemoryRecord], Dict[str, Any]]:\n",
    "        \"\"\"Keep only top K records by relevance score.\"\"\"\n",
    "        original_count = len(records)\n",
    "        \n",
    "        # Group by memory type and keep top K for each type\n",
    "        records_by_type = {}\n",
    "        for record in records:\n",
    "            if record.memory_type not in records_by_type:\n",
    "                records_by_type[record.memory_type] = []\n",
    "            records_by_type[record.memory_type].append(record)\n",
    "        \n",
    "        kept_records = []\n",
    "        for memory_type, type_records in records_by_type.items():\n",
    "            # Sort by relevance score and keep top K\n",
    "            type_records.sort(key=lambda r: r.relevance_score, reverse=True)\n",
    "            kept_records.extend(type_records[:config.max_records_per_type])\n",
    "        \n",
    "        return kept_records, {\n",
    "            \"operation\": \"top_k_retention\",\n",
    "            \"max_per_type\": config.max_records_per_type,\n",
    "            \"original_count\": original_count,\n",
    "            \"kept_count\": len(kept_records),\n",
    "            \"pruned_count\": original_count - len(kept_records)\n",
    "        }\n",
    "    \n",
    "    def _prune_by_age(self, records: List[MemoryRecord], config: PruningConfig) -> Tuple[List[MemoryRecord], Dict[str, Any]]:\n",
    "        \"\"\"Prune records older than max age.\"\"\"\n",
    "        original_count = len(records)\n",
    "        \n",
    "        # Keep records newer than max age or marked as important\n",
    "        kept_records = [\n",
    "            record for record in records\n",
    "            if record.age_in_days() <= config.max_age_days or\n",
    "               (config.preserve_important and record.importance_weight > 0.8)\n",
    "        ]\n",
    "        \n",
    "        return kept_records, {\n",
    "            \"operation\": \"time_based\",\n",
    "            \"max_age_days\": config.max_age_days,\n",
    "            \"original_count\": original_count,\n",
    "            \"kept_count\": len(kept_records),\n",
    "            \"pruned_count\": original_count - len(kept_records)\n",
    "        }\n",
    "    \n",
    "    def _prune_duplicates(self, records: List[MemoryRecord], config: PruningConfig) -> Tuple[List[MemoryRecord], Dict[str, Any]]:\n",
    "        \"\"\"Remove duplicate records based on content hash.\"\"\"\n",
    "        original_count = len(records)\n",
    "        \n",
    "        # Group by content hash\n",
    "        hash_groups = {}\n",
    "        for record in records:\n",
    "            if record.content_hash not in hash_groups:\n",
    "                hash_groups[record.content_hash] = []\n",
    "            hash_groups[record.content_hash].append(record)\n",
    "        \n",
    "        # Keep the most relevant record from each group\n",
    "        kept_records = []\n",
    "        for hash_value, group_records in hash_groups.items():\n",
    "            if len(group_records) == 1:\n",
    "                kept_records.append(group_records[0])\n",
    "            else:\n",
    "                # Keep the most relevant record\n",
    "                best_record = max(group_records, key=lambda r: r.relevance_score)\n",
    "                kept_records.append(best_record)\n",
    "        \n",
    "        return kept_records, {\n",
    "            \"operation\": \"deduplication\",\n",
    "            \"original_count\": original_count,\n",
    "            \"kept_count\": len(kept_records),\n",
    "            \"pruned_count\": original_count - len(kept_records),\n",
    "            \"duplicate_groups\": len([g for g in hash_groups.values() if len(g) > 1])\n",
    "        }\n",
    "    \n",
    "    def get_pruning_statistics(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get overall pruning statistics.\"\"\"\n",
    "        return self.pruning_stats.copy()\n",
    "\n",
    "# Initialize the context pruner\n",
    "context_pruner = ContextPruner(relevance_scorer)\n",
    "\n",
    "print(\"✅ Context pruning engine initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstration: Context Pruning in Action\n",
    "\n",
    "Let's create some sample memory records and see how different pruning strategies work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample memory records for demonstration\n",
    "def create_sample_memory_records() -> List[MemoryRecord]:\n",
    "    \"\"\"Create sample memory records for testing pruning.\"\"\"\n",
    "    \n",
    "    base_time = datetime.now()\n",
    "    records = []\n",
    "    \n",
    "    # Recent academic progress (high importance)\n",
    "    records.append(MemoryRecord(\n",
    "        id=\"prog_001\",\n",
    "        memory_type=MemoryType.ACADEMIC_PROGRESS,\n",
    "        content=\"Completed CS201 with grade A, now eligible for CS301\",\n",
    "        timestamp=base_time - timedelta(days=5),\n",
    "        student_id=\"test_student\",\n",
    "        access_count=8,\n",
    "        importance_weight=1.0\n",
    "    ))\n",
    "    \n",
    "    # Old preference (should be pruned)\n",
    "    records.append(MemoryRecord(\n",
    "        id=\"pref_001\",\n",
    "        memory_type=MemoryType.PREFERENCE,\n",
    "        content=\"I prefer morning classes\",\n",
    "        timestamp=base_time - timedelta(days=120),\n",
    "        student_id=\"test_student\",\n",
    "        access_count=1,\n",
    "        importance_weight=0.5\n",
    "    ))\n",
    "    \n",
    "    # Recent preference (should be kept)\n",
    "    records.append(MemoryRecord(\n",
    "        id=\"pref_002\",\n",
    "        memory_type=MemoryType.PREFERENCE,\n",
    "        content=\"I prefer online courses due to work schedule\",\n",
    "        timestamp=base_time - timedelta(days=10),\n",
    "        student_id=\"test_student\",\n",
    "        access_count=5,\n",
    "        importance_weight=0.8\n",
    "    ))\n",
    "    \n",
    "    # Duplicate course searches\n",
    "    for i in range(3):\n",
    "        records.append(MemoryRecord(\n",
    "            id=f\"search_{i:03d}\",\n",
    "            memory_type=MemoryType.SEARCH_HISTORY,\n",
    "            content=\"searched for machine learning courses\",  # Same content\n",
    "            timestamp=base_time - timedelta(days=15 + i),\n",
    "            student_id=\"test_student\",\n",
    "            access_count=1,\n",
    "            importance_weight=0.3\n",
    "        ))\n",
    "    \n",
    "    # Various course interactions\n",
    "    course_interactions = [\n",
    "        \"Viewed details for CS401: Machine Learning\",\n",
    "        \"Checked prerequisites for MATH301\",\n",
    "        \"Added CS402 to wishlist\",\n",
    "        \"Compared CS401 and CS402 courses\",\n",
    "        \"Asked about CS401 difficulty level\"\n",
    "    ]\n",
    "    \n",
    "    for i, interaction in enumerate(course_interactions):\n",
    "        records.append(MemoryRecord(\n",
    "            id=f\"course_{i:03d}\",\n",
    "            memory_type=MemoryType.COURSE_INTERACTION,\n",
    "            content=interaction,\n",
    "            timestamp=base_time - timedelta(days=20 + i * 5),\n",
    "            student_id=\"test_student\",\n",
    "            access_count=2 + i,\n",
    "            importance_weight=0.6\n",
    "        ))\n",
    "    \n",
    "    # Old conversations (low relevance)\n",
    "    old_conversations = [\n",
    "        \"Asked about general course catalog\",\n",
    "        \"Inquired about registration deadlines\",\n",
    "        \"General questions about university policies\"\n",
    "    ]\n",
    "    \n",
    "    for i, conv in enumerate(old_conversations):\n",
    "        records.append(MemoryRecord(\n",
    "            id=f\"conv_{i:03d}\",\n",
    "            memory_type=MemoryType.CONVERSATION,\n",
    "            content=conv,\n",
    "            timestamp=base_time - timedelta(days=60 + i * 10),\n",
    "            student_id=\"test_student\",\n",
    "            access_count=1,\n",
    "            importance_weight=0.4\n",
    "        ))\n",
    "    \n",
    "    # Career interests\n",
    "    records.append(MemoryRecord(\n",
    "        id=\"career_001\",\n",
    "        memory_type=MemoryType.CAREER_INTEREST,\n",
    "        content=\"Interested in AI and machine learning careers\",\n",
    "        timestamp=base_time - timedelta(days=30),\n",
    "        student_id=\"test_student\",\n",
    "        access_count=4,\n",
    "        importance_weight=0.9\n",
    "    ))\n",
    "    \n",
    "    return records\n",
    "\n",
    "# Create sample data\n",
    "sample_records = create_sample_memory_records()\n",
    "\n",
    "print(f\"📚 Created {len(sample_records)} sample memory records\")\n",
    "print(\"\\n📋 Record Distribution:\")\n",
    "type_counts = {}\n",
    "for record in sample_records:\n",
    "    type_counts[record.memory_type] = type_counts.get(record.memory_type, 0) + 1\n",
    "\n",
    "for memory_type, count in type_counts.items():\n",
    "    print(f\"   • {memory_type.value}: {count} records\")\n",
    "\n",
    "# Show some sample records\n",
    "print(\"\\n🔍 Sample Records:\")\n",
    "for i, record in enumerate(sample_records[:5]):\n",
    "    print(f\"   {i+1}. [{record.memory_type.value}] {record.content[:50]}... (Age: {record.age_in_days():.1f} days)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Different Pruning Strategies\n",
    "\n",
    "Let's test each pruning strategy and see how they affect our memory records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different pruning strategies\n",
    "print(\"🧪 Testing Different Pruning Strategies\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Current context for relevance scoring\n",
    "current_context = \"I want to take machine learning courses and plan my AI career path\"\n",
    "\n",
    "# Test configurations\n",
    "test_configs = [\n",
    "    {\n",
    "        \"name\": \"Relevance Threshold\",\n",
    "        \"config\": PruningConfig(\n",
    "            strategy=PruningStrategy.RELEVANCE_THRESHOLD,\n",
    "            relevance_threshold=0.4\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Top-K Retention\",\n",
    "        \"config\": PruningConfig(\n",
    "            strategy=PruningStrategy.TOP_K_RETENTION,\n",
    "            max_records_per_type=2\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Time-Based\",\n",
    "        \"config\": PruningConfig(\n",
    "            strategy=PruningStrategy.TIME_BASED,\n",
    "            max_age_days=45\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Deduplication\",\n",
    "        \"config\": PruningConfig(\n",
    "            strategy=PruningStrategy.DEDUPLICATION\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Hybrid Strategy\",\n",
    "        \"config\": PruningConfig(\n",
    "            strategy=PruningStrategy.HYBRID,\n",
    "            relevance_threshold=0.3,\n",
    "            max_age_days=60,\n",
    "            max_records_per_type=3\n",
    "        )\n",
    "    }\n",
    "]\n",
    "\n",
    "# Test each strategy\n",
    "for test_case in test_configs:\n",
    "    print(f\"\\n🎯 Testing: {test_case['name']}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Apply pruning\n",
    "    pruned_records, report = await context_pruner.prune_memory_records(\n",
    "        sample_records.copy(),\n",
    "        test_case['config'],\n",
    "        current_context\n",
    "    )\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"📊 Results:\")\n",
    "    print(f\"   Original: {report['original_count']} records\")\n",
    "    print(f\"   Kept: {report['final_count']} records\")\n",
    "    print(f\"   Pruned: {report['pruned_count']} records\")\n",
    "    print(f\"   Retention Rate: {report['retention_rate']:.1%}\")\n",
    "    \n",
    "    # Show operations performed\n",
    "    if report['operations']:\n",
    "        print(f\"\\n🔧 Operations:\")\n",
    "        for op in report['operations']:\n",
    "            print(f\"   • {op['operation']}: {op['pruned_count']} records removed\")\n",
    "    \n",
    "    # Show what was kept by type\n",
    "    kept_by_type = {}\n",
    "    for record in pruned_records:\n",
    "        kept_by_type[record.memory_type] = kept_by_type.get(record.memory_type, 0) + 1\n",
    "    \n",
    "    print(f\"\\n📋 Kept by Type:\")\n",
    "    for memory_type, count in kept_by_type.items():\n",
    "        print(f\"   • {memory_type.value}: {count} records\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relevance Score Analysis\n",
    "\n",
    "Let's analyze how relevance scores are calculated and what factors influence them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze relevance scores\n",
    "print(\"📊 Relevance Score Analysis\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Calculate relevance scores for all records\n",
    "current_context = \"machine learning courses and AI career planning\"\n",
    "\n",
    "scored_records = []\n",
    "for record in sample_records:\n",
    "    score = relevance_scorer.calculate_relevance_score(record, current_context)\n",
    "    scored_records.append((record, score))\n",
    "\n",
    "# Sort by relevance score\n",
    "scored_records.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(f\"📝 Context: '{current_context}'\")\n",
    "print(\"\\n🏆 Top 10 Most Relevant Records:\")\n",
    "print(\"Rank | Score | Type | Age | Access | Content\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for i, (record, score) in enumerate(scored_records[:10], 1):\n",
    "    content_preview = record.content[:40] + \"...\" if len(record.content) > 40 else record.content\n",
    "    print(f\"{i:4d} | {score:.3f} | {record.memory_type.value[:12]:12s} | {record.age_in_days():4.0f}d | {record.access_count:6d} | {content_preview}\")\n",
    "\n",
    "print(\"\\n📉 Bottom 5 Least Relevant Records:\")\n",
    "print(\"Rank | Score | Type | Age | Access | Content\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for i, (record, score) in enumerate(scored_records[-5:], len(scored_records)-4):\n",
    "    content_preview = record.content[:40] + \"...\" if len(record.content) > 40 else record.content\n",
    "    print(f\"{i:4d} | {score:.3f} | {record.memory_type.value[:12]:12s} | {record.age_in_days():4.0f}d | {record.access_count:6d} | {content_preview}\")\n",
    "\n",
    "# Analyze score distribution\n",
    "scores = [score for _, score in scored_records]\n",
    "print(f\"\\n📈 Score Statistics:\")\n",
    "print(f\"   Average: {sum(scores)/len(scores):.3f}\")\n",
    "print(f\"   Highest: {max(scores):.3f}\")\n",
    "print(f\"   Lowest: {min(scores):.3f}\")\n",
    "print(f\"   Above 0.5: {len([s for s in scores if s > 0.5])} records\")\n",
    "print(f\"   Below 0.3: {len([s for s in scores if s < 0.3])} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧪 Hands-on Exercise: Design Your Pruning Strategy\n",
    "\n",
    "Now it's your turn to experiment with context pruning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Create your own pruning strategy\n",
    "print(\"🧪 Exercise: Design Your Context Pruning Strategy\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# TODO: Create a custom pruning strategy\n",
    "class CustomPruningStrategy:\n",
    "    \"\"\"Custom pruning strategy that combines multiple factors.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.name = \"Smart Academic Pruning\"\n",
    "    \n",
    "    def should_keep_record(self, record: MemoryRecord, current_context: str = \"\") -> bool:\n",
    "        \"\"\"Decide whether to keep a record based on custom logic.\"\"\"\n",
    "        \n",
    "        # Always keep recent academic progress\n",
    "        if (record.memory_type == MemoryType.ACADEMIC_PROGRESS and \n",
    "            record.age_in_days() <= 180):\n",
    "            return True\n",
    "        \n",
    "        # Keep recent preferences that are frequently accessed\n",
    "        if (record.memory_type == MemoryType.PREFERENCE and \n",
    "            record.age_in_days() <= 60 and \n",
    "            record.access_count >= 3):\n",
    "            return True\n",
    "        \n",
    "        # Keep career interests if they're relevant to current context\n",
    "        if record.memory_type == MemoryType.CAREER_INTEREST:\n",
    "            if current_context and any(word in current_context.lower() \n",
    "                                     for word in [\"career\", \"job\", \"work\", \"ai\", \"machine learning\"]):\n",
    "                return True\n",
    "        \n",
    "        # Keep course interactions if they're recent or frequently accessed\n",
    "        if (record.memory_type == MemoryType.COURSE_INTERACTION and \n",
    "            (record.age_in_days() <= 30 or record.access_count >= 5)):\n",
    "            return True\n",
    "        \n",
    "        # Prune old search history and conversations\n",
    "        if record.memory_type in [MemoryType.SEARCH_HISTORY, MemoryType.CONVERSATION]:\n",
    "            if record.age_in_days() > 30 and record.access_count <= 2:\n",
    "                return False\n",
    "        \n",
    "        # Default: keep if relevance score is decent\n",
    "        return record.relevance_score >= 0.4\n",
    "    \n",
    "    def prune_records(self, records: List[MemoryRecord], current_context: str = \"\") -> Tuple[List[MemoryRecord], Dict[str, Any]]:\n",
    "        \"\"\"Apply custom pruning logic.\"\"\"\n",
    "        original_count = len(records)\n",
    "        \n",
    "        kept_records = []\n",
    "        pruning_reasons = {}\n",
    "        \n",
    "        for record in records:\n",
    "            if self.should_keep_record(record, current_context):\n",
    "                kept_records.append(record)\n",
    "            else:\n",
    "                # Track why it was pruned\n",
    "                reason = self._get_pruning_reason(record, current_context)\n",
    "                pruning_reasons[record.id] = reason\n",
    "        \n",
    "        return kept_records, {\n",
    "            \"strategy\": self.name,\n",
    "            \"original_count\": original_count,\n",
    "            \"kept_count\": len(kept_records),\n",
    "            \"pruned_count\": original_count - len(kept_records),\n",
    "            \"pruning_reasons\": pruning_reasons\n",
    "        }\n",
    "    \n",
    "    def _get_pruning_reason(self, record: MemoryRecord, current_context: str) -> str:\n",
    "        \"\"\"Get reason why record was pruned.\"\"\"\n",
    "        if record.memory_type in [MemoryType.SEARCH_HISTORY, MemoryType.CONVERSATION]:\n",
    "            if record.age_in_days() > 30 and record.access_count <= 2:\n",
    "                return \"Old and rarely accessed\"\n",
    "        \n",
    "        if record.relevance_score < 0.4:\n",
    "            return \"Low relevance score\"\n",
    "        \n",
    "        return \"Custom logic\"\n",
    "\n",
    "# Test your custom strategy\n",
    "custom_strategy = CustomPruningStrategy()\n",
    "current_context = \"I want to plan my AI career and take machine learning courses\"\n",
    "\n",
    "print(f\"\\n🎯 Testing Custom Strategy: {custom_strategy.name}\")\n",
    "print(f\"📝 Context: '{current_context}'\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Apply custom pruning\n",
    "custom_kept, custom_report = custom_strategy.prune_records(sample_records.copy(), current_context)\n",
    "\n",
    "print(f\"📊 Results:\")\n",
    "print(f\"   Original: {custom_report['original_count']} records\")\n",
    "print(f\"   Kept: {custom_report['kept_count']} records\")\n",
    "print(f\"   Pruned: {custom_report['pruned_count']} records\")\n",
    "print(f\"   Retention Rate: {custom_report['kept_count']/custom_report['original_count']:.1%}\")\n",
    "\n",
    "# Show pruning reasons\n",
    "if custom_report['pruning_reasons']:\n",
    "    print(f\"\\n🗑️ Pruning Reasons:\")\n",
    "    reason_counts = {}\n",
    "    for reason in custom_report['pruning_reasons'].values():\n",
    "        reason_counts[reason] = reason_counts.get(reason, 0) + 1\n",
    "    \n",
    "    for reason, count in reason_counts.items():\n",
    "        print(f\"   • {reason}: {count} records\")\n",
    "\n",
    "# Compare with hybrid strategy\n",
    "hybrid_config = PruningConfig(strategy=PruningStrategy.HYBRID, relevance_threshold=0.4)\n",
    "hybrid_kept, hybrid_report = await context_pruner.prune_memory_records(\n",
    "    sample_records.copy(), hybrid_config, current_context\n",
    ")\n",
    "\n",
    "print(f\"\\n🔄 Comparison with Hybrid Strategy:\")\n",
    "print(f\"   Custom Strategy: {len(custom_kept)} records kept\")\n",
    "print(f\"   Hybrid Strategy: {len(hybrid_kept)} records kept\")\n",
    "print(f\"   Difference: {len(custom_kept) - len(hybrid_kept)} records\")\n",
    "\n",
    "print(\"\\n🤔 Reflection Questions:\")\n",
    "print(\"1. Which strategy better preserves important academic information?\")\n",
    "print(\"2. How does context-awareness affect pruning decisions?\")\n",
    "print(\"3. What are the trade-offs between aggressive and conservative pruning?\")\n",
    "print(\"4. How would you adapt this strategy for different student types?\")\n",
    "\n",
    "print(\"\\n🔧 Your Turn: Try These Modifications:\")\n",
    "print(\"   • Add student-specific pruning rules\")\n",
    "print(\"   • Implement seasonal pruning (end of semester cleanup)\")\n",
    "print(\"   • Create domain-specific relevance scoring\")\n",
    "print(\"   • Add user feedback to improve pruning decisions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "From this exploration of context pruning, you've learned:\n",
    "\n",
    "### 🎯 **Core Concepts**\n",
    "- **Context accumulation** naturally leads to performance degradation\n",
    "- **Relevance scoring** combines multiple factors (recency, frequency, importance, context)\n",
    "- **Intelligent pruning** preserves important information while removing cruft\n",
    "- **Multiple strategies** serve different use cases and requirements\n",
    "\n",
    "### 🛠️ **Implementation Patterns**\n",
    "- **Multi-factor scoring** for nuanced relevance assessment\n",
    "- **Strategy composition** for hybrid approaches\n",
    "- **Content deduplication** using hashing techniques\n",
    "- **Preservation rules** for critical information types\n",
    "\n",
    "### 📊 **Performance Benefits**\n",
    "- **Reduced context noise** improves decision quality\n",
    "- **Faster retrieval** with smaller memory footprint\n",
    "- **Better relevance** through focused information\n",
    "- **Proactive maintenance** prevents context degradation\n",
    "\n",
    "### 🔄 **Pruning Strategies**\n",
    "- **Relevance threshold**: Remove below quality bar\n",
    "- **Top-K retention**: Keep only the best records\n",
    "- **Time-based**: Remove outdated information\n",
    "- **Deduplication**: Eliminate redundant content\n",
    "- **Hybrid**: Combine multiple approaches\n",
    "\n",
    "### 🚀 **Next Steps**\n",
    "In the next notebook, we'll explore **Context Summarization** - how to compress accumulated context into concise summaries while preserving essential information for decision-making.\n",
    "\n",
    "The pruning techniques you've learned provide the foundation for maintaining clean, relevant context that can be effectively summarized.\n",
    "\n",
    "---\n",
    "\n",
    "**Ready to continue?** Move on to `04_context_summarization.ipynb` to learn about intelligent context compression!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
