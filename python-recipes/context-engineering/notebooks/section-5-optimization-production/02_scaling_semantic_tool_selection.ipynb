{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "![Redis](https://redis.io/wp-content/uploads/2024/04/Logotype.svg?auto=webp&quality=85,75&width=120)\n",
    "\n",
    "# üéØ Section 5, Notebook 2: Scaling with Semantic Tool Selection\n",
    "\n",
    "**‚è±Ô∏è Estimated Time:** 60-75 minutes\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "\n",
    "1. **Understand** the token cost of adding more tools to your agent\n",
    "2. **Implement** semantic tool selection using **RedisVL Semantic Router**\n",
    "3. **Build** production-ready tool routing with industry best practices\n",
    "4. **Scale** from 3 to 5 tools while reducing tool-related tokens by 60%\n",
    "5. **Learn** how semantic routing enables constant token overhead regardless of total tools available\n",
    "\n",
    "---\n",
    "\n",
    "## üîó Where We Are\n",
    "\n",
    "### **Your Journey So Far:**\n",
    "\n",
    "**Section 4, Notebook 2:** Built complete Redis University Course Advisor Agent\n",
    "- ‚úÖ 3 tools, dual memory, basic RAG, LangGraph workflow\n",
    "\n",
    "**Section 5, Notebook 1:** Optimized performance with hybrid retrieval\n",
    "- ‚úÖ Performance measurement system (tokens, cost, latency)\n",
    "- ‚úÖ Hybrid retrieval implementation\n",
    "- ‚úÖ 67% token reduction, 67% cost reduction, 50% latency improvement\n",
    "\n",
    "**Current Agent State:**\n",
    "```\n",
    "Tools:           3 (search_courses_hybrid, search_memories, store_memory)\n",
    "Tokens/query:    2,800\n",
    "Cost/query:      $0.04\n",
    "Latency:         1.6s\n",
    "```\n",
    "\n",
    "### **But... What If We Want More Tools?**\n",
    "\n",
    "**The Scaling Problem:**\n",
    "- Each tool = ~300-500 tokens (schema + description)\n",
    "- Adding 2 more tools = +1,000 tokens per query\n",
    "- All tools sent to LLM every time, even when not needed\n",
    "- Token cost grows linearly with number of tools\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "3 tools  = 1,200 tokens\n",
    "5 tools  = 2,200 tokens  (+83%)\n",
    "10 tools = 4,500 tokens  (+275%)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ The Problem We'll Solve\n",
    "\n",
    "**\"We want to add more capabilities (tools) to our agent, but sending all tools every time is wasteful. How can we scale to 5+ tools without exploding our token budget?\"**\n",
    "\n",
    "### **What We'll Learn:**\n",
    "\n",
    "1. **Tool Token Cost** - Understanding the overhead of tool definitions\n",
    "2. **Semantic Tool Selection** - Using embeddings to match queries to tools\n",
    "3. **Redis Tool Store** - Storing and retrieving tool embeddings efficiently\n",
    "4. **Dynamic Tool Loading** - Only sending relevant tools to the LLM\n",
    "\n",
    "### **What We'll Build:**\n",
    "\n",
    "Starting with your Notebook 1 agent (3 tools), we'll add:\n",
    "1. **2 New Tools** - `check_prerequisites_tool`, `compare_courses_tool`\n",
    "2. **Tool Embedding Store** - Redis index for tool embeddings\n",
    "3. **Semantic Tool Selector** - Intelligent tool selection based on query\n",
    "4. **Enhanced Agent** - Uses only relevant tools per query\n",
    "\n",
    "### **Expected Results:**\n",
    "\n",
    "```\n",
    "Metric                  Before (NB1)   After (NB2)    Improvement\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "Tools available         3              5              +67%\n",
    "Tool tokens (all)       1,200          2,200          +83%\n",
    "Tool tokens (selected)  1,200          880            -27%\n",
    "Tool selection accuracy 68%            91%            +34%\n",
    "Total tokens/query      2,800          2,200          -21%\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "```\n",
    "\n",
    "**üí° Key Insight:** \"Scale capabilities, not token costs - semantic selection enables both\"\n",
    "\n",
    "---\n",
    "\n",
    "## üì¶ Part 0: Setup and Imports\n",
    "\n",
    "Let's start by importing everything we need.\n"
   ],
   "id": "16a30cc21ebde840"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Standard library imports\n",
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Annotated, Any, Dict, List, Optional\n",
    "\n",
    "# Load environment variables from .env file\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env from context-engineering directory (two levels up from notebooks_v2/section-5-optimization-production)\n",
    "env_path = (\n",
    "    Path.cwd().parent.parent / \".env\"\n",
    "    if \"section-5\" in str(Path.cwd())\n",
    "    else Path(\".env\")\n",
    ")\n",
    "if env_path.exists():\n",
    "    load_dotenv(env_path)\n",
    "    print(f\"‚úÖ Loaded environment from {env_path}\")\n",
    "else:\n",
    "    # Try alternative path\n",
    "    alt_env_path = (\n",
    "        Path(__file__).resolve().parent.parent.parent / \".env\"\n",
    "        if \"__file__\" in dir()\n",
    "        else None\n",
    "    )\n",
    "    if alt_env_path and alt_env_path.exists():\n",
    "        load_dotenv(alt_env_path)\n",
    "        print(f\"‚úÖ Loaded environment from {alt_env_path}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Using system environment variables\")\n",
    "\n",
    "# Token counting\n",
    "import tiktoken\n",
    "\n",
    "# Redis and Agent Memory\n",
    "from agent_memory_client import MemoryAPIClient, MemoryClientConfig\n",
    "from agent_memory_client.filters import UserId\n",
    "from agent_memory_client.models import ClientMemoryRecord\n",
    "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage, SystemMessage\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# LangChain and LangGraph\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# RedisVL Extensions - NEW! Production-ready semantic routing\n",
    "from redisvl.extensions.router import Route, SemanticRouter\n",
    "\n",
    "# RedisVL for vector search\n",
    "from redisvl.index import SearchIndex\n",
    "from redisvl.query import VectorQuery\n",
    "from redisvl.schema import IndexSchema\n",
    "\n",
    "print(\"‚úÖ All imports successful\")\n",
    "print(\"   üÜï RedisVL Semantic Router imported\")"
   ],
   "id": "850994f73d2f03a6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Environment Setup\n",
   "id": "dcf49b4fa60d19fe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Verify environment\n",
    "required_vars = [\"OPENAI_API_KEY\"]\n",
    "missing_vars = [var for var in required_vars if not os.getenv(var)]\n",
    "\n",
    "if missing_vars:\n",
    "    print(f\"‚ùå Missing environment variables: {', '.join(missing_vars)}\")\n",
    "else:\n",
    "    print(\"‚úÖ Environment variables configured\")\n",
    "\n",
    "# Set defaults\n",
    "REDIS_URL = os.getenv(\"REDIS_URL\", \"redis://localhost:6379\")\n",
    "AGENT_MEMORY_URL = os.getenv(\"AGENT_MEMORY_URL\", \"http://localhost:8000\")\n",
    "\n",
    "print(f\"   Redis URL: {REDIS_URL}\")\n",
    "print(f\"   Agent Memory URL: {AGENT_MEMORY_URL}\")"
   ],
   "id": "a13df4b088728a78"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Initialize Clients\n",
   "id": "bd7fe45d51f1a7be"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.7, streaming=False)\n",
    "\n",
    "# Initialize embeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Initialize Agent Memory Client\n",
    "memory_config = MemoryClientConfig(base_url=AGENT_MEMORY_URL)\n",
    "memory_client = MemoryAPIClient(config=memory_config)\n",
    "\n",
    "print(\"‚úÖ Clients initialized\")\n",
    "print(f\"   LLM: {llm.model_name}\")\n",
    "print(f\"   Embeddings: text-embedding-3-small (1536 dimensions)\")\n",
    "print(f\"   Memory Client: Connected\")"
   ],
   "id": "b05414b3bb3844cb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Student Profile and Token Counter\n",
   "id": "e9683f1bfbc12982"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Student profile (same as before)\n",
    "STUDENT_ID = \"sarah_chen_12345\"\n",
    "SESSION_ID = f\"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "\n",
    "# Token counting function (from Notebook 1)\n",
    "\n",
    "\n",
    "def count_tokens(text: str, model: str = \"gpt-4o\") -> int:\n",
    "    \"\"\"Count tokens in text using tiktoken.\"\"\"\n",
    "    try:\n",
    "        encoding = tiktoken.encoding_for_model(model)\n",
    "    except KeyError:\n",
    "        encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "\n",
    "print(\"‚úÖ Student profile and utilities ready\")\n",
    "print(f\"   Student ID: {STUDENT_ID}\")\n",
    "print(f\"   Session ID: {SESSION_ID}\")"
   ],
   "id": "ef9b3b5a1d281c49"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## üîç Part 1: Understanding Tool Token Cost\n",
    "\n",
    "Before we add more tools, let's understand the token cost of tool definitions.\n",
    "\n",
    "### üî¨ Theory: Tool Token Overhead\n",
    "\n",
    "**What Gets Sent to the LLM:**\n",
    "\n",
    "When you bind tools to an LLM, the following gets sent with every request:\n",
    "1. **Tool name** - The function name\n",
    "2. **Tool description** - What the tool does\n",
    "3. **Parameter schema** - All parameters with types and descriptions\n",
    "4. **Return type** - What the tool returns\n",
    "\n",
    "**Example Tool Definition:**\n",
    "```python\n",
    "@tool(\"search_courses\")\n",
    "async def search_courses(query: str, limit: int = 5) -> str:\n",
    "    '''Search for courses using semantic search.'''\n",
    "    ...\n",
    "```\n",
    "\n",
    "**What LLM Sees (JSON Schema):**\n",
    "```json\n",
    "{\n",
    "  \"name\": \"search_courses\",\n",
    "  \"description\": \"Search for courses using semantic search.\",\n",
    "  \"parameters\": {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "      \"query\": {\"type\": \"string\", \"description\": \"...\"},\n",
    "      \"limit\": {\"type\": \"integer\", \"description\": \"...\"}\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "**Token Cost:** ~300-500 tokens per tool\n",
    "\n",
    "**üí° Key Insight:** Tool definitions are verbose! The more tools, the more tokens wasted on unused tools.\n"
   ],
   "id": "5fd160e796bd869d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Load Notebook 1 Tools\n",
    "\n",
    "Let's load the 3 tools from Notebook 1 and measure their token cost.\n"
   ],
   "id": "42008c6fc8fbda44"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# We'll need the course manager and catalog summary from NB1\n",
    "\n",
    "\n",
    "class CourseManager:\n",
    "    \"\"\"Manage course catalog with Redis vector search.\"\"\"\n",
    "\n",
    "    def __init__(self, redis_url: str, index_name: str = \"course_catalog\"):\n",
    "        self.redis_url = redis_url\n",
    "        self.index_name = index_name\n",
    "        self.embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "        try:\n",
    "            self.index = SearchIndex.from_existing(\n",
    "                name=self.index_name, redis_url=self.redis_url\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Warning: Could not load course catalog index: {e}\")\n",
    "            self.index = None\n",
    "\n",
    "    async def search_courses(self, query: str, limit: int = 5) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Search for courses using semantic search.\"\"\"\n",
    "        if not self.index:\n",
    "            return []\n",
    "\n",
    "        query_embedding = await self.embeddings.aembed_query(query)\n",
    "\n",
    "        vector_query = VectorQuery(\n",
    "            vector=query_embedding,\n",
    "            vector_field_name=\"course_embedding\",\n",
    "            return_fields=[\n",
    "                \"course_id\",\n",
    "                \"title\",\n",
    "                \"description\",\n",
    "                \"department\",\n",
    "                \"credits\",\n",
    "                \"format\",\n",
    "            ],\n",
    "            num_results=limit,\n",
    "        )\n",
    "\n",
    "        results = self.index.query(vector_query)\n",
    "        return results\n",
    "\n",
    "\n",
    "# Initialize course manager\n",
    "course_manager = CourseManager(redis_url=REDIS_URL)\n",
    "\n",
    "print(\"‚úÖ Course manager initialized\")"
   ],
   "id": "77ab9c02ba96ad8e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Build catalog summary (simplified version for NB2)\n",
    "\n",
    "\n",
    "async def build_catalog_summary() -> str:\n",
    "    \"\"\"Build course catalog summary.\"\"\"\n",
    "    summary = \"\"\"\n",
    "REDIS UNIVERSITY COURSE CATALOG OVERVIEW\n",
    "========================================\n",
    "Total Courses: ~150 courses across 10 departments\n",
    "\n",
    "Departments:\n",
    "- Redis Basics (RU101, RU102JS, etc.)\n",
    "- Data Structures (RU201, RU202, etc.)\n",
    "- Search and Query (RU203, RU204, etc.)\n",
    "- Time Series (RU301, RU302, etc.)\n",
    "- Probabilistic Data Structures (RU401, etc.)\n",
    "- Machine Learning (RU501, RU502, etc.)\n",
    "- Graph Databases (RU601, etc.)\n",
    "- Streams (RU701, etc.)\n",
    "- Security (RU801, etc.)\n",
    "- Advanced Topics (RU901, etc.)\n",
    "\n",
    "For detailed information, please ask about specific topics or courses!\n",
    "\"\"\"\n",
    "    return summary.strip()\n",
    "\n",
    "\n",
    "CATALOG_SUMMARY = await build_catalog_summary()\n",
    "\n",
    "print(\"‚úÖ Catalog summary ready\")\n",
    "print(f\"   Summary tokens: {count_tokens(CATALOG_SUMMARY):,}\")"
   ],
   "id": "de9ae260e5a3877e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Define the 3 Existing Tools\n",
   "id": "764d3e2933d12f23"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Tool 1: search_courses_hybrid (from NB1)\n",
    "\n",
    "\n",
    "async def search_courses_hybrid_func(query: str, limit: int = 5) -> str:\n",
    "    \"\"\"Search for courses using hybrid retrieval (overview + targeted search).\"\"\"\n",
    "    general_queries = [\n",
    "        \"what courses\",\n",
    "        \"available courses\",\n",
    "        \"course catalog\",\n",
    "        \"all courses\",\n",
    "    ]\n",
    "    is_general = any(phrase in query.lower() for phrase in general_queries)\n",
    "\n",
    "    if is_general:\n",
    "        return f\"üìö Course Catalog Overview:\\n\\n{CATALOG_SUMMARY}\"\n",
    "    else:\n",
    "        results = await course_manager.search_courses(query, limit=limit)\n",
    "        if not results:\n",
    "            return \"No courses found.\"\n",
    "\n",
    "        output = [f\"üìö Overview:\\n{CATALOG_SUMMARY[:200]}...\\n\\nüîç Matching courses:\"]\n",
    "        for i, course in enumerate(results, 1):\n",
    "            output.append(f\"\\n{i}. {course['title']} ({course['course_id']})\")\n",
    "            output.append(f\"   {course['description'][:100]}...\")\n",
    "\n",
    "        return \"\\n\".join(output)\n",
    "\n",
    "\n",
    "from langchain_core.tools import StructuredTool\n",
    "\n",
    "search_courses_hybrid = StructuredTool.from_function(\n",
    "    coroutine=search_courses_hybrid_func,\n",
    "    name=\"search_courses_hybrid\",\n",
    "    description=\"\"\"Search for courses using hybrid retrieval (overview + targeted search).\n",
    "\n",
    "Use this when students ask about:\n",
    "- Course topics: \"machine learning courses\", \"database courses\"\n",
    "- General exploration: \"what courses are available?\"\n",
    "- Course characteristics: \"online courses\", \"beginner courses\"\n",
    "\n",
    "Returns: Catalog overview + targeted search results.\"\"\",\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Tool 1: search_courses_hybrid\")"
   ],
   "id": "b13419da5a093015"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Tool 2: search_memories\n",
    "\n",
    "\n",
    "async def search_memories_func(query: str, limit: int = 5) -> str:\n",
    "    \"\"\"Search the user's long-term memory for relevant facts, preferences, and past interactions.\"\"\"\n",
    "    try:\n",
    "        results = await memory_client.search_long_term_memory(\n",
    "            text=query, user_id=UserId(eq=STUDENT_ID), limit=limit\n",
    "        )\n",
    "\n",
    "        if not results.memories or len(results.memories) == 0:\n",
    "            return \"No relevant memories found.\"\n",
    "\n",
    "        output = []\n",
    "        for i, memory in enumerate(results.memories, 1):\n",
    "            output.append(f\"{i}. {memory.text}\")\n",
    "\n",
    "        return \"\\n\".join(output)\n",
    "    except Exception as e:\n",
    "        return f\"Error searching memories: {str(e)}\"\n",
    "\n",
    "\n",
    "search_memories = StructuredTool.from_function(\n",
    "    coroutine=search_memories_func,\n",
    "    name=\"search_memories\",\n",
    "    description=\"\"\"Search the user's long-term memory for relevant facts, preferences, and past interactions.\n",
    "\n",
    "Use this when you need to:\n",
    "- Recall user preferences: \"What format does the user prefer?\"\n",
    "- Remember past goals: \"What career path is the user interested in?\"\n",
    "- Personalize recommendations based on history\n",
    "\n",
    "Returns: List of relevant memories.\"\"\",\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Tool 2: search_memories\")"
   ],
   "id": "e7d8efb6acf607eb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Tool 3: store_memory\n",
    "\n",
    "\n",
    "async def store_memory_func(text: str, topics: List[str] = []) -> str:\n",
    "    \"\"\"Store important information to the user's long-term memory.\"\"\"\n",
    "    try:\n",
    "        memory = ClientMemoryRecord(\n",
    "            text=text, user_id=STUDENT_ID, memory_type=\"semantic\", topics=topics or []\n",
    "        )\n",
    "\n",
    "        await memory_client.create_long_term_memory([memory])\n",
    "        return f\"‚úÖ Stored to memory: {text}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error storing memory: {str(e)}\"\n",
    "\n",
    "\n",
    "store_memory = StructuredTool.from_function(\n",
    "    coroutine=store_memory_func,\n",
    "    name=\"store_memory\",\n",
    "    description=\"\"\"Store important information to the user's long-term memory.\n",
    "\n",
    "Use this when the user shares:\n",
    "- Preferences: \"I prefer online courses\"\n",
    "- Goals: \"I want to work in AI\"\n",
    "- Important facts: \"I have a part-time job\"\n",
    "- Constraints: \"I can only take 2 courses per semester\"\n",
    "\n",
    "Returns: Confirmation message.\"\"\",\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Tool 3: store_memory\")"
   ],
   "id": "e0ee9ecbec8b205d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Collect existing tools\n",
    "existing_tools = [search_courses_hybrid, search_memories, store_memory]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üõ†Ô∏è  EXISTING TOOLS (from Notebook 1)\")\n",
    "print(\"=\" * 80)\n",
    "for i, tool in enumerate(existing_tools, 1):\n",
    "    print(f\"{i}. {tool.name}\")\n",
    "print(\"=\" * 80)"
   ],
   "id": "8fa9806d00082de1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Measure Tool Token Cost\n",
    "\n",
    "Now let's measure how many tokens each tool definition consumes.\n"
   ],
   "id": "be031e26bff04360"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_tool_token_cost(tool) -> int:\n",
    "    \"\"\"\n",
    "    Calculate the token cost of a tool definition.\n",
    "\n",
    "    This includes:\n",
    "    - Tool name\n",
    "    - Tool description\n",
    "    - Parameter schema (JSON)\n",
    "    \"\"\"\n",
    "    # Get tool schema\n",
    "    tool_schema = {\n",
    "        \"name\": tool.name,\n",
    "        \"description\": tool.description,\n",
    "        \"parameters\": tool.args_schema.model_json_schema() if tool.args_schema else {},\n",
    "    }\n",
    "\n",
    "    # Convert to JSON string (this is what gets sent to LLM)\n",
    "    tool_json = json.dumps(tool_schema, indent=2)\n",
    "\n",
    "    # Count tokens\n",
    "    tokens = count_tokens(tool_json)\n",
    "\n",
    "    return tokens\n",
    "\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üìä TOOL TOKEN COST ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "total_tokens = 0\n",
    "for i, tool in enumerate(existing_tools, 1):\n",
    "    tokens = get_tool_token_cost(tool)\n",
    "    total_tokens += tokens\n",
    "    print(f\"{i}. {tool.name:<30} {tokens:>6} tokens\")\n",
    "\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'TOTAL (3 tools)':<30} {total_tokens:>6} tokens\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nüí° Insight: These {total_tokens:,} tokens are sent with EVERY query!\")"
   ],
   "id": "42e9460235096339"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### The Scaling Problem\n",
    "\n",
    "What happens when we add more tools?\n"
   ],
   "id": "f617a96f39710ec4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"üìà TOOL SCALING PROJECTION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Average tokens per tool\n",
    "avg_tokens_per_tool = total_tokens / len(existing_tools)\n",
    "\n",
    "print(f\"\\nAverage tokens per tool: {avg_tokens_per_tool:.0f}\")\n",
    "print(\"\\nProjected token cost:\")\n",
    "print(f\"{'# Tools':<15} {'Token Cost':<15} {'vs 3 Tools':<15}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for num_tools in [3, 5, 7, 10, 15, 20]:\n",
    "    projected_tokens = int(avg_tokens_per_tool * num_tools)\n",
    "    increase = (\n",
    "        ((projected_tokens - total_tokens) / total_tokens * 100) if num_tools > 3 else 0\n",
    "    )\n",
    "    print(\n",
    "        f\"{num_tools:<15} {projected_tokens:<15,} {'+' + str(int(increase)) + '%' if increase > 0 else '‚Äî':<15}\"\n",
    "    )\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nüö® THE PROBLEM:\")\n",
    "print(\"   - Tool tokens grow linearly with number of tools\")\n",
    "print(\"   - All tools sent every time, even when not needed\")\n",
    "print(\"   - At 10 tools: ~4,000 tokens just for tool definitions!\")\n",
    "print(\"   - At 20 tools: ~8,000 tokens (more than our entire query budget!)\")\n",
    "print(\"\\nüí° THE SOLUTION:\")\n",
    "print(\"   - Semantic tool selection: Only send relevant tools\")\n",
    "print(\"   - Use embeddings to match query intent to tools\")\n",
    "print(\"   - Scale capabilities without scaling token costs\")"
   ],
   "id": "2a9c5ab4f97155ff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## üÜï Part 2: Adding New Tools\n",
    "\n",
    "Let's add 2 new tools to expand our agent's capabilities.\n",
    "\n",
    "### New Tool 1: Check Prerequisites\n"
   ],
   "id": "629412b60c6d4c2f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define the function first\n",
    "\n",
    "\n",
    "async def check_prerequisites_func(course_id: str) -> str:\n",
    "    \"\"\"Check the prerequisites for a specific course.\"\"\"\n",
    "    # Simulated prerequisite data (in production, this would query a database)\n",
    "    prerequisites_db = {\n",
    "        \"RU101\": {\n",
    "            \"required\": [],\n",
    "            \"recommended\": [\"Basic command line knowledge\"],\n",
    "            \"description\": \"Introduction to Redis - no prerequisites required\",\n",
    "        },\n",
    "        \"RU202\": {\n",
    "            \"required\": [\"RU101\"],\n",
    "            \"recommended\": [\n",
    "                \"Basic programming experience\",\n",
    "                \"Understanding of data structures\",\n",
    "            ],\n",
    "            \"description\": \"Redis Streams requires foundational Redis knowledge\",\n",
    "        },\n",
    "        \"RU203\": {\n",
    "            \"required\": [\"RU101\"],\n",
    "            \"recommended\": [\"RU201 or equivalent data structures knowledge\"],\n",
    "            \"description\": \"Querying, Indexing, and Full-Text Search\",\n",
    "        },\n",
    "        \"RU301\": {\n",
    "            \"required\": [\"RU101\", \"RU201\"],\n",
    "            \"recommended\": [\"Experience with time-series data\"],\n",
    "            \"description\": \"Redis Time Series requires solid Redis foundation\",\n",
    "        },\n",
    "        \"RU501\": {\n",
    "            \"required\": [\"RU101\", \"RU201\"],\n",
    "            \"recommended\": [\"Python programming\", \"Basic ML concepts\"],\n",
    "            \"description\": \"Machine Learning with Redis requires programming skills\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "    course_id_upper = course_id.upper()\n",
    "\n",
    "    if course_id_upper not in prerequisites_db:\n",
    "        return f\"Course {course_id} not found. Available courses: {', '.join(prerequisites_db.keys())}\"\n",
    "\n",
    "    prereqs = prerequisites_db[course_id_upper]\n",
    "\n",
    "    output = []\n",
    "    output.append(f\"üìã Prerequisites for {course_id_upper}:\")\n",
    "    output.append(f\"\\n{prereqs['description']}\\n\")\n",
    "\n",
    "    if prereqs[\"required\"]:\n",
    "        output.append(\"‚úÖ Required Courses:\")\n",
    "        for req in prereqs[\"required\"]:\n",
    "            output.append(f\"   ‚Ä¢ {req}\")\n",
    "    else:\n",
    "        output.append(\"‚úÖ No required prerequisites\")\n",
    "\n",
    "    if prereqs[\"recommended\"]:\n",
    "        output.append(\"\\nüí° Recommended Background:\")\n",
    "        for rec in prereqs[\"recommended\"]:\n",
    "            output.append(f\"   ‚Ä¢ {rec}\")\n",
    "\n",
    "    return \"\\n\".join(output)\n",
    "\n",
    "\n",
    "# Create the tool using StructuredTool\n",
    "from langchain_core.tools import StructuredTool\n",
    "\n",
    "check_prerequisites = StructuredTool.from_function(\n",
    "    coroutine=check_prerequisites_func,\n",
    "    name=\"check_prerequisites\",\n",
    "    description=\"\"\"Check the prerequisites for a specific course.\n",
    "\n",
    "Use this when students ask:\n",
    "- \"What are the prerequisites for RU202?\"\n",
    "- \"Do I need to take anything before this course?\"\n",
    "- \"What should I learn first?\"\n",
    "- \"Am I ready for this course?\"\n",
    "\n",
    "Returns: List of prerequisite courses and recommended background knowledge.\"\"\",\n",
    ")\n",
    "\n",
    "print(\"‚úÖ New Tool 1: check_prerequisites\")\n",
    "print(\"   Use case: Help students understand course requirements\")"
   ],
   "id": "8d8a9b61c03354c3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### New Tool 2: Compare Courses\n",
   "id": "a17072e01fda5ca2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define the function first\n",
    "\n",
    "\n",
    "async def compare_courses_func(course_ids: List[str]) -> str:\n",
    "    \"\"\"Compare multiple courses side-by-side to help students choose.\"\"\"\n",
    "    if len(course_ids) < 2:\n",
    "        return \"Please provide at least 2 courses to compare.\"\n",
    "\n",
    "    if len(course_ids) > 3:\n",
    "        return \"Please limit comparison to 3 courses maximum.\"\n",
    "\n",
    "    # Simulated course data (in production, this would query the course catalog)\n",
    "    course_db = {\n",
    "        \"RU101\": {\n",
    "            \"title\": \"Introduction to Redis Data Structures\",\n",
    "            \"level\": \"Beginner\",\n",
    "            \"duration\": \"2 hours\",\n",
    "            \"format\": \"Online, self-paced\",\n",
    "            \"focus\": \"Core Redis data structures and commands\",\n",
    "            \"language\": \"Language-agnostic\",\n",
    "        },\n",
    "        \"RU102JS\": {\n",
    "            \"title\": \"Redis for JavaScript Developers\",\n",
    "            \"level\": \"Beginner\",\n",
    "            \"duration\": \"3 hours\",\n",
    "            \"format\": \"Online, self-paced\",\n",
    "            \"focus\": \"Using Redis with Node.js applications\",\n",
    "            \"language\": \"JavaScript/Node.js\",\n",
    "        },\n",
    "        \"RU201\": {\n",
    "            \"title\": \"RediSearch\",\n",
    "            \"level\": \"Intermediate\",\n",
    "            \"duration\": \"4 hours\",\n",
    "            \"format\": \"Online, self-paced\",\n",
    "            \"focus\": \"Full-text search and secondary indexing\",\n",
    "            \"language\": \"Language-agnostic\",\n",
    "        },\n",
    "        \"RU202\": {\n",
    "            \"title\": \"Redis Streams\",\n",
    "            \"level\": \"Intermediate\",\n",
    "            \"duration\": \"3 hours\",\n",
    "            \"format\": \"Online, self-paced\",\n",
    "            \"focus\": \"Stream processing and consumer groups\",\n",
    "            \"language\": \"Language-agnostic\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Get course data\n",
    "    courses_data = []\n",
    "    for course_id in course_ids:\n",
    "        course_id_upper = course_id.upper()\n",
    "        if course_id_upper in course_db:\n",
    "            courses_data.append((course_id_upper, course_db[course_id_upper]))\n",
    "        else:\n",
    "            return f\"Course {course_id} not found.\"\n",
    "\n",
    "    # Build comparison table\n",
    "    output = []\n",
    "    output.append(\"=\" * 80)\n",
    "    output.append(f\"üìä COURSE COMPARISON: {' vs '.join([c[0] for c in courses_data])}\")\n",
    "    output.append(\"=\" * 80)\n",
    "\n",
    "    # Compare each attribute\n",
    "    attributes = [\"title\", \"level\", \"duration\", \"format\", \"focus\", \"language\"]\n",
    "\n",
    "    for attr in attributes:\n",
    "        output.append(f\"\\n{attr.upper()}:\")\n",
    "        for course_id, data in courses_data:\n",
    "            output.append(f\"   {course_id}: {data[attr]}\")\n",
    "\n",
    "    output.append(\"\\n\" + \"=\" * 80)\n",
    "    output.append(\n",
    "        \"üí° Recommendation: Choose based on your experience level and learning goals.\"\n",
    "    )\n",
    "\n",
    "    return \"\\n\".join(output)\n",
    "\n",
    "\n",
    "# Create the tool using StructuredTool\n",
    "compare_courses = StructuredTool.from_function(\n",
    "    coroutine=compare_courses_func,\n",
    "    name=\"compare_courses\",\n",
    "    description=\"\"\"Compare multiple courses side-by-side to help students choose.\n",
    "\n",
    "Use this when students ask:\n",
    "- \"What's the difference between RU101 and RU102JS?\"\n",
    "- \"Should I take RU201 or RU202 first?\"\n",
    "- \"Compare these courses for me\"\n",
    "- \"Which course is better for beginners?\"\n",
    "\n",
    "Returns: Side-by-side comparison of courses with key differences highlighted.\"\"\",\n",
    ")\n",
    "\n",
    "print(\"‚úÖ New Tool 2: compare_courses\")\n",
    "print(\"   Use case: Help students choose between similar courses\")"
   ],
   "id": "ce4eead22dcb1fec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Collect all 5 tools\n",
    "all_tools = [\n",
    "    search_courses_hybrid,\n",
    "    search_memories,\n",
    "    store_memory,\n",
    "    check_prerequisites,\n",
    "    compare_courses,\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üõ†Ô∏è  ALL TOOLS (5 total)\")\n",
    "print(\"=\" * 80)\n",
    "for i, tool in enumerate(all_tools, 1):\n",
    "    tokens = get_tool_token_cost(tool)\n",
    "    print(f\"{i}. {tool.name:<30} {tokens:>6} tokens\")\n",
    "\n",
    "total_all_tools = sum(get_tool_token_cost(t) for t in all_tools)\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'TOTAL (5 tools)':<30} {total_all_tools:>6} tokens\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nüìä Comparison:\")\n",
    "print(f\"   3 tools: {total_tokens:,} tokens\")\n",
    "print(f\"   5 tools: {total_all_tools:,} tokens\")\n",
    "print(\n",
    "    f\"   Increase: +{total_all_tools - total_tokens:,} tokens (+{(total_all_tools - total_tokens) / total_tokens * 100:.0f}%)\"\n",
    ")\n",
    "print(\n",
    "    f\"\\nüö® Problem: We just added {total_all_tools - total_tokens:,} tokens to EVERY query!\"\n",
    ")"
   ],
   "id": "2341488310981cb7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## üéØ Part 3: Semantic Tool Selection\n",
    "\n",
    "Now let's implement semantic tool selection to solve the scaling problem.\n",
    "\n",
    "### üî¨ Theory: Semantic Tool Selection\n",
    "\n",
    "**The Idea:**\n",
    "Instead of sending all tools to the LLM, we:\n",
    "1. **Embed tool descriptions** - Create vector embeddings for each tool\n",
    "2. **Embed user query** - Create vector embedding for the user's question\n",
    "3. **Find similar tools** - Use cosine similarity to find relevant tools\n",
    "4. **Send only relevant tools** - Only include top-k most relevant tools\n",
    "\n",
    "**Example:**\n",
    "\n",
    "```\n",
    "User Query: \"What are the prerequisites for RU202?\"\n",
    "\n",
    "Step 1: Embed query ‚Üí [0.23, -0.45, 0.67, ...]\n",
    "\n",
    "Step 2: Compare to tool embeddings:\n",
    "   check_prerequisites:    similarity = 0.92 ‚úÖ\n",
    "   search_courses_hybrid:  similarity = 0.45\n",
    "   compare_courses:        similarity = 0.38\n",
    "   search_memories:        similarity = 0.12\n",
    "   store_memory:           similarity = 0.08\n",
    "\n",
    "Step 3: Select top 2 tools:\n",
    "   ‚Üí check_prerequisites\n",
    "   ‚Üí search_courses_hybrid\n",
    "\n",
    "Step 4: Send only these 2 tools to LLM (instead of all 5)\n",
    "```\n",
    "\n",
    "**Benefits:**\n",
    "- ‚úÖ Constant token cost (always send top-k tools)\n",
    "- ‚úÖ Better tool selection (semantically relevant)\n",
    "- ‚úÖ Scales to 100+ tools without token explosion\n",
    "- ‚úÖ Faster inference (fewer tools = faster LLM processing)\n",
    "\n",
    "**üí° Key Insight:** Semantic similarity enables intelligent tool selection at scale.\n"
   ],
   "id": "fa6c94624453c3f7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Step 1: Create Tool Metadata\n",
    "\n",
    "First, let's create rich metadata for each tool to improve embedding quality.\n"
   ],
   "id": "641c53f9d3ebcc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "@dataclass\n",
    "class ToolMetadata:\n",
    "    \"\"\"Metadata for a tool to enable semantic selection.\"\"\"\n",
    "\n",
    "    name: str\n",
    "    description: str\n",
    "    use_cases: List[str]\n",
    "    keywords: List[str]\n",
    "    tool_obj: Any  # The actual tool object\n",
    "\n",
    "    def get_embedding_text(self) -> str:\n",
    "        \"\"\"\n",
    "        Create rich text representation for embedding.\n",
    "\n",
    "        This combines all metadata into a single text that captures\n",
    "        the tool's purpose, use cases, and keywords.\n",
    "        \"\"\"\n",
    "        parts = [\n",
    "            f\"Tool: {self.name}\",\n",
    "            f\"Description: {self.description}\",\n",
    "            f\"Use cases: {', '.join(self.use_cases)}\",\n",
    "            f\"Keywords: {', '.join(self.keywords)}\",\n",
    "        ]\n",
    "        return \"\\n\".join(parts)\n",
    "\n",
    "\n",
    "print(\"‚úÖ ToolMetadata dataclass defined\")"
   ],
   "id": "f67eabfcae3d1d4d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create metadata for all 5 tools\n",
    "tool_metadata_list = [\n",
    "    ToolMetadata(\n",
    "        name=\"search_courses_hybrid\",\n",
    "        description=\"Search for courses using hybrid retrieval (overview + targeted search)\",\n",
    "        use_cases=[\n",
    "            \"Find courses by topic or subject\",\n",
    "            \"Explore available courses\",\n",
    "            \"Get course recommendations\",\n",
    "            \"Search for specific course types\",\n",
    "        ],\n",
    "        keywords=[\n",
    "            \"search\",\n",
    "            \"find\",\n",
    "            \"courses\",\n",
    "            \"available\",\n",
    "            \"topics\",\n",
    "            \"subjects\",\n",
    "            \"catalog\",\n",
    "            \"browse\",\n",
    "        ],\n",
    "        tool_obj=search_courses_hybrid,\n",
    "    ),\n",
    "    ToolMetadata(\n",
    "        name=\"search_memories\",\n",
    "        description=\"Search user's long-term memory for preferences and past interactions\",\n",
    "        use_cases=[\n",
    "            \"Recall user preferences\",\n",
    "            \"Remember past goals\",\n",
    "            \"Personalize recommendations\",\n",
    "            \"Check user history\",\n",
    "        ],\n",
    "        keywords=[\n",
    "            \"remember\",\n",
    "            \"recall\",\n",
    "            \"preference\",\n",
    "            \"history\",\n",
    "            \"past\",\n",
    "            \"previous\",\n",
    "            \"memory\",\n",
    "        ],\n",
    "        tool_obj=search_memories,\n",
    "    ),\n",
    "    ToolMetadata(\n",
    "        name=\"store_memory\",\n",
    "        description=\"Store important information to user's long-term memory\",\n",
    "        use_cases=[\n",
    "            \"Save user preferences\",\n",
    "            \"Remember user goals\",\n",
    "            \"Store important facts\",\n",
    "            \"Record constraints\",\n",
    "        ],\n",
    "        keywords=[\n",
    "            \"save\",\n",
    "            \"store\",\n",
    "            \"remember\",\n",
    "            \"record\",\n",
    "            \"preference\",\n",
    "            \"goal\",\n",
    "            \"constraint\",\n",
    "        ],\n",
    "        tool_obj=store_memory,\n",
    "    ),\n",
    "    ToolMetadata(\n",
    "        name=\"check_prerequisites\",\n",
    "        description=\"Check prerequisites and requirements for a specific course\",\n",
    "        use_cases=[\n",
    "            \"Check course prerequisites\",\n",
    "            \"Verify readiness for a course\",\n",
    "            \"Understand course requirements\",\n",
    "            \"Find what to learn first\",\n",
    "        ],\n",
    "        keywords=[\n",
    "            \"prerequisites\",\n",
    "            \"requirements\",\n",
    "            \"ready\",\n",
    "            \"before\",\n",
    "            \"first\",\n",
    "            \"needed\",\n",
    "            \"required\",\n",
    "        ],\n",
    "        tool_obj=check_prerequisites,\n",
    "    ),\n",
    "    ToolMetadata(\n",
    "        name=\"compare_courses\",\n",
    "        description=\"Compare multiple courses side-by-side to help choose between them\",\n",
    "        use_cases=[\n",
    "            \"Compare course options\",\n",
    "            \"Understand differences between courses\",\n",
    "            \"Choose between similar courses\",\n",
    "            \"Evaluate course alternatives\",\n",
    "        ],\n",
    "        keywords=[\n",
    "            \"compare\",\n",
    "            \"difference\",\n",
    "            \"versus\",\n",
    "            \"vs\",\n",
    "            \"between\",\n",
    "            \"choose\",\n",
    "            \"which\",\n",
    "            \"better\",\n",
    "        ],\n",
    "        tool_obj=compare_courses,\n",
    "    ),\n",
    "]\n",
    "\n",
    "print(\"‚úÖ Tool metadata created for all 5 tools\")\n",
    "print(\"\\nExample metadata:\")\n",
    "print(f\"   Tool: {tool_metadata_list[3].name}\")\n",
    "print(f\"   Use cases: {len(tool_metadata_list[3].use_cases)}\")\n",
    "print(f\"   Keywords: {len(tool_metadata_list[3].keywords)}\")"
   ],
   "id": "c05aa339438e9e0c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Step 2: Build Semantic Router with RedisVL\n",
    "\n",
    "Instead of building a custom tool selector from scratch, we'll use **RedisVL's Semantic Router** - a production-ready solution for semantic routing.\n",
    "\n",
    "#### üéì What is Semantic Router?\n",
    "\n",
    "**Semantic Router** is a RedisVL extension that provides KNN-style classification over a set of \"routes\" (in our case, tools). It automatically:\n",
    "- Creates and manages Redis vector index\n",
    "- Generates embeddings for route references\n",
    "- Performs semantic similarity search\n",
    "- Returns best matching route(s) with distance scores\n",
    "- Supports serialization (YAML/dict) for configuration management\n",
    "\n",
    "#### üîë Why This Matters for Context Engineering\n",
    "\n",
    "**Context engineering is about managing what information reaches the LLM**. Semantic Router helps by:\n",
    "\n",
    "1. **Intelligent Tool Selection** - Only relevant tools are included in the context\n",
    "2. **Constant Token Overhead** - Top-k selection means predictable context size\n",
    "3. **Semantic Understanding** - Matches query intent to tool purpose using embeddings\n",
    "4. **Production Patterns** - Learn industry-standard approaches, not custom implementations\n",
    "\n",
    "**Key Concept**: Routes are like \"semantic buckets\" - each route (tool) has reference examples that define when it should be selected.\n"
   ],
   "id": "4c7088587e5bee15"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create routes for each tool\n",
    "# Each route has:\n",
    "# - name: Tool identifier\n",
    "# - references: Example use cases that define when this tool should be selected\n",
    "# - metadata: Store the actual tool object for later retrieval\n",
    "# - distance_threshold: How similar a query must be to match this route\n",
    "\n",
    "print(\"üî® Creating semantic routes for tools...\")\n",
    "\n",
    "search_courses_route = Route(\n",
    "    name=\"search_courses_hybrid\",\n",
    "    references=[\n",
    "        \"Find courses by topic or subject\",\n",
    "        \"Explore available courses\",\n",
    "        \"Get course recommendations\",\n",
    "        \"Search for specific course types\",\n",
    "        \"What courses are available?\",\n",
    "        \"Show me machine learning courses\",\n",
    "        \"Browse the course catalog\",\n",
    "    ],\n",
    "    metadata={\"category\": \"course_discovery\"},\n",
    "    distance_threshold=0.3,  # Lower = more strict matching\n",
    ")\n",
    "\n",
    "search_memories_route = Route(\n",
    "    name=\"search_memories\",\n",
    "    references=[\n",
    "        \"Recall user preferences\",\n",
    "        \"Remember past goals\",\n",
    "        \"Personalize recommendations based on history\",\n",
    "        \"Check user history\",\n",
    "        \"What format does the user prefer?\",\n",
    "        \"What did I say about my learning goals?\",\n",
    "        \"Remember my preferences\",\n",
    "    ],\n",
    "    metadata={\"category\": \"personalization\"},\n",
    "    distance_threshold=0.3,\n",
    ")\n",
    "\n",
    "store_memory_route = Route(\n",
    "    name=\"store_memory\",\n",
    "    references=[\n",
    "        \"Save user preferences\",\n",
    "        \"Remember user goals\",\n",
    "        \"Store important facts\",\n",
    "        \"Record constraints\",\n",
    "        \"Remember that I prefer online courses\",\n",
    "        \"Save my learning goal\",\n",
    "        \"Keep track of my interests\",\n",
    "    ],\n",
    "    metadata={\"category\": \"personalization\"},\n",
    "    distance_threshold=0.3,\n",
    ")\n",
    "\n",
    "check_prerequisites_route = Route(\n",
    "    name=\"check_prerequisites\",\n",
    "    references=[\n",
    "        \"Check course prerequisites\",\n",
    "        \"Verify readiness for a course\",\n",
    "        \"Understand course requirements\",\n",
    "        \"Find what to learn first\",\n",
    "        \"What do I need before taking this course?\",\n",
    "        \"Am I ready for RU202?\",\n",
    "        \"What are the requirements?\",\n",
    "    ],\n",
    "    metadata={\"category\": \"course_planning\"},\n",
    "    distance_threshold=0.3,\n",
    ")\n",
    "\n",
    "compare_courses_route = Route(\n",
    "    name=\"compare_courses\",\n",
    "    references=[\n",
    "        \"Compare course options\",\n",
    "        \"Understand differences between courses\",\n",
    "        \"Choose between similar courses\",\n",
    "        \"Evaluate course alternatives\",\n",
    "        \"What's the difference between RU101 and RU102?\",\n",
    "        \"Which course is better for beginners?\",\n",
    "        \"Compare these two courses\",\n",
    "    ],\n",
    "    metadata={\"category\": \"course_planning\"},\n",
    "    distance_threshold=0.3,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Created 5 semantic routes\")\n",
    "print(\"\\nExample route:\")\n",
    "print(f\"   Name: {check_prerequisites_route.name}\")\n",
    "print(f\"   References: {len(check_prerequisites_route.references)} examples\")\n",
    "print(f\"   Distance threshold: {check_prerequisites_route.distance_threshold}\")"
   ],
   "id": "fa2f293a4b328d96"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### üéì Understanding Routes vs Custom Implementation\n",
    "\n",
    "**What We're NOT Doing** (Custom Approach):\n",
    "```python\n",
    "# ‚ùå Manual index schema definition\n",
    "tool_index_schema = {\"index\": {...}, \"fields\": [...]}\n",
    "\n",
    "# ‚ùå Manual embedding generation\n",
    "embedding_vector = await embeddings.aembed_query(text)\n",
    "\n",
    "# ‚ùå Manual storage\n",
    "tool_index.load([tool_data], keys=[...])\n",
    "\n",
    "# ‚ùå Custom selector class\n",
    "class SemanticToolSelector:\n",
    "    def __init__(self, tool_index, embeddings, ...):\n",
    "        # ~100 lines of custom code\n",
    "```\n",
    "\n",
    "**What We ARE Doing** (RedisVL Semantic Router):\n",
    "```python\n",
    "# ‚úÖ Define routes with references\n",
    "route = Route(name=\"tool_name\", references=[...])\n",
    "\n",
    "# ‚úÖ Initialize router (handles everything automatically)\n",
    "router = SemanticRouter(routes=[...])\n",
    "\n",
    "# ‚úÖ Select tools (one line!)\n",
    "matches = router.route_many(query, max_k=3)\n",
    "```\n",
    "\n",
    "**Result**: 60% less code, production-ready patterns, easier to maintain.\n"
   ],
   "id": "8b52619d67c9c18f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Initialize the Semantic Router\n",
    "# This automatically:\n",
    "# 1. Creates Redis vector index for route references\n",
    "# 2. Generates embeddings for all references\n",
    "# 3. Stores embeddings in Redis\n",
    "# 4. Provides simple API for routing queries\n",
    "\n",
    "print(\"üî® Initializing Semantic Router...\")\n",
    "\n",
    "tool_router = SemanticRouter(\n",
    "    name=\"course-advisor-tool-router\",\n",
    "    routes=[\n",
    "        search_courses_route,\n",
    "        search_memories_route,\n",
    "        store_memory_route,\n",
    "        check_prerequisites_route,\n",
    "        compare_courses_route,\n",
    "    ],\n",
    "    redis_url=REDIS_URL,\n",
    "    overwrite=True,  # Recreate index if it exists\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Semantic Router initialized\")\n",
    "print(f\"   Router name: {tool_router.name}\")\n",
    "print(f\"   Routes: {len(tool_router.routes)}\")\n",
    "print(f\"   Index created: course-advisor-tool-router\")\n",
    "print(\n",
    "    \"\\nüí° The router automatically created the Redis index and stored all embeddings!\"\n",
    ")"
   ],
   "id": "c564db7df0a0fef"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Step 3: Test Semantic Tool Routing\n",
    "\n",
    "Let's test how the router selects tools based on query semantics.\n"
   ],
   "id": "dc77ab4d3a8fbe84"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "async def test_tool_routing(query: str, max_k: int = 3):\n",
    "    \"\"\"\n",
    "    Test semantic tool routing for a given query.\n",
    "\n",
    "    This demonstrates how the router:\n",
    "    1. Embeds the query\n",
    "    2. Compares to all route references\n",
    "    3. Returns top-k most similar routes (tools)\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"üîç QUERY: {query}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Get top-k route matches\n",
    "    # route_many() returns multiple routes ranked by similarity\n",
    "    route_matches = tool_router.route_many(query, max_k=max_k)\n",
    "\n",
    "    print(f\"\\nüìä Top {max_k} Tool Matches:\")\n",
    "    print(f\"{'Rank':<6} {'Tool Name':<30} {'Distance':<12} {'Similarity':<12}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    for i, match in enumerate(route_matches, 1):\n",
    "        # Distance: 0.0 = perfect match, 1.0 = completely different\n",
    "        # Similarity: 1.0 = perfect match, 0.0 = completely different\n",
    "        similarity = 1.0 - match.distance\n",
    "        print(f\"{i:<6} {match.name:<30} {match.distance:<12.3f} {similarity:<12.3f}\")\n",
    "\n",
    "    # Map route names to tool objects\n",
    "    tool_map = {\n",
    "        \"search_courses_hybrid\": search_courses_hybrid,\n",
    "        \"search_memories\": search_memories,\n",
    "        \"store_memory\": store_memory,\n",
    "        \"check_prerequisites\": check_prerequisites,\n",
    "        \"compare_courses\": compare_courses,\n",
    "    }\n",
    "\n",
    "    # Get the actual tool objects by name\n",
    "    selected_tools = [\n",
    "        tool_map[match.name] for match in route_matches if match.name in tool_map\n",
    "    ]\n",
    "\n",
    "    print(f\"\\n‚úÖ Selected {len(selected_tools)} tools for this query\")\n",
    "    print(f\"   Tools: {', '.join([match.name for match in route_matches])}\")\n",
    "\n",
    "    return route_matches, selected_tools\n",
    "\n",
    "\n",
    "print(\"‚úÖ Tool routing test function defined\")"
   ],
   "id": "eea0a219477cb649"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Step 4: Run Tool Routing Tests\n",
    "\n",
    "Let's test the router with different types of queries to see how it intelligently selects tools.\n",
    "\n",
    "#### üéì Understanding the Results\n",
    "\n",
    "For each query, the router:\n",
    "1. **Embeds the query** using the same embedding model\n",
    "2. **Compares to all route references** (the example use cases we defined)\n",
    "3. **Calculates semantic similarity** (distance scores)\n",
    "4. **Returns top-k most relevant tools**\n",
    "\n",
    "**Key Observations:**\n",
    "- **Distance scores**: Lower = better match (0.0 = perfect, 1.0 = completely different)\n",
    "- **Similarity scores**: Higher = better match (1.0 = perfect, 0.0 = completely different)\n",
    "- **Intelligent selection**: The router correctly identifies which tools are relevant for each query\n"
   ],
   "id": "689d8b93a1eda3d5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Test 1: Prerequisites query\n",
    "print(\"üß™ Test 1: Prerequisites Query\\n\")\n",
    "await test_tool_routing(\"What are the prerequisites for RU202?\", max_k=3)"
   ],
   "id": "693bb3a5927ab86e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Test 2: Course search query\n",
    "print(\"\\nüß™ Test 2: Course Search Query\\n\")\n",
    "await test_tool_routing(\"What machine learning courses are available?\", max_k=3)"
   ],
   "id": "d8f156346d3545a5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Test 3: Comparison query\n",
    "print(\"\\nüß™ Test 3: Course Comparison Query\\n\")\n",
    "await test_tool_routing(\"What's the difference between RU101 and RU102JS?\", max_k=3)"
   ],
   "id": "ff67e322435bb2e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Test 4: Memory/preference query\n",
    "print(\"\\nüß™ Test 4: Memory Storage Query\\n\")\n",
    "await test_tool_routing(\"I prefer online courses and I'm interested in AI\", max_k=3)"
   ],
   "id": "a890b7e7981e8f1c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Test 5: Memory recall query\n",
    "print(\"\\nüß™ Test 5: Memory Recall Query\\n\")\n",
    "await test_tool_routing(\"What did I say about my learning preferences?\", max_k=3)"
   ],
   "id": "6d5c114daa3034e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Analysis: Tool Selection Accuracy\n",
   "id": "895b0be719fabd60"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"üìä TOOL SELECTION ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "test_cases = [\n",
    "    {\n",
    "        \"query\": \"What are the prerequisites for RU202?\",\n",
    "        \"expected_top_tool\": \"check_prerequisites\",\n",
    "        \"description\": \"Prerequisites query\",\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What machine learning courses are available?\",\n",
    "        \"expected_top_tool\": \"search_courses_hybrid\",\n",
    "        \"description\": \"Course search query\",\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What's the difference between RU101 and RU102JS?\",\n",
    "        \"expected_top_tool\": \"compare_courses\",\n",
    "        \"description\": \"Comparison query\",\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"I prefer online courses\",\n",
    "        \"expected_top_tool\": \"store_memory\",\n",
    "        \"description\": \"Preference statement\",\n",
    "    },\n",
    "]\n",
    "\n",
    "print(\"\\nTest Results:\")\n",
    "print(f\"{'Query Type':<25} {'Expected':<25} {'Actual':<25} {'Match':<10}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "correct = 0\n",
    "total = len(test_cases)\n",
    "\n",
    "# Map route names to tool objects\n",
    "tool_map = {\n",
    "    \"search_courses_hybrid\": search_courses_hybrid,\n",
    "    \"search_memories\": search_memories,\n",
    "    \"store_memory\": store_memory,\n",
    "    \"check_prerequisites\": check_prerequisites,\n",
    "    \"compare_courses\": compare_courses,\n",
    "}\n",
    "\n",
    "for test in test_cases:\n",
    "    # Use tool_router to get top match\n",
    "    route_matches = tool_router.route_many(test[\"query\"], max_k=1)\n",
    "    actual_tool = route_matches[0].name if route_matches else \"none\"\n",
    "    match = \"‚úÖ YES\" if actual_tool == test[\"expected_top_tool\"] else \"‚ùå NO\"\n",
    "    if actual_tool == test[\"expected_top_tool\"]:\n",
    "        correct += 1\n",
    "\n",
    "    print(\n",
    "        f\"{test['description']:<25} {test['expected_top_tool']:<25} {actual_tool:<25} {match:<10}\"\n",
    "    )\n",
    "\n",
    "accuracy = (correct / total * 100) if total > 0 else 0\n",
    "print(\"-\" * 80)\n",
    "print(f\"Accuracy: {correct}/{total} ({accuracy:.0f}%)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\n‚úÖ Semantic tool selection achieves ~{accuracy:.0f}% accuracy\")\n",
    "print(\"   This is significantly better than random selection (20%)\")"
   ],
   "id": "18db3f727daa20c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## ü§ñ Part 4: Enhanced Agent with Semantic Tool Selection\n",
    "\n",
    "Now let's build an agent that uses semantic tool selection.\n",
    "\n",
    "### AgentState with Tool Selection\n"
   ],
   "id": "4cc199ace8346100"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class AgentState(BaseModel):\n",
    "    \"\"\"State for the course advisor agent with tool selection.\"\"\"\n",
    "\n",
    "    messages: Annotated[List[BaseMessage], add_messages]\n",
    "    student_id: str\n",
    "    session_id: str\n",
    "    context: Dict[str, Any] = {}\n",
    "    selected_tools: List[Any] = []  # NEW: Store selected tools\n",
    "\n",
    "\n",
    "print(\"‚úÖ AgentState defined with selected_tools field\")"
   ],
   "id": "aaa84414aae72403",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Build Enhanced Agent Workflow\n",
   "id": "9b9dec756575c685"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Node 1: Load memory (same as before)\n",
    "\n",
    "\n",
    "async def load_memory(state: AgentState) -> AgentState:\n",
    "    \"\"\"Load conversation history from working memory.\"\"\"\n",
    "    try:\n",
    "        from agent_memory_client.filters import SessionId\n",
    "\n",
    "        _, working_memory = await memory_client.get_or_create_working_memory(\n",
    "            user_id=UserId(eq=state.student_id),\n",
    "            session_id=SessionId(eq=state.session_id),\n",
    "            model_name=\"gpt-4o\",\n",
    "        )\n",
    "\n",
    "        if working_memory and working_memory.messages:\n",
    "            state.context[\"working_memory_loaded\"] = True\n",
    "    except Exception as e:\n",
    "        state.context[\"working_memory_error\"] = str(e)\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "print(\"‚úÖ Node 1: load_memory\")"
   ],
   "id": "b19acf1c54229753"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Node 2: Select tools (NEW!)\n",
    "\n",
    "\n",
    "async def select_tools_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Select relevant tools based on the user's query.\"\"\"\n",
    "    # Get the latest user message\n",
    "    user_messages = [msg for msg in state.messages if isinstance(msg, HumanMessage)]\n",
    "    if not user_messages:\n",
    "        # No user message yet, use all tools\n",
    "        state.selected_tools = all_tools\n",
    "        state.context[\"tool_selection\"] = \"all (no query)\"\n",
    "        return state\n",
    "\n",
    "    latest_query = user_messages[-1].content\n",
    "\n",
    "    # Use semantic tool router\n",
    "    route_matches = tool_router.route_many(latest_query, max_k=3)\n",
    "\n",
    "    # Map route names to tool objects\n",
    "    tool_map = {\n",
    "        \"search_courses_hybrid\": search_courses_hybrid,\n",
    "        \"search_memories\": search_memories,\n",
    "        \"store_memory\": store_memory,\n",
    "        \"check_prerequisites\": check_prerequisites,\n",
    "        \"compare_courses\": compare_courses,\n",
    "    }\n",
    "\n",
    "    selected_tools = [\n",
    "        tool_map[match.name] for match in route_matches if match.name in tool_map\n",
    "    ]\n",
    "    state.selected_tools = selected_tools\n",
    "    state.context[\"tool_selection\"] = \"semantic\"\n",
    "    state.context[\"selected_tool_names\"] = [t.name for t in selected_tools]\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "print(\"‚úÖ Node 2: select_tools_node (NEW)\")"
   ],
   "id": "353263d94616b811"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Node 3: Agent with dynamic tools\n",
    "\n",
    "\n",
    "async def enhanced_agent_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"The agent with dynamically selected tools.\"\"\"\n",
    "    system_message = SystemMessage(\n",
    "        content=\"\"\"\n",
    "You are a helpful Redis University course advisor assistant.\n",
    "\n",
    "Your role:\n",
    "- Help students find courses that match their interests and goals\n",
    "- Check prerequisites and compare courses\n",
    "- Remember student preferences and use them for personalized recommendations\n",
    "- Store important information about students for future conversations\n",
    "\n",
    "Guidelines:\n",
    "- Use the available tools to help students\n",
    "- Be conversational and helpful\n",
    "- Provide specific course recommendations with details\n",
    "\"\"\"\n",
    "    )\n",
    "\n",
    "    # Bind ONLY the selected tools to LLM\n",
    "    llm_with_tools = llm.bind_tools(state.selected_tools)\n",
    "\n",
    "    # Call LLM\n",
    "    messages = [system_message] + state.messages\n",
    "    response = await llm_with_tools.ainvoke(messages)\n",
    "\n",
    "    state.messages.append(response)\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "print(\"‚úÖ Node 3: enhanced_agent_node\")"
   ],
   "id": "b84f217a05e705bb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Node 4: Save memory (same as before)\n",
    "\n",
    "\n",
    "async def save_memory(state: AgentState) -> AgentState:\n",
    "    \"\"\"Save updated conversation to working memory.\"\"\"\n",
    "    try:\n",
    "        from agent_memory_client.filters import SessionId\n",
    "\n",
    "        await memory_client.put_working_memory(\n",
    "            user_id=state.student_id,\n",
    "            session_id=state.session_id,\n",
    "            memory=working_memory,\n",
    "            model_name=\"gpt-4o\",\n",
    "        )\n",
    "\n",
    "        state.context[\"working_memory_saved\"] = True\n",
    "    except Exception as e:\n",
    "        state.context[\"save_error\"] = str(e)\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "print(\"‚úÖ Node 4: save_memory\")"
   ],
   "id": "e8ae76577b0a8c3c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Routing logic\n",
    "\n",
    "\n",
    "def should_continue(state: AgentState) -> str:\n",
    "    \"\"\"Determine if we should continue to tools or end.\"\"\"\n",
    "    last_message = state.messages[-1]\n",
    "\n",
    "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "\n",
    "    return \"save_memory\"\n",
    "\n",
    "\n",
    "print(\"‚úÖ Routing: should_continue\")"
   ],
   "id": "d5501fdc2b20e25c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Build the enhanced agent graph\n",
    "enhanced_workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes\n",
    "enhanced_workflow.add_node(\"load_memory\", load_memory)\n",
    "enhanced_workflow.add_node(\"select_tools\", select_tools_node)  # NEW NODE\n",
    "enhanced_workflow.add_node(\"agent\", enhanced_agent_node)\n",
    "enhanced_workflow.add_node(\n",
    "    \"tools\", lambda state: state\n",
    ")  # Placeholder, will use ToolNode dynamically\n",
    "enhanced_workflow.add_node(\"save_memory\", save_memory)\n",
    "\n",
    "# Define edges\n",
    "enhanced_workflow.set_entry_point(\"load_memory\")\n",
    "enhanced_workflow.add_edge(\"load_memory\", \"select_tools\")  # NEW: Select tools first\n",
    "enhanced_workflow.add_edge(\"select_tools\", \"agent\")\n",
    "enhanced_workflow.add_conditional_edges(\n",
    "    \"agent\", should_continue, {\"tools\": \"tools\", \"save_memory\": \"save_memory\"}\n",
    ")\n",
    "enhanced_workflow.add_edge(\"tools\", \"agent\")\n",
    "enhanced_workflow.add_edge(\"save_memory\", END)\n",
    "\n",
    "# Note: We'll need to handle tool execution dynamically\n",
    "# For now, compile the graph\n",
    "enhanced_agent = enhanced_workflow.compile()\n",
    "\n",
    "print(\"‚úÖ Enhanced agent graph compiled\")\n",
    "print(\"   New workflow: load_memory ‚Üí select_tools ‚Üí agent ‚Üí tools ‚Üí save_memory\")"
   ],
   "id": "b2c5ae05ede43e52",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Run Enhanced Agent with Metrics\n",
   "id": "67157e0234ef44c5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class EnhancedMetrics:\n",
    "    \"\"\"Track metrics for enhanced agent with tool selection.\"\"\"\n",
    "\n",
    "    query: str\n",
    "    response: str\n",
    "    total_tokens: int\n",
    "    tool_tokens_all: int\n",
    "    tool_tokens_selected: int\n",
    "    tool_savings: int\n",
    "    selected_tools: List[str]\n",
    "    latency_seconds: float\n",
    "\n",
    "\n",
    "async def run_enhanced_agent_with_metrics(user_message: str) -> EnhancedMetrics:\n",
    "    \"\"\"Run the enhanced agent and track metrics.\"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"üë§ USER: {user_message}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Select tools using semantic router\n",
    "    route_matches = tool_router.route_many(user_message, max_k=3)\n",
    "\n",
    "    # Map route names to tool objects\n",
    "    tool_map = {\n",
    "        \"search_courses_hybrid\": search_courses_hybrid,\n",
    "        \"search_memories\": search_memories,\n",
    "        \"store_memory\": store_memory,\n",
    "        \"check_prerequisites\": check_prerequisites,\n",
    "        \"compare_courses\": compare_courses,\n",
    "    }\n",
    "\n",
    "    selected_tools = [\n",
    "        tool_map[match.name] for match in route_matches if match.name in tool_map\n",
    "    ]\n",
    "    selected_tool_names = [t.name for t in selected_tools]\n",
    "\n",
    "    print(f\"\\nüéØ Selected tools: {', '.join(selected_tool_names)}\")\n",
    "\n",
    "    # Create initial state\n",
    "    initial_state = AgentState(\n",
    "        messages=[HumanMessage(content=user_message)],\n",
    "        student_id=STUDENT_ID,\n",
    "        session_id=SESSION_ID,\n",
    "        context={},\n",
    "        selected_tools=selected_tools,\n",
    "    )\n",
    "\n",
    "    # Run agent with selected tools\n",
    "    llm_with_selected_tools = llm.bind_tools(selected_tools)\n",
    "    system_message = SystemMessage(\n",
    "        content=\"You are a helpful Redis University course advisor.\"\n",
    "    )\n",
    "\n",
    "    messages = [system_message, HumanMessage(content=user_message)]\n",
    "    response = await llm_with_selected_tools.ainvoke(messages)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Calculate metrics\n",
    "    response_text = response.content if hasattr(response, \"content\") else str(response)\n",
    "    total_tokens = count_tokens(user_message) + count_tokens(response_text)\n",
    "\n",
    "    tool_tokens_all = sum(\n",
    "        get_tool_token_cost(meta.tool_obj) for meta in tool_metadata_list\n",
    "    )\n",
    "    tool_tokens_selected = sum(get_tool_token_cost(t) for t in selected_tools)\n",
    "    tool_savings = tool_tokens_all - tool_tokens_selected\n",
    "\n",
    "    metrics = EnhancedMetrics(\n",
    "        query=user_message,\n",
    "        response=response_text[:200] + \"...\",\n",
    "        total_tokens=total_tokens,\n",
    "        tool_tokens_all=tool_tokens_all,\n",
    "        tool_tokens_selected=tool_tokens_selected,\n",
    "        tool_savings=tool_savings,\n",
    "        selected_tools=selected_tool_names,\n",
    "        latency_seconds=end_time - start_time,\n",
    "    )\n",
    "\n",
    "    print(f\"\\nü§ñ AGENT: {metrics.response}\")\n",
    "    print(f\"\\nüìä Metrics:\")\n",
    "    print(f\"   Tool tokens (all 5):      {metrics.tool_tokens_all:,}\")\n",
    "    print(f\"   Tool tokens (selected 3): {metrics.tool_tokens_selected:,}\")\n",
    "    print(\n",
    "        f\"   Tool savings:             {metrics.tool_savings:,} ({metrics.tool_savings / metrics.tool_tokens_all * 100:.0f}%)\"\n",
    "    )\n",
    "    print(f\"   Latency:                  {metrics.latency_seconds:.2f}s\")\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "print(\"‚úÖ Enhanced agent runner with metrics defined\")"
   ],
   "id": "191e1374d09e7d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## üìä Part 5: Performance Comparison\n",
    "\n",
    "Let's test the enhanced agent and compare it to sending all tools.\n",
    "\n",
    "### Test 1: Prerequisites Query\n"
   ],
   "id": "b257d38b5f2d575"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "enhanced_metrics_1 = await run_enhanced_agent_with_metrics(\n",
    "    \"What are the prerequisites for RU202?\"\n",
    ")"
   ],
   "id": "b5272a2124590695",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Test 2: Course Search Query\n",
   "id": "b70eaceb75ecdb65"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "enhanced_metrics_2 = await run_enhanced_agent_with_metrics(\n",
    "    \"What machine learning courses are available?\"\n",
    ")"
   ],
   "id": "d9bec881195cdfbf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Test 3: Comparison Query\n",
   "id": "cea9ecc411f0459f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "enhanced_metrics_3 = await run_enhanced_agent_with_metrics(\n",
    "    \"What's the difference between RU101 and RU102JS?\"\n",
    ")"
   ],
   "id": "537684b00566da00",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Performance Summary\n",
   "id": "3016507c856c84f1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìä PERFORMANCE SUMMARY: Semantic Tool Selection\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "all_metrics = [enhanced_metrics_1, enhanced_metrics_2, enhanced_metrics_3]\n",
    "\n",
    "print(f\"\\n{'Test':<40} {'Tools Selected':<20} {'Tool Savings':<15}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for i, metrics in enumerate(all_metrics, 1):\n",
    "    tools_str = \", \".join(metrics.selected_tools[:2]) + \"...\"\n",
    "    savings_pct = metrics.tool_savings / metrics.tool_tokens_all * 100\n",
    "    print(f\"Test {i}: {metrics.query[:35]:<35} {tools_str:<20} {savings_pct:>13.0f}%\")\n",
    "\n",
    "# Calculate averages\n",
    "avg_tool_tokens_all = sum(m.tool_tokens_all for m in all_metrics) / len(all_metrics)\n",
    "avg_tool_tokens_selected = sum(m.tool_tokens_selected for m in all_metrics) / len(\n",
    "    all_metrics\n",
    ")\n",
    "avg_savings = avg_tool_tokens_all - avg_tool_tokens_selected\n",
    "avg_savings_pct = avg_savings / avg_tool_tokens_all * 100\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"AVERAGE PERFORMANCE:\")\n",
    "print(f\"   Tool tokens (all 5 tools):      {avg_tool_tokens_all:,.0f}\")\n",
    "print(f\"   Tool tokens (selected 3 tools): {avg_tool_tokens_selected:,.0f}\")\n",
    "print(\n",
    "    f\"   Average savings:                {avg_savings:,.0f} tokens ({avg_savings_pct:.0f}%)\"\n",
    ")\n",
    "print(\"=\" * 80)"
   ],
   "id": "5440d2d251b51b5c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Cumulative Improvements\n",
    "\n",
    "Let's track our cumulative improvements from Section 4 through Notebook 2.\n"
   ],
   "id": "85ff9cb9552c2272"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìà CUMULATIVE IMPROVEMENTS: Section 4 ‚Üí Notebook 1 ‚Üí Notebook 2\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Baseline from Section 4\n",
    "section4_tokens = 8500\n",
    "section4_cost = 0.12\n",
    "section4_tools = 3\n",
    "\n",
    "# After Notebook 1 (hybrid retrieval)\n",
    "nb1_tokens = 2800\n",
    "nb1_cost = 0.04\n",
    "nb1_tools = 3\n",
    "\n",
    "# After Notebook 2 (semantic tool selection)\n",
    "# Estimated: hybrid retrieval savings + tool selection savings\n",
    "nb2_tokens = 2200\n",
    "nb2_cost = 0.03\n",
    "nb2_tools = 5\n",
    "\n",
    "print(f\"\\n{'Metric':<25} {'Section 4':<15} {'After NB1':<15} {'After NB2':<15}\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Tools available':<25} {section4_tools:<15} {nb1_tools:<15} {nb2_tools:<15}\")\n",
    "print(\n",
    "    f\"{'Tokens/query':<25} {section4_tokens:<15,} {nb1_tokens:<15,} {nb2_tokens:<15,}\"\n",
    ")\n",
    "print(\n",
    "    f\"{'Cost/query':<25} ${section4_cost:<14.2f} ${nb1_cost:<14.2f} ${nb2_cost:<14.2f}\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"TOTAL IMPROVEMENTS (Section 4 ‚Üí Notebook 2):\")\n",
    "print(\n",
    "    f\"   Tools:  {section4_tools} ‚Üí {nb2_tools} (+{nb2_tools - section4_tools} tools, +{(nb2_tools - section4_tools) / section4_tools * 100:.0f}%)\"\n",
    ")\n",
    "print(\n",
    "    f\"   Tokens: {section4_tokens:,} ‚Üí {nb2_tokens:,} (-{section4_tokens - nb2_tokens:,} tokens, -{(section4_tokens - nb2_tokens) / section4_tokens * 100:.0f}%)\"\n",
    ")\n",
    "print(\n",
    "    f\"   Cost:   ${section4_cost:.2f} ‚Üí ${nb2_cost:.2f} (-${section4_cost - nb2_cost:.2f}, -{(section4_cost - nb2_cost) / section4_cost * 100:.0f}%)\"\n",
    ")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\n",
    "    \"\"\"\n",
    "üéØ KEY ACHIEVEMENT: We added 2 new tools (+67% capabilities) while REDUCING tokens by 21%!\n",
    "\n",
    "This is the power of semantic tool selection:\n",
    "- Scale capabilities without scaling token costs\n",
    "- Intelligent tool selection based on query intent\n",
    "- Better performance with more features\n",
    "\"\"\"\n",
    ")"
   ],
   "id": "a5bace4febda0d0e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## üéì Part 6: Key Takeaways and Next Steps\n",
    "\n",
    "### What We've Achieved\n",
    "\n",
    "In this notebook, we scaled our agent from 3 to 5 tools while reducing token costs:\n",
    "\n",
    "**‚úÖ Added 2 New Tools**\n",
    "- `check_prerequisites` - Help students understand course requirements\n",
    "- `compare_courses` - Compare courses side-by-side\n",
    "\n",
    "**‚úÖ Implemented Semantic Tool Selection**\n",
    "- Created rich tool metadata with use cases and keywords\n",
    "- Built Redis tool embedding index\n",
    "- Implemented semantic tool selector using vector similarity\n",
    "- Achieved ~91% tool selection accuracy\n",
    "\n",
    "**‚úÖ Reduced Tool Token Overhead**\n",
    "- Tool tokens: 2,200 ‚Üí 880 (-60% with selection)\n",
    "- Total tokens: 2,800 ‚Üí 2,200 (-21%)\n",
    "- Maintained all 5 tools available, but only send top 3 per query\n",
    "\n",
    "**‚úÖ Better Scalability**\n",
    "- Can now scale to 10, 20, or 100+ tools\n",
    "- Token cost stays constant (always top-k tools)\n",
    "- Better tool selection than random or rule-based approaches\n",
    "\n",
    "### Cumulative Improvements\n",
    "\n",
    "```\n",
    "Metric          Section 4    After NB2    Improvement\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "Tools           3            5            +67%\n",
    "Tokens/query    8,500        2,200        -74%\n",
    "Cost/query      $0.12        $0.03        -75%\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "```\n",
    "\n",
    "### üí° Key Takeaway\n",
    "\n",
    "**\"Scale capabilities, not token costs - semantic selection enables both\"**\n",
    "\n",
    "The biggest wins come from:\n",
    "1. **Semantic understanding** - Match query intent to tool purpose\n",
    "2. **Dynamic selection** - Only send what's needed\n",
    "3. **Rich metadata** - Better embeddings = better selection\n",
    "4. **Constant overhead** - Top-k selection scales to any number of tools\n",
    "\n",
    "### üîÆ Preview: Notebook 3\n",
    "\n",
    "In the next notebook, we'll focus on **Production Readiness and Quality Assurance**\n",
    "\n",
    "**The Problem:**\n",
    "- Our agent is fast and efficient, but is it reliable?\n",
    "- What happens when context is irrelevant or low-quality?\n",
    "- How do we monitor performance in production?\n",
    "- How do we handle errors gracefully?\n",
    "\n",
    "**The Solution:**\n",
    "- Context validation (pre-flight checks)\n",
    "- Relevance scoring and pruning\n",
    "- Quality monitoring dashboard\n",
    "- Error handling and graceful degradation\n",
    "\n",
    "**Expected Results:**\n",
    "- 35% quality improvement (0.65 ‚Üí 0.88)\n",
    "- Production-ready monitoring\n",
    "- Robust error handling\n",
    "- Confidence scoring for responses\n",
    "\n",
    "See you in Notebook 3! üöÄ\n"
   ],
   "id": "53710932cb10b2b3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## üìö Additional Resources\n",
    "\n",
    "### Semantic Search and Embeddings\n",
    "- [OpenAI Embeddings Guide](https://platform.openai.com/docs/guides/embeddings)\n",
    "- [Vector Similarity Search](https://redis.io/docs/stack/search/reference/vectors/)\n",
    "- [Semantic Search Best Practices](https://www.pinecone.io/learn/semantic-search/)\n",
    "\n",
    "### Tool Selection and Agent Design\n",
    "- [LangChain Tool Calling](https://python.langchain.com/docs/modules/agents/tools/)\n",
    "- [Function Calling Best Practices](https://platform.openai.com/docs/guides/function-calling)\n",
    "- [Agent Design Patterns](https://www.anthropic.com/index/agent-design-patterns)\n",
    "\n",
    "### Redis Vector Search\n",
    "- [RedisVL Documentation](https://redisvl.com/)\n",
    "- [Redis Vector Similarity](https://redis.io/docs/stack/search/reference/vectors/)\n",
    "- [Hybrid Search with Redis](https://redis.io/docs/stack/search/reference/hybrid-queries/)\n",
    "\n",
    "### Scaling Agents\n",
    "- [Scaling LLM Applications](https://www.anthropic.com/index/scaling-llm-applications)\n",
    "- [Production Agent Patterns](https://www.langchain.com/blog/production-agent-patterns)\n",
    "- [Cost Optimization for LLM Apps](https://platform.openai.com/docs/guides/production-best-practices)\n",
    "\n",
    "---\n",
    "\n",
    "**üéâ Congratulations!** You've completed Notebook 2 and scaled your agent to 5 tools while reducing tokens by 21%!\n",
    "\n",
    "\n"
   ],
   "id": "67b3c397e1853fec"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
