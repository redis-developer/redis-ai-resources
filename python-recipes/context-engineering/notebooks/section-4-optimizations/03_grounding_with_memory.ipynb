{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Grounding with Memory: Using Context to Resolve References\n",
        "\n",
        "## Introduction\n",
        "\n",
        "In this notebook, you'll learn about grounding - how agents use memory to understand references and maintain context across a conversation. When users say \"that course\" or \"my advisor\", the agent needs to know what they're referring to. The Agent Memory Server's extracted memories provide this grounding automatically.\n",
        "\n",
        "### What You'll Learn\n",
        "\n",
        "- What grounding is and why it matters\n",
        "- How extracted memories provide grounding\n",
        "- How to handle references to people, places, and things\n",
        "- How memory enables natural conversation flow\n",
        "\n",
        "### Prerequisites\n",
        "\n",
        "- Completed Section 3 notebooks\n",
        "- Redis 8 running locally\n",
        "- Agent Memory Server running\n",
        "- OpenAI API key set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Concepts: Grounding\n",
        "\n",
        "### What is Grounding?\n",
        "\n",
        "**Grounding** is the process of connecting references in conversation to their actual meanings. When someone says:\n",
        "\n",
        "- \"Tell me more about **that course**\" - Which course?\n",
        "- \"When does **she** teach?\" - Who is \"she\"?\n",
        "- \"Is **it** available online?\" - What is \"it\"?\n",
        "- \"What about **the other one**?\" - Which one?\n",
        "\n",
        "The agent needs to **ground** these references to specific entities mentioned earlier in the conversation.\n",
        "\n",
        "### Grounding Without Memory (Bad)\n",
        "\n",
        "```\n",
        "User: I'm interested in machine learning.\n",
        "Agent: Great! We have CS401: Machine Learning.\n",
        "\n",
        "User: Tell me more about that course.\n",
        "Agent: Which course are you asking about? ‚ùå\n",
        "```\n",
        "\n",
        "### Grounding With Memory (Good)\n",
        "\n",
        "```\n",
        "User: I'm interested in machine learning.\n",
        "Agent: Great! We have CS401: Machine Learning.\n",
        "[Memory extracted: \"Student interested in CS401\"]\n",
        "\n",
        "User: Tell me more about that course.\n",
        "Agent: CS401 covers supervised learning, neural networks... ‚úÖ\n",
        "[Memory grounds \"that course\" to CS401]\n",
        "```\n",
        "\n",
        "### How Agent Memory Server Provides Grounding\n",
        "\n",
        "The Agent Memory Server automatically:\n",
        "1. **Extracts entities** from conversations (courses, people, places)\n",
        "2. **Stores them** in long-term memory with context\n",
        "3. **Retrieves them** when similar references appear\n",
        "4. **Provides context** to ground ambiguous references\n",
        "\n",
        "### Types of References\n",
        "\n",
        "**Pronouns:**\n",
        "- \"it\", \"that\", \"this\", \"those\"\n",
        "- \"he\", \"she\", \"they\"\n",
        "\n",
        "**Descriptions:**\n",
        "- \"the ML class\"\n",
        "- \"my advisor\"\n",
        "- \"the main campus\"\n",
        "\n",
        "**Implicit references:**\n",
        "- \"What are the prerequisites?\" (for what?)\n",
        "- \"When does it meet?\" (what meets?)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import asyncio\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
        "from agent_memory_client import MemoryAPIClient as MemoryClient, MemoryClientConfig\n",
        "\n",
        "# Initialize\n",
        "student_id = \"student_789\"\n",
        "session_id = \"grounding_demo\"\n",
        "\n",
        "# Initialize memory client with proper config\n",
        "import os\n",
        "config = MemoryClientConfig(\n",
        "    base_url=os.getenv(\"AGENT_MEMORY_URL\", \"http://localhost:8000\"),\n",
        "    default_namespace=\"redis_university\"\n",
        ")\n",
        "memory_client = MemoryClient(config=config)\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.7)\n",
        "\n",
        "print(f\"‚úÖ Setup complete for {student_id}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hands-on: Grounding Through Conversation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example 1: Grounding Course References\n",
        "\n",
        "Let's have a conversation where we refer to courses in different ways."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "async def chat_turn(user_message, conversation_history):\n",
        "    \"\"\"Helper function to process a conversation turn.\"\"\"\n",
        "    \n",
        "    # Search long-term memory for context\n",
        "    memories = await memory_client.search_long_term_memory(\n",
        "        text=user_message,\n",
        "        limit=5\n",
        "    )\n",
        "    \n",
        "    # Build context from memories\n",
        "    memory_context = \"\\n\".join([f\"- {m.text}\" for m in memories]) if memories else \"None\".memories\n",
        "    \n",
        "    system_prompt = f\"\"\"You are a helpful class scheduling agent for Redis University.\n",
        "\n",
        "What you remember about this student:\n",
        "{memory_context}\n",
        "\n",
        "Use this context to understand references like \"that course\", \"it\", \"the one I mentioned\", etc.\n",
        "\"\"\"\n",
        "    \n",
        "    # Build messages\n",
        "    messages = [SystemMessage(content=system_prompt)]\n",
        "    messages.extend(conversation_history)\n",
        "    messages.append(HumanMessage(content=user_message))\n",
        "    \n",
        "    # Get response\n",
        "    response = llm.invoke(messages)\n",
        "    \n",
        "    # Update conversation history\n",
        "    conversation_history.append(HumanMessage(content=user_message))\n",
        "    conversation_history.append(AIMessage(content=response.content))\n",
        "    \n",
        "    # Save to working memory (triggers extraction)\n",
        "    messages_to_save = [\n",
        "        {\"role\": \"user\" if isinstance(m, HumanMessage) else \"assistant\", \"content\": m.content}\n",
        "        for m in conversation_history\n",
        "    ]\n",
        "    from agent_memory_client.models import WorkingMemory, MemoryMessage\n",
        "    \n",
        "    # Convert messages to MemoryMessage format\n",
        "    memory_messages = [MemoryMessage(**msg) for msg in messages_to_save]\n",
        "    \n",
        "    # Create WorkingMemory object\n",
        "    working_memory = WorkingMemory(\n",
        "        session_id=session_id,\n",
        "        user_id=\"demo_user\",\n",
        "        messages=memory_messages,\n",
        "        memories=[],\n",
        "        data={}\n",
        "    )\n",
        "    \n",
        "    await memory_client.put_working_memory(\n",
        "        session_id=session_id,\n",
        "        memory=working_memory,\n",
        "        user_id=\"demo_user\",\n",
        "        model_name=\"gpt-4o\"\n",
        "    )\n",
        "    \n",
        "    return response.content, conversation_history\n",
        "\n",
        "print(\"‚úÖ Helper function defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Start conversation\n",
        "conversation = []\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"CONVERSATION: Grounding Course References\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Turn 1: Mention a specific course\n",
        "print(\"\\nüë§ User: I'm interested in CS401, the machine learning course.\")\n",
        "response, conversation = await chat_turn(\n",
        "    \"I'm interested in CS401, the machine learning course.\",\n",
        "    conversation\n",
        ")\n",
        "print(f\"ü§ñ Agent: {response}\")\n",
        "\n",
        "# Wait for extraction\n",
        "await asyncio.sleep(2)\n",
        "\n",
        "# Turn 2: Use pronoun \"it\"\n",
        "print(\"\\nüë§ User: What are the prerequisites for it?\")\n",
        "response, conversation = await chat_turn(\n",
        "    \"What are the prerequisites for it?\",\n",
        "    conversation\n",
        ")\n",
        "print(f\"ü§ñ Agent: {response}\")\n",
        "print(\"\\n‚úÖ Agent grounded 'it' to CS401\")\n",
        "\n",
        "# Turn 3: Use description \"that ML class\"\n",
        "print(\"\\nüë§ User: Is that ML class available online?\")\n",
        "response, conversation = await chat_turn(\n",
        "    \"Is that ML class available online?\",\n",
        "    conversation\n",
        ")\n",
        "print(f\"ü§ñ Agent: {response}\")\n",
        "print(\"\\n‚úÖ Agent grounded 'that ML class' to CS401\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example 2: Grounding People References\n",
        "\n",
        "Let's have a conversation about people (advisors, professors)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# New conversation\n",
        "conversation = []\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"CONVERSATION: Grounding People References\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Turn 1: Mention a person\n",
        "print(\"\\nüë§ User: My advisor is Professor Smith from the CS department.\")\n",
        "response, conversation = await chat_turn(\n",
        "    \"My advisor is Professor Smith from the CS department.\",\n",
        "    conversation\n",
        ")\n",
        "print(f\"ü§ñ Agent: {response}\")\n",
        "\n",
        "await asyncio.sleep(2)\n",
        "\n",
        "# Turn 2: Use pronoun \"she\"\n",
        "print(\"\\nüë§ User: What courses does she teach?\")\n",
        "response, conversation = await chat_turn(\n",
        "    \"What courses does she teach?\",\n",
        "    conversation\n",
        ")\n",
        "print(f\"ü§ñ Agent: {response}\")\n",
        "print(\"\\n‚úÖ Agent grounded 'she' to Professor Smith\")\n",
        "\n",
        "# Turn 3: Use description \"my advisor\"\n",
        "print(\"\\nüë§ User: Can my advisor help me with course selection?\")\n",
        "response, conversation = await chat_turn(\n",
        "    \"Can my advisor help me with course selection?\",\n",
        "    conversation\n",
        ")\n",
        "print(f\"ü§ñ Agent: {response}\")\n",
        "print(\"\\n‚úÖ Agent grounded 'my advisor' to Professor Smith\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example 3: Grounding Place References\n",
        "\n",
        "Let's talk about campus locations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# New conversation\n",
        "conversation = []\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"CONVERSATION: Grounding Place References\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Turn 1: Mention a place\n",
        "print(\"\\nüë§ User: I prefer taking classes at the downtown campus.\")\n",
        "response, conversation = await chat_turn(\n",
        "    \"I prefer taking classes at the downtown campus.\",\n",
        "    conversation\n",
        ")\n",
        "print(f\"ü§ñ Agent: {response}\")\n",
        "\n",
        "await asyncio.sleep(2)\n",
        "\n",
        "# Turn 2: Use pronoun \"there\"\n",
        "print(\"\\nüë§ User: What CS courses are offered there?\")\n",
        "response, conversation = await chat_turn(\n",
        "    \"What CS courses are offered there?\",\n",
        "    conversation\n",
        ")\n",
        "print(f\"ü§ñ Agent: {response}\")\n",
        "print(\"\\n‚úÖ Agent grounded 'there' to downtown campus\")\n",
        "\n",
        "# Turn 3: Use description \"that campus\"\n",
        "print(\"\\nüë§ User: How do I get to that campus?\")\n",
        "response, conversation = await chat_turn(\n",
        "    \"How do I get to that campus?\",\n",
        "    conversation\n",
        ")\n",
        "print(f\"ü§ñ Agent: {response}\")\n",
        "print(\"\\n‚úÖ Agent grounded 'that campus' to downtown campus\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example 4: Complex Multi-Reference Conversation\n",
        "\n",
        "Let's have a longer conversation with multiple entities to ground."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# New conversation\n",
        "conversation = []\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"CONVERSATION: Complex Multi-Reference\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Turn 1\n",
        "print(\"\\nüë§ User: I'm looking at CS401 and CS402. Which one should I take first?\")\n",
        "response, conversation = await chat_turn(\n",
        "    \"I'm looking at CS401 and CS402. Which one should I take first?\",\n",
        "    conversation\n",
        ")\n",
        "print(f\"ü§ñ Agent: {response}\")\n",
        "\n",
        "await asyncio.sleep(2)\n",
        "\n",
        "# Turn 2\n",
        "print(\"\\nüë§ User: What about the other one? When is it offered?\")\n",
        "response, conversation = await chat_turn(\n",
        "    \"What about the other one? When is it offered?\",\n",
        "    conversation\n",
        ")\n",
        "print(f\"ü§ñ Agent: {response}\")\n",
        "print(\"\\n‚úÖ Agent grounded 'the other one' to the second course mentioned\")\n",
        "\n",
        "# Turn 3\n",
        "print(\"\\nüë§ User: Can I take both in the same semester?\")\n",
        "response, conversation = await chat_turn(\n",
        "    \"Can I take both in the same semester?\",\n",
        "    conversation\n",
        ")\n",
        "print(f\"ü§ñ Agent: {response}\")\n",
        "print(\"\\n‚úÖ Agent grounded 'both' to CS401 and CS402\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Verify Extracted Memories\n",
        "\n",
        "Let's check what memories were extracted to enable grounding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"EXTRACTED MEMORIES (Enable Grounding)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Get all memories\n",
        "all_memories = await memory_client.search_long_term_memory(\n",
        "    text=\"\",\n",
        "    limit=20\n",
        ")\n",
        "\n",
        "print(\"\\nMemories that enable grounding:\\n\")\n",
        "for i, memory in enumerate(all_memories.memories, 1):\n",
        "    print(f\"{i}. {memory.text}\")\n",
        "    print(f\"   Type: {memory.memory_type} | Topics: {', '.join(memory.topics)}\")\n",
        "    print()\n",
        "\n",
        "print(\"‚úÖ These memories provide the context needed to ground references!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Takeaways\n",
        "\n",
        "### How Grounding Works\n",
        "\n",
        "1. **User mentions entity** (course, person, place)\n",
        "2. **Agent Memory Server extracts** entity to long-term memory\n",
        "3. **User makes reference** (\"it\", \"that\", \"she\", etc.)\n",
        "4. **Semantic search retrieves** relevant memories\n",
        "5. **Agent grounds reference** using memory context\n",
        "\n",
        "### Types of Grounding\n",
        "\n",
        "**Direct references:**\n",
        "- \"CS401\" ‚Üí Specific course\n",
        "- \"Professor Smith\" ‚Üí Specific person\n",
        "\n",
        "**Pronoun references:**\n",
        "- \"it\" ‚Üí Last mentioned thing\n",
        "- \"she\" ‚Üí Last mentioned person\n",
        "- \"there\" ‚Üí Last mentioned place\n",
        "\n",
        "**Description references:**\n",
        "- \"that ML class\" ‚Üí Course about ML\n",
        "- \"my advisor\" ‚Üí Student's advisor\n",
        "- \"the downtown campus\" ‚Üí Specific campus\n",
        "\n",
        "**Implicit references:**\n",
        "- \"What are the prerequisites?\" ‚Üí For the course we're discussing\n",
        "- \"When does it meet?\" ‚Üí The course mentioned\n",
        "\n",
        "### Why Memory-Based Grounding Works\n",
        "\n",
        "‚úÖ **Automatic** - No manual entity tracking needed\n",
        "‚úÖ **Semantic** - Understands similar references\n",
        "‚úÖ **Persistent** - Works across sessions\n",
        "‚úÖ **Contextual** - Uses conversation history\n",
        "‚úÖ **Natural** - Enables human-like conversation\n",
        "\n",
        "### Best Practices\n",
        "\n",
        "1. **Include memory context in system prompt** - Give LLM grounding information\n",
        "2. **Search with user's query** - Find relevant entities\n",
        "3. **Trust semantic search** - It finds related memories\n",
        "4. **Let extraction happen** - Don't manually track entities\n",
        "5. **Test with pronouns** - Verify grounding works"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercises\n",
        "\n",
        "1. **Test ambiguous references**: Have a conversation mentioning multiple courses, then use \"it\". Does the agent ground correctly?\n",
        "\n",
        "2. **Cross-session grounding**: Start a new session and refer to entities from a previous session. Does it work?\n",
        "\n",
        "3. **Complex conversation**: Have a 10-turn conversation with multiple entities. Track how grounding evolves.\n",
        "\n",
        "4. **Grounding failure**: Try to break grounding by using very ambiguous references. What happens?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "In this notebook, you learned:\n",
        "\n",
        "- ‚úÖ Grounding connects references to their actual meanings\n",
        "- ‚úÖ Agent Memory Server's extracted memories provide grounding automatically\n",
        "- ‚úÖ Semantic search retrieves relevant context for grounding\n",
        "- ‚úÖ Grounding enables natural, human-like conversations\n",
        "- ‚úÖ No manual entity tracking needed - memory handles it\n",
        "\n",
        "**Key insight:** Memory-based grounding is what makes agents feel intelligent and context-aware. Without it, every reference needs to be explicit, making conversations robotic and frustrating."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
