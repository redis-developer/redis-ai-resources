{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9ca47ea4d1348e8",
   "metadata": {},
   "source": [
    "![Redis](https://redis.io/wp-content/uploads/2024/04/Logotype.svg?auto=webp&quality=85,75&width=120)\n",
    "\n",
    "# üß† Section 3: Memory Architecture - From Stateless RAG to Stateful Conversations\n",
    "\n",
    "**‚è±Ô∏è Estimated Time:** 45-60 minutes\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "\n",
    "1. **Understand** why memory is essential for context engineering\n",
    "2. **Implement** working memory for conversation continuity\n",
    "3. **Use** long-term memory for persistent user knowledge\n",
    "4. **Integrate** memory with your Section 2 RAG system\n",
    "5. **Build** a complete memory-enhanced course advisor\n",
    "\n",
    "---\n",
    "\n",
    "## üîó Bridge from Sections 1 & 2\n",
    "\n",
    "### **Section 1: The Four Context Types**\n",
    "\n",
    "Recall the four context types from Section 1:\n",
    "\n",
    "1. **System Context** (Static) - Role, instructions, guidelines\n",
    "2. **User Context** (Dynamic, User-Specific) - Profile, preferences, goals\n",
    "3. **Conversation Context** (Dynamic, Session-Specific) - **‚Üê Memory enables this!**\n",
    "4. **Retrieved Context** (Dynamic, Query-Specific) - RAG results\n",
    "\n",
    "### **Section 2: Stateless RAG**\n",
    "\n",
    "Your Section 2 RAG system was **stateless**:\n",
    "\n",
    "```python\n",
    "def rag_query(query, student_profile):\n",
    "    # 1. Search courses (Retrieved Context)\n",
    "    courses = course_manager.search(query)\n",
    "\n",
    "    # 2. Assemble context (System + User + Retrieved)\n",
    "    context = assemble_context(system_prompt, student_profile, courses)\n",
    "\n",
    "    # 3. Generate response\n",
    "    response = llm.invoke(context)\n",
    "\n",
    "    # ‚ùå No conversation history stored\n",
    "    # ‚ùå Each query is independent\n",
    "    # ‚ùå Can't reference previous messages\n",
    "```\n",
    "\n",
    "**The Problem:** Every query starts from scratch. No conversation continuity.\n",
    "\n",
    "---\n",
    "\n",
    "## üö® The Grounding Problem\n",
    "\n",
    "**Grounding** means understanding what users are referring to. Natural conversation is full of references:\n",
    "\n",
    "### **Without Memory:**\n",
    "\n",
    "```\n",
    "User: \"Tell me about CS401\"\n",
    "Agent: \"CS401 is Machine Learning. It covers supervised learning...\"\n",
    "\n",
    "User: \"What are its prerequisites?\"\n",
    "Agent: ‚ùå \"What does 'its' refer to? Please specify which course.\"\n",
    "\n",
    "User: \"The course we just discussed!\"\n",
    "Agent: ‚ùå \"I don't have access to previous messages. Which course?\"\n",
    "```\n",
    "\n",
    "**This is a terrible user experience.**\n",
    "\n",
    "### **With Memory:**\n",
    "\n",
    "```\n",
    "User: \"Tell me about CS401\"\n",
    "Agent: \"CS401 is Machine Learning. It covers...\"\n",
    "[Stores: User asked about CS401]\n",
    "\n",
    "User: \"What are its prerequisites?\"\n",
    "Agent: [Checks memory: \"its\" = CS401]\n",
    "Agent: ‚úÖ \"CS401 requires CS201 and MATH301\"\n",
    "\n",
    "User: \"Can I take it?\"\n",
    "Agent: [Checks memory: \"it\" = CS401, checks student transcript]\n",
    "Agent: ‚úÖ \"You've completed CS201 but still need MATH301\"\n",
    "```\n",
    "\n",
    "**Now the conversation flows naturally!**\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Two Types of Memory\n",
    "\n",
    "### **1. Working Memory (Session-Scoped)**\n",
    "\n",
    "**What:** Conversation messages from the current session\n",
    "\n",
    "**Purpose:** Reference resolution, conversation continuity\n",
    "\n",
    "**Lifetime:** Session duration (e.g., 1 hour TTL)\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "Session: session_123\n",
    "Messages:\n",
    "  1. User: \"Tell me about CS401\"\n",
    "  2. Agent: \"CS401 is Machine Learning...\"\n",
    "  3. User: \"What are its prerequisites?\"\n",
    "  4. Agent: \"CS401 requires CS201 and MATH301\"\n",
    "```\n",
    "\n",
    "### **2. Long-term Memory (Cross-Session)**\n",
    "\n",
    "**What:** Persistent facts, preferences, goals\n",
    "\n",
    "**Purpose:** Personalization across sessions\n",
    "\n",
    "**Lifetime:** Permanent (until explicitly deleted)\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "User: student_sarah\n",
    "Memories:\n",
    "  - \"Prefers online courses over in-person\"\n",
    "  - \"Major: Computer Science, focus on AI/ML\"\n",
    "  - \"Goal: Graduate Spring 2026\"\n",
    "  - \"Completed: CS101, CS201, MATH301\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üèóÔ∏è Memory Architecture\n",
    "\n",
    "We'll use **Redis Agent Memory Server** - a production-ready dual-memory system:\n",
    "\n",
    "**Working Memory:**\n",
    "- Session-scoped conversation context\n",
    "- Automatic extraction to long-term storage\n",
    "- TTL-based expiration\n",
    "\n",
    "**Long-term Memory:**\n",
    "- Vector-indexed for semantic search\n",
    "- Automatic deduplication\n",
    "- Three types: semantic (facts), episodic (events), message\n",
    "\n",
    "**Why Agent Memory Server?**\n",
    "- Production-ready (handles thousands of users)\n",
    "- Redis-backed (fast, scalable)\n",
    "- Automatic memory management (extraction, deduplication)\n",
    "- Semantic search built-in\n",
    "\n",
    "---\n",
    "\n",
    "## üì¶ Setup\n",
    "\n",
    "### **What We're Importing:**\n",
    "\n",
    "- **Section 2 components** - `redis_config`, `CourseManager`, models\n",
    "- **Agent Memory Server client** - `MemoryAPIClient` for memory operations\n",
    "- **LangChain** - `ChatOpenAI` for LLM interaction\n",
    "\n",
    "### **Why:**\n",
    "\n",
    "- Build on Section 2's RAG foundation\n",
    "- Add memory capabilities without rewriting everything\n",
    "- Use production-ready memory infrastructure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd7842e97737332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Import components\n",
    "import os\n",
    "import sys\n",
    "import asyncio\n",
    "from typing import List, Dict, Any, Optional\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment\n",
    "load_dotenv()\n",
    "sys.path.append('../../reference-agent')\n",
    "\n",
    "# Import Section 2 components\n",
    "from redis_context_course.redis_config import redis_config\n",
    "from redis_context_course.course_manager import CourseManager\n",
    "from redis_context_course.models import (\n",
    "    Course, StudentProfile, DifficultyLevel,\n",
    "    CourseFormat, Semester\n",
    ")\n",
    "\n",
    "# Import LangChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "# Import Agent Memory Server client\n",
    "try:\n",
    "    from agent_memory_client import MemoryAPIClient, MemoryClientConfig\n",
    "    from agent_memory_client.models import WorkingMemory, MemoryMessage, ClientMemoryRecord\n",
    "    MEMORY_SERVER_AVAILABLE = True\n",
    "    print(\"‚úÖ Agent Memory Server client available\")\n",
    "except ImportError:\n",
    "    MEMORY_SERVER_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è  Agent Memory Server not available\")\n",
    "    print(\"üìù Install with: pip install agent-memory-client\")\n",
    "    print(\"üöÄ Start server: See reference-agent/README.md\")\n",
    "\n",
    "# Verify environment\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"‚ùå OPENAI_API_KEY not found. Please set in .env file.\")\n",
    "else:\n",
    "    print(\"‚úÖ OPENAI_API_KEY found\")\n",
    "\n",
    "print(f\"\\nüîß Environment Setup:\")\n",
    "print(f\"   OPENAI_API_KEY: {'‚úì Set' if os.getenv('OPENAI_API_KEY') else '‚úó Not set'}\")\n",
    "print(f\"   REDIS_URL: {os.getenv('REDIS_URL', 'redis://localhost:6379')}\")\n",
    "print(f\"   AGENT_MEMORY_URL: {os.getenv('AGENT_MEMORY_URL', 'http://localhost:8088')}\")\n",
    "print(f\"   Memory Server: {'‚úì Available' if MEMORY_SERVER_AVAILABLE else '‚úó Not available'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe496852db5b1091",
   "metadata": {},
   "source": [
    "### üéØ What We Just Did\n",
    "\n",
    "**Successfully Imported:**\n",
    "- ‚úÖ **Section 2 RAG components** - `redis_config`, `CourseManager`, models\n",
    "- ‚úÖ **Agent Memory Server client** - Production-ready memory system\n",
    "- ‚úÖ **Environment verified** - OpenAI API key, Redis, Memory Server\n",
    "\n",
    "**Why This Matters:**\n",
    "- We're **building on Section 2's foundation** (not starting from scratch)\n",
    "- **Agent Memory Server** provides scalable, persistent memory\n",
    "- **Same Redis University domain** for consistency\n",
    "\n",
    "---\n",
    "\n",
    "## üîß Initialize Components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f17188b6e0a9f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize components\n",
    "course_manager = CourseManager()\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.0)\n",
    "\n",
    "# Initialize Memory Client\n",
    "if MEMORY_SERVER_AVAILABLE:\n",
    "    config = MemoryClientConfig(\n",
    "        base_url=os.getenv(\"AGENT_MEMORY_URL\", \"http://localhost:8088\"),\n",
    "        default_namespace=\"redis_university\"\n",
    "    )\n",
    "    memory_client = MemoryAPIClient(config=config)\n",
    "    print(\"üß† Memory Client Initialized\")\n",
    "    print(f\"   Base URL: {config.base_url}\")\n",
    "    print(f\"   Namespace: {config.default_namespace}\")\n",
    "else:\n",
    "    memory_client = None\n",
    "    print(\"‚ö†Ô∏è  Running without Memory Server (limited functionality)\")\n",
    "\n",
    "# Create a sample student profile (reusing Section 2 pattern)\n",
    "sarah = StudentProfile(\n",
    "    name=\"Sarah Chen\",\n",
    "    email=\"sarah.chen@university.edu\",\n",
    "    major=\"Computer Science\",\n",
    "    year=2,\n",
    "    interests=[\"machine learning\", \"data science\", \"algorithms\"],\n",
    "    completed_courses=[\"CS101\", \"CS201\"],\n",
    "    current_courses=[\"MATH301\"],\n",
    "    preferred_format=CourseFormat.ONLINE,\n",
    "    preferred_difficulty=DifficultyLevel.INTERMEDIATE\n",
    ")\n",
    "\n",
    "print(f\"\\nüë§ Student Profile: {sarah.name}\")\n",
    "print(f\"   Major: {sarah.major}\")\n",
    "print(f\"   Interests: {', '.join(sarah.interests)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45061d8caccc5a1",
   "metadata": {},
   "source": [
    "### üí° Key Insight\n",
    "\n",
    "We're reusing:\n",
    "- ‚úÖ **Same `CourseManager`** from Section 2\n",
    "- ‚úÖ **Same `StudentProfile`** model\n",
    "- ‚úÖ **Same Redis configuration**\n",
    "\n",
    "We're adding:\n",
    "- ‚ú® **Memory Client** for conversation history\n",
    "- ‚ú® **Working Memory** for session context\n",
    "- ‚ú® **Long-term Memory** for persistent knowledge\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Part 1: Working Memory Fundamentals\n",
    "\n",
    "### **What is Working Memory?**\n",
    "\n",
    "Working memory stores **conversation messages** for the current session. It enables:\n",
    "\n",
    "‚úÖ **Reference resolution** - \"it\", \"that course\", \"the one you mentioned\"\n",
    "‚úÖ **Context continuity** - Each message builds on previous messages\n",
    "‚úÖ **Natural conversations** - Users don't repeat themselves\n",
    "\n",
    "### **How It Works:**\n",
    "\n",
    "```\n",
    "Turn 1: Load working memory (empty) ‚Üí Process query ‚Üí Save messages\n",
    "Turn 2: Load working memory (1 exchange) ‚Üí Process query ‚Üí Save messages\n",
    "Turn 3: Load working memory (2 exchanges) ‚Üí Process query ‚Üí Save messages\n",
    "```\n",
    "\n",
    "Each turn has access to all previous messages in the session.\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Part 2: Long-term Memory Fundamentals\n",
    "\n",
    "### **What is Long-term Memory?**\n",
    "\n",
    "Long-term memory stores **persistent facts, preferences, and goals** across sessions. It enables:\n",
    "\n",
    "‚úÖ **Personalization** - Remember user preferences across conversations\n",
    "‚úÖ **Knowledge accumulation** - Build understanding over time\n",
    "‚úÖ **Semantic search** - Find relevant memories using natural language\n",
    "\n",
    "### **Memory Types:**\n",
    "\n",
    "1. **Semantic** - Facts and knowledge (\"Prefers online courses\")\n",
    "2. **Episodic** - Events and experiences (\"Enrolled in CS101 on 2024-09-01\")\n",
    "3. **Message** - Important conversation excerpts\n",
    "\n",
    "### **How It Works:**\n",
    "\n",
    "```\n",
    "Session 1: User shares preferences ‚Üí Store in long-term memory\n",
    "Session 2: User asks for recommendations ‚Üí Search long-term memory ‚Üí Personalized response\n",
    "Session 3: User updates preferences ‚Üí Update long-term memory\n",
    "```\n",
    "\n",
    "Long-term memory persists across sessions and is searchable via semantic vector search.\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ Hands-On: Long-term Memory in Action\n",
    "\n",
    "Let's store and search long-term memories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b141f12e505897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Long-term Memory Demo\n",
    "async def longterm_memory_demo():\n",
    "    \"\"\"Demonstrate long-term memory for persistent knowledge\"\"\"\n",
    "\n",
    "    if not MEMORY_SERVER_AVAILABLE:\n",
    "        print(\"‚ö†Ô∏è  Memory Server not available. Skipping demo.\")\n",
    "        return\n",
    "\n",
    "    student_id = \"sarah_chen\"\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(\"üß™ LONG-TERM MEMORY DEMO: Persistent Knowledge\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Step 1: Store semantic memories (facts)\n",
    "    print(\"\\nüìç STEP 1: Storing Semantic Memories (Facts)\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    semantic_memories = [\n",
    "        \"Student prefers online courses over in-person classes\",\n",
    "        \"Student's major is Computer Science with focus on AI/ML\",\n",
    "        \"Student wants to graduate in Spring 2026\",\n",
    "        \"Student prefers morning classes, no classes on Fridays\",\n",
    "        \"Student has completed CS101 and CS201\",\n",
    "        \"Student is currently taking MATH301\"\n",
    "    ]\n",
    "\n",
    "    for memory_text in semantic_memories:\n",
    "        memory_record = ClientMemoryRecord(\n",
    "            text=memory_text,\n",
    "            user_id=student_id,\n",
    "            memory_type=\"semantic\",\n",
    "            topics=[\"preferences\", \"academic_info\"]\n",
    "        )\n",
    "        await memory_client.create_long_term_memory([memory_record])\n",
    "        print(f\"   ‚úÖ Stored: {memory_text}\")\n",
    "\n",
    "    # Step 2: Store episodic memories (events)\n",
    "    print(\"\\nüìç STEP 2: Storing Episodic Memories (Events)\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    episodic_memories = [\n",
    "        \"Student enrolled in CS101 on 2024-09-01\",\n",
    "        \"Student completed CS101 with grade A on 2024-12-15\",\n",
    "        \"Student asked about machine learning courses on 2024-09-20\"\n",
    "    ]\n",
    "\n",
    "    for memory_text in episodic_memories:\n",
    "        memory_record = ClientMemoryRecord(\n",
    "            text=memory_text,\n",
    "            user_id=student_id,\n",
    "            memory_type=\"episodic\",\n",
    "            topics=[\"enrollment\", \"courses\"]\n",
    "        )\n",
    "        await memory_client.create_long_term_memory([memory_record])\n",
    "        print(f\"   ‚úÖ Stored: {memory_text}\")\n",
    "\n",
    "    # Step 3: Search long-term memory with semantic queries\n",
    "    print(\"\\nüìç STEP 3: Searching Long-term Memory\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    search_queries = [\n",
    "        \"What does the student prefer?\",\n",
    "        \"What courses has the student completed?\",\n",
    "        \"What is the student's major?\"\n",
    "    ]\n",
    "\n",
    "    for query in search_queries:\n",
    "        print(f\"\\n   üîç Query: '{query}'\")\n",
    "        results = await memory_client.search_long_term_memory(\n",
    "            text=query,\n",
    "            user_id=student_id,\n",
    "            limit=3\n",
    "        )\n",
    "\n",
    "        if results.memories:\n",
    "            print(f\"   üìö Found {len(results.memories)} relevant memories:\")\n",
    "            for i, memory in enumerate(results.memories[:3], 1):\n",
    "                print(f\"      {i}. {memory.text}\")\n",
    "        else:\n",
    "            print(\"   ‚ö†Ô∏è  No memories found\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"‚úÖ DEMO COMPLETE: Long-term memory enables persistent knowledge!\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "# Run the demo\n",
    "await longterm_memory_demo()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa657511cfb98e51",
   "metadata": {},
   "source": [
    "### üéØ What Just Happened?\n",
    "\n",
    "**Step 1: Stored Semantic Memories**\n",
    "- Facts about preferences (\"prefers online courses\")\n",
    "- Academic information (\"major is Computer Science\")\n",
    "- Goals (\"graduate Spring 2026\")\n",
    "\n",
    "**Step 2: Stored Episodic Memories**\n",
    "- Events (\"enrolled in CS101 on 2024-09-01\")\n",
    "- Experiences (\"completed CS101 with grade A\")\n",
    "\n",
    "**Step 3: Searched with Natural Language**\n",
    "- Query: \"What does the student prefer?\"\n",
    "- Results: Memories about preferences (online courses, morning classes)\n",
    "- **Semantic search** finds relevant memories even without exact keyword matches\n",
    "\n",
    "**üí° Key Insight:** Long-term memory enables **personalization** and **knowledge accumulation** across sessions.\n",
    "\n",
    "---\n",
    "\n",
    "## üîó Part 3: Integrating Memory with RAG\n",
    "\n",
    "Now let's combine **working memory** + **long-term memory** + **RAG** from Section 2.\n",
    "\n",
    "### **The Complete Picture:**\n",
    "\n",
    "```\n",
    "User Query\n",
    "    ‚Üì\n",
    "1. Load Working Memory (conversation history)\n",
    "2. Search Long-term Memory (user preferences, facts)\n",
    "3. RAG Search (relevant courses)\n",
    "4. Assemble Context (System + User + Conversation + Retrieved)\n",
    "5. Generate Response\n",
    "6. Save Working Memory (updated conversation)\n",
    "```\n",
    "\n",
    "This gives us **all four context types** from Section 1:\n",
    "- ‚úÖ System Context (static instructions)\n",
    "- ‚úÖ User Context (profile + long-term memories)\n",
    "- ‚úÖ Conversation Context (working memory)\n",
    "- ‚úÖ Retrieved Context (RAG results)\n",
    "\n",
    "---\n",
    "\n",
    "## üèóÔ∏è Building the Memory-Enhanced RAG System\n",
    "\n",
    "Let's build a complete function that integrates everything.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5dbf4ea20793e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory-Enhanced RAG Function\n",
    "async def memory_enhanced_rag_query(\n",
    "    user_query: str,\n",
    "    student_profile: StudentProfile,\n",
    "    session_id: str,\n",
    "    top_k: int = 3\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Complete memory-enhanced RAG query.\n",
    "\n",
    "    Combines:\n",
    "    - Working memory (conversation history)\n",
    "    - Long-term memory (user preferences, facts)\n",
    "    - RAG (semantic search for courses)\n",
    "\n",
    "    Args:\n",
    "        user_query: User's question\n",
    "        student_profile: Student profile (User Context)\n",
    "        session_id: Session ID for working memory\n",
    "        top_k: Number of courses to retrieve\n",
    "\n",
    "    Returns:\n",
    "        Agent's response\n",
    "    \"\"\"\n",
    "\n",
    "    if not MEMORY_SERVER_AVAILABLE:\n",
    "        print(\"‚ö†Ô∏è  Memory Server not available. Using simplified RAG.\")\n",
    "        # Fallback to Section 2 RAG\n",
    "        courses = course_manager.search(user_query, limit=top_k)\n",
    "        context = f\"Student: {student_profile.name}\\nQuery: {user_query}\\nCourses: {[c.course_code for c in courses]}\"\n",
    "        messages = [\n",
    "            SystemMessage(content=\"You are a helpful course advisor.\"),\n",
    "            HumanMessage(content=context)\n",
    "        ]\n",
    "        return llm.invoke(messages).content\n",
    "\n",
    "    student_id = student_profile.email.split('@')[0]\n",
    "\n",
    "    # Step 1: Load working memory (conversation history)\n",
    "    _, working_memory = await memory_client.get_or_create_working_memory(\n",
    "        session_id=session_id,\n",
    "        user_id=student_id,\n",
    "        model_name=\"gpt-4o\"\n",
    "    )\n",
    "\n",
    "    # Step 2: Search long-term memory (user preferences, facts)\n",
    "    longterm_results = await memory_client.search_long_term_memory(\n",
    "        text=user_query,\n",
    "        user_id=student_id,\n",
    "        limit=5\n",
    "    )\n",
    "\n",
    "    longterm_memories = [m.text for m in longterm_results.memories] if longterm_results.memories else []\n",
    "\n",
    "    # Step 3: RAG search (relevant courses)\n",
    "    courses = course_manager.search(user_query, limit=top_k)\n",
    "\n",
    "    # Step 4: Assemble context (all four context types!)\n",
    "\n",
    "    # System Context\n",
    "    system_prompt = \"\"\"You are a Redis University course advisor.\n",
    "\n",
    "Your role:\n",
    "- Help students find and enroll in courses\n",
    "- Provide personalized recommendations\n",
    "- Answer questions about courses, prerequisites, schedules\n",
    "\n",
    "Guidelines:\n",
    "- Use conversation history to resolve references (\"it\", \"that course\")\n",
    "- Use long-term memories to personalize recommendations\n",
    "- Be helpful, supportive, and encouraging\n",
    "- If you don't know something, say so\"\"\"\n",
    "\n",
    "    # User Context (profile + long-term memories)\n",
    "    user_context = f\"\"\"Student Profile:\n",
    "- Name: {student_profile.name}\n",
    "- Major: {student_profile.major}\n",
    "- Year: {student_profile.year}\n",
    "- Interests: {', '.join(student_profile.interests)}\n",
    "- Completed: {', '.join(student_profile.completed_courses)}\n",
    "- Current: {', '.join(student_profile.current_courses)}\n",
    "- Preferred Format: {student_profile.preferred_format.value}\n",
    "- Preferred Difficulty: {student_profile.preferred_difficulty.value}\"\"\"\n",
    "\n",
    "    if longterm_memories:\n",
    "        user_context += f\"\\n\\nLong-term Memories:\\n\" + \"\\n\".join([f\"- {m}\" for m in longterm_memories])\n",
    "\n",
    "    # Retrieved Context (RAG results)\n",
    "    retrieved_context = \"Relevant Courses:\\n\"\n",
    "    for i, course in enumerate(courses, 1):\n",
    "        retrieved_context += f\"\\n{i}. {course.course_code}: {course.title}\"\n",
    "        retrieved_context += f\"\\n   Description: {course.description}\"\n",
    "        retrieved_context += f\"\\n   Difficulty: {course.difficulty_level.value}\"\n",
    "        retrieved_context += f\"\\n   Format: {course.format.value}\"\n",
    "        retrieved_context += f\"\\n   Credits: {course.credits}\"\n",
    "        if course.prerequisites:\n",
    "            prereqs = [p.course_code for p in course.prerequisites]\n",
    "            retrieved_context += f\"\\n   Prerequisites: {', '.join(prereqs)}\"\n",
    "        retrieved_context += \"\\n\"\n",
    "\n",
    "    # Build messages with all context types\n",
    "    messages = [\n",
    "        SystemMessage(content=system_prompt)\n",
    "    ]\n",
    "\n",
    "    # Add conversation history (Conversation Context)\n",
    "    for msg in working_memory.messages:\n",
    "        if msg.role == \"user\":\n",
    "            messages.append(HumanMessage(content=msg.content))\n",
    "        elif msg.role == \"assistant\":\n",
    "            messages.append(AIMessage(content=msg.content))\n",
    "\n",
    "    # Add current query with assembled context\n",
    "    current_message = f\"\"\"{user_context}\n",
    "\n",
    "{retrieved_context}\n",
    "\n",
    "User Query: {user_query}\"\"\"\n",
    "\n",
    "    messages.append(HumanMessage(content=current_message))\n",
    "\n",
    "    # Step 5: Generate response\n",
    "    response = llm.invoke(messages).content\n",
    "\n",
    "    # Step 6: Save working memory (updated conversation)\n",
    "    working_memory.messages.extend([\n",
    "        MemoryMessage(role=\"user\", content=user_query),\n",
    "        MemoryMessage(role=\"assistant\", content=response)\n",
    "    ])\n",
    "\n",
    "    await memory_client.put_working_memory(\n",
    "        session_id=session_id,\n",
    "        memory=working_memory,\n",
    "        user_id=student_id,\n",
    "        model_name=\"gpt-4o\"\n",
    "    )\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb0ad6489de1a45",
   "metadata": {},
   "source": [
    "### üéØ What This Function Does\n",
    "\n",
    "**Integrates All Four Context Types:**\n",
    "\n",
    "1. **System Context** - Role, instructions, guidelines (static)\n",
    "2. **User Context** - Profile + long-term memories (dynamic, user-specific)\n",
    "3. **Conversation Context** - Working memory messages (dynamic, session-specific)\n",
    "4. **Retrieved Context** - RAG search results (dynamic, query-specific)\n",
    "\n",
    "**Memory Operations:**\n",
    "\n",
    "1. **Load** working memory (conversation history)\n",
    "2. **Search** long-term memory (relevant facts)\n",
    "3. **Search** courses (RAG)\n",
    "4. **Assemble** all context types\n",
    "5. **Generate** response\n",
    "6. **Save** working memory (updated conversation)\n",
    "\n",
    "**Why This Matters:**\n",
    "\n",
    "- ‚úÖ **Stateful conversations** - Remembers previous messages\n",
    "- ‚úÖ **Personalized responses** - Uses long-term memories\n",
    "- ‚úÖ **Reference resolution** - Resolves \"it\", \"that course\", etc.\n",
    "- ‚úÖ **Complete context** - All four context types working together\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ Hands-On: Complete Memory-Enhanced RAG\n",
    "\n",
    "Let's test the complete system with a multi-turn conversation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53699887297ed594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete Memory-Enhanced RAG Demo\n",
    "async def complete_demo():\n",
    "    \"\"\"Demonstrate complete memory-enhanced RAG system\"\"\"\n",
    "\n",
    "    session_id = f\"session_{sarah.email.split('@')[0]}_complete\"\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(\"üß™ COMPLETE DEMO: Memory-Enhanced RAG System\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nüë§ Student: {sarah.name}\")\n",
    "    print(f\"üìß Session: {session_id}\")\n",
    "\n",
    "    # Turn 1: Initial query\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üìç TURN 1: Initial Query\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    query_1 = \"I'm interested in machine learning courses\"\n",
    "    print(f\"\\nüë§ User: {query_1}\")\n",
    "\n",
    "    response_1 = await memory_enhanced_rag_query(\n",
    "        user_query=query_1,\n",
    "        student_profile=sarah,\n",
    "        session_id=session_id,\n",
    "        top_k=3\n",
    "    )\n",
    "\n",
    "    print(f\"\\nü§ñ Agent: {response_1}\")\n",
    "\n",
    "    # Turn 2: Follow-up with pronoun reference\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üìç TURN 2: Follow-up with Pronoun Reference\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    query_2 = \"What are the prerequisites for the first one?\"\n",
    "    print(f\"\\nüë§ User: {query_2}\")\n",
    "\n",
    "    response_2 = await memory_enhanced_rag_query(\n",
    "        user_query=query_2,\n",
    "        student_profile=sarah,\n",
    "        session_id=session_id,\n",
    "        top_k=3\n",
    "    )\n",
    "\n",
    "    print(f\"\\nü§ñ Agent: {response_2}\")\n",
    "\n",
    "    # Turn 3: Another follow-up\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üìç TURN 3: Another Follow-up\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    query_3 = \"Do I meet those prerequisites?\"\n",
    "    print(f\"\\nüë§ User: {query_3}\")\n",
    "\n",
    "    response_3 = await memory_enhanced_rag_query(\n",
    "        user_query=query_3,\n",
    "        student_profile=sarah,\n",
    "        session_id=session_id,\n",
    "        top_k=3\n",
    "    )\n",
    "\n",
    "    print(f\"\\nü§ñ Agent: {response_3}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"‚úÖ DEMO COMPLETE: Memory-enhanced RAG enables natural conversations!\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "# Run the complete demo\n",
    "await complete_demo()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7631809870ed08c0",
   "metadata": {},
   "source": [
    "### üéØ What Just Happened?\n",
    "\n",
    "**Turn 1:** \"I'm interested in machine learning courses\"\n",
    "- System searches courses\n",
    "- Finds ML-related courses\n",
    "- Responds with recommendations\n",
    "- **Saves conversation to working memory**\n",
    "\n",
    "**Turn 2:** \"What are the prerequisites for **the first one**?\"\n",
    "- System loads working memory (Turn 1)\n",
    "- Resolves \"the first one\" ‚Üí first course mentioned in Turn 1\n",
    "- Responds with prerequisites\n",
    "- **Saves updated conversation**\n",
    "\n",
    "**Turn 3:** \"Do I meet **those prerequisites**?\"\n",
    "- System loads working memory (Turns 1-2)\n",
    "- Resolves \"those prerequisites\" ‚Üí prerequisites from Turn 2\n",
    "- Checks student's completed courses (from profile)\n",
    "- Responds with personalized answer\n",
    "- **Saves updated conversation**\n",
    "\n",
    "**üí° Key Insight:** Memory + RAG = **Natural, stateful, personalized conversations**\n",
    "\n",
    "---\n",
    "\n",
    "## üéì Key Takeaways\n",
    "\n",
    "### **1. Memory Solves the Grounding Problem**\n",
    "\n",
    "Without memory, agents can't resolve references:\n",
    "- ‚ùå \"What are **its** prerequisites?\" ‚Üí Agent doesn't know what \"its\" refers to\n",
    "- ‚úÖ With working memory ‚Üí Agent resolves \"its\" from conversation history\n",
    "\n",
    "### **2. Two Types of Memory Serve Different Purposes**\n",
    "\n",
    "**Working Memory (Session-Scoped):**\n",
    "- Conversation messages from current session\n",
    "- Enables reference resolution and conversation continuity\n",
    "- TTL-based (expires after session ends)\n",
    "\n",
    "**Long-term Memory (Cross-Session):**\n",
    "- Persistent facts, preferences, goals\n",
    "- Enables personalization across sessions\n",
    "- Searchable via semantic vector search\n",
    "\n",
    "### **3. Memory Completes the Four Context Types**\n",
    "\n",
    "From Section 1, we learned about four context types. Memory enables two of them:\n",
    "\n",
    "1. **System Context** (Static) - ‚úÖ Section 2\n",
    "2. **User Context** (Dynamic, User-Specific) - ‚úÖ Section 2 + Long-term Memory\n",
    "3. **Conversation Context** (Dynamic, Session-Specific) - ‚ú® **Working Memory**\n",
    "4. **Retrieved Context** (Dynamic, Query-Specific) - ‚úÖ Section 2 RAG\n",
    "\n",
    "### **4. Memory + RAG = Complete Context Engineering**\n",
    "\n",
    "The integration pattern:\n",
    "```\n",
    "1. Load working memory (conversation history)\n",
    "2. Search long-term memory (user facts)\n",
    "3. RAG search (relevant documents)\n",
    "4. Assemble all context types\n",
    "5. Generate response\n",
    "6. Save working memory (updated conversation)\n",
    "```\n",
    "\n",
    "This gives us **stateful, personalized, context-aware conversations**.\n",
    "\n",
    "### **5. Agent Memory Server is Production-Ready**\n",
    "\n",
    "Why use Agent Memory Server instead of simple in-memory storage:\n",
    "- ‚úÖ **Scalable** - Redis-backed, handles thousands of users\n",
    "- ‚úÖ **Automatic** - Extracts important facts to long-term storage\n",
    "- ‚úÖ **Semantic search** - Vector-indexed memory retrieval\n",
    "- ‚úÖ **Deduplication** - Prevents redundant memories\n",
    "- ‚úÖ **TTL management** - Automatic expiration of old sessions\n",
    "\n",
    "### **6. LangChain is Sufficient for Memory + RAG**\n",
    "\n",
    "We didn't need LangGraph for this section because:\n",
    "- Simple linear flow (load ‚Üí search ‚Üí generate ‚Üí save)\n",
    "- No conditional branching or complex state management\n",
    "- No tool calling required\n",
    "\n",
    "**LangGraph becomes necessary in Section 4** when we add tools and multi-step workflows.\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ What's Next?\n",
    "\n",
    "### üõ†Ô∏è Section 4: Tool Selection & Agentic Workflows\n",
    "\n",
    "Now that you have **memory-enhanced RAG**, you'll add **tools** to create a complete agent:\n",
    "\n",
    "**Tools You'll Add:**\n",
    "- `search_courses` - Semantic search (you already have this!)\n",
    "- `get_course_details` - Fetch specific course information\n",
    "- `check_prerequisites` - Verify student eligibility\n",
    "- `enroll_course` - Register student for a course\n",
    "- `store_memory` - Explicitly save important facts\n",
    "- `search_memories` - Query long-term memory\n",
    "\n",
    "**Why LangGraph in Section 4:**\n",
    "- **Tool calling** - Agent decides which tools to use\n",
    "- **Conditional branching** - Different paths based on tool results\n",
    "- **State management** - Track tool execution across steps\n",
    "- **Error handling** - Retry failed tool calls\n",
    "\n",
    "**The Complete Picture:**\n",
    "\n",
    "```\n",
    "Section 1: Context Engineering Fundamentals\n",
    "    ‚Üì\n",
    "Section 2: RAG (Retrieved Context)\n",
    "    ‚Üì\n",
    "Section 3: Memory (Conversation Context + Long-term Knowledge)\n",
    "    ‚Üì\n",
    "Section 4: Tools + Agents (Complete Agentic System)\n",
    "```\n",
    "\n",
    "By Section 4, you'll have a **complete course advisor agent** that:\n",
    "- ‚úÖ Remembers conversations (working memory)\n",
    "- ‚úÖ Knows user preferences (long-term memory)\n",
    "- ‚úÖ Searches courses (RAG)\n",
    "- ‚úÖ Takes actions (tools)\n",
    "- ‚úÖ Makes decisions (agentic workflow)\n",
    "\n",
    "---\n",
    "\n",
    "## üí™ Practice Exercises\n",
    "\n",
    "### **Exercise 1: Cross-Session Personalization**\n",
    "\n",
    "Modify the `memory_enhanced_rag_query` function to:\n",
    "1. Store user preferences in long-term memory when mentioned\n",
    "2. Use those preferences in future sessions\n",
    "3. Test with two different sessions for the same student\n",
    "\n",
    "**Hint:** Look for phrases like \"I prefer...\", \"I like...\", \"I want...\" and store them as semantic memories.\n",
    "\n",
    "### **Exercise 2: Memory-Aware Filtering**\n",
    "\n",
    "Enhance the RAG search to use long-term memories as filters:\n",
    "1. Search long-term memory for preferences (format, difficulty, schedule)\n",
    "2. Apply those preferences as filters to `course_manager.search()`\n",
    "3. Compare results with and without memory-aware filtering\n",
    "\n",
    "**Hint:** Use the `filters` parameter in `course_manager.search()`.\n",
    "\n",
    "### **Exercise 3: Conversation Summarization**\n",
    "\n",
    "Implement a function that summarizes long conversations:\n",
    "1. When working memory exceeds 10 messages, summarize the conversation\n",
    "2. Store the summary in long-term memory\n",
    "3. Clear old messages from working memory (keep only recent 4)\n",
    "4. Test that reference resolution still works with summarized history\n",
    "\n",
    "**Hint:** Use the LLM to generate summaries, then store as semantic memories.\n",
    "\n",
    "### **Exercise 4: Multi-User Memory Management**\n",
    "\n",
    "Create a simple CLI that:\n",
    "1. Supports multiple students (different user IDs)\n",
    "2. Maintains separate working memory per session\n",
    "3. Maintains separate long-term memory per user\n",
    "4. Demonstrates cross-session continuity for each user\n",
    "\n",
    "**Hint:** Use different `session_id` and `user_id` for each student.\n",
    "\n",
    "### **Exercise 5: Memory Search Quality**\n",
    "\n",
    "Experiment with long-term memory search:\n",
    "1. Store 20+ diverse memories for a student\n",
    "2. Try different search queries\n",
    "3. Analyze which memories are retrieved\n",
    "4. Adjust memory text to improve search relevance\n",
    "\n",
    "**Hint:** More specific memory text leads to better semantic search results.\n",
    "\n",
    "---\n",
    "\n",
    "## üìù Summary\n",
    "\n",
    "### **What You Learned:**\n",
    "\n",
    "1. **The Grounding Problem** - Why agents need memory to resolve references\n",
    "2. **Working Memory** - Session-scoped conversation history for continuity\n",
    "3. **Long-term Memory** - Cross-session persistent knowledge for personalization\n",
    "4. **Memory Integration** - Combining memory with Section 2's RAG system\n",
    "5. **Complete Context Engineering** - All four context types working together\n",
    "6. **Production Architecture** - Using Agent Memory Server for scalable memory\n",
    "\n",
    "### **What You Built:**\n",
    "\n",
    "- ‚úÖ Working memory demo (multi-turn conversations)\n",
    "- ‚úÖ Long-term memory demo (persistent knowledge)\n",
    "- ‚úÖ Complete memory-enhanced RAG system\n",
    "- ‚úÖ Integration of all four context types\n",
    "\n",
    "### **Key Functions:**\n",
    "\n",
    "- `memory_enhanced_rag_query()` - Complete memory + RAG pipeline\n",
    "- `working_memory_demo()` - Demonstrates conversation continuity\n",
    "- `longterm_memory_demo()` - Demonstrates persistent knowledge\n",
    "- `complete_demo()` - End-to-end multi-turn conversation\n",
    "\n",
    "### **Architecture Pattern:**\n",
    "\n",
    "```\n",
    "User Query\n",
    "    ‚Üì\n",
    "Load Working Memory (conversation history)\n",
    "    ‚Üì\n",
    "Search Long-term Memory (user facts)\n",
    "    ‚Üì\n",
    "RAG Search (relevant courses)\n",
    "    ‚Üì\n",
    "Assemble Context (System + User + Conversation + Retrieved)\n",
    "    ‚Üì\n",
    "Generate Response\n",
    "    ‚Üì\n",
    "Save Working Memory (updated conversation)\n",
    "```\n",
    "\n",
    "### **From Section 2 to Section 3:**\n",
    "\n",
    "**Section 2 (Stateless RAG):**\n",
    "- ‚ùå No conversation history\n",
    "- ‚ùå Each query independent\n",
    "- ‚ùå Can't resolve references\n",
    "- ‚úÖ Retrieves relevant documents\n",
    "\n",
    "**Section 3 (Memory-Enhanced RAG):**\n",
    "- ‚úÖ Conversation history (working memory)\n",
    "- ‚úÖ Multi-turn conversations\n",
    "- ‚úÖ Reference resolution\n",
    "- ‚úÖ Persistent user knowledge (long-term memory)\n",
    "- ‚úÖ Personalization across sessions\n",
    "\n",
    "### **Next Steps:**\n",
    "\n",
    "**Section 4** will add **tools** and **agentic workflows** using **LangGraph**, completing your journey from context engineering fundamentals to production-ready AI agents.\n",
    "\n",
    "---\n",
    "\n",
    "## üéâ Congratulations!\n",
    "\n",
    "You've successfully built a **memory-enhanced RAG system** that:\n",
    "- Remembers conversations (working memory)\n",
    "- Accumulates knowledge (long-term memory)\n",
    "- Resolves references naturally\n",
    "- Personalizes responses\n",
    "- Integrates all four context types\n",
    "\n",
    "**You're now ready for Section 4: Tools & Agentic Workflows!** üöÄ\n",
    "\n",
    "## üß™ Hands-On: Working Memory in Action\n",
    "\n",
    "Let's simulate a multi-turn conversation with working memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599edeb033acd8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working Memory Demo\n",
    "async def working_memory_demo():\n",
    "    \"\"\"Demonstrate working memory for conversation continuity\"\"\"\n",
    "\n",
    "    if not MEMORY_SERVER_AVAILABLE:\n",
    "        print(\"‚ö†Ô∏è  Memory Server not available. Skipping demo.\")\n",
    "        return\n",
    "\n",
    "    student_id = \"sarah_chen\"\n",
    "    session_id = f\"session_{student_id}_demo\"\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(\"üß™ WORKING MEMORY DEMO: Multi-Turn Conversation\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Turn 1: First query\n",
    "    print(\"\\nüìç TURN 1: User asks about a course\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    user_query_1 = \"Tell me about CS401\"\n",
    "\n",
    "    # Load working memory (empty for first turn)\n",
    "    _, working_memory = await memory_client.get_or_create_working_memory(\n",
    "        session_id=session_id,\n",
    "        user_id=student_id,\n",
    "        model_name=\"gpt-4o\"\n",
    "    )\n",
    "\n",
    "    print(f\"   Messages in working memory: {len(working_memory.messages)}\")\n",
    "    print(f\"   User: {user_query_1}\")\n",
    "\n",
    "    # Search for course\n",
    "    courses = course_manager.search(user_query_1, limit=1)\n",
    "\n",
    "    # Generate response (simplified - no full RAG for demo)\n",
    "    if courses:\n",
    "        course = courses[0]\n",
    "        response_1 = f\"{course.course_code}: {course.title}. {course.description[:100]}...\"\n",
    "    else:\n",
    "        response_1 = \"I couldn't find that course.\"\n",
    "\n",
    "    print(f\"   Agent: {response_1}\")\n",
    "\n",
    "    # Save to working memory\n",
    "    working_memory.messages.extend([\n",
    "        MemoryMessage(role=\"user\", content=user_query_1),\n",
    "        MemoryMessage(role=\"assistant\", content=response_1)\n",
    "    ])\n",
    "\n",
    "    await memory_client.put_working_memory(\n",
    "        session_id=session_id,\n",
    "        memory=working_memory,\n",
    "        user_id=student_id,\n",
    "        model_name=\"gpt-4o\"\n",
    "    )\n",
    "\n",
    "    print(f\"   ‚úÖ Saved to working memory\")\n",
    "\n",
    "    # Turn 2: Follow-up with pronoun reference\n",
    "    print(\"\\nüìç TURN 2: User uses pronoun reference ('its')\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    user_query_2 = \"What are its prerequisites?\"\n",
    "\n",
    "    # Load working memory (now has 1 exchange)\n",
    "    _, working_memory = await memory_client.get_or_create_working_memory(\n",
    "        session_id=session_id,\n",
    "        user_id=student_id,\n",
    "        model_name=\"gpt-4o\"\n",
    "    )\n",
    "\n",
    "    print(f\"   Messages in working memory: {len(working_memory.messages)}\")\n",
    "    print(f\"   User: {user_query_2}\")\n",
    "\n",
    "    # Build context with conversation history\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are a helpful course advisor. Use conversation history to resolve references like 'it', 'that course', etc.\")\n",
    "    ]\n",
    "\n",
    "    # Add conversation history from working memory\n",
    "    for msg in working_memory.messages:\n",
    "        if msg.role == \"user\":\n",
    "            messages.append(HumanMessage(content=msg.content))\n",
    "        elif msg.role == \"assistant\":\n",
    "            messages.append(AIMessage(content=msg.content))\n",
    "\n",
    "    # Add current query\n",
    "    messages.append(HumanMessage(content=user_query_2))\n",
    "\n",
    "    # Generate response (LLM can now resolve \"its\" using conversation history)\n",
    "    response_2 = llm.invoke(messages).content\n",
    "\n",
    "    print(f\"   Agent: {response_2}\")\n",
    "\n",
    "    # Save to working memory\n",
    "    working_memory.messages.extend([\n",
    "        MemoryMessage(role=\"user\", content=user_query_2),\n",
    "        MemoryMessage(role=\"assistant\", content=response_2)\n",
    "    ])\n",
    "\n",
    "    await memory_client.put_working_memory(\n",
    "        session_id=session_id,\n",
    "        memory=working_memory,\n",
    "        user_id=student_id,\n",
    "        model_name=\"gpt-4o\"\n",
    "    )\n",
    "\n",
    "    print(f\"   ‚úÖ Saved to working memory\")\n",
    "\n",
    "    # Turn 3: Another follow-up\n",
    "    print(\"\\nüìç TURN 3: User asks another follow-up\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    user_query_3 = \"Can I take it next semester?\"\n",
    "\n",
    "    # Load working memory (now has 2 exchanges)\n",
    "    _, working_memory = await memory_client.get_or_create_working_memory(\n",
    "        session_id=session_id,\n",
    "        user_id=student_id,\n",
    "        model_name=\"gpt-4o\"\n",
    "    )\n",
    "\n",
    "    print(f\"   Messages in working memory: {len(working_memory.messages)}\")\n",
    "    print(f\"   User: {user_query_3}\")\n",
    "\n",
    "    # Build context with full conversation history\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are a helpful course advisor. Use conversation history to resolve references.\")\n",
    "    ]\n",
    "\n",
    "    for msg in working_memory.messages:\n",
    "        if msg.role == \"user\":\n",
    "            messages.append(HumanMessage(content=msg.content))\n",
    "        elif msg.role == \"assistant\":\n",
    "            messages.append(AIMessage(content=msg.content))\n",
    "\n",
    "    messages.append(HumanMessage(content=user_query_3))\n",
    "\n",
    "    response_3 = llm.invoke(messages).content\n",
    "\n",
    "    print(f\"   Agent: {response_3}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"‚úÖ DEMO COMPLETE: Working memory enabled natural conversation flow!\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "# Run the demo\n",
    "await working_memory_demo()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17207cb65c8d39a3",
   "metadata": {},
   "source": [
    "### üéØ What Just Happened?\n",
    "\n",
    "**Turn 1:** User asks about CS401\n",
    "- Working memory: **empty**\n",
    "- Agent responds with course info\n",
    "- Saves: User query + Agent response\n",
    "\n",
    "**Turn 2:** User asks \"What are **its** prerequisites?\"\n",
    "- Working memory: **1 exchange** (Turn 1)\n",
    "- LLM resolves \"its\" ‚Üí CS401 (from conversation history)\n",
    "- Agent answers correctly\n",
    "- Saves: Updated conversation\n",
    "\n",
    "**Turn 3:** User asks \"Can I take **it** next semester?\"\n",
    "- Working memory: **2 exchanges** (Turns 1-2)\n",
    "- LLM resolves \"it\" ‚Üí CS401 (from conversation history)\n",
    "- Agent answers correctly\n",
    "\n",
    "**üí° Key Insight:** Working memory enables **reference resolution** and **conversation continuity**.\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
