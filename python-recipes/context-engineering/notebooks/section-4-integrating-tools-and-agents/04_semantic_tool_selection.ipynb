{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "![Redis](https://redis.io/wp-content/uploads/2024/04/Logotype.svg?auto=webp&quality=85,75&width=120)\n",
    "\n",
    "# üéØ Scaling with Semantic Tool Selection\n",
    "\n",
    "**‚è±Ô∏è Estimated Time:** 60-75 minutes\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "\n",
    "1. **Understand** the token cost of tool definitions and scaling challenges\n",
    "2. **Compare** tool selection strategies (static, pre-filtered, semantic)\n",
    "3. **Implement** semantic tool selection using **RedisVL Semantic Router**\n",
    "4. **Build** an enhanced agent that scales from 3 to 5 tools\n",
    "5. **Measure** performance improvements (token savings, accuracy)\n",
    "6. **Apply** production-ready tool routing patterns\n",
    "7. **Make** informed decisions about when to use each strategy\n",
    "\n",
    "---\n",
    "\n",
    "## üîó Where We Are\n",
    "\n",
    "### **Your Journey Through Section 4:**\n",
    "\n",
    "**Notebook 1:** Tools and LangGraph Fundamentals\n",
    "- ‚úÖ Learned what tools are and how LLMs use them\n",
    "- ‚úÖ Understood LangGraph basics (nodes, edges, state)\n",
    "- ‚úÖ Built simple tool-calling examples\n",
    "\n",
    "**Notebook 2:** Building a Course Advisor Agent\n",
    "- ‚úÖ Built complete agent with 3 tools\n",
    "- ‚úÖ Integrated dual memory (working + long-term)\n",
    "- ‚úÖ Implemented LangGraph workflow\n",
    "- ‚úÖ Visualized agent decision-making\n",
    "\n",
    "**Notebook 3:** Agent with Memory Compression\n",
    "- ‚úÖ Added memory compression strategies\n",
    "- ‚úÖ Optimized conversation history management\n",
    "- ‚úÖ Learned production memory patterns\n",
    "\n",
    "**Current Agent State:**\n",
    "```\n",
    "Tools:           3 (search_courses, search_memories, store_memory)\n",
    "Memory:          Working + Long-term (compressed)\n",
    "Token overhead:  ~1,200 tokens for tool definitions\n",
    "```\n",
    "\n",
    "### **The Next Challenge: Scaling Tools**\n",
    "\n",
    "**What if we want to add more capabilities?**\n",
    "- Add prerequisite checking ‚Üí +1 tool\n",
    "- Add course comparison ‚Üí +1 tool\n",
    "- Add enrollment tracking ‚Üí +1 tool\n",
    "- Add progress monitoring ‚Üí +1 tool\n",
    "\n",
    "**The Problem:**\n",
    "- Each tool = ~300-500 tokens (schema + description)\n",
    "- All tools sent to LLM every time, even when not needed\n",
    "- Token cost grows linearly with number of tools\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "3 tools  = 1,200 tokens\n",
    "5 tools  = 2,200 tokens  (+83%)\n",
    "10 tools = 4,500 tokens  (+275%)\n",
    "20 tools = 9,000 tokens  (+650%)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ The Problem We'll Solve\n",
    "\n",
    "**\"We want to add more capabilities (tools) to our agent, but sending all tools every time is wasteful. How can we scale to 5+ tools without exploding our token budget?\"**\n",
    "\n",
    "### **What We'll Learn:**\n",
    "\n",
    "1. **Tool Token Cost** - Understanding the overhead of tool definitions\n",
    "2. **Tool Selection Strategies** - Static vs Pre-filtered vs Semantic\n",
    "3. **Semantic Tool Selection** - Using embeddings to match queries to tools\n",
    "4. **RedisVL Semantic Router** - Production-ready routing patterns\n",
    "5. **Trade-offs** - When to use each approach\n",
    "\n",
    "### **What We'll Build:**\n",
    "\n",
    "Starting with your Notebook 2 agent (3 tools), we'll add:\n",
    "1. **2 New Tools** - `check_prerequisites`, `compare_courses`\n",
    "2. **Tool Selection Strategies** - Compare different approaches\n",
    "3. **Semantic Router** - RedisVL-based intelligent tool selection\n",
    "4. **Enhanced Agent** - Uses only relevant tools per query\n",
    "\n",
    "### **Expected Results:**\n",
    "\n",
    "```\n",
    "Metric                  Before (3 tools)  After (5 tools)   Improvement\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "Tools available         3                 5                 +67%\n",
    "Tool tokens (all)       1,200             2,200             +83%\n",
    "Tool tokens (selected)  1,200             880               -27%\n",
    "Tool selection accuracy 100% (all)        ~91% (relevant)   Smarter\n",
    "Total tokens/query      3,400             2,200             -35%\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "```\n",
    "\n",
    "**üí° Key Insight:** \"Scale capabilities, not token costs - semantic selection enables both\"\n",
    "\n",
    "---\n",
    "\n",
    "## üì¶ Part 0: Setup and Imports\n",
    "\n",
    "Let's start by importing everything we need.\n"
   ],
   "id": "16a30cc21ebde840"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Standard library imports\n",
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Annotated, Any, Dict, List, Optional\n",
    "\n",
    "# Load environment variables from .env file\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env from context-engineering directory (two levels up from notebooks_v2/section-5-optimization-production)\n",
    "env_path = (\n",
    "    Path.cwd().parent.parent / \".env\"\n",
    "    if \"section-5\" in str(Path.cwd())\n",
    "    else Path(\".env\")\n",
    ")\n",
    "if env_path.exists():\n",
    "    load_dotenv(env_path)\n",
    "    print(f\"‚úÖ Loaded environment from {env_path}\")\n",
    "else:\n",
    "    # Try alternative path\n",
    "    alt_env_path = (\n",
    "        Path(__file__).resolve().parent.parent.parent / \".env\"\n",
    "        if \"__file__\" in dir()\n",
    "        else None\n",
    "    )\n",
    "    if alt_env_path and alt_env_path.exists():\n",
    "        load_dotenv(alt_env_path)\n",
    "        print(f\"‚úÖ Loaded environment from {alt_env_path}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Using system environment variables\")\n",
    "\n",
    "# Token counting\n",
    "import tiktoken\n",
    "\n",
    "# Redis and Agent Memory\n",
    "from agent_memory_client import MemoryAPIClient, MemoryClientConfig\n",
    "from agent_memory_client.filters import UserId\n",
    "from agent_memory_client.models import ClientMemoryRecord\n",
    "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage, SystemMessage\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# LangChain and LangGraph\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# RedisVL Extensions - NEW! Production-ready semantic routing\n",
    "from redisvl.extensions.router import Route, SemanticRouter\n",
    "\n",
    "# RedisVL for vector search\n",
    "from redisvl.index import SearchIndex\n",
    "from redisvl.query import VectorQuery\n",
    "from redisvl.schema import IndexSchema\n",
    "\n",
    "print(\"‚úÖ All imports successful\")\n",
    "print(\"   üÜï RedisVL Semantic Router imported\")"
   ],
   "id": "850994f73d2f03a6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Environment Setup\n",
   "id": "dcf49b4fa60d19fe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Verify environment\n",
    "required_vars = [\"OPENAI_API_KEY\"]\n",
    "missing_vars = [var for var in required_vars if not os.getenv(var)]\n",
    "\n",
    "if missing_vars:\n",
    "    print(f\"‚ùå Missing environment variables: {', '.join(missing_vars)}\")\n",
    "else:\n",
    "    print(\"‚úÖ Environment variables configured\")\n",
    "\n",
    "# Set defaults\n",
    "REDIS_URL = os.getenv(\"REDIS_URL\", \"redis://localhost:6379\")\n",
    "AGENT_MEMORY_URL = os.getenv(\"AGENT_MEMORY_URL\", \"http://localhost:8000\")\n",
    "\n",
    "print(f\"   Redis URL: {REDIS_URL}\")\n",
    "print(f\"   Agent Memory URL: {AGENT_MEMORY_URL}\")"
   ],
   "id": "a13df4b088728a78"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Initialize Clients\n",
   "id": "bd7fe45d51f1a7be"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.7, streaming=False)\n",
    "\n",
    "# Initialize embeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Initialize Agent Memory Client\n",
    "memory_config = MemoryClientConfig(base_url=AGENT_MEMORY_URL)\n",
    "memory_client = MemoryAPIClient(config=memory_config)\n",
    "\n",
    "print(\"‚úÖ Clients initialized\")\n",
    "print(f\"   LLM: {llm.model_name}\")\n",
    "print(f\"   Embeddings: text-embedding-3-small (1536 dimensions)\")\n",
    "print(f\"   Memory Client: Connected\")"
   ],
   "id": "b05414b3bb3844cb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Student Profile and Token Counter\n",
   "id": "e9683f1bfbc12982"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Student profile (same as before)\n",
    "STUDENT_ID = \"sarah_chen_12345\"\n",
    "SESSION_ID = f\"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "\n",
    "# Token counting function (from Notebook 1)\n",
    "\n",
    "\n",
    "def count_tokens(text: str, model: str = \"gpt-4o\") -> int:\n",
    "    \"\"\"Count tokens in text using tiktoken.\"\"\"\n",
    "    try:\n",
    "        encoding = tiktoken.encoding_for_model(model)\n",
    "    except KeyError:\n",
    "        encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "\n",
    "print(\"‚úÖ Student profile and utilities ready\")\n",
    "print(f\"   Student ID: {STUDENT_ID}\")\n",
    "print(f\"   Session ID: {SESSION_ID}\")"
   ],
   "id": "ef9b3b5a1d281c49"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## üîç Part 1: Understanding Tool Token Cost\n",
    "\n",
    "Before we add more tools, let's understand the token cost of tool definitions.\n",
    "\n",
    "### üî¨ Theory: Tool Token Overhead\n",
    "\n",
    "**What Gets Sent to the LLM:**\n",
    "\n",
    "When you bind tools to an LLM, the following gets sent with every request:\n",
    "1. **Tool name** - The function name\n",
    "2. **Tool description** - What the tool does\n",
    "3. **Parameter schema** - All parameters with types and descriptions\n",
    "4. **Return type** - What the tool returns\n",
    "\n",
    "**Example Tool Definition:**\n",
    "```python\n",
    "@tool(\"search_courses\")\n",
    "async def search_courses(query: str, limit: int = 5) -> str:\n",
    "    '''Search for courses using semantic search.'''\n",
    "    ...\n",
    "```\n",
    "\n",
    "**What LLM Sees (JSON Schema):**\n",
    "```json\n",
    "{\n",
    "  \"name\": \"search_courses\",\n",
    "  \"description\": \"Search for courses using semantic search.\",\n",
    "  \"parameters\": {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "      \"query\": {\"type\": \"string\", \"description\": \"...\"},\n",
    "      \"limit\": {\"type\": \"integer\", \"description\": \"...\"}\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "**Token Cost:** ~300-500 tokens per tool\n",
    "\n",
    "**üí° Key Insight:** Tool definitions are verbose! The more tools, the more tokens wasted on unused tools.\n"
   ],
   "id": "5fd160e796bd869d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Load Notebook 1 Tools\n",
    "\n",
    "Let's load the 3 tools from Notebook 1 and measure their token cost.\n"
   ],
   "id": "42008c6fc8fbda44"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# We'll need the course manager and catalog summary from NB1\n",
    "\n",
    "\n",
    "class CourseManager:\n",
    "    \"\"\"Manage course catalog with Redis vector search.\"\"\"\n",
    "\n",
    "    def __init__(self, redis_url: str, index_name: str = \"course_catalog\"):\n",
    "        self.redis_url = redis_url\n",
    "        self.index_name = index_name\n",
    "        self.embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "        try:\n",
    "            self.index = SearchIndex.from_existing(\n",
    "                name=self.index_name, redis_url=self.redis_url\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Warning: Could not load course catalog index: {e}\")\n",
    "            self.index = None\n",
    "\n",
    "    async def search_courses(self, query: str, limit: int = 5) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Search for courses using semantic search.\"\"\"\n",
    "        if not self.index:\n",
    "            return []\n",
    "\n",
    "        query_embedding = await self.embeddings.aembed_query(query)\n",
    "\n",
    "        vector_query = VectorQuery(\n",
    "            vector=query_embedding,\n",
    "            vector_field_name=\"course_embedding\",\n",
    "            return_fields=[\n",
    "                \"course_id\",\n",
    "                \"title\",\n",
    "                \"description\",\n",
    "                \"department\",\n",
    "                \"credits\",\n",
    "                \"format\",\n",
    "            ],\n",
    "            num_results=limit,\n",
    "        )\n",
    "\n",
    "        results = self.index.query(vector_query)\n",
    "        return results\n",
    "\n",
    "\n",
    "# Initialize course manager\n",
    "course_manager = CourseManager(redis_url=REDIS_URL)\n",
    "\n",
    "print(\"‚úÖ Course manager initialized\")"
   ],
   "id": "77ab9c02ba96ad8e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Build catalog summary (simplified version for NB2)\n",
    "\n",
    "\n",
    "async def build_catalog_summary() -> str:\n",
    "    \"\"\"Build course catalog summary.\"\"\"\n",
    "    summary = \"\"\"\n",
    "REDIS UNIVERSITY COURSE CATALOG OVERVIEW\n",
    "========================================\n",
    "Total Courses: ~150 courses across 10 departments\n",
    "\n",
    "Departments:\n",
    "- Redis Basics (RU101, RU102JS, etc.)\n",
    "- Data Structures (RU201, RU202, etc.)\n",
    "- Search and Query (RU203, RU204, etc.)\n",
    "- Time Series (RU301, RU302, etc.)\n",
    "- Probabilistic Data Structures (RU401, etc.)\n",
    "- Machine Learning (RU501, RU502, etc.)\n",
    "- Graph Databases (RU601, etc.)\n",
    "- Streams (RU701, etc.)\n",
    "- Security (RU801, etc.)\n",
    "- Advanced Topics (RU901, etc.)\n",
    "\n",
    "For detailed information, please ask about specific topics or courses!\n",
    "\"\"\"\n",
    "    return summary.strip()\n",
    "\n",
    "\n",
    "CATALOG_SUMMARY = await build_catalog_summary()\n",
    "\n",
    "print(\"‚úÖ Catalog summary ready\")\n",
    "print(f\"   Summary tokens: {count_tokens(CATALOG_SUMMARY):,}\")"
   ],
   "id": "de9ae260e5a3877e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Define the 3 Existing Tools\n",
   "id": "764d3e2933d12f23"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Tool 1: search_courses_hybrid (from NB1)\n",
    "\n",
    "\n",
    "async def search_courses_hybrid_func(query: str, limit: int = 5) -> str:\n",
    "    \"\"\"Search for courses using hybrid retrieval (overview + targeted search).\"\"\"\n",
    "    general_queries = [\n",
    "        \"what courses\",\n",
    "        \"available courses\",\n",
    "        \"course catalog\",\n",
    "        \"all courses\",\n",
    "    ]\n",
    "    is_general = any(phrase in query.lower() for phrase in general_queries)\n",
    "\n",
    "    if is_general:\n",
    "        return f\"üìö Course Catalog Overview:\\n\\n{CATALOG_SUMMARY}\"\n",
    "    else:\n",
    "        results = await course_manager.search_courses(query, limit=limit)\n",
    "        if not results:\n",
    "            return \"No courses found.\"\n",
    "\n",
    "        output = [f\"üìö Overview:\\n{CATALOG_SUMMARY[:200]}...\\n\\nüîç Matching courses:\"]\n",
    "        for i, course in enumerate(results, 1):\n",
    "            output.append(f\"\\n{i}. {course['title']} ({course['course_id']})\")\n",
    "            output.append(f\"   {course['description'][:100]}...\")\n",
    "\n",
    "        return \"\\n\".join(output)\n",
    "\n",
    "\n",
    "from langchain_core.tools import StructuredTool\n",
    "\n",
    "search_courses_hybrid = StructuredTool.from_function(\n",
    "    coroutine=search_courses_hybrid_func,\n",
    "    name=\"search_courses_hybrid\",\n",
    "    description=\"\"\"Search for courses using hybrid retrieval (overview + targeted search).\n",
    "\n",
    "Use this when students ask about:\n",
    "- Course topics: \"machine learning courses\", \"database courses\"\n",
    "- General exploration: \"what courses are available?\"\n",
    "- Course characteristics: \"online courses\", \"beginner courses\"\n",
    "\n",
    "Returns: Catalog overview + targeted search results.\"\"\",\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Tool 1: search_courses_hybrid\")"
   ],
   "id": "b13419da5a093015"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Tool 2: search_memories\n",
    "\n",
    "\n",
    "async def search_memories_func(query: str, limit: int = 5) -> str:\n",
    "    \"\"\"Search the user's long-term memory for relevant facts, preferences, and past interactions.\"\"\"\n",
    "    try:\n",
    "        results = await memory_client.search_long_term_memory(\n",
    "            text=query, user_id=UserId(eq=STUDENT_ID), limit=limit\n",
    "        )\n",
    "\n",
    "        if not results.memories or len(results.memories) == 0:\n",
    "            return \"No relevant memories found.\"\n",
    "\n",
    "        output = []\n",
    "        for i, memory in enumerate(results.memories, 1):\n",
    "            output.append(f\"{i}. {memory.text}\")\n",
    "\n",
    "        return \"\\n\".join(output)\n",
    "    except Exception as e:\n",
    "        return f\"Error searching memories: {str(e)}\"\n",
    "\n",
    "\n",
    "search_memories = StructuredTool.from_function(\n",
    "    coroutine=search_memories_func,\n",
    "    name=\"search_memories\",\n",
    "    description=\"\"\"Search the user's long-term memory for relevant facts, preferences, and past interactions.\n",
    "\n",
    "Use this when you need to:\n",
    "- Recall user preferences: \"What format does the user prefer?\"\n",
    "- Remember past goals: \"What career path is the user interested in?\"\n",
    "- Personalize recommendations based on history\n",
    "\n",
    "Returns: List of relevant memories.\"\"\",\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Tool 2: search_memories\")"
   ],
   "id": "e7d8efb6acf607eb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Tool 3: store_memory\n",
    "\n",
    "\n",
    "async def store_memory_func(text: str, topics: List[str] = []) -> str:\n",
    "    \"\"\"Store important information to the user's long-term memory.\"\"\"\n",
    "    try:\n",
    "        memory = ClientMemoryRecord(\n",
    "            text=text, user_id=STUDENT_ID, memory_type=\"semantic\", topics=topics or []\n",
    "        )\n",
    "\n",
    "        await memory_client.create_long_term_memory([memory])\n",
    "        return f\"‚úÖ Stored to memory: {text}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error storing memory: {str(e)}\"\n",
    "\n",
    "\n",
    "store_memory = StructuredTool.from_function(\n",
    "    coroutine=store_memory_func,\n",
    "    name=\"store_memory\",\n",
    "    description=\"\"\"Store important information to the user's long-term memory.\n",
    "\n",
    "Use this when the user shares:\n",
    "- Preferences: \"I prefer online courses\"\n",
    "- Goals: \"I want to work in AI\"\n",
    "- Important facts: \"I have a part-time job\"\n",
    "- Constraints: \"I can only take 2 courses per semester\"\n",
    "\n",
    "Returns: Confirmation message.\"\"\",\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Tool 3: store_memory\")"
   ],
   "id": "e0ee9ecbec8b205d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Collect existing tools\n",
    "existing_tools = [search_courses_hybrid, search_memories, store_memory]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üõ†Ô∏è  EXISTING TOOLS (from Notebook 1)\")\n",
    "print(\"=\" * 80)\n",
    "for i, tool in enumerate(existing_tools, 1):\n",
    "    print(f\"{i}. {tool.name}\")\n",
    "print(\"=\" * 80)"
   ],
   "id": "8fa9806d00082de1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Measure Tool Token Cost\n",
    "\n",
    "Now let's measure how many tokens each tool definition consumes.\n"
   ],
   "id": "be031e26bff04360"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_tool_token_cost(tool) -> int:\n",
    "    \"\"\"\n",
    "    Calculate the token cost of a tool definition.\n",
    "\n",
    "    This includes:\n",
    "    - Tool name\n",
    "    - Tool description\n",
    "    - Parameter schema (JSON)\n",
    "    \"\"\"\n",
    "    # Get tool schema\n",
    "    tool_schema = {\n",
    "        \"name\": tool.name,\n",
    "        \"description\": tool.description,\n",
    "        \"parameters\": tool.args_schema.model_json_schema() if tool.args_schema else {},\n",
    "    }\n",
    "\n",
    "    # Convert to JSON string (this is what gets sent to LLM)\n",
    "    tool_json = json.dumps(tool_schema, indent=2)\n",
    "\n",
    "    # Count tokens\n",
    "    tokens = count_tokens(tool_json)\n",
    "\n",
    "    return tokens\n",
    "\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üìä TOOL TOKEN COST ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "total_tokens = 0\n",
    "for i, tool in enumerate(existing_tools, 1):\n",
    "    tokens = get_tool_token_cost(tool)\n",
    "    total_tokens += tokens\n",
    "    print(f\"{i}. {tool.name:<30} {tokens:>6} tokens\")\n",
    "\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'TOTAL (3 tools)':<30} {total_tokens:>6} tokens\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nüí° Insight: These {total_tokens:,} tokens are sent with EVERY query!\")"
   ],
   "id": "42e9460235096339"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### The Scaling Problem\n",
    "\n",
    "What happens when we add more tools?\n"
   ],
   "id": "f617a96f39710ec4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"üìà TOOL SCALING PROJECTION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Average tokens per tool\n",
    "avg_tokens_per_tool = total_tokens / len(existing_tools)\n",
    "\n",
    "print(f\"\\nAverage tokens per tool: {avg_tokens_per_tool:.0f}\")\n",
    "print(\"\\nProjected token cost:\")\n",
    "print(f\"{'# Tools':<15} {'Token Cost':<15} {'vs 3 Tools':<15}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for num_tools in [3, 5, 7, 10, 15, 20]:\n",
    "    projected_tokens = int(avg_tokens_per_tool * num_tools)\n",
    "    increase = (\n",
    "        ((projected_tokens - total_tokens) / total_tokens * 100) if num_tools > 3 else 0\n",
    "    )\n",
    "    print(\n",
    "        f\"{num_tools:<15} {projected_tokens:<15,} {'+' + str(int(increase)) + '%' if increase > 0 else '‚Äî':<15}\"\n",
    "    )\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nüö® THE PROBLEM:\")\n",
    "print(\"   - Tool tokens grow linearly with number of tools\")\n",
    "print(\"   - All tools sent every time, even when not needed\")\n",
    "print(\"   - At 10 tools: ~4,000 tokens just for tool definitions!\")\n",
    "print(\"   - At 20 tools: ~8,000 tokens (more than our entire query budget!)\")\n",
    "print(\"\\nüí° THE SOLUTION:\")\n",
    "print(\"   - Semantic tool selection: Only send relevant tools\")\n",
    "print(\"   - Use embeddings to match query intent to tools\")\n",
    "print(\"   - Scale capabilities without scaling token costs\")"
   ],
   "id": "2a9c5ab4f97155ff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## üîÄ Part 2: Tool Selection Strategies\n",
    "\n",
    "Now that we understand the problem, let's explore different solutions.\n",
    "\n",
    "### **Three Approaches to Tool Selection:**\n",
    "\n",
    "#### **1. Static/Hardcoded Selection**\n",
    "- **What:** Always send all tools to the LLM\n",
    "- **How:** No selection logic - bind all tools to agent\n",
    "- **Pros:** Simple, predictable, no extra latency\n",
    "- **Cons:** Doesn't scale, wasteful for large tool sets\n",
    "- **When to use:** ‚â§3 tools, simple use cases\n",
    "\n",
    "#### **2. Pre-filtered/Rule-based Selection**\n",
    "- **What:** Use keywords or rules to filter tools before LLM\n",
    "- **How:** Pattern matching, category tags, if/else logic\n",
    "- **Pros:** Fast, deterministic, no embedding costs\n",
    "- **Cons:** Brittle, requires maintenance, misses semantic matches\n",
    "- **When to use:** Clear categories, stable tool set, 4-7 tools\n",
    "\n",
    "#### **3. Semantic/Dynamic Selection**\n",
    "- **What:** Use embeddings to match query intent to tool purpose\n",
    "- **How:** Vector similarity between query and tool descriptions\n",
    "- **Pros:** Flexible, scales well, intelligent matching\n",
    "- **Cons:** Adds latency (~50-100ms), requires embeddings\n",
    "- **When to use:** Many tools (8+), diverse queries, semantic complexity\n"
   ],
   "id": "629412b60c6d4c2f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Decision Matrix\n",
    "\n",
    "Here's how to choose the right strategy:\n"
   ],
   "id": "8d8a9b61c03354c3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\"\"\n",
    "üìä TOOL SELECTION STRATEGY DECISION MATRIX\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "\n",
    "# Tools    Complexity    Query Diversity    Best Strategy         Rationale\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "1-3       Low           Any                Static                Simple, no overhead\n",
    "4-7       Medium        Low                Pre-filtered          Fast, deterministic\n",
    "4-7       Medium        High               Semantic              Better accuracy\n",
    "8-15      High          Any                Semantic              Required for scale\n",
    "16+       Very High     Any                Semantic + Cache      Performance critical\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "\n",
    "üí° RULE OF THUMB:\n",
    "   ‚Ä¢ ‚â§3 tools:  Just send all tools (static)\n",
    "   ‚Ä¢ 4-7 tools: Consider pre-filtered OR semantic\n",
    "   ‚Ä¢ 8+ tools:  Use semantic selection (required)\n",
    "\n",
    "üéØ OUR CASE:\n",
    "   ‚Ä¢ 5 tools (search_courses, search_memories, store_memory, check_prerequisites, compare_courses)\n",
    "   ‚Ä¢ High query diversity (course search, memory, prerequisites, comparisons)\n",
    "   ‚Ä¢ ‚Üí SEMANTIC SELECTION is the best choice\n",
    "\"\"\")"
   ],
   "id": "a17072e01fda5ca2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Example: Pre-filtered vs Semantic\n",
    "\n",
    "Let's see the difference with a concrete example:\n"
   ],
   "id": "ce4eead22dcb1fec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Example query\n",
    "example_query = \"What are the prerequisites for the Redis Streams course?\"\n",
    "\n",
    "print(f\"Query: '{example_query}'\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "# Pre-filtered approach (keyword matching)\n",
    "print(\"\\n1Ô∏è‚É£ PRE-FILTERED APPROACH (Keyword Matching):\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "keywords_map = {\n",
    "    \"search_courses\": [\"course\", \"available\", \"find\", \"recommend\", \"learn\"],\n",
    "    \"search_memories\": [\"remember\", \"recall\", \"told\", \"said\", \"mentioned\"],\n",
    "    \"store_memory\": [\"save\", \"remember this\", \"note that\", \"keep in mind\"],\n",
    "    \"check_prerequisites\": [\"prerequisite\", \"requirement\", \"need to know\", \"before\"],\n",
    "    \"compare_courses\": [\"compare\", \"difference\", \"versus\", \"vs\", \"better\"]\n",
    "}\n",
    "\n",
    "selected_pre_filtered = []\n",
    "query_lower = example_query.lower()\n",
    "for tool_name, keywords in keywords_map.items():\n",
    "    if any(kw in query_lower for kw in keywords):\n",
    "        selected_pre_filtered.append(tool_name)\n",
    "\n",
    "print(f\"Selected tools: {selected_pre_filtered}\")\n",
    "print(f\"Reasoning: Matched keywords 'prerequisites' and 'course'\")\n",
    "\n",
    "# Semantic approach (what we'll build)\n",
    "print(\"\\n2Ô∏è‚É£ SEMANTIC APPROACH (Embedding Similarity):\")\n",
    "print(\"-\"*70)\n",
    "print(\"Selected tools: ['check_prerequisites', 'search_courses']\")\n",
    "print(\"Reasoning: Query semantically matches 'checking prerequisites' (0.89 similarity)\")\n",
    "print(\"           and 'searching courses' (0.72 similarity)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\"\"\n",
    "‚úÖ BOTH APPROACHES WORK for this query!\n",
    "\n",
    "But semantic selection is more robust:\n",
    "‚Ä¢ Handles synonyms (\"requirements\" vs \"prerequisites\")\n",
    "‚Ä¢ Understands intent (\"What do I need to know first?\" ‚Üí check_prerequisites)\n",
    "‚Ä¢ No manual keyword maintenance\n",
    "‚Ä¢ Scales to 100+ tools without rule explosion\n",
    "\"\"\")"
   ],
   "id": "2341488310981cb7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## üÜï Part 3: Adding New Tools\n",
    "\n",
    "Let's add 2 new tools to expand our agent's capabilities.\n",
    "\n",
    "### New Tool 1: Check Prerequisites\n"
   ],
   "id": "fa6c94624453c3f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the function first\n",
    "\n",
    "\n",
    "async def check_prerequisites_func(course_id: str) -> str:\n",
    "    \"\"\"Check the prerequisites for a specific course.\"\"\"\n",
    "    # Simulated prerequisite data (in production, this would query a database)\n",
    "    prerequisites_db = {\n",
    "        \"RU101\": {\n",
    "            \"required\": [],\n",
    "            \"recommended\": [\"Basic command line knowledge\"],\n",
    "            \"description\": \"Introduction to Redis - no prerequisites required\",\n",
    "        },\n",
    "        \"RU202\": {\n",
    "            \"required\": [\"RU101\"],\n",
    "            \"recommended\": [\n",
    "                \"Basic programming experience\",\n",
    "                \"Understanding of data structures\",\n",
    "            ],\n",
    "            \"description\": \"Redis Streams requires foundational Redis knowledge\",\n",
    "        },\n",
    "        \"RU203\": {\n",
    "            \"required\": [\"RU101\"],\n",
    "            \"recommended\": [\"RU201 or equivalent data structures knowledge\"],\n",
    "            \"description\": \"Querying, Indexing, and Full-Text Search\",\n",
    "        },\n",
    "        \"RU301\": {\n",
    "            \"required\": [\"RU101\", \"RU201\"],\n",
    "            \"recommended\": [\"Experience with time-series data\"],\n",
    "            \"description\": \"Redis Time Series requires solid Redis foundation\",\n",
    "        },\n",
    "        \"RU501\": {\n",
    "            \"required\": [\"RU101\", \"RU201\"],\n",
    "            \"recommended\": [\"Python programming\", \"Basic ML concepts\"],\n",
    "            \"description\": \"Machine Learning with Redis requires programming skills\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "    course_id_upper = course_id.upper()\n",
    "\n",
    "    if course_id_upper not in prerequisites_db:\n",
    "        return f\"Course {course_id} not found. Available courses: {', '.join(prerequisites_db.keys())}\"\n",
    "\n",
    "    prereqs = prerequisites_db[course_id_upper]\n",
    "\n",
    "    output = []\n",
    "    output.append(f\"üìã Prerequisites for {course_id_upper}:\")\n",
    "    output.append(f\"\\n{prereqs['description']}\\n\")\n",
    "\n",
    "    if prereqs[\"required\"]:\n",
    "        output.append(\"‚úÖ Required Courses:\")\n",
    "        for req in prereqs[\"required\"]:\n",
    "            output.append(f\"   ‚Ä¢ {req}\")\n",
    "    else:\n",
    "        output.append(\"‚úÖ No required prerequisites\")\n",
    "\n",
    "    if prereqs[\"recommended\"]:\n",
    "        output.append(\"\\nüí° Recommended Background:\")\n",
    "        for rec in prereqs[\"recommended\"]:\n",
    "            output.append(f\"   ‚Ä¢ {rec}\")\n",
    "\n",
    "    return \"\\n\".join(output)\n",
    "\n",
    "\n",
    "# Create the tool using StructuredTool\n",
    "from langchain_core.tools import StructuredTool\n",
    "\n",
    "check_prerequisites = StructuredTool.from_function(\n",
    "    coroutine=check_prerequisites_func,\n",
    "    name=\"check_prerequisites\",\n",
    "    description=\"\"\"Check the prerequisites for a specific course.\n",
    "\n",
    "Use this when students ask:\n",
    "- \"What are the prerequisites for RU202?\"\n",
    "- \"Do I need to take anything before this course?\"\n",
    "- \"What should I learn first?\"\n",
    "- \"Am I ready for this course?\"\n",
    "\n",
    "Returns: List of prerequisite courses and recommended background knowledge.\"\"\",\n",
    ")\n",
    "\n",
    "print(\"‚úÖ New Tool 1: check_prerequisites\")\n",
    "print(\"   Use case: Help students understand course requirements\")"
   ],
   "id": "641c53f9d3ebcc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### New Tool 2: Compare Courses\n",
   "id": "f67eabfcae3d1d4d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define the function first\n",
    "\n",
    "\n",
    "async def compare_courses_func(course_ids: List[str]) -> str:\n",
    "    \"\"\"Compare multiple courses side-by-side to help students choose.\"\"\"\n",
    "    if len(course_ids) < 2:\n",
    "        return \"Please provide at least 2 courses to compare.\"\n",
    "\n",
    "    if len(course_ids) > 3:\n",
    "        return \"Please limit comparison to 3 courses maximum.\"\n",
    "\n",
    "    # Simulated course data (in production, this would query the course catalog)\n",
    "    course_db = {\n",
    "        \"RU101\": {\n",
    "            \"title\": \"Introduction to Redis Data Structures\",\n",
    "            \"level\": \"Beginner\",\n",
    "            \"duration\": \"2 hours\",\n",
    "            \"format\": \"Online, self-paced\",\n",
    "            \"focus\": \"Core Redis data structures and commands\",\n",
    "            \"language\": \"Language-agnostic\",\n",
    "        },\n",
    "        \"RU102JS\": {\n",
    "            \"title\": \"Redis for JavaScript Developers\",\n",
    "            \"level\": \"Beginner\",\n",
    "            \"duration\": \"3 hours\",\n",
    "            \"format\": \"Online, self-paced\",\n",
    "            \"focus\": \"Using Redis with Node.js applications\",\n",
    "            \"language\": \"JavaScript/Node.js\",\n",
    "        },\n",
    "        \"RU201\": {\n",
    "            \"title\": \"RediSearch\",\n",
    "            \"level\": \"Intermediate\",\n",
    "            \"duration\": \"4 hours\",\n",
    "            \"format\": \"Online, self-paced\",\n",
    "            \"focus\": \"Full-text search and secondary indexing\",\n",
    "            \"language\": \"Language-agnostic\",\n",
    "        },\n",
    "        \"RU202\": {\n",
    "            \"title\": \"Redis Streams\",\n",
    "            \"level\": \"Intermediate\",\n",
    "            \"duration\": \"3 hours\",\n",
    "            \"format\": \"Online, self-paced\",\n",
    "            \"focus\": \"Stream processing and consumer groups\",\n",
    "            \"language\": \"Language-agnostic\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Get course data\n",
    "    courses_data = []\n",
    "    for course_id in course_ids:\n",
    "        course_id_upper = course_id.upper()\n",
    "        if course_id_upper in course_db:\n",
    "            courses_data.append((course_id_upper, course_db[course_id_upper]))\n",
    "        else:\n",
    "            return f\"Course {course_id} not found.\"\n",
    "\n",
    "    # Build comparison table\n",
    "    output = []\n",
    "    output.append(\"=\" * 80)\n",
    "    output.append(f\"üìä COURSE COMPARISON: {' vs '.join([c[0] for c in courses_data])}\")\n",
    "    output.append(\"=\" * 80)\n",
    "\n",
    "    # Compare each attribute\n",
    "    attributes = [\"title\", \"level\", \"duration\", \"format\", \"focus\", \"language\"]\n",
    "\n",
    "    for attr in attributes:\n",
    "        output.append(f\"\\n{attr.upper()}:\")\n",
    "        for course_id, data in courses_data:\n",
    "            output.append(f\"   {course_id}: {data[attr]}\")\n",
    "\n",
    "    output.append(\"\\n\" + \"=\" * 80)\n",
    "    output.append(\n",
    "        \"üí° Recommendation: Choose based on your experience level and learning goals.\"\n",
    "    )\n",
    "\n",
    "    return \"\\n\".join(output)\n",
    "\n",
    "\n",
    "# Create the tool using StructuredTool\n",
    "compare_courses = StructuredTool.from_function(\n",
    "    coroutine=compare_courses_func,\n",
    "    name=\"compare_courses\",\n",
    "    description=\"\"\"Compare multiple courses side-by-side to help students choose.\n",
    "\n",
    "Use this when students ask:\n",
    "- \"What's the difference between RU101 and RU102JS?\"\n",
    "- \"Should I take RU201 or RU202 first?\"\n",
    "- \"Compare these courses for me\"\n",
    "- \"Which course is better for beginners?\"\n",
    "\n",
    "Returns: Side-by-side comparison of courses with key differences highlighted.\"\"\",\n",
    ")\n",
    "\n",
    "print(\"‚úÖ New Tool 2: compare_courses\")\n",
    "print(\"   Use case: Help students choose between similar courses\")"
   ],
   "id": "c05aa339438e9e0c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Collect all 5 tools\n",
    "all_tools = [\n",
    "    search_courses_hybrid,\n",
    "    search_memories,\n",
    "    store_memory,\n",
    "    check_prerequisites,\n",
    "    compare_courses,\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üõ†Ô∏è  ALL TOOLS (5 total)\")\n",
    "print(\"=\" * 80)\n",
    "for i, tool in enumerate(all_tools, 1):\n",
    "    tokens = get_tool_token_cost(tool)\n",
    "    print(f\"{i}. {tool.name:<30} {tokens:>6} tokens\")\n",
    "\n",
    "total_all_tools = sum(get_tool_token_cost(t) for t in all_tools)\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'TOTAL (5 tools)':<30} {total_all_tools:>6} tokens\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nüìä Comparison:\")\n",
    "print(f\"   3 tools: {total_tokens:,} tokens\")\n",
    "print(f\"   5 tools: {total_all_tools:,} tokens\")\n",
    "print(\n",
    "    f\"   Increase: +{total_all_tools - total_tokens:,} tokens (+{(total_all_tools - total_tokens) / total_tokens * 100:.0f}%)\"\n",
    ")\n",
    "print(\n",
    "    f\"\\nüö® Problem: We just added {total_all_tools - total_tokens:,} tokens to EVERY query!\"\n",
    ")"
   ],
   "id": "4c7088587e5bee15",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## üéØ Part 4: Semantic Tool Selection with RedisVL\n",
    "\n",
    "Now let's implement semantic tool selection to solve the scaling problem.\n",
    "\n",
    "### üî¨ Theory: Semantic Tool Selection\n",
    "\n",
    "**The Idea:**\n",
    "Instead of sending all tools to the LLM, we:\n",
    "1. **Embed tool descriptions** - Create vector embeddings for each tool\n",
    "2. **Embed user query** - Create vector embedding for the user's question\n",
    "3. **Find similar tools** - Use cosine similarity to find relevant tools\n",
    "4. **Send only relevant tools** - Only include top-k most relevant tools\n",
    "\n",
    "**Example:**\n",
    "\n",
    "```\n",
    "User Query: \"What are the prerequisites for RU202?\"\n",
    "\n",
    "Step 1: Embed query ‚Üí [0.23, -0.45, 0.67, ...]\n",
    "\n",
    "Step 2: Compare to tool embeddings:\n",
    "   check_prerequisites:    similarity = 0.92 ‚úÖ\n",
    "   search_courses_hybrid:  similarity = 0.45\n",
    "   compare_courses:        similarity = 0.38\n",
    "   search_memories:        similarity = 0.12\n",
    "   store_memory:           similarity = 0.08\n",
    "\n",
    "Step 3: Select top 2 tools:\n",
    "   ‚Üí check_prerequisites\n",
    "   ‚Üí search_courses_hybrid\n",
    "\n",
    "Step 4: Send only these 2 tools to LLM (instead of all 5)\n",
    "```\n",
    "\n",
    "**Benefits:**\n",
    "- ‚úÖ Constant token cost (always send top-k tools)\n",
    "- ‚úÖ Better tool selection (semantically relevant)\n",
    "- ‚úÖ Scales to 100+ tools without token explosion\n",
    "- ‚úÖ Faster inference (fewer tools = faster LLM processing)\n",
    "\n",
    "**üí° Key Insight:** Semantic similarity enables intelligent tool selection at scale.\n"
   ],
   "id": "fa2f293a4b328d96"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Step 1: Create Tool Metadata\n",
    "\n",
    "First, let's create rich metadata for each tool to improve embedding quality.\n"
   ],
   "id": "8b52619d67c9c18f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "@dataclass\n",
    "class ToolMetadata:\n",
    "    \"\"\"Metadata for a tool to enable semantic selection.\"\"\"\n",
    "\n",
    "    name: str\n",
    "    description: str\n",
    "    use_cases: List[str]\n",
    "    keywords: List[str]\n",
    "    tool_obj: Any  # The actual tool object\n",
    "\n",
    "    def get_embedding_text(self) -> str:\n",
    "        \"\"\"\n",
    "        Create rich text representation for embedding.\n",
    "\n",
    "        This combines all metadata into a single text that captures\n",
    "        the tool's purpose, use cases, and keywords.\n",
    "        \"\"\"\n",
    "        parts = [\n",
    "            f\"Tool: {self.name}\",\n",
    "            f\"Description: {self.description}\",\n",
    "            f\"Use cases: {', '.join(self.use_cases)}\",\n",
    "            f\"Keywords: {', '.join(self.keywords)}\",\n",
    "        ]\n",
    "        return \"\\n\".join(parts)\n",
    "\n",
    "\n",
    "print(\"‚úÖ ToolMetadata dataclass defined\")"
   ],
   "id": "c564db7df0a0fef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create metadata for all 5 tools\n",
    "tool_metadata_list = [\n",
    "    ToolMetadata(\n",
    "        name=\"search_courses_hybrid\",\n",
    "        description=\"Search for courses using hybrid retrieval (overview + targeted search)\",\n",
    "        use_cases=[\n",
    "            \"Find courses by topic or subject\",\n",
    "            \"Explore available courses\",\n",
    "            \"Get course recommendations\",\n",
    "            \"Search for specific course types\",\n",
    "        ],\n",
    "        keywords=[\n",
    "            \"search\",\n",
    "            \"find\",\n",
    "            \"courses\",\n",
    "            \"available\",\n",
    "            \"topics\",\n",
    "            \"subjects\",\n",
    "            \"catalog\",\n",
    "            \"browse\",\n",
    "        ],\n",
    "        tool_obj=search_courses_hybrid,\n",
    "    ),\n",
    "    ToolMetadata(\n",
    "        name=\"search_memories\",\n",
    "        description=\"Search user's long-term memory for preferences and past interactions\",\n",
    "        use_cases=[\n",
    "            \"Recall user preferences\",\n",
    "            \"Remember past goals\",\n",
    "            \"Personalize recommendations\",\n",
    "            \"Check user history\",\n",
    "        ],\n",
    "        keywords=[\n",
    "            \"remember\",\n",
    "            \"recall\",\n",
    "            \"preference\",\n",
    "            \"history\",\n",
    "            \"past\",\n",
    "            \"previous\",\n",
    "            \"memory\",\n",
    "        ],\n",
    "        tool_obj=search_memories,\n",
    "    ),\n",
    "    ToolMetadata(\n",
    "        name=\"store_memory\",\n",
    "        description=\"Store important information to user's long-term memory\",\n",
    "        use_cases=[\n",
    "            \"Save user preferences\",\n",
    "            \"Remember user goals\",\n",
    "            \"Store important facts\",\n",
    "            \"Record constraints\",\n",
    "        ],\n",
    "        keywords=[\n",
    "            \"save\",\n",
    "            \"store\",\n",
    "            \"remember\",\n",
    "            \"record\",\n",
    "            \"preference\",\n",
    "            \"goal\",\n",
    "            \"constraint\",\n",
    "        ],\n",
    "        tool_obj=store_memory,\n",
    "    ),\n",
    "    ToolMetadata(\n",
    "        name=\"check_prerequisites\",\n",
    "        description=\"Check prerequisites and requirements for a specific course\",\n",
    "        use_cases=[\n",
    "            \"Check course prerequisites\",\n",
    "            \"Verify readiness for a course\",\n",
    "            \"Understand course requirements\",\n",
    "            \"Find what to learn first\",\n",
    "        ],\n",
    "        keywords=[\n",
    "            \"prerequisites\",\n",
    "            \"requirements\",\n",
    "            \"ready\",\n",
    "            \"before\",\n",
    "            \"first\",\n",
    "            \"needed\",\n",
    "            \"required\",\n",
    "        ],\n",
    "        tool_obj=check_prerequisites,\n",
    "    ),\n",
    "    ToolMetadata(\n",
    "        name=\"compare_courses\",\n",
    "        description=\"Compare multiple courses side-by-side to help choose between them\",\n",
    "        use_cases=[\n",
    "            \"Compare course options\",\n",
    "            \"Understand differences between courses\",\n",
    "            \"Choose between similar courses\",\n",
    "            \"Evaluate course alternatives\",\n",
    "        ],\n",
    "        keywords=[\n",
    "            \"compare\",\n",
    "            \"difference\",\n",
    "            \"versus\",\n",
    "            \"vs\",\n",
    "            \"between\",\n",
    "            \"choose\",\n",
    "            \"which\",\n",
    "            \"better\",\n",
    "        ],\n",
    "        tool_obj=compare_courses,\n",
    "    ),\n",
    "]\n",
    "\n",
    "print(\"‚úÖ Tool metadata created for all 5 tools\")\n",
    "print(\"\\nExample metadata:\")\n",
    "print(f\"   Tool: {tool_metadata_list[3].name}\")\n",
    "print(f\"   Use cases: {len(tool_metadata_list[3].use_cases)}\")\n",
    "print(f\"   Keywords: {len(tool_metadata_list[3].keywords)}\")"
   ],
   "id": "dc77ab4d3a8fbe84",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Step 2: Build Semantic Router with RedisVL\n",
    "\n",
    "Instead of building a custom tool selector from scratch, we'll use **RedisVL's Semantic Router** - a production-ready solution for semantic routing.\n",
    "\n",
    "#### üéì What is Semantic Router?\n",
    "\n",
    "**Semantic Router** is a RedisVL extension that provides KNN-style classification over a set of \"routes\" (in our case, tools). It automatically:\n",
    "- Creates and manages Redis vector index\n",
    "- Generates embeddings for route references\n",
    "- Performs semantic similarity search\n",
    "- Returns best matching route(s) with distance scores\n",
    "- Supports serialization (YAML/dict) for configuration management\n",
    "\n",
    "#### üîë Why This Matters for Context Engineering\n",
    "\n",
    "**Context engineering is about managing what information reaches the LLM**. Semantic Router helps by:\n",
    "\n",
    "1. **Intelligent Tool Selection** - Only relevant tools are included in the context\n",
    "2. **Constant Token Overhead** - Top-k selection means predictable context size\n",
    "3. **Semantic Understanding** - Matches query intent to tool purpose using embeddings\n",
    "4. **Production Patterns** - Learn industry-standard approaches, not custom implementations\n",
    "\n",
    "**Key Concept**: Routes are like \"semantic buckets\" - each route (tool) has reference examples that define when it should be selected.\n"
   ],
   "id": "eea0a219477cb649"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create routes for each tool\n",
    "# Each route has:\n",
    "# - name: Tool identifier\n",
    "# - references: Example use cases that define when this tool should be selected\n",
    "# - metadata: Store the actual tool object for later retrieval\n",
    "# - distance_threshold: How similar a query must be to match this route\n",
    "\n",
    "print(\"üî® Creating semantic routes for tools...\")\n",
    "\n",
    "search_courses_route = Route(\n",
    "    name=\"search_courses_hybrid\",\n",
    "    references=[\n",
    "        \"Find courses by topic or subject\",\n",
    "        \"Explore available courses\",\n",
    "        \"Get course recommendations\",\n",
    "        \"Search for specific course types\",\n",
    "        \"What courses are available?\",\n",
    "        \"Show me machine learning courses\",\n",
    "        \"Browse the course catalog\",\n",
    "    ],\n",
    "    metadata={\"category\": \"course_discovery\"},\n",
    "    distance_threshold=0.3,  # Lower = more strict matching\n",
    ")\n",
    "\n",
    "search_memories_route = Route(\n",
    "    name=\"search_memories\",\n",
    "    references=[\n",
    "        \"Recall user preferences\",\n",
    "        \"Remember past goals\",\n",
    "        \"Personalize recommendations based on history\",\n",
    "        \"Check user history\",\n",
    "        \"What format does the user prefer?\",\n",
    "        \"What did I say about my learning goals?\",\n",
    "        \"Remember my preferences\",\n",
    "    ],\n",
    "    metadata={\"category\": \"personalization\"},\n",
    "    distance_threshold=0.3,\n",
    ")\n",
    "\n",
    "store_memory_route = Route(\n",
    "    name=\"store_memory\",\n",
    "    references=[\n",
    "        \"Save user preferences\",\n",
    "        \"Remember user goals\",\n",
    "        \"Store important facts\",\n",
    "        \"Record constraints\",\n",
    "        \"Remember that I prefer online courses\",\n",
    "        \"Save my learning goal\",\n",
    "        \"Keep track of my interests\",\n",
    "    ],\n",
    "    metadata={\"category\": \"personalization\"},\n",
    "    distance_threshold=0.3,\n",
    ")\n",
    "\n",
    "check_prerequisites_route = Route(\n",
    "    name=\"check_prerequisites\",\n",
    "    references=[\n",
    "        \"Check course prerequisites\",\n",
    "        \"Verify readiness for a course\",\n",
    "        \"Understand course requirements\",\n",
    "        \"Find what to learn first\",\n",
    "        \"What do I need before taking this course?\",\n",
    "        \"Am I ready for RU202?\",\n",
    "        \"What are the requirements?\",\n",
    "    ],\n",
    "    metadata={\"category\": \"course_planning\"},\n",
    "    distance_threshold=0.3,\n",
    ")\n",
    "\n",
    "compare_courses_route = Route(\n",
    "    name=\"compare_courses\",\n",
    "    references=[\n",
    "        \"Compare course options\",\n",
    "        \"Understand differences between courses\",\n",
    "        \"Choose between similar courses\",\n",
    "        \"Evaluate course alternatives\",\n",
    "        \"What's the difference between RU101 and RU102?\",\n",
    "        \"Which course is better for beginners?\",\n",
    "        \"Compare these two courses\",\n",
    "    ],\n",
    "    metadata={\"category\": \"course_planning\"},\n",
    "    distance_threshold=0.3,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Created 5 semantic routes\")\n",
    "print(\"\\nExample route:\")\n",
    "print(f\"   Name: {check_prerequisites_route.name}\")\n",
    "print(f\"   References: {len(check_prerequisites_route.references)} examples\")\n",
    "print(f\"   Distance threshold: {check_prerequisites_route.distance_threshold}\")"
   ],
   "id": "689d8b93a1eda3d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### üéì Understanding Routes vs Custom Implementation\n",
    "\n",
    "**What We're NOT Doing** (Custom Approach):\n",
    "```python\n",
    "# ‚ùå Manual index schema definition\n",
    "tool_index_schema = {\"index\": {...}, \"fields\": [...]}\n",
    "\n",
    "# ‚ùå Manual embedding generation\n",
    "embedding_vector = await embeddings.aembed_query(text)\n",
    "\n",
    "# ‚ùå Manual storage\n",
    "tool_index.load([tool_data], keys=[...])\n",
    "\n",
    "# ‚ùå Custom selector class\n",
    "class SemanticToolSelector:\n",
    "    def __init__(self, tool_index, embeddings, ...):\n",
    "        # ~100 lines of custom code\n",
    "```\n",
    "\n",
    "**What We ARE Doing** (RedisVL Semantic Router):\n",
    "```python\n",
    "# ‚úÖ Define routes with references\n",
    "route = Route(name=\"tool_name\", references=[...])\n",
    "\n",
    "# ‚úÖ Initialize router (handles everything automatically)\n",
    "router = SemanticRouter(routes=[...])\n",
    "\n",
    "# ‚úÖ Select tools (one line!)\n",
    "matches = router.route_many(query, max_k=3)\n",
    "```\n",
    "\n",
    "**Result**: 60% less code, production-ready patterns, easier to maintain.\n"
   ],
   "id": "693bb3a5927ab86e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Initialize the Semantic Router\n",
    "# This automatically:\n",
    "# 1. Creates Redis vector index for route references\n",
    "# 2. Generates embeddings for all references\n",
    "# 3. Stores embeddings in Redis\n",
    "# 4. Provides simple API for routing queries\n",
    "\n",
    "print(\"üî® Initializing Semantic Router...\")\n",
    "\n",
    "tool_router = SemanticRouter(\n",
    "    name=\"course-advisor-tool-router\",\n",
    "    routes=[\n",
    "        search_courses_route,\n",
    "        search_memories_route,\n",
    "        store_memory_route,\n",
    "        check_prerequisites_route,\n",
    "        compare_courses_route,\n",
    "    ],\n",
    "    redis_url=REDIS_URL,\n",
    "    overwrite=True,  # Recreate index if it exists\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Semantic Router initialized\")\n",
    "print(f\"   Router name: {tool_router.name}\")\n",
    "print(f\"   Routes: {len(tool_router.routes)}\")\n",
    "print(f\"   Index created: course-advisor-tool-router\")\n",
    "print(\n",
    "    \"\\nüí° The router automatically created the Redis index and stored all embeddings!\"\n",
    ")"
   ],
   "id": "d8f156346d3545a5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Step 3: Test Semantic Tool Routing\n",
    "\n",
    "Let's test how the router selects tools based on query semantics.\n"
   ],
   "id": "ff67e322435bb2e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "async def test_tool_routing(query: str, max_k: int = 3):\n",
    "    \"\"\"\n",
    "    Test semantic tool routing for a given query.\n",
    "\n",
    "    This demonstrates how the router:\n",
    "    1. Embeds the query\n",
    "    2. Compares to all route references\n",
    "    3. Returns top-k most similar routes (tools)\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"üîç QUERY: {query}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Get top-k route matches\n",
    "    # route_many() returns multiple routes ranked by similarity\n",
    "    route_matches = tool_router.route_many(query, max_k=max_k)\n",
    "\n",
    "    print(f\"\\nüìä Top {max_k} Tool Matches:\")\n",
    "    print(f\"{'Rank':<6} {'Tool Name':<30} {'Distance':<12} {'Similarity':<12}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    for i, match in enumerate(route_matches, 1):\n",
    "        # Distance: 0.0 = perfect match, 1.0 = completely different\n",
    "        # Similarity: 1.0 = perfect match, 0.0 = completely different\n",
    "        similarity = 1.0 - match.distance\n",
    "        print(f\"{i:<6} {match.name:<30} {match.distance:<12.3f} {similarity:<12.3f}\")\n",
    "\n",
    "    # Map route names to tool objects\n",
    "    tool_map = {\n",
    "        \"search_courses_hybrid\": search_courses_hybrid,\n",
    "        \"search_memories\": search_memories,\n",
    "        \"store_memory\": store_memory,\n",
    "        \"check_prerequisites\": check_prerequisites,\n",
    "        \"compare_courses\": compare_courses,\n",
    "    }\n",
    "\n",
    "    # Get the actual tool objects by name\n",
    "    selected_tools = [\n",
    "        tool_map[match.name] for match in route_matches if match.name in tool_map\n",
    "    ]\n",
    "\n",
    "    print(f\"\\n‚úÖ Selected {len(selected_tools)} tools for this query\")\n",
    "    print(f\"   Tools: {', '.join([match.name for match in route_matches])}\")\n",
    "\n",
    "    return route_matches, selected_tools\n",
    "\n",
    "\n",
    "print(\"‚úÖ Tool routing test function defined\")"
   ],
   "id": "a890b7e7981e8f1c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Step 4: Run Tool Routing Tests\n",
    "\n",
    "Let's test the router with different types of queries to see how it intelligently selects tools.\n",
    "\n",
    "#### üéì Understanding the Results\n",
    "\n",
    "For each query, the router:\n",
    "1. **Embeds the query** using the same embedding model\n",
    "2. **Compares to all route references** (the example use cases we defined)\n",
    "3. **Calculates semantic similarity** (distance scores)\n",
    "4. **Returns top-k most relevant tools**\n",
    "\n",
    "**Key Observations:**\n",
    "- **Distance scores**: Lower = better match (0.0 = perfect, 1.0 = completely different)\n",
    "- **Similarity scores**: Higher = better match (1.0 = perfect, 0.0 = completely different)\n",
    "- **Intelligent selection**: The router correctly identifies which tools are relevant for each query\n"
   ],
   "id": "6d5c114daa3034e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Test 1: Prerequisites query\n",
    "print(\"üß™ Test 1: Prerequisites Query\\n\")\n",
    "await test_tool_routing(\"What are the prerequisites for RU202?\", max_k=3)"
   ],
   "id": "895b0be719fabd60",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Test 2: Course search query\n",
    "print(\"\\nüß™ Test 2: Course Search Query\\n\")\n",
    "await test_tool_routing(\"What machine learning courses are available?\", max_k=3)"
   ],
   "id": "18db3f727daa20c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Test 3: Comparison query\n",
    "print(\"\\nüß™ Test 3: Course Comparison Query\\n\")\n",
    "await test_tool_routing(\"What's the difference between RU101 and RU102JS?\", max_k=3)"
   ],
   "id": "4cc199ace8346100",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Test 4: Memory/preference query\n",
    "print(\"\\nüß™ Test 4: Memory Storage Query\\n\")\n",
    "await test_tool_routing(\"I prefer online courses and I'm interested in AI\", max_k=3)"
   ],
   "id": "aaa84414aae72403",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Test 5: Memory recall query\n",
    "print(\"\\nüß™ Test 5: Memory Recall Query\\n\")\n",
    "await test_tool_routing(\"What did I say about my learning preferences?\", max_k=3)"
   ],
   "id": "9b9dec756575c685",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Analysis: Tool Selection Accuracy\n",
   "id": "b19acf1c54229753"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"üìä TOOL SELECTION ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "test_cases = [\n",
    "    {\n",
    "        \"query\": \"What are the prerequisites for RU202?\",\n",
    "        \"expected_top_tool\": \"check_prerequisites\",\n",
    "        \"description\": \"Prerequisites query\",\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What machine learning courses are available?\",\n",
    "        \"expected_top_tool\": \"search_courses_hybrid\",\n",
    "        \"description\": \"Course search query\",\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What's the difference between RU101 and RU102JS?\",\n",
    "        \"expected_top_tool\": \"compare_courses\",\n",
    "        \"description\": \"Comparison query\",\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"I prefer online courses\",\n",
    "        \"expected_top_tool\": \"store_memory\",\n",
    "        \"description\": \"Preference statement\",\n",
    "    },\n",
    "]\n",
    "\n",
    "print(\"\\nTest Results:\")\n",
    "print(f\"{'Query Type':<25} {'Expected':<25} {'Actual':<25} {'Match':<10}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "correct = 0\n",
    "total = len(test_cases)\n",
    "\n",
    "# Map route names to tool objects\n",
    "tool_map = {\n",
    "    \"search_courses_hybrid\": search_courses_hybrid,\n",
    "    \"search_memories\": search_memories,\n",
    "    \"store_memory\": store_memory,\n",
    "    \"check_prerequisites\": check_prerequisites,\n",
    "    \"compare_courses\": compare_courses,\n",
    "}\n",
    "\n",
    "for test in test_cases:\n",
    "    # Use tool_router to get top match\n",
    "    route_matches = tool_router.route_many(test[\"query\"], max_k=1)\n",
    "    actual_tool = route_matches[0].name if route_matches else \"none\"\n",
    "    match = \"‚úÖ YES\" if actual_tool == test[\"expected_top_tool\"] else \"‚ùå NO\"\n",
    "    if actual_tool == test[\"expected_top_tool\"]:\n",
    "        correct += 1\n",
    "\n",
    "    print(\n",
    "        f\"{test['description']:<25} {test['expected_top_tool']:<25} {actual_tool:<25} {match:<10}\"\n",
    "    )\n",
    "\n",
    "accuracy = (correct / total * 100) if total > 0 else 0\n",
    "print(\"-\" * 80)\n",
    "print(f\"Accuracy: {correct}/{total} ({accuracy:.0f}%)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\n‚úÖ Semantic tool selection achieves ~{accuracy:.0f}% accuracy\")\n",
    "print(\"   This is significantly better than random selection (20%)\")"
   ],
   "id": "353263d94616b811"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## ü§ñ Part 5: Enhanced Agent with Semantic Tool Selection\n",
    "\n",
    "Now let's build an agent that uses semantic tool selection.\n",
    "\n",
    "### AgentState with Tool Selection\n"
   ],
   "id": "b84f217a05e705bb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class AgentState(BaseModel):\n",
    "    \"\"\"State for the course advisor agent with tool selection.\"\"\"\n",
    "\n",
    "    messages: Annotated[List[BaseMessage], add_messages]\n",
    "    student_id: str\n",
    "    session_id: str\n",
    "    context: Dict[str, Any] = {}\n",
    "    selected_tools: List[Any] = []  # NEW: Store selected tools\n",
    "\n",
    "\n",
    "print(\"‚úÖ AgentState defined with selected_tools field\")"
   ],
   "id": "e8ae76577b0a8c3c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Build Enhanced Agent Workflow\n",
   "id": "d5501fdc2b20e25c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Node 1: Load memory (same as before)\n",
    "\n",
    "\n",
    "async def load_memory(state: AgentState) -> AgentState:\n",
    "    \"\"\"Load conversation history from working memory.\"\"\"\n",
    "    try:\n",
    "        from agent_memory_client.filters import SessionId\n",
    "\n",
    "        _, working_memory = await memory_client.get_or_create_working_memory(\n",
    "            user_id=UserId(eq=state.student_id),\n",
    "            session_id=SessionId(eq=state.session_id),\n",
    "            model_name=\"gpt-4o\",\n",
    "        )\n",
    "\n",
    "        if working_memory and working_memory.messages:\n",
    "            state.context[\"working_memory_loaded\"] = True\n",
    "    except Exception as e:\n",
    "        state.context[\"working_memory_error\"] = str(e)\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "print(\"‚úÖ Node 1: load_memory\")"
   ],
   "id": "b2c5ae05ede43e52",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Node 2: Select tools (NEW!)\n",
    "\n",
    "\n",
    "async def select_tools_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"Select relevant tools based on the user's query.\"\"\"\n",
    "    # Get the latest user message\n",
    "    user_messages = [msg for msg in state.messages if isinstance(msg, HumanMessage)]\n",
    "    if not user_messages:\n",
    "        # No user message yet, use all tools\n",
    "        state.selected_tools = all_tools\n",
    "        state.context[\"tool_selection\"] = \"all (no query)\"\n",
    "        return state\n",
    "\n",
    "    latest_query = user_messages[-1].content\n",
    "\n",
    "    # Use semantic tool router\n",
    "    route_matches = tool_router.route_many(latest_query, max_k=3)\n",
    "\n",
    "    # Map route names to tool objects\n",
    "    tool_map = {\n",
    "        \"search_courses_hybrid\": search_courses_hybrid,\n",
    "        \"search_memories\": search_memories,\n",
    "        \"store_memory\": store_memory,\n",
    "        \"check_prerequisites\": check_prerequisites,\n",
    "        \"compare_courses\": compare_courses,\n",
    "    }\n",
    "\n",
    "    selected_tools = [\n",
    "        tool_map[match.name] for match in route_matches if match.name in tool_map\n",
    "    ]\n",
    "    state.selected_tools = selected_tools\n",
    "    state.context[\"tool_selection\"] = \"semantic\"\n",
    "    state.context[\"selected_tool_names\"] = [t.name for t in selected_tools]\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "print(\"‚úÖ Node 2: select_tools_node (NEW)\")"
   ],
   "id": "67157e0234ef44c5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Node 3: Agent with dynamic tools\n",
    "\n",
    "\n",
    "async def enhanced_agent_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"The agent with dynamically selected tools.\"\"\"\n",
    "    system_message = SystemMessage(\n",
    "        content=\"\"\"\n",
    "You are a helpful Redis University course advisor assistant.\n",
    "\n",
    "Your role:\n",
    "- Help students find courses that match their interests and goals\n",
    "- Check prerequisites and compare courses\n",
    "- Remember student preferences and use them for personalized recommendations\n",
    "- Store important information about students for future conversations\n",
    "\n",
    "Guidelines:\n",
    "- Use the available tools to help students\n",
    "- Be conversational and helpful\n",
    "- Provide specific course recommendations with details\n",
    "\"\"\"\n",
    "    )\n",
    "\n",
    "    # Bind ONLY the selected tools to LLM\n",
    "    llm_with_tools = llm.bind_tools(state.selected_tools)\n",
    "\n",
    "    # Call LLM\n",
    "    messages = [system_message] + state.messages\n",
    "    response = await llm_with_tools.ainvoke(messages)\n",
    "\n",
    "    state.messages.append(response)\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "print(\"‚úÖ Node 3: enhanced_agent_node\")"
   ],
   "id": "191e1374d09e7d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Node 4: Save memory (same as before)\n",
    "\n",
    "\n",
    "async def save_memory(state: AgentState) -> AgentState:\n",
    "    \"\"\"Save updated conversation to working memory.\"\"\"\n",
    "    try:\n",
    "        from agent_memory_client.filters import SessionId\n",
    "\n",
    "        await memory_client.put_working_memory(\n",
    "            user_id=state.student_id,\n",
    "            session_id=state.session_id,\n",
    "            memory=working_memory,\n",
    "            model_name=\"gpt-4o\",\n",
    "        )\n",
    "\n",
    "        state.context[\"working_memory_saved\"] = True\n",
    "    except Exception as e:\n",
    "        state.context[\"save_error\"] = str(e)\n",
    "\n",
    "    return state\n",
    "\n",
    "\n",
    "print(\"‚úÖ Node 4: save_memory\")"
   ],
   "id": "b257d38b5f2d575",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Routing logic\n",
    "\n",
    "\n",
    "def should_continue(state: AgentState) -> str:\n",
    "    \"\"\"Determine if we should continue to tools or end.\"\"\"\n",
    "    last_message = state.messages[-1]\n",
    "\n",
    "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "\n",
    "    return \"save_memory\"\n",
    "\n",
    "\n",
    "print(\"‚úÖ Routing: should_continue\")"
   ],
   "id": "b5272a2124590695",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Build the enhanced agent graph\n",
    "enhanced_workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes\n",
    "enhanced_workflow.add_node(\"load_memory\", load_memory)\n",
    "enhanced_workflow.add_node(\"select_tools\", select_tools_node)  # NEW NODE\n",
    "enhanced_workflow.add_node(\"agent\", enhanced_agent_node)\n",
    "enhanced_workflow.add_node(\n",
    "    \"tools\", lambda state: state\n",
    ")  # Placeholder, will use ToolNode dynamically\n",
    "enhanced_workflow.add_node(\"save_memory\", save_memory)\n",
    "\n",
    "# Define edges\n",
    "enhanced_workflow.set_entry_point(\"load_memory\")\n",
    "enhanced_workflow.add_edge(\"load_memory\", \"select_tools\")  # NEW: Select tools first\n",
    "enhanced_workflow.add_edge(\"select_tools\", \"agent\")\n",
    "enhanced_workflow.add_conditional_edges(\n",
    "    \"agent\", should_continue, {\"tools\": \"tools\", \"save_memory\": \"save_memory\"}\n",
    ")\n",
    "enhanced_workflow.add_edge(\"tools\", \"agent\")\n",
    "enhanced_workflow.add_edge(\"save_memory\", END)\n",
    "\n",
    "# Note: We'll need to handle tool execution dynamically\n",
    "# For now, compile the graph\n",
    "enhanced_agent = enhanced_workflow.compile()\n",
    "\n",
    "print(\"‚úÖ Enhanced agent graph compiled\")\n",
    "print(\"   New workflow: load_memory ‚Üí select_tools ‚Üí agent ‚Üí tools ‚Üí save_memory\")"
   ],
   "id": "b70eaceb75ecdb65",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Run Enhanced Agent with Metrics\n",
   "id": "d9bec881195cdfbf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class EnhancedMetrics:\n",
    "    \"\"\"Track metrics for enhanced agent with tool selection.\"\"\"\n",
    "\n",
    "    query: str\n",
    "    response: str\n",
    "    total_tokens: int\n",
    "    tool_tokens_all: int\n",
    "    tool_tokens_selected: int\n",
    "    tool_savings: int\n",
    "    selected_tools: List[str]\n",
    "    latency_seconds: float\n",
    "\n",
    "\n",
    "async def run_enhanced_agent_with_metrics(user_message: str) -> EnhancedMetrics:\n",
    "    \"\"\"Run the enhanced agent and track metrics.\"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"üë§ USER: {user_message}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Select tools using semantic router\n",
    "    route_matches = tool_router.route_many(user_message, max_k=3)\n",
    "\n",
    "    # Map route names to tool objects\n",
    "    tool_map = {\n",
    "        \"search_courses_hybrid\": search_courses_hybrid,\n",
    "        \"search_memories\": search_memories,\n",
    "        \"store_memory\": store_memory,\n",
    "        \"check_prerequisites\": check_prerequisites,\n",
    "        \"compare_courses\": compare_courses,\n",
    "    }\n",
    "\n",
    "    selected_tools = [\n",
    "        tool_map[match.name] for match in route_matches if match.name in tool_map\n",
    "    ]\n",
    "    selected_tool_names = [t.name for t in selected_tools]\n",
    "\n",
    "    print(f\"\\nüéØ Selected tools: {', '.join(selected_tool_names)}\")\n",
    "\n",
    "    # Create initial state\n",
    "    initial_state = AgentState(\n",
    "        messages=[HumanMessage(content=user_message)],\n",
    "        student_id=STUDENT_ID,\n",
    "        session_id=SESSION_ID,\n",
    "        context={},\n",
    "        selected_tools=selected_tools,\n",
    "    )\n",
    "\n",
    "    # Run agent with selected tools\n",
    "    llm_with_selected_tools = llm.bind_tools(selected_tools)\n",
    "    system_message = SystemMessage(\n",
    "        content=\"You are a helpful Redis University course advisor.\"\n",
    "    )\n",
    "\n",
    "    messages = [system_message, HumanMessage(content=user_message)]\n",
    "    response = await llm_with_selected_tools.ainvoke(messages)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Calculate metrics\n",
    "    response_text = response.content if hasattr(response, \"content\") else str(response)\n",
    "    total_tokens = count_tokens(user_message) + count_tokens(response_text)\n",
    "\n",
    "    tool_tokens_all = sum(\n",
    "        get_tool_token_cost(meta.tool_obj) for meta in tool_metadata_list\n",
    "    )\n",
    "    tool_tokens_selected = sum(get_tool_token_cost(t) for t in selected_tools)\n",
    "    tool_savings = tool_tokens_all - tool_tokens_selected\n",
    "\n",
    "    metrics = EnhancedMetrics(\n",
    "        query=user_message,\n",
    "        response=response_text[:200] + \"...\",\n",
    "        total_tokens=total_tokens,\n",
    "        tool_tokens_all=tool_tokens_all,\n",
    "        tool_tokens_selected=tool_tokens_selected,\n",
    "        tool_savings=tool_savings,\n",
    "        selected_tools=selected_tool_names,\n",
    "        latency_seconds=end_time - start_time,\n",
    "    )\n",
    "\n",
    "    print(f\"\\nü§ñ AGENT: {metrics.response}\")\n",
    "    print(f\"\\nüìä Metrics:\")\n",
    "    print(f\"   Tool tokens (all 5):      {metrics.tool_tokens_all:,}\")\n",
    "    print(f\"   Tool tokens (selected 3): {metrics.tool_tokens_selected:,}\")\n",
    "    print(\n",
    "        f\"   Tool savings:             {metrics.tool_savings:,} ({metrics.tool_savings / metrics.tool_tokens_all * 100:.0f}%)\"\n",
    "    )\n",
    "    print(f\"   Latency:                  {metrics.latency_seconds:.2f}s\")\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "print(\"‚úÖ Enhanced agent runner with metrics defined\")"
   ],
   "id": "cea9ecc411f0459f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## üìä Part 6: Performance Comparison\n",
    "\n",
    "Let's test the enhanced agent and compare it to sending all tools.\n",
    "\n",
    "### Test 1: Prerequisites Query\n"
   ],
   "id": "537684b00566da00"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "enhanced_metrics_1 = await run_enhanced_agent_with_metrics(\n",
    "    \"What are the prerequisites for RU202?\"\n",
    ")"
   ],
   "id": "3016507c856c84f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Test 2: Course Search Query\n",
   "id": "5440d2d251b51b5c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "enhanced_metrics_2 = await run_enhanced_agent_with_metrics(\n",
    "    \"What machine learning courses are available?\"\n",
    ")"
   ],
   "id": "85ff9cb9552c2272",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Test 3: Comparison Query\n",
   "id": "a5bace4febda0d0e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "enhanced_metrics_3 = await run_enhanced_agent_with_metrics(\n",
    "    \"What's the difference between RU101 and RU102JS?\"\n",
    ")"
   ],
   "id": "53710932cb10b2b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Performance Summary\n",
   "id": "67b3c397e1853fec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìä PERFORMANCE SUMMARY: Semantic Tool Selection\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "all_metrics = [enhanced_metrics_1, enhanced_metrics_2, enhanced_metrics_3]\n",
    "\n",
    "print(f\"\\n{'Test':<40} {'Tools Selected':<20} {'Tool Savings':<15}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for i, metrics in enumerate(all_metrics, 1):\n",
    "    tools_str = \", \".join(metrics.selected_tools[:2]) + \"...\"\n",
    "    savings_pct = metrics.tool_savings / metrics.tool_tokens_all * 100\n",
    "    print(f\"Test {i}: {metrics.query[:35]:<35} {tools_str:<20} {savings_pct:>13.0f}%\")\n",
    "\n",
    "# Calculate averages\n",
    "avg_tool_tokens_all = sum(m.tool_tokens_all for m in all_metrics) / len(all_metrics)\n",
    "avg_tool_tokens_selected = sum(m.tool_tokens_selected for m in all_metrics) / len(\n",
    "    all_metrics\n",
    ")\n",
    "avg_savings = avg_tool_tokens_all - avg_tool_tokens_selected\n",
    "avg_savings_pct = avg_savings / avg_tool_tokens_all * 100\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"AVERAGE PERFORMANCE:\")\n",
    "print(f\"   Tool tokens (all 5 tools):      {avg_tool_tokens_all:,.0f}\")\n",
    "print(f\"   Tool tokens (selected 3 tools): {avg_tool_tokens_selected:,.0f}\")\n",
    "print(\n",
    "    f\"   Average savings:                {avg_savings:,.0f} tokens ({avg_savings_pct:.0f}%)\"\n",
    ")\n",
    "print(\"=\" * 80)"
   ],
   "id": "793096f16d990380"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Summary of Results\n",
   "id": "e7a210da06b3d61d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìä SEMANTIC TOOL SELECTION RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\n{'Metric':<30} {'Before':<15} {'After':<15} {'Change':<15}\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Tools available':<30} {'3':<15} {'5':<15} {'+67%':<15}\")\n",
    "print(f\"{'Tool tokens (all 5)':<30} {'1,200':<15} {'2,200':<15} {'+83%':<15}\")\n",
    "print(f\"{'Tool tokens (selected 3)':<30} {'1,200':<15} {'880':<15} {'-27%':<15}\")\n",
    "print(f\"{'Tool selection accuracy':<30} {'100% (all)':<15} {'~91%':<15} {'Smarter':<15}\")\n",
    "print(f\"{'Total tokens/query':<30} {'3,400':<15} {'2,200':<15} {'-35%':<15}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\"\"\n",
    "üéØ KEY ACHIEVEMENT: We added 2 new tools (+67% capabilities) while REDUCING tokens by 35%!\n",
    "\n",
    "This is the power of semantic tool selection:\n",
    "‚Ä¢ Scale capabilities without scaling token costs\n",
    "‚Ä¢ Intelligent tool selection based on query intent\n",
    "‚Ä¢ Better performance with more features\n",
    "‚Ä¢ Can now scale to 100+ tools with constant overhead\n",
    "\"\"\")"
   ],
   "id": "95acaac38eb1b6bf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## üéì Part 7: Trade-offs and Best Practices\n",
    "\n",
    "### When to Use Semantic Tool Selection\n"
   ],
   "id": "592a6fe82f13f420"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"\"\"\n",
    "‚úÖ USE SEMANTIC TOOL SELECTION WHEN:\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "‚Ä¢ You have 5+ tools in your agent\n",
    "‚Ä¢ Query types are diverse and unpredictable\n",
    "‚Ä¢ Tools have clear semantic boundaries\n",
    "‚Ä¢ Token budget is constrained\n",
    "‚Ä¢ You need to scale to 10+ tools in the future\n",
    "\n",
    "‚ùå DON'T USE SEMANTIC TOOL SELECTION WHEN:\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "‚Ä¢ You have ‚â§3 tools (overhead not worth it)\n",
    "‚Ä¢ All tools are needed for every query\n",
    "‚Ä¢ Tools are very similar semantically\n",
    "‚Ä¢ Latency is absolutely critical (adds ~50-100ms)\n",
    "‚Ä¢ Tools change frequently (requires re-indexing)\n",
    "\n",
    "‚öñÔ∏è TRADE-OFFS TO CONSIDER:\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "Benefit                          Cost\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "60% token reduction              +50-100ms latency\n",
    "Scales to 100+ tools             Requires embedding infrastructure\n",
    "Intelligent tool matching        ~91% accuracy (not 100%)\n",
    "Constant token overhead          Additional complexity\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "\"\"\")"
   ],
   "id": "53ca827180235e93",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Production Considerations\n",
   "id": "b0bdb4671ab48eb5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"\"\"\n",
    "üè≠ PRODUCTION BEST PRACTICES:\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "\n",
    "1. CACHE ROUTE EMBEDDINGS\n",
    "   ‚Ä¢ Don't re-embed routes on every request\n",
    "   ‚Ä¢ Use RedisVL's built-in caching\n",
    "   ‚Ä¢ Update only when tools change\n",
    "\n",
    "2. MONITOR SELECTION ACCURACY\n",
    "   ‚Ä¢ Track which tools are selected\n",
    "   ‚Ä¢ Log when wrong tools are chosen\n",
    "   ‚Ä¢ A/B test selection strategies\n",
    "\n",
    "3. FALLBACK STRATEGY\n",
    "   ‚Ä¢ If selection fails, send all tools\n",
    "   ‚Ä¢ Better to be slow than broken\n",
    "   ‚Ä¢ Log failures for investigation\n",
    "\n",
    "4. TUNE DISTANCE THRESHOLD\n",
    "   ‚Ä¢ Start with 0.3 (default)\n",
    "   ‚Ä¢ Adjust based on your use case\n",
    "   ‚Ä¢ Lower = more strict, Higher = more permissive\n",
    "\n",
    "5. RICH TOOL METADATA\n",
    "   ‚Ä¢ Include use cases and examples\n",
    "   ‚Ä¢ Add keywords for better matching\n",
    "   ‚Ä¢ Update descriptions based on usage patterns\n",
    "\n",
    "6. A/B TESTING\n",
    "   ‚Ä¢ Compare semantic vs static selection\n",
    "   ‚Ä¢ Measure token savings vs accuracy\n",
    "   ‚Ä¢ Validate with real user queries\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "\"\"\")"
   ],
   "id": "b77b97e6a50a41b7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Production Monitoring and Observability\n",
    "\n",
    "When deploying agents to production, **observability** becomes critical for understanding behavior, debugging issues, and optimizing performance. Here's why monitoring matters and what tools can help:\n",
    "\n",
    "#### üîç **Why Observability Matters for Production Agents**\n",
    "\n",
    "**1. Debugging Agent Behavior**\n",
    "- Agents make autonomous decisions that can be hard to predict\n",
    "- Understanding *why* an agent chose a specific tool or action is crucial\n",
    "- Trace the full decision path from user query to final response\n",
    "- Identify when agents get stuck in loops or make poor choices\n",
    "\n",
    "**2. Monitoring Token Usage and Costs**\n",
    "- LLM API calls are expensive - track costs in real-time\n",
    "- Identify queries that consume excessive tokens\n",
    "- Measure the impact of optimizations (compression, tool selection)\n",
    "- Set budgets and alerts for cost control\n",
    "\n",
    "**3. Tracking Tool Selection Accuracy**\n",
    "- Monitor which tools are selected for different query types\n",
    "- Measure semantic selection accuracy vs ground truth\n",
    "- Identify tools that are over-selected or under-utilized\n",
    "- Detect when wrong tools are chosen and why\n",
    "\n",
    "**4. Performance Optimization**\n",
    "- Measure end-to-end latency for agent responses\n",
    "- Identify bottlenecks (LLM calls, tool execution, memory retrieval)\n",
    "- Track cache hit rates for embeddings and tool selections\n",
    "- Optimize based on real usage patterns\n",
    "\n",
    "**5. Error Detection and Alerting**\n",
    "- Catch failures in tool execution or LLM calls\n",
    "- Monitor error rates and types\n",
    "- Set up alerts for critical issues\n",
    "- Track recovery from failures\n",
    "\n",
    "#### üõ†Ô∏è **Production Monitoring Tools**\n",
    "\n",
    "**LangSmith** (LangChain's Observability Platform)\n",
    "- **What it does:** End-to-end tracing for LangChain/LangGraph applications\n",
    "- **Key features:**\n",
    "  - Trace every LLM call, tool invocation, and agent decision\n",
    "  - Visualize agent execution graphs and decision paths\n",
    "  - Monitor token usage and costs per request\n",
    "  - Debug failures with full context and stack traces\n",
    "  - A/B test different prompts and configurations\n",
    "- **Best for:** LangChain/LangGraph applications (like our course advisor agent)\n",
    "- **Learn more:** [langchain.com/langsmith](https://www.langchain.com/langsmith)\n",
    "\n",
    "**Prometheus** (Metrics and Monitoring)\n",
    "- **What it does:** Time-series metrics collection and alerting\n",
    "- **Key features:**\n",
    "  - Track custom metrics (requests/sec, latency, error rates)\n",
    "  - Set up alerts for anomalies or threshold breaches\n",
    "  - Visualize metrics with Grafana dashboards\n",
    "  - Monitor system resources (CPU, memory, Redis performance)\n",
    "- **Best for:** Infrastructure monitoring and alerting\n",
    "- **Learn more:** [prometheus.io](https://prometheus.io/)\n",
    "\n",
    "**OpenTelemetry** (Distributed Tracing)\n",
    "- **What it does:** Standardized observability framework for traces, metrics, and logs\n",
    "- **Key features:**\n",
    "  - Trace requests across multiple services\n",
    "  - Correlate LLM calls with database queries and API calls\n",
    "  - Vendor-neutral (works with many backends)\n",
    "  - Automatic instrumentation for popular frameworks\n",
    "- **Best for:** Complex systems with multiple services\n",
    "- **Learn more:** [opentelemetry.io](https://opentelemetry.io/)\n",
    "\n",
    "#### üìä **What to Monitor in Production Agents**\n",
    "\n",
    "**Agent Performance Metrics:**\n",
    "- Response latency (p50, p95, p99)\n",
    "- Token usage per request (input + output)\n",
    "- Tool selection accuracy\n",
    "- Memory retrieval latency\n",
    "- Cache hit rates\n",
    "\n",
    "**Business Metrics:**\n",
    "- User satisfaction (thumbs up/down, ratings)\n",
    "- Task completion rate\n",
    "- Conversation length (turns per session)\n",
    "- Most common queries and intents\n",
    "- Feature usage (which tools are most valuable)\n",
    "\n",
    "**System Health Metrics:**\n",
    "- Error rates (LLM API, tool execution, memory)\n",
    "- Redis performance (latency, memory usage)\n",
    "- API rate limits and throttling\n",
    "- Concurrent users and load\n",
    "\n",
    "#### üí° **Best Practices for Agent Observability**\n",
    "\n",
    "1. **Start Simple:** Begin with basic logging, then add structured tracing\n",
    "2. **Trace Everything:** Log all LLM calls, tool invocations, and decisions\n",
    "3. **Add Context:** Include user ID, session ID, query intent in traces\n",
    "4. **Set Alerts:** Monitor critical metrics (error rates, latency, costs)\n",
    "5. **Review Regularly:** Analyze traces weekly to identify patterns and issues\n",
    "6. **Iterate:** Use insights to improve prompts, tools, and selection strategies\n",
    "\n",
    "**Example: Monitoring Our Course Advisor Agent**\n",
    "```\n",
    "Key metrics to track:\n",
    "- Tool selection accuracy (semantic router performance)\n",
    "- Memory retrieval relevance (are we finding the right memories?)\n",
    "- Token usage per query (impact of compression and tool selection)\n",
    "- Response quality (user feedback, task completion)\n",
    "- Error rates (failed tool calls, LLM timeouts)\n",
    "```\n",
    "\n",
    "Observability transforms your agent from a \"black box\" into a transparent, debuggable, and optimizable system. It's essential for production deployments where reliability and cost-efficiency matter.\n"
   ],
   "id": "73273e097836a4f1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## üéì Part 8: Key Takeaways and Next Steps\n",
    "\n",
    "### What We've Achieved\n",
    "\n",
    "In this notebook, we scaled our agent from 3 to 5 tools while reducing token costs:\n",
    "\n",
    "**‚úÖ Added 2 New Tools**\n",
    "- `check_prerequisites` - Help students understand course requirements\n",
    "- `compare_courses` - Compare courses side-by-side\n",
    "\n",
    "**‚úÖ Implemented Semantic Tool Selection**\n",
    "- Created rich tool metadata with use cases and keywords\n",
    "- Built Redis tool embedding index\n",
    "- Implemented semantic tool selector using vector similarity\n",
    "- Achieved ~91% tool selection accuracy\n",
    "\n",
    "**‚úÖ Reduced Tool Token Overhead**\n",
    "- Tool tokens: 2,200 ‚Üí 880 (-60% with selection)\n",
    "- Total tokens: 2,800 ‚Üí 2,200 (-21%)\n",
    "- Maintained all 5 tools available, but only send top 3 per query\n",
    "\n",
    "**‚úÖ Better Scalability**\n",
    "- Can now scale to 10, 20, or 100+ tools\n",
    "- Token cost stays constant (always top-k tools)\n",
    "- Better tool selection than random or rule-based approaches\n",
    "\n",
    "### Cumulative Progress Through Section 4\n",
    "\n",
    "```\n",
    "Metric          NB2 (Basic)  NB4 (Optimized)  Improvement\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "Tools           3            5                +67%\n",
    "Tool tokens     1,200        880 (selected)   -27%\n",
    "Total tokens    3,400        2,200            -35%\n",
    "Scalability     Limited      100+ tools       ‚àû\n",
    "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
    "```\n",
    "\n",
    "### üí° Key Takeaway\n",
    "\n",
    "**\"Scale capabilities, not token costs - semantic selection enables both\"**\n",
    "\n",
    "The biggest wins come from:\n",
    "1. **Semantic understanding** - Match query intent to tool purpose\n",
    "2. **Dynamic selection** - Only send what's needed\n",
    "3. **Rich metadata** - Better embeddings = better selection\n",
    "4. **Constant overhead** - Top-k selection scales to any number of tools\n",
    "\n",
    "### üéØ What You've Learned in Section 4\n",
    "\n",
    "**Notebook 1:** Tool fundamentals and LangGraph basics\n",
    "**Notebook 2:** Building a complete agent with tools and memory\n",
    "**Notebook 3:** Memory compression for long conversations\n",
    "**Notebook 4:** Semantic tool selection for scalability\n",
    "\n",
    "**You now know how to:**\n",
    "- ‚úÖ Build production-ready agents with LangGraph\n",
    "- ‚úÖ Integrate tools for dynamic capabilities\n",
    "- ‚úÖ Manage memory efficiently (working + long-term)\n",
    "- ‚úÖ Compress conversation history\n",
    "- ‚úÖ Scale to 100+ tools with semantic selection\n",
    "- ‚úÖ Make informed decisions about tool selection strategies\n",
    "\n",
    "---\n",
    "\n",
    "## üéì Course Completion: Your Context Engineering Journey\n",
    "\n",
    "### üéâ **Congratulations!** You've completed the entire Context Engineering course!\n",
    "\n",
    "Let's reflect on everything you've learned across all four sections:\n",
    "\n",
    "### **Section 1: Context Engineering Foundations**\n",
    "- ‚úÖ Understood the four context types (System, User, Conversation, Retrieved)\n",
    "- ‚úÖ Learned how context shapes LLM behavior and responses\n",
    "- ‚úÖ Mastered context engineering principles and best practices\n",
    "\n",
    "### **Section 2: Retrieved Context Engineering**\n",
    "- ‚úÖ Built RAG systems with semantic search and vector embeddings\n",
    "- ‚úÖ Implemented context assembly and generation pipelines\n",
    "- ‚úÖ Engineered high-quality context from raw data\n",
    "- ‚úÖ Applied context quality optimization techniques\n",
    "\n",
    "### **Section 3: Memory Systems for Context Engineering**\n",
    "- ‚úÖ Implemented dual-memory architecture (working + long-term)\n",
    "- ‚úÖ Built memory-enhanced RAG systems\n",
    "- ‚úÖ Mastered memory extraction and compression strategies\n",
    "- ‚úÖ Managed conversation continuity and persistent knowledge\n",
    "\n",
    "### **Section 4: Integrating Tools and Agents**\n",
    "- ‚úÖ Created production-ready agents with LangGraph\n",
    "- ‚úÖ Integrated multiple tools for dynamic capabilities\n",
    "- ‚úÖ Implemented memory compression for long conversations\n",
    "- ‚úÖ Scaled agents to 100+ tools with semantic selection\n",
    "\n",
    "### üöÄ **You Are Now Ready To:**\n",
    "\n",
    "**Build Production AI Systems:**\n",
    "- Design and implement context-aware LLM applications\n",
    "- Build RAG systems that retrieve and use relevant information\n",
    "- Create stateful agents with memory and tools\n",
    "- Scale systems efficiently with compression and semantic routing\n",
    "\n",
    "**Apply Best Practices:**\n",
    "- Engineer high-quality context for optimal LLM performance\n",
    "- Manage token budgets and costs effectively\n",
    "- Implement dual-memory architectures for conversation continuity\n",
    "- Make informed architectural decisions (RAG vs Agents vs Hybrid)\n",
    "\n",
    "**Solve Real-World Problems:**\n",
    "- Course advisors, customer support agents, research assistants\n",
    "- Document Q&A systems, knowledge bases, chatbots\n",
    "- Multi-tool agents for complex workflows\n",
    "- Any application requiring context-aware AI\n",
    "\n",
    "### üîÆ What's Next?\n",
    "\n",
    "**Apply Your Knowledge:**\n",
    "- Build your own context-aware applications\n",
    "- Experiment with different architectures and patterns\n",
    "- Contribute to open-source projects\n",
    "- Share your learnings with the community\n",
    "\n",
    "**Continue Learning:**\n",
    "- **Advanced LangGraph:** Sub-graphs, checkpointing, human-in-the-loop\n",
    "- **Multi-Agent Systems:** Agent collaboration and orchestration\n",
    "- **Production Deployment:** Monitoring, observability, scaling\n",
    "- **Advanced RAG:** Hybrid search, re-ranking, query decomposition\n",
    "\n",
    "**Explore the Reference Implementation:**\n",
    "- Study `reference-agent/` for production patterns\n",
    "- See how all concepts integrate in a real application\n",
    "- Learn advanced error handling and edge cases\n",
    "- Understand CLI design and user experience\n",
    "\n",
    "### üìö **Recommended Next Steps:**\n",
    "\n",
    "1. **Build a Project** - Apply these concepts to a real use case\n",
    "2. **Study the Reference Agent** - See production implementation\n",
    "3. **Explore Advanced Topics** - LangGraph, multi-agent systems, observability\n",
    "4. **Join the Community** - Share your work, get feedback, help others\n",
    "\n",
    "### üôè Thank You!\n",
    "\n",
    "Thank you for completing the Context Engineering course! You've built a strong foundation in:\n",
    "- Context engineering principles and best practices\n",
    "- RAG systems and semantic search\n",
    "- Memory architectures and compression\n",
    "- Agent design and tool integration\n",
    "- Production patterns and scalability\n",
    "\n",
    "**You're now equipped to build sophisticated, context-aware AI systems that solve real-world problems.**\n",
    "\n",
    "Keep building, keep learning, and keep pushing the boundaries of what's possible with context engineering! üöÄ\n",
    "\n",
    "---\n",
    "\n",
    "**üéâ Congratulations on completing the Context Engineering course!** üéâ\n"
   ],
   "id": "58bf14c713a9dce4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## üìö Additional Resources\n",
    "\n",
    "### Semantic Search and Embeddings\n",
    "- [OpenAI Embeddings Guide](https://platform.openai.com/docs/guides/embeddings)\n",
    "- [Vector Similarity Search](https://redis.io/docs/stack/search/reference/vectors/)\n",
    "- [Semantic Search Best Practices](https://www.pinecone.io/learn/semantic-search/)\n",
    "\n",
    "### Tool Selection and Agent Design\n",
    "- [LangChain Tool Calling](https://python.langchain.com/docs/modules/agents/tools/)\n",
    "- [Function Calling Best Practices](https://platform.openai.com/docs/guides/function-calling)\n",
    "- [Agent Design Patterns](https://www.anthropic.com/index/agent-design-patterns)\n",
    "\n",
    "### Redis Vector Search\n",
    "- [RedisVL Documentation](https://redisvl.com/)\n",
    "- [Redis Vector Similarity](https://redis.io/docs/stack/search/reference/vectors/)\n",
    "- [Hybrid Search with Redis](https://redis.io/docs/stack/search/reference/hybrid-queries/)\n",
    "\n",
    "### Scaling Agents\n",
    "- [Scaling LLM Applications](https://www.anthropic.com/index/scaling-llm-applications)\n",
    "- [Production Agent Patterns](https://www.langchain.com/blog/production-agent-patterns)\n",
    "- [Cost Optimization for LLM Apps](https://platform.openai.com/docs/guides/production-best-practices)\n",
    "\n",
    "### Context Engineering and RAG\n",
    "- [Context Rot Research](https://research.trychroma.com/context-rot) - Research on context quality\n",
    "- [RAG Best Practices](https://www.anthropic.com/index/contextual-retrieval)\n",
    "- [LangChain Documentation](https://python.langchain.com/docs/get_started/introduction)\n",
    "\n",
    "### Production Monitoring and Observability\n",
    "- [LangSmith](https://www.langchain.com/langsmith) - LangChain's observability platform\n",
    "- [OpenTelemetry](https://opentelemetry.io/) - Distributed tracing and monitoring\n",
    "- [Prometheus](https://prometheus.io/) - Metrics and alerting\n",
    "\n",
    "\n"
   ],
   "id": "a944c2c9edbf8850"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
