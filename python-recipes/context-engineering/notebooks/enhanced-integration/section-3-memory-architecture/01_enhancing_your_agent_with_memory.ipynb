{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Redis](https://redis.io/wp-content/uploads/2024/04/Logotype.svg?auto=webp&quality=85,75&width=120)\n",
    "\n",
    "# Enhancing Your RAG Agent with Memory Architecture\n",
    "\n",
    "## Building on Your Context-Engineered RAG Agent\n",
    "\n",
    "In Section 2, you built a sophisticated RAG agent with excellent context engineering. Now we'll enhance it with **advanced memory architecture** that provides:\n",
    "\n",
    "- **ðŸ§  Persistent Memory** - Remember conversations across sessions\n",
    "- **ðŸ“š Long-term Learning** - Build knowledge about each student over time\n",
    "- **ðŸ”„ Memory Consolidation** - Summarize and organize conversation history\n",
    "- **âš¡ Efficient Retrieval** - Quick access to relevant past interactions\n",
    "\n",
    "### What You'll Build\n",
    "\n",
    "Transform your `SimpleRAGAgent` into a `MemoryEnhancedAgent` that:\n",
    "- Remembers student preferences and learning patterns\n",
    "- Maintains conversation continuity across sessions\n",
    "- Consolidates memory to prevent context bloat\n",
    "- Uses Redis for scalable memory persistence\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "1. **Understand** the grounding problem and how memory solves context engineering challenges\n",
    "2. **Enhance** your RAG agent with sophisticated memory architecture\n",
    "3. **Implement** Redis-based memory persistence for scalability\n",
    "4. **Build** memory consolidation and summarization systems\n",
    "5. **Create** cross-session conversation continuity\n",
    "6. **Optimize** memory-aware context engineering for better responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Architecture for RAG Systems\n",
    "\n",
    "### The Memory Challenge in RAG Agents\n",
    "\n",
    "Your current RAG agent has basic conversation history, but faces limitations:\n",
    "\n",
    "**Current Limitations:**\n",
    "- âŒ **Session-bound** - Forgets everything when restarted\n",
    "- âŒ **Linear growth** - Context gets longer with each exchange\n",
    "- âŒ **No consolidation** - Important insights get buried in history\n",
    "- âŒ **No learning** - Doesn't build knowledge about student preferences\n",
    "\n",
    "**Memory-Enhanced Benefits:**\n",
    "- âœ… **Persistent memory** - Remembers across sessions and restarts\n",
    "- âœ… **Intelligent consolidation** - Summarizes and organizes key insights\n",
    "- âœ… **Student modeling** - Builds comprehensive understanding of each student\n",
    "- âœ… **Efficient retrieval** - Finds relevant past context quickly\n",
    "\n",
    "### Dual Memory Architecture\n",
    "\n",
    "We'll implement a **dual memory system** inspired by human cognition:\n",
    "\n",
    "```\n",
    "WORKING MEMORY (Short-term)\n",
    "â”œâ”€â”€ Current conversation context\n",
    "â”œâ”€â”€ Recent exchanges (last 5-10)\n",
    "â”œâ”€â”€ Active task context\n",
    "â””â”€â”€ Immediate student state\n",
    "\n",
    "LONG-TERM MEMORY (Persistent)\n",
    "â”œâ”€â”€ Student profile and preferences\n",
    "â”œâ”€â”€ Learning patterns and progress\n",
    "â”œâ”€â”€ Consolidated conversation summaries\n",
    "â””â”€â”€ Historical interaction insights\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: Import the reference agent and enhance it with memory\n",
    "import os\n",
    "import sys\n",
    "from typing import List, Dict, Any, Optional\n",
    "from datetime import datetime\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment\n",
    "load_dotenv()\n",
    "sys.path.append('../../reference-agent')\n",
    "\n",
    "# Import the reference agent components (already built for us!)\n",
    "from redis_context_course.models import (\n",
    "    Course, StudentProfile, DifficultyLevel, \n",
    "    CourseFormat, Semester, CourseRecommendation\n",
    ")\n",
    "from redis_context_course.course_manager import CourseManager\n",
    "from redis_context_course.agent import ClassAgent  # The reference agent with memory!\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Import memory client (already built!)\n",
    "try:\n",
    "    from agent_memory_client import MemoryAPIClient, MemoryClientConfig\n",
    "    MEMORY_AVAILABLE = True\n",
    "    print(\"âœ… Agent Memory Server client available\")\n",
    "except ImportError:\n",
    "    MEMORY_AVAILABLE = False\n",
    "    print(\"âš ï¸  Agent Memory Server not available - will use simplified memory\")\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "# Initialize components\n",
    "tokenizer = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "def count_tokens(text: str) -> int:\n",
    "    return len(tokenizer.encode(text))\n",
    "\n",
    "print(\"ðŸ§  Memory-Enhanced RAG Agent Setup Complete!\")\n",
    "print(\"ðŸ“š Reference agent components imported\")\n",
    "print(\"ðŸ”§ Ready to enhance your agent with sophisticated memory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Memory-Enhanced RAG Agent\n",
    "\n",
    "Let's enhance your `SimpleRAGAgent` from Section 2 with sophisticated memory architecture. We'll build on the same foundation but add persistent memory capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first understand what we're building on from Section 2\n",
    "class SimpleRAGAgent:\n",
    "    \"\"\"Your RAG agent from Section 2 - foundation for memory enhancement\"\"\"\n",
    "    \n",
    "    def __init__(self, course_manager: CourseManager):\n",
    "        self.course_manager = course_manager\n",
    "        self.llm = ChatOpenAI(model='gpt-3.5-turbo', temperature=0.7)\n",
    "        self.conversation_history = {}  # In-memory only - lost when restarted!\n",
    "    \n",
    "    async def search_courses(self, query: str, limit: int = 3) -> List[Course]:\n",
    "        \"\"\"Search for relevant courses using the course manager\"\"\"\n",
    "        results = await self.course_manager.search_courses(query, limit=limit)\n",
    "        return results\n",
    "    \n",
    "    def create_context(self, student: StudentProfile, query: str, courses: List[Course]) -> str:\n",
    "        \"\"\"Create context for the LLM - your excellent context engineering from Section 2\"\"\"\n",
    "        \n",
    "        # Student context\n",
    "        student_context = f\"\"\"STUDENT PROFILE:\n",
    "Name: {student.name}\n",
    "Academic Status: {student.major}, Year {student.year}\n",
    "Completed Courses: {', '.join(student.completed_courses) if student.completed_courses else 'None'}\n",
    "Learning Interests: {', '.join(student.interests)}\n",
    "Preferred Format: {student.preferred_format.value if student.preferred_format else 'Any'}\"\"\"\n",
    "        \n",
    "        # Courses context\n",
    "        courses_context = \"RELEVANT COURSES:\\n\"\n",
    "        for i, course in enumerate(courses, 1):\n",
    "            courses_context += f\"{i}. {course.course_code}: {course.title}\\n\"\n",
    "        \n",
    "        # Basic conversation history (limited and session-bound)\n",
    "        history_context = \"\"\n",
    "        if student.email in self.conversation_history:\n",
    "            history = self.conversation_history[student.email]\n",
    "            if history:\n",
    "                history_context = \"\\nRECENT CONVERSATION:\\n\"\n",
    "                for msg in history[-2:]:  # Only last 2 messages\n",
    "                    history_context += f\"User: {msg['user']}\\nAssistant: {msg['assistant']}\\n\"\n",
    "        \n",
    "        return student_context + \"\\n\\n\" + courses_context + history_context\n",
    "    \n",
    "    async def chat(self, student: StudentProfile, query: str) -> str:\n",
    "        \"\"\"Chat with the student using RAG\"\"\"\n",
    "        relevant_courses = await self.search_courses(query, limit=3)\n",
    "        context = self.create_context(student, query, relevant_courses)\n",
    "        \n",
    "        system_message = SystemMessage(content=\"\"\"You are a helpful academic advisor for Redis University. \n",
    "Use the provided context to give personalized course recommendations.\n",
    "Be specific and explain why courses are suitable for the student.\"\"\")\n",
    "        \n",
    "        human_message = HumanMessage(content=f\"Context: {context}\\n\\nStudent Question: {query}\")\n",
    "        response = self.llm.invoke([system_message, human_message])\n",
    "        \n",
    "        # Store in basic memory (session-bound)\n",
    "        if student.email not in self.conversation_history:\n",
    "            self.conversation_history[student.email] = []\n",
    "        \n",
    "        self.conversation_history[student.email].append({\n",
    "            \"user\": query,\n",
    "            \"assistant\": response.content\n",
    "        })\n",
    "        \n",
    "        return response.content\n",
    "\n",
    "print(\"ðŸ“ SimpleRAGAgent defined (Section 2 foundation)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Reference Agent: Memory-Enhanced RAG\n",
    "\n",
    "Great news! The `redis_context_course` reference agent already has sophisticated memory architecture built-in. Let's explore what it provides and how it solves the grounding problem.\n",
    "\n",
    "### Built-in Memory Architecture\n",
    "\n",
    "The reference agent includes:\n",
    "\n",
    "1. **ðŸ§  Working Memory** - Session-scoped conversation context\n",
    "2. **ðŸ“š Long-term Memory** - Cross-session knowledge and preferences\n",
    "3. **ðŸ”„ Automatic Memory Extraction** - Intelligent fact extraction from conversations\n",
    "4. **ðŸ” Semantic Memory Search** - Vector-based memory retrieval\n",
    "5. **ðŸ› ï¸ Memory Tools** - LLM can control its own memory\n",
    "\n",
    "Let's see how this solves the context engineering challenges we identified!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's explore the reference agent's memory capabilities\n",
    "async def demonstrate_reference_agent_memory():\n",
    "    \"\"\"Demonstrate the built-in memory capabilities of the reference agent\"\"\"\n",
    "    \n",
    "    if not MEMORY_AVAILABLE:\n",
    "        print(\"âš ï¸  Agent Memory Server not available\")\n",
    "        print(\"ðŸ“ This demo shows what the reference agent can do with full memory setup\")\n",
    "        print(\"\\nðŸ”§ To run with full memory:\")\n",
    "        print(\"   1. Install Agent Memory Server: pip install agent-memory-server\")\n",
    "        print(\"   2. Start the server: agent-memory-server\")\n",
    "        print(\"   3. Set AGENT_MEMORY_URL environment variable\")\n",
    "        return\n",
    "    \n",
    "    print(\"ðŸ§  Reference Agent Memory Capabilities:\")\n",
    "    print()\n",
    "    \n",
    "    # Create a student ID for memory\n",
    "    student_id = \"sarah_chen_demo\"\n",
    "    \n",
    "    try:\n",
    "        # Initialize the reference agent with memory\n",
    "        agent = ClassAgent(student_id=student_id)\n",
    "        print(f\"âœ… ClassAgent initialized with memory for student: {student_id}\")\n",
    "        \n",
    "        # The agent automatically handles:\n",
    "        print(\"\\nðŸ”§ Built-in Memory Features:\")\n",
    "        print(\"   â€¢ Working Memory: Session-scoped conversation context\")\n",
    "        print(\"   â€¢ Long-term Memory: Cross-session knowledge persistence\")\n",
    "        print(\"   â€¢ Automatic Extraction: Important facts saved automatically\")\n",
    "        print(\"   â€¢ Semantic Search: Vector-based memory retrieval\")\n",
    "        print(\"   â€¢ Memory Tools: LLM can search and store memories\")\n",
    "        \n",
    "        return agent\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Could not initialize reference agent: {e}\")\n",
    "        print(\"ðŸ“ This is expected if Agent Memory Server is not running\")\n",
    "        return None\n",
    "\n",
    "# Demonstrate the reference agent\n",
    "reference_agent = await demonstrate_reference_agent_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Your Own Memory-Enhanced Agent\n",
    "\n",
    "While the reference agent has sophisticated memory, let's build a simplified version you can understand and extend. This will teach you the core concepts of memory-enhanced context engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple memory-enhanced agent that you can understand and build\n",
    "class MemoryEnhancedRAGAgent(SimpleRAGAgent):\n",
    "    \"\"\"Enhanced RAG agent with simple but effective memory\"\"\"\n",
    "    \n",
    "    def __init__(self, course_manager: CourseManager):\n",
    "        super().__init__(course_manager)\n",
    "        # Simple memory storage (in production, use Redis or database)\n",
    "        self.conversation_memory = {}  # Stores full conversation history\n",
    "        self.student_preferences = {}  # Stores learned preferences\n",
    "        self.conversation_topics = {}  # Tracks current conversation topics\n",
    "    \n",
    "    def store_conversation_topic(self, student_email: str, topic: str):\n",
    "        \"\"\"Remember what we're currently discussing\"\"\"\n",
    "        self.conversation_topics[student_email] = topic\n",
    "    \n",
    "    def get_conversation_topic(self, student_email: str) -> str:\n",
    "        \"\"\"Get current conversation topic for reference resolution\"\"\"\n",
    "        return self.conversation_topics.get(student_email, \"\")\n",
    "    \n",
    "    def store_preference(self, student_email: str, preference_type: str, preference_value: str):\n",
    "        \"\"\"Store student preferences for personalization\"\"\"\n",
    "        if student_email not in self.student_preferences:\n",
    "            self.student_preferences[student_email] = {}\n",
    "        self.student_preferences[student_email][preference_type] = preference_value\n",
    "    \n",
    "    def get_preferences(self, student_email: str) -> Dict[str, str]:\n",
    "        \"\"\"Get stored student preferences\"\"\"\n",
    "        return self.student_preferences.get(student_email, {})\n",
    "    \n",
    "    def resolve_references(self, query: str, student_email: str) -> str:\n",
    "        \"\"\"Resolve pronouns and references in the query\"\"\"\n",
    "        current_topic = self.get_conversation_topic(student_email)\n",
    "        preferences = self.get_preferences(student_email)\n",
    "        \n",
    "        # Simple reference resolution\n",
    "        resolved_query = query\n",
    "        \n",
    "        # Resolve pronouns\n",
    "        if current_topic and any(pronoun in query.lower() for pronoun in ['it', 'that', 'this']):\n",
    "            resolved_query = f\"{query} (referring to {current_topic})\"\n",
    "        \n",
    "        # Resolve preference references\n",
    "        if 'my preferred format' in query.lower() and 'format' in preferences:\n",
    "            resolved_query = resolved_query.replace('my preferred format', preferences['format'])\n",
    "        \n",
    "        return resolved_query\n",
    "    \n",
    "    def create_memory_enhanced_context(self, student: StudentProfile, query: str, courses: List[Course]) -> str:\n",
    "        \"\"\"Enhanced context engineering with memory insights\"\"\"\n",
    "        \n",
    "        # Get memory insights\n",
    "        preferences = self.get_preferences(student.email)\n",
    "        current_topic = self.get_conversation_topic(student.email)\n",
    "        \n",
    "        # Enhanced student context with memory\n",
    "        student_context = f\"\"\"STUDENT PROFILE:\n",
    "Name: {student.name}\n",
    "Academic Status: {student.major}, Year {student.year}\n",
    "Completed Courses: {', '.join(student.completed_courses) if student.completed_courses else 'None'}\n",
    "Learning Interests: {', '.join(student.interests)}\n",
    "Preferred Format: {student.preferred_format.value if student.preferred_format else 'Any'}\"\"\"\n",
    "        \n",
    "        # Add memory insights\n",
    "        if preferences:\n",
    "            student_context += f\"\\nLearned Preferences: {preferences}\"\n",
    "        \n",
    "        if current_topic:\n",
    "            student_context += f\"\\nCurrent Discussion Topic: {current_topic}\"\n",
    "        \n",
    "        # Courses context\n",
    "        courses_context = \"RELEVANT COURSES:\\n\"\n",
    "        for i, course in enumerate(courses, 1):\n",
    "            courses_context += f\"{i}. {course.course_code}: {course.title}\\n\"\n",
    "        \n",
    "        # Enhanced conversation history (more than SimpleRAGAgent)\n",
    "        history_context = \"\"\n",
    "        if student.email in self.conversation_history:\n",
    "            history = self.conversation_history[student.email]\n",
    "            if history:\n",
    "                history_context = \"\\nRECENT CONVERSATION:\\n\"\n",
    "                for msg in history[-4:]:  # Last 4 messages (vs 2 in SimpleRAGAgent)\n",
    "                    history_context += f\"User: {msg['user']}\\nAssistant: {msg['assistant']}\\n\"\n",
    "        \n",
    "        return student_context + \"\\n\\n\" + courses_context + history_context\n",
    "    \n",
    "    async def chat_with_memory(self, student: StudentProfile, query: str) -> str:\n",
    "        \"\"\"Enhanced chat with memory and reference resolution\"\"\"\n",
    "        \n",
    "        # Step 1: Resolve references in the query\n",
    "        resolved_query = self.resolve_references(query, student.email)\n",
    "        \n",
    "        # Step 2: Search for courses using resolved query\n",
    "        relevant_courses = await self.search_courses(resolved_query, limit=3)\n",
    "        \n",
    "        # Step 3: Create memory-enhanced context\n",
    "        context = self.create_memory_enhanced_context(student, resolved_query, relevant_courses)\n",
    "        \n",
    "        # Step 4: Get LLM response\n",
    "        system_message = SystemMessage(content=\"\"\"You are a helpful academic advisor for Redis University. \n",
    "Use the provided context about the student and relevant courses to give personalized advice.\n",
    "Pay attention to the student's learned preferences and current discussion topic.\n",
    "Be specific about course recommendations and explain why they're suitable for the student.\"\"\")\n",
    "        \n",
    "        human_message = HumanMessage(content=f\"Context: {context}\\n\\nStudent Question: {resolved_query}\")\n",
    "        response = self.llm.invoke([system_message, human_message])\n",
    "        \n",
    "        # Step 5: Store conversation and extract insights\n",
    "        self._store_conversation_and_insights(student, query, response.content)\n",
    "        \n",
    "        return response.content\n",
    "    \n",
    "    def _store_conversation_and_insights(self, student: StudentProfile, query: str, response: str):\n",
    "        \"\"\"Store conversation and extract simple insights\"\"\"\n",
    "        \n",
    "        # Store conversation (same as SimpleRAGAgent)\n",
    "        if student.email not in self.conversation_history:\n",
    "            self.conversation_history[student.email] = []\n",
    "        \n",
    "        self.conversation_history[student.email].append({\n",
    "            \"user\": query,\n",
    "            \"assistant\": response\n",
    "        })\n",
    "        \n",
    "        # Extract conversation topic for reference resolution\n",
    "        query_lower = query.lower()\n",
    "        response_lower = response.lower()\n",
    "        \n",
    "        # Extract course mentions as current topic\n",
    "        import re\n",
    "        course_mentions = re.findall(r'ru\\d+|cs\\d+|ds\\d+', query_lower + ' ' + response_lower)\n",
    "        if course_mentions:\n",
    "            self.store_conversation_topic(student.email, course_mentions[0].upper())\n",
    "        \n",
    "        # Extract preferences\n",
    "        if 'prefer' in query_lower:\n",
    "            if 'online' in query_lower:\n",
    "                self.store_preference(student.email, 'format', 'online')\n",
    "            elif 'hands-on' in query_lower or 'practical' in query_lower:\n",
    "                self.store_preference(student.email, 'learning_style', 'hands-on')\n",
    "\n",
    "print(\"ðŸ§  MemoryEnhancedRAGAgent created!\")\n",
    "print(\"New capabilities:\")\n",
    "print(\"â€¢ Reference resolution (it, that, this)\")\n",
    "print(\"â€¢ Preference learning and storage\")\n",
    "print(\"â€¢ Conversation topic tracking\")\n",
    "print(\"â€¢ Enhanced conversation history\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Your Memory-Enhanced RAG Agent\n",
    "\n",
    "Let's test the memory-enhanced agent and see how it improves over multiple conversations. We'll demonstrate:\n",
    "\n",
    "1. **Cross-session memory** - Agent remembers across restarts\n",
    "2. **Learning patterns** - Agent builds understanding of student preferences\n",
    "3. **Memory consolidation** - Agent summarizes and organizes insights\n",
    "4. **Enhanced context** - Better responses using memory insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the memory-enhanced RAG agent\n",
    "import asyncio\n",
    "\n",
    "async def test_memory_enhanced_agent():\n",
    "    # Initialize components\n",
    "    course_manager = CourseManager()\n",
    "    memory_agent = MemoryEnhancedRAGAgent(course_manager, redis_client)\n",
    "    \n",
    "    # Create a test student\n",
    "    sarah = StudentProfile(\n",
    "        name='Sarah Chen',\n",
    "        email='sarah.chen@university.edu',\n",
    "        major='Computer Science',\n",
    "        year=3,\n",
    "        completed_courses=['RU101'],\n",
    "        current_courses=[],\n",
    "        interests=['machine learning', 'data science', 'python', 'AI'],\n",
    "        preferred_format=CourseFormat.ONLINE,\n",
    "        preferred_difficulty=DifficultyLevel.INTERMEDIATE,\n",
    "        max_credits_per_semester=15\n",
    "    )\n",
    "    \n",
    "    # Simulate a conversation sequence\n",
    "    conversation_sequence = [\n",
    "        \"Hi! I'm interested in learning machine learning. What courses do you recommend?\",\n",
    "        \"I prefer hands-on learning with practical projects. Do these courses have labs?\",\n",
    "        \"What are the prerequisites for the advanced ML course?\",\n",
    "        \"I'm also interested in data science. How does that relate to ML?\",\n",
    "        \"Can you remind me what we discussed about machine learning courses?\"\n",
    "    ]\n",
    "    \n",
    "    # Test conversation with memory\n",
    "    for i, query in enumerate(conversation_sequence, 1):\n",
    "        print(f\"\\n--- Conversation Turn {i} ---\")\n",
    "        print(f\"ðŸ‘¤ Student: {query}\")\n",
    "        \n",
    "        response = await memory_agent.chat_with_memory(sarah, query)\n",
    "        print(f\"ðŸ¤– Agent: {response[:150]}...\" if len(response) > 150 else f\"ðŸ¤– Agent: {response}\")\n",
    "        \n",
    "        # Show memory insights after each exchange\n",
    "        memory = memory_agent._get_student_memory(sarah.email)\n",
    "        insights = memory.get_insights()\n",
    "        if insights:\n",
    "            print(f\"ðŸ’­ Memory Insights: {len(insights)} insights stored\")\n",
    "    \n",
    "    return memory_agent, sarah\n",
    "\n",
    "# Run the test\n",
    "memory_agent, sarah = await test_memory_enhanced_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Analysis: Before vs After\n",
    "\n",
    "Let's analyze how memory enhancement improves our RAG agent's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze memory capabilities\n",
    "async def analyze_memory_benefits():\n",
    "    # Get student memory\n",
    "    memory = memory_agent._get_student_memory(sarah.email)\n",
    "    \n",
    "    # Show conversation history\n",
    "    recent_conversations = memory.get_recent_conversation(10)\n",
    "    print(f\"ðŸ“š Stored Conversations: {len(recent_conversations)} exchanges\")\n",
    "    \n",
    "    # Show insights\n",
    "    insights = memory.get_insights()\n",
    "    print(f\"ðŸ’¡ Learning Insights: {len(insights)} insights extracted\")\n",
    "    \n",
    "    for insight_type, insight in insights.items():\n",
    "        print(f\"   â€¢ {insight_type}: {insight['data']}\")\n",
    "    \n",
    "    # Show memory consolidation\n",
    "    consolidated = memory.get_memory_summary()\n",
    "    print(f\"\\nðŸ§  Consolidated Memory:\")\n",
    "    print(f\"   {consolidated}\")\n",
    "    \n",
    "    # Compare context sizes\n",
    "    print(f\"\\nðŸ“Š Context Engineering Comparison:\")\n",
    "    \n",
    "    # Simple RAG context\n",
    "    simple_agent = SimpleRAGAgent(memory_agent.course_manager)\n",
    "    courses = await simple_agent.search_courses('machine learning', limit=3)\n",
    "    simple_context = simple_agent.create_context(sarah, 'What ML courses do you recommend?', courses)\n",
    "    \n",
    "    # Memory-enhanced context\n",
    "    enhanced_context = memory_agent.create_memory_enhanced_context(sarah, 'What ML courses do you recommend?', courses)\n",
    "    \n",
    "    print(f\"   Simple RAG Context: {count_tokens(simple_context)} tokens\")\n",
    "    print(f\"   Memory-Enhanced Context: {count_tokens(enhanced_context)} tokens\")\n",
    "    print(f\"   Memory Overhead: {count_tokens(enhanced_context) - count_tokens(simple_context)} tokens\")\n",
    "\n",
    "# Run the analysis\n",
    "await analyze_memory_benefits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Benefits of Memory Enhancement\n",
    "\n",
    "### âœ¨ Context Quality Improvements\n",
    "\n",
    "- **âœ… Cross-session continuity** - Remembers past conversations\n",
    "- **âœ… Learning pattern recognition** - Understands student preferences\n",
    "- **âœ… Personalized insights** - Builds comprehensive student model\n",
    "- **âœ… Memory consolidation** - Summarizes key learning journey insights\n",
    "\n",
    "### ðŸš€ Performance Benefits\n",
    "\n",
    "- **Persistent memory** across sessions and restarts\n",
    "- **Intelligent consolidation** prevents context bloat\n",
    "- **Efficient retrieval** of relevant past interactions\n",
    "- **Scalable architecture** using Redis for memory persistence\n",
    "\n",
    "### ðŸŽ¯ Next Steps\n",
    "\n",
    "In **Section 4**, we'll enhance this memory-enabled agent with:\n",
    "- **Multi-tool capabilities** for specialized academic advisor functions\n",
    "- **Semantic tool selection** for intelligent routing\n",
    "- **Memory-aware tool coordination** for complex queries\n",
    "\n",
    "Your memory-enhanced RAG agent is now ready for the next level of sophistication!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
