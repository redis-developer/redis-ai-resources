{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Redis](https://redis.io/wp-content/uploads/2024/04/Logotype.svg?auto=webp&quality=85,75&width=120)\n",
    "\n",
    "# The Grounding Problem: Why Agents Need Memory\n",
    "\n",
    "Before diving into implementation, let's understand the fundamental problem that memory solves.\n",
    "\n",
    "## The Grounding Problem\n",
    "\n",
    "**Grounding** means understanding what users are referring to. Natural conversation is full of references:\n",
    "\n",
    "**Without Memory:**\n",
    "```\n",
    "User: \"Tell me about CS401\"\n",
    "Agent: \"CS401 is Machine Learning. It covers supervised learning...\"\n",
    "\n",
    "User: \"What are its prerequisites?\"\n",
    "Agent: ❌ \"What does 'its' refer to? Please specify which course.\"\n",
    "\n",
    "User: \"The course we just discussed!\"\n",
    "Agent: ❌ \"I don't have access to previous messages. Which course?\"\n",
    "```\n",
    "\n",
    "**This is a terrible user experience.**\n",
    "\n",
    "### Types of References That Need Grounding\n",
    "\n",
    "**Pronouns:**\n",
    "- \"it\", \"that course\", \"those\", \"this one\"\n",
    "- \"he\", \"she\", \"they\" (referring to people)\n",
    "\n",
    "**Descriptions:**\n",
    "- \"the easy one\", \"the online course\"\n",
    "- \"my advisor\", \"that professor\"\n",
    "\n",
    "**Implicit context:**\n",
    "- \"Can I take it?\" → Take what?\n",
    "- \"When does it start?\" → What starts?\n",
    "\n",
    "**Temporal references:**\n",
    "- \"you mentioned\", \"earlier\", \"last time\"\n",
    "\n",
    "### How Working Memory Provides Grounding\n",
    "\n",
    "**With Working Memory:**\n",
    "```\n",
    "User: \"Tell me about CS401\"\n",
    "Agent: \"CS401 is Machine Learning. It covers...\"\n",
    "[Stores: User asked about CS401]\n",
    "\n",
    "User: \"What are its prerequisites?\"\n",
    "Agent: [Checks memory: \"its\" = CS401]\n",
    "Agent: ✅ \"CS401 requires CS201 and MATH301\"\n",
    "\n",
    "User: \"Can I take it?\"\n",
    "Agent: [Checks memory: \"it\" = CS401]\n",
    "Agent: [Checks student transcript]\n",
    "Agent: ✅ \"You've completed CS201 but still need MATH301\"\n",
    "```\n",
    "\n",
    "**Now the conversation flows naturally!**\n",
    "\n",
    "### What Working Memory Stores\n",
    "\n",
    "Working memory maintains the **current conversation context**:\n",
    "\n",
    "```\n",
    "Session: session_123\n",
    "Messages:\n",
    "  1. User: \"Tell me about CS401\"\n",
    "  2. Agent: \"CS401 is Machine Learning...\"\n",
    "  3. User: \"What are its prerequisites?\"\n",
    "  4. Agent: \"CS401 requires CS201 and MATH301\"\n",
    "  5. User: \"Can I take it?\"\n",
    "  [Current turn - needs context from messages 1-4]\n",
    "```\n",
    "\n",
    "**Each message builds on previous messages.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Memory: Every Message is Isolated\n",
    "\n",
    "```\n",
    "Turn 1: User asks about CS401\n",
    "        → Agent responds\n",
    "        → Agent forgets everything ❌\n",
    "\n",
    "Turn 2: User asks \"What are its prerequisites?\"\n",
    "        → Agent doesn't know what \"its\" refers to ❌\n",
    "        → Conversation breaks ❌\n",
    "```\n",
    "\n",
    "### The Problem This Notebook Solves\n",
    "\n",
    "**Working memory** stores conversation messages so that:\n",
    "\n",
    "✅ Pronouns can be resolved (\"it\" → CS401)  \n",
    "✅ Context carries forward (knows what was discussed)  \n",
    "✅ Multi-turn conversations work naturally  \n",
    "✅ Users don't repeat themselves  \n",
    "\n",
    "**Now let's implement this solution.**\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "- **Working Memory**: Session-scoped storage for conversation messages and context\n",
    "- **Session Scope**: Working memory is tied to a specific conversation session\n",
    "- **Message History**: The sequence of user and assistant messages that form the conversation\n",
    "- **Grounding**: Using stored context to understand what users are referring to\n",
    "\n",
    "### Technical Implementation\n",
    "\n",
    "Working memory solves the grounding problem by:\n",
    "- Storing conversation messages so the LLM can reference earlier parts of the conversation\n",
    "- Maintaining task-specific context (like current goals, preferences mentioned in this session)\n",
    "- Persisting this information across multiple turns of the conversation\n",
    "- Providing a foundation for extracting important information to long-term storage\n",
    "\n",
    "Because working memory stores messages, we can extract long-term data from it. When using the Agent Memory Server, extraction happens automatically in the background based on a configured strategy that controls what kind of information gets extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Verify required environment variables are set\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    raise ValueError(\n",
    "        \"OPENAI_API_KEY not found. Please create a .env file with your OpenAI API key. \"\n",
    "        \"See SETUP.md for instructions.\"\n",
    "    )\n",
    "\n",
    "print(\"✅ Environment variables loaded\")\n",
    "print(f\"   REDIS_URL: {os.getenv('REDIS_URL', 'redis://localhost:6379')}\")\n",
    "print(f\"   AGENT_MEMORY_URL: {os.getenv('AGENT_MEMORY_URL', 'http://localhost:8000')}\")\n",
    "print(f\"   OPENAI_API_KEY: {'✓ Set' if os.getenv('OPENAI_API_KEY') else '✗ Not set'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrating the Grounding Problem\n",
    "\n",
    "Let's create a simple agent **without memory** to show how the grounding problem breaks conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "class MemorylessAgent:\n",
    "    \"\"\"An agent without memory - demonstrates the grounding problem\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.7)\n",
    "    \n",
    "    def chat(self, user_message: str) -> str:\n",
    "        \"\"\"Process a single message with no memory of previous messages\"\"\"\n",
    "        messages = [\n",
    "            SystemMessage(content=\"You are a helpful academic advisor. Answer the user's question.\"),\n",
    "            HumanMessage(content=user_message)\n",
    "        ]\n",
    "        \n",
    "        response = self.llm.invoke(messages)\n",
    "        return response.content\n",
    "\n",
    "# Create the memoryless agent\n",
    "agent = MemorylessAgent()\n",
    "print(\"🤖 Memoryless agent created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstration 1: Pronoun References Break\n",
    "\n",
    "Watch what happens when we use pronouns like \"it\", \"that\", \"this\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== PRONOUN REFERENCE PROBLEM ===\")\n",
    "print()\n",
    "\n",
    "# First message - establishes context\n",
    "message1 = \"Tell me about CS401 Machine Learning\"\n",
    "print(f\"👤 User: {message1}\")\n",
    "\n",
    "response1 = agent.chat(message1)\n",
    "print(f\"🤖 Agent: {response1}\")\n",
    "print()\n",
    "\n",
    "# Second message - uses pronoun reference\n",
    "message2 = \"What are its prerequisites?\"\n",
    "print(f\"👤 User: {message2}\")\n",
    "print(\"💭 Human thinking: 'its' refers to CS401 from the previous question\")\n",
    "\n",
    "response2 = agent.chat(message2)\n",
    "print(f\"🤖 Agent: {response2}\")\n",
    "print()\n",
    "\n",
    "print(\"❌ PROBLEM: Agent can't resolve 'its' because it has no memory of CS401!\")\n",
    "print(\"💡 SOLUTION: Working memory would remember CS401 was the topic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstration 2: Temporal References Break\n",
    "\n",
    "Users often refer to previous parts of the conversation with phrases like \"you mentioned\", \"earlier\", \"last time\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== TEMPORAL REFERENCE PROBLEM ===\")\n",
    "print()\n",
    "\n",
    "# First message - agent gives advice\n",
    "message1 = \"What should I take after completing CS201?\"\n",
    "print(f\"👤 User: {message1}\")\n",
    "\n",
    "response1 = agent.chat(message1)\n",
    "print(f\"🤖 Agent: {response1}\")\n",
    "print()\n",
    "\n",
    "# Second message - refers to previous advice\n",
    "message2 = \"How long will the course you mentioned take?\"\n",
    "print(f\"👤 User: {message2}\")\n",
    "print(\"💭 Human thinking: 'course you mentioned' = the course from the previous response\")\n",
    "\n",
    "response2 = agent.chat(message2)\n",
    "print(f\"🤖 Agent: {response2}\")\n",
    "print()\n",
    "\n",
    "print(\"❌ PROBLEM: Agent doesn't remember what course it recommended!\")\n",
    "print(\"💡 SOLUTION: Working memory would store the conversation history\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstration 3: Implicit Context Breaks\n",
    "\n",
    "Sometimes users ask questions that depend on implicit context from earlier in the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== IMPLICIT CONTEXT PROBLEM ===\")\n",
    "print()\n",
    "\n",
    "# First message - establishes context\n",
    "message1 = \"I'm interested in data science courses\"\n",
    "print(f\"👤 User: {message1}\")\n",
    "\n",
    "response1 = agent.chat(message1)\n",
    "print(f\"🤖 Agent: {response1}\")\n",
    "print()\n",
    "\n",
    "# Second message - implicit context\n",
    "message2 = \"Can I take it next semester?\"\n",
    "print(f\"👤 User: {message2}\")\n",
    "print(\"💭 Human thinking: 'it' refers to one of the data science courses mentioned\")\n",
    "\n",
    "response2 = agent.chat(message2)\n",
    "print(f\"🤖 Agent: {response2}\")\n",
    "print()\n",
    "\n",
    "print(\"❌ PROBLEM: Agent doesn't know what 'it' refers to!\")\n",
    "print(\"💡 SOLUTION: Working memory would maintain the conversation context\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Solution: Working Memory\n",
    "\n",
    "Working memory solves the grounding problem by storing conversation messages and context. This enables:\n",
    "\n",
    "### ✅ Reference Resolution\n",
    "- **Pronouns**: \"it\" → CS401 (from conversation history)\n",
    "- **Descriptions**: \"the easy one\" → beginner course mentioned earlier\n",
    "- **Temporal**: \"you mentioned\" → specific advice from previous response\n",
    "\n",
    "### ✅ Conversation Continuity\n",
    "- Each message builds on previous messages\n",
    "- Context carries forward naturally\n",
    "- Users don't need to repeat information\n",
    "\n",
    "### ✅ Natural User Experience\n",
    "- Conversations flow like human-to-human interaction\n",
    "- Users can use natural language patterns\n",
    "- No need to be overly explicit about references\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "In the next notebook, we'll implement working memory and show how it solves these grounding problems. You'll see how to:\n",
    "\n",
    "1. **Store conversation messages** in working memory\n",
    "2. **Provide conversation context** to the LLM\n",
    "3. **Enable reference resolution** for natural conversations\n",
    "4. **Build on this foundation** for more sophisticated memory systems\n",
    "\n",
    "**The grounding problem is fundamental to conversational AI - and working memory is the solution!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
