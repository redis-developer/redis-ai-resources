{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "![Redis](https://redis.io/wp-content/uploads/2024/04/Logotype.svg?auto=webp&quality=85,75&width=120)\n",
    "\n",
    "# ðŸ¤– Section 4: Building a Redis University Course Advisor Agent\n",
    "\n",
    "**â±ï¸ Estimated Time:** 60-75 minutes\n",
    "\n",
    "## ðŸŽ¯ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "\n",
    "1. **Build** a complete LangGraph agent with tools and memory\n",
    "2. **Implement** exactly 3 tools: memory storage, memory search, and course search\n",
    "3. **Integrate** Redis Agent Memory Server for dual-memory architecture\n",
    "4. **Visualize** the agent's decision-making graph\n",
    "5. **Demonstrate** the progression from RAG (Section 3) to full agent\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”— Bridge from Previous Sections\n",
    "\n",
    "### **Your Learning Journey:**\n",
    "\n",
    "**Section 1:** Context Types\n",
    "- System, User, Conversation, Retrieved context\n",
    "- How context shapes LLM responses\n",
    "\n",
    "**Section 2:** RAG Foundations\n",
    "- Semantic search with vector embeddings\n",
    "- Retrieving and presenting information\n",
    "- Single-step retrieval â†’ generation\n",
    "\n",
    "**Section 3:** Memory Architecture\n",
    "- Working memory (conversation continuity)\n",
    "- Long-term memory (persistent knowledge)\n",
    "- Memory-enhanced RAG systems\n",
    "\n",
    "**Section 4 (Notebook 1):** Tool-Calling Basics\n",
    "- What tools are and how LLMs use them\n",
    "- LangGraph fundamentals (nodes, edges, state)\n",
    "- Simple tool-calling examples\n",
    "- Agents vs RAG comparison\n",
    "\n",
    "### **What We're Building Now:**\n",
    "\n",
    "**A Full Agent** that combines everything:\n",
    "- âœ… **Tools** for actions (search courses, manage memory)\n",
    "- âœ… **Memory** for personalization (working + long-term)\n",
    "- âœ… **RAG** for course information (semantic search)\n",
    "- âœ… **LangGraph** for orchestration (state management)\n",
    "\n",
    "**ðŸ’¡ Key Insight:** This agent is RAG + Memory + Tools + Decision-Making\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“Š Agent Architecture\n",
    "\n",
    "### **The Complete Flow:**\n",
    "\n",
    "```\n",
    "User Query\n",
    "    â†“\n",
    "[Load Working Memory] â† Conversation history\n",
    "    â†“\n",
    "[Agent Node] â† Decides what to do\n",
    "    â†“\n",
    "    â”œâ”€â†’ [search_courses] â† Find relevant courses\n",
    "    â”œâ”€â†’ [search_memories] â† Recall user preferences\n",
    "    â”œâ”€â†’ [store_memory] â† Save important facts\n",
    "    â†“\n",
    "[Agent Node] â† Processes tool results\n",
    "    â†“\n",
    "[Generate Response] â† Final answer\n",
    "    â†“\n",
    "[Save Working Memory] â† Update conversation\n",
    "```\n",
    "\n",
    "### **Our 3 Tools:**\n",
    "\n",
    "1. **`search_courses`** - Semantic search over course catalog\n",
    "   - When: Student asks about courses, topics, or recommendations\n",
    "   - Example: \"What machine learning courses are available?\"\n",
    "\n",
    "2. **`search_memories`** - Search long-term memory for user facts\n",
    "   - When: Need to recall preferences, goals, or past interactions\n",
    "   - Example: \"What courses did I say I was interested in?\"\n",
    "\n",
    "3. **`store_memory`** - Save important information to long-term memory\n",
    "   - When: User shares preferences, goals, or important facts\n",
    "   - Example: \"I'm interested in AI and want to work at a startup\"\n",
    "\n",
    "### **Memory Architecture:**\n",
    "\n",
    "| Memory Type | Purpose | Managed By | Lifespan |\n",
    "|------------|---------|------------|----------|\n",
    "| **Working Memory** | Conversation history | Agent Memory Server | Session |\n",
    "| **Long-term Memory** | User preferences, facts | Agent Memory Server | Persistent |\n",
    "| **Graph State** | Current execution state | LangGraph | Single turn |\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“¦ Setup and Environment\n",
    "\n",
    "### âš ï¸ **CRITICAL: Prerequisites Required**\n",
    "\n",
    "**This notebook requires ALL services to be running. If any service is down, the agent will not work.**\n",
    "\n",
    "**Required Services:**\n",
    "1. **Redis** - Vector storage and caching (port 6379)\n",
    "2. **Agent Memory Server** - Memory management (port 8088)\n",
    "3. **OpenAI API** - LLM functionality\n",
    "\n",
    "**ðŸš€ Quick Setup (Run this first!):**\n",
    "```bash\n",
    "# Navigate to notebooks_v2 directory\n",
    "cd ../../\n",
    "\n",
    "# Check if services are running\n",
    "./check_setup.sh\n",
    "\n",
    "# If services are down, run setup\n",
    "./setup_memory_server.sh\n",
    "```\n",
    "\n",
    "**ðŸ“– Need help?** See `../SETUP_GUIDE.md` for detailed setup instructions.\n",
    "\n",
    "**ðŸ” Manual Check:**\n",
    "- Redis: `redis-cli ping` should return `PONG`\n",
    "- Memory Server: `curl http://localhost:8088/v1/health` should return `{\"status\":\"ok\"}`\n",
    "- Environment: Create `.env` file in `reference-agent/` with your `OPENAI_API_KEY`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "install-packages",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "install",
   "metadata": {},
   "source": [
    "### Automated Setup Check\n",
    "\n",
    "Let's run the setup script to ensure all services are running properly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "import-libraries",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T23:57:51.825255Z",
     "iopub.status.busy": "2025-10-31T23:57:51.825073Z",
     "iopub.status.idle": "2025-10-31T23:57:52.103012Z",
     "shell.execute_reply": "2025-10-31T23:57:52.102484Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running automated setup check...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”§ Agent Memory Server Setup\n",
      "===========================\n",
      "ðŸ“Š Checking Redis...\n",
      "âœ… Redis is running\n",
      "ðŸ“Š Checking Agent Memory Server...\n",
      "ðŸ” Agent Memory Server container exists. Checking health...\n",
      "âœ… Agent Memory Server is running and healthy\n",
      "âœ… No Redis connection issues detected\n",
      "\n",
      "âœ… Setup Complete!\n",
      "=================\n",
      "ðŸ“Š Services Status:\n",
      "   â€¢ Redis: Running on port 6379\n",
      "   â€¢ Agent Memory Server: Running on port 8088\n",
      "\n",
      "ðŸŽ¯ You can now run the notebooks!\n",
      "\n",
      "\n",
      "âœ… All services are ready!\n"
     ]
    }
   ],
   "source": [
    "# Run the setup script to ensure Redis and Agent Memory Server are running\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to setup script\n",
    "setup_script = Path(\"../../reference-agent/setup_agent_memory_server.py\")\n",
    "\n",
    "if setup_script.exists():\n",
    "    print(\"Running automated setup check...\\n\")\n",
    "    result = subprocess.run(\n",
    "        [sys.executable, str(setup_script)],\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    print(result.stdout)\n",
    "    if result.returncode != 0:\n",
    "        print(\"âš ï¸  Setup check failed. Please review the output above.\")\n",
    "        print(result.stderr)\n",
    "    else:\n",
    "        print(\"\\nâœ… All services are ready!\")\n",
    "else:\n",
    "    print(\"âš ï¸  Setup script not found. Please ensure services are running manually.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-env",
   "metadata": {},
   "source": [
    "### Install Dependencies\n",
    "\n",
    "If you haven't already installed the reference-agent package, uncomment and run the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "env-setup",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T23:57:52.104763Z",
     "iopub.status.busy": "2025-10-31T23:57:52.104657Z",
     "iopub.status.idle": "2025-10-31T23:57:52.106517Z",
     "shell.execute_reply": "2025-10-31T23:57:52.106037Z"
    }
   },
   "outputs": [],
   "source": [
    "# Uncomment to install reference-agent package\n",
    "# %pip install -q -e ../../reference-agent\n",
    "\n",
    "# Uncomment to install agent-memory-client\n",
    "# %pip install -q agent-memory-client\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "check-services",
   "metadata": {},
   "source": [
    "### Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "service-check",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T23:57:52.107702Z",
     "iopub.status.busy": "2025-10-31T23:57:52.107645Z",
     "iopub.status.idle": "2025-10-31T23:57:53.822487Z",
     "shell.execute_reply": "2025-10-31T23:57:53.821994Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Core libraries\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from typing import List, Dict, Any, Optional, Annotated\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# LangChain and LangGraph\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Redis and Agent Memory\n",
    "from agent_memory_client import MemoryAPIClient, MemoryClientConfig\n",
    "from agent_memory_client.models import WorkingMemory, MemoryMessage\n",
    "\n",
    "# Add reference-agent to path for course utilities\n",
    "sys.path.insert(0, os.path.abspath(\"../../reference-agent\"))\n",
    "from redis_context_course.course_manager import CourseManager\n",
    "from redis_context_course.models import StudentProfile, DifficultyLevel, CourseFormat\n",
    "\n",
    "print(\"âœ… Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "init-components",
   "metadata": {},
   "source": [
    "### Load Environment Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "init-course-manager",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T23:57:53.823677Z",
     "iopub.status.busy": "2025-10-31T23:57:53.823553Z",
     "iopub.status.idle": "2025-10-31T23:57:53.826253Z",
     "shell.execute_reply": "2025-10-31T23:57:53.825901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Environment configured successfully!\n",
      "   OpenAI API Key: ********************wTMA\n",
      "   Redis URL: redis://localhost:6379\n",
      "   Agent Memory URL: http://localhost:8088\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv(\"../../reference-agent/.env\")\n",
    "\n",
    "# Get configuration\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "REDIS_URL = os.getenv(\"REDIS_URL\", \"redis://localhost:6379\")\n",
    "AGENT_MEMORY_URL = os.getenv(\"AGENT_MEMORY_URL\", \"http://localhost:8088\")\n",
    "\n",
    "# Verify OpenAI API key\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"\"\"\n",
    "    âš ï¸  OPENAI_API_KEY not found!\n",
    "    \n",
    "    Please create a .env file in the reference-agent directory:\n",
    "    1. cd ../../reference-agent\n",
    "    2. cp .env.example .env\n",
    "    3. Edit .env and add your OpenAI API key\n",
    "    \"\"\")\n",
    "\n",
    "print(\"âœ… Environment configured successfully!\")\n",
    "print(f\"   OpenAI API Key: {'*' * 20}{OPENAI_API_KEY[-4:]}\")\n",
    "print(f\"   Redis URL: {REDIS_URL}\")\n",
    "print(f\"   Agent Memory URL: {AGENT_MEMORY_URL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "course-manager",
   "metadata": {},
   "source": [
    "### Check Required Services\n",
    "\n",
    "Let's verify that Redis and the Agent Memory Server are running.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "init-llm",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T23:57:53.827385Z",
     "iopub.status.busy": "2025-10-31T23:57:53.827318Z",
     "iopub.status.idle": "2025-10-31T23:57:53.839615Z",
     "shell.execute_reply": "2025-10-31T23:57:53.839213Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Redis is running\n",
      "âœ… Agent Memory Server is running\n",
      "\n",
      "âœ… All services are ready!\n"
     ]
    }
   ],
   "source": [
    "import redis\n",
    "import requests\n",
    "\n",
    "# Check Redis\n",
    "try:\n",
    "    redis_client = redis.from_url(REDIS_URL)\n",
    "    redis_client.ping()\n",
    "    print(\"âœ… Redis is running\")\n",
    "    REDIS_AVAILABLE = True\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Redis is not available: {e}\")\n",
    "    print(\"   Please start Redis using Docker:\")\n",
    "    print(\"   docker run -d -p 6379:6379 redis/redis-stack:latest\")\n",
    "    REDIS_AVAILABLE = False\n",
    "\n",
    "# Check Agent Memory Server\n",
    "try:\n",
    "    response = requests.get(f\"{AGENT_MEMORY_URL}/v1/health\", timeout=2)\n",
    "    if response.status_code == 200:\n",
    "        print(\"âœ… Agent Memory Server is running\")\n",
    "        MEMORY_SERVER_AVAILABLE = True\n",
    "    else:\n",
    "        print(f\"âš ï¸  Agent Memory Server returned status {response.status_code}\")\n",
    "        MEMORY_SERVER_AVAILABLE = False\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Agent Memory Server is not available: {e}\")\n",
    "    print(\"   Please start the Agent Memory Server:\")\n",
    "    print(\"   cd ../../reference-agent && python setup_agent_memory_server.py\")\n",
    "    MEMORY_SERVER_AVAILABLE = False\n",
    "\n",
    "if not (REDIS_AVAILABLE and MEMORY_SERVER_AVAILABLE):\n",
    "    print(\"\\nâš ï¸  Some services are not available. Please start them before continuing.\")\n",
    "else:\n",
    "    print(\"\\nâœ… All services are ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "llm-init",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ”§ Initialize Components\n",
    "\n",
    "Now let's initialize the components we'll use to build our agent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "init-memory",
   "metadata": {},
   "source": [
    "### Initialize Course Manager\n",
    "\n",
    "The `CourseManager` handles course storage and semantic search, just like in Section 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "memory-init",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T23:57:53.840793Z",
     "iopub.status.busy": "2025-10-31T23:57:53.840727Z",
     "iopub.status.idle": "2025-10-31T23:57:53.933415Z",
     "shell.execute_reply": "2025-10-31T23:57:53.933012Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:57:53 redisvl.index.index INFO   Index already exists, not overwriting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Course Manager initialized\n",
      "   Ready to search and retrieve courses\n"
     ]
    }
   ],
   "source": [
    "# Initialize Course Manager\n",
    "course_manager = CourseManager()\n",
    "\n",
    "print(\"âœ… Course Manager initialized\")\n",
    "print(\"   Ready to search and retrieve courses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "student-profile",
   "metadata": {},
   "source": [
    "### Initialize LLM\n",
    "\n",
    "We'll use GPT-4o with temperature=0.0 for consistent, deterministic responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "create-student",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T23:57:53.934684Z",
     "iopub.status.busy": "2025-10-31T23:57:53.934605Z",
     "iopub.status.idle": "2025-10-31T23:57:53.943986Z",
     "shell.execute_reply": "2025-10-31T23:57:53.943698Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LLM initialized\n",
      "   Model: gpt-4o\n",
      "   Temperature: 0.0 (deterministic)\n"
     ]
    }
   ],
   "source": [
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.0)\n",
    "\n",
    "print(\"âœ… LLM initialized\")\n",
    "print(\"   Model: gpt-4o\")\n",
    "print(\"   Temperature: 0.0 (deterministic)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tools-section",
   "metadata": {},
   "source": [
    "### Initialize Memory Client\n",
    "\n",
    "The memory client handles both working memory (conversation history) and long-term memory (persistent facts).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "tool-1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T23:57:53.945184Z",
     "iopub.status.busy": "2025-10-31T23:57:53.945115Z",
     "iopub.status.idle": "2025-10-31T23:57:53.950020Z",
     "shell.execute_reply": "2025-10-31T23:57:53.949643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Memory Client initialized\n",
      "   Base URL: http://localhost:8088\n",
      "   Namespace: redis_university\n",
      "   Ready for working memory and long-term memory operations\n"
     ]
    }
   ],
   "source": [
    "# Initialize Memory Client\n",
    "config = MemoryClientConfig(\n",
    "    base_url=AGENT_MEMORY_URL,\n",
    "    default_namespace=\"redis_university\"\n",
    ")\n",
    "memory_client = MemoryAPIClient(config=config)\n",
    "\n",
    "print(\"âœ… Memory Client initialized\")\n",
    "print(f\"   Base URL: {config.base_url}\")\n",
    "print(f\"   Namespace: {config.default_namespace}\")\n",
    "print(\"   Ready for working memory and long-term memory operations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "search-courses-tool",
   "metadata": {},
   "source": [
    "### Create Sample Student Profile\n",
    "\n",
    "We'll create a sample student to use throughout our demos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "tool-2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T23:57:53.951077Z",
     "iopub.status.busy": "2025-10-31T23:57:53.951016Z",
     "iopub.status.idle": "2025-10-31T23:57:53.953293Z",
     "shell.execute_reply": "2025-10-31T23:57:53.952950Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Student profile created\n",
      "   Name: Sarah Chen\n",
      "   Student ID: student_sarah_001\n",
      "   Session ID: session_student_sarah_001_20251031_195753\n",
      "   Major: Computer Science\n",
      "   Interests: machine learning, data science, algorithms\n"
     ]
    }
   ],
   "source": [
    "# Create sample student profile\n",
    "STUDENT_ID = \"student_sarah_001\"\n",
    "SESSION_ID = f\"session_{STUDENT_ID}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "\n",
    "sarah = StudentProfile(\n",
    "    name=\"Sarah Chen\",\n",
    "    email=\"sarah.chen@university.edu\",\n",
    "    major=\"Computer Science\",\n",
    "    year=2,\n",
    "    interests=[\"machine learning\", \"data science\", \"algorithms\"],\n",
    "    completed_courses=[\"Introduction to Programming\", \"Data Structures\"],\n",
    "    current_courses=[\"Linear Algebra\"],\n",
    "    preferred_format=CourseFormat.ONLINE,\n",
    "    preferred_difficulty=DifficultyLevel.INTERMEDIATE\n",
    ")\n",
    "\n",
    "print(\"âœ… Student profile created\")\n",
    "print(f\"   Name: {sarah.name}\")\n",
    "print(f\"   Student ID: {STUDENT_ID}\")\n",
    "print(f\"   Session ID: {SESSION_ID}\")\n",
    "print(f\"   Major: {sarah.major}\")\n",
    "print(f\"   Interests: {', '.join(sarah.interests)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "search-memories-tool",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ› ï¸ Part 1: Define the Agent's Tools\n",
    "\n",
    "Let's build our 3 tools step by step. Each tool will have:\n",
    "- Clear input schema (what parameters it accepts)\n",
    "- Descriptive docstring (tells the LLM when to use it)\n",
    "- Implementation (the actual logic)\n",
    "\n",
    "**Remember:** The LLM only sees the tool name, description, and parametersâ€”not the implementation!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tool-3",
   "metadata": {},
   "source": [
    "### Tool 1: `search_courses`\n",
    "\n",
    "This tool searches the course catalog using semantic search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "store-memory-tool",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T23:57:53.954314Z",
     "iopub.status.busy": "2025-10-31T23:57:53.954256Z",
     "iopub.status.idle": "2025-10-31T23:57:53.957045Z",
     "shell.execute_reply": "2025-10-31T23:57:53.956679Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Tool 1 defined: search_courses\n",
      "   Purpose: Search course catalog with semantic search\n",
      "   Parameters: query (str), limit (int)\n"
     ]
    }
   ],
   "source": [
    "# Define input schema\n",
    "class SearchCoursesInput(BaseModel):\n",
    "    \"\"\"Input schema for searching courses.\"\"\"\n",
    "    query: str = Field(\n",
    "        description=\"Natural language search query. Can be topics (e.g., 'machine learning'), \"\n",
    "                    \"characteristics (e.g., 'online courses'), or general questions \"\n",
    "                    \"(e.g., 'beginner programming courses')\"\n",
    "    )\n",
    "    limit: int = Field(\n",
    "        default=5,\n",
    "        description=\"Maximum number of results to return. Default is 5. \"\n",
    "                    \"Use 3 for quick answers, 10 for comprehensive results.\"\n",
    "    )\n",
    "\n",
    "# Define the tool\n",
    "@tool(\"search_courses\", args_schema=SearchCoursesInput)\n",
    "async def search_courses(query: str, limit: int = 5) -> str:\n",
    "    \"\"\"\n",
    "    Search for courses using semantic search based on topics, descriptions, or characteristics.\n",
    "    \n",
    "    Use this tool when students ask about:\n",
    "    - Topics or subjects: \"machine learning courses\", \"database courses\"\n",
    "    - Course characteristics: \"online courses\", \"beginner courses\", \"3-credit courses\"\n",
    "    - General exploration: \"what courses are available in AI?\"\n",
    "    \n",
    "    The search uses semantic matching, so natural language queries work well.\n",
    "    \n",
    "    Returns: Formatted list of matching courses with details.\n",
    "    \"\"\"\n",
    "    results = await course_manager.search_courses(query, limit=limit)\n",
    "    \n",
    "    if not results:\n",
    "        return \"No courses found matching your query.\"\n",
    "    \n",
    "    output = []\n",
    "    for course in results:\n",
    "        output.append(\n",
    "            f\"{course.course_code}: {course.title}\\n\"\n",
    "            f\"  Credits: {course.credits} | {course.format.value} | {course.difficulty_level.value}\\n\"\n",
    "            f\"  {course.description[:150]}...\"\n",
    "        )\n",
    "    \n",
    "    return \"\\n\\n\".join(output)\n",
    "\n",
    "print(\"âœ… Tool 1 defined: search_courses\")\n",
    "print(\"   Purpose: Search course catalog with semantic search\")\n",
    "print(\"   Parameters: query (str), limit (int)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tools-summary",
   "metadata": {},
   "source": [
    "### Tool 2: `search_memories`\n",
    "\n",
    "This tool searches long-term memory for user preferences and facts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "list-tools",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T23:57:53.958090Z",
     "iopub.status.busy": "2025-10-31T23:57:53.958029Z",
     "iopub.status.idle": "2025-10-31T23:57:53.960900Z",
     "shell.execute_reply": "2025-10-31T23:57:53.960462Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Tool 2 defined: search_memories\n",
      "   Purpose: Search long-term memory for user facts\n",
      "   Parameters: query (str), limit (int)\n"
     ]
    }
   ],
   "source": [
    "# Define input schema\n",
    "class SearchMemoriesInput(BaseModel):\n",
    "    \"\"\"Input schema for searching memories.\"\"\"\n",
    "    query: str = Field(\n",
    "        description=\"Natural language query to search for in user's long-term memory. \"\n",
    "                    \"Examples: 'career goals', 'course preferences', 'learning style'\"\n",
    "    )\n",
    "    limit: int = Field(\n",
    "        default=5,\n",
    "        description=\"Maximum number of memories to return. Default is 5.\"\n",
    "    )\n",
    "\n",
    "# Define the tool\n",
    "@tool(\"search_memories\", args_schema=SearchMemoriesInput)\n",
    "async def search_memories(query: str, limit: int = 5) -> str:\n",
    "    \"\"\"\n",
    "    Search the user's long-term memory for relevant facts, preferences, and past interactions.\n",
    "    \n",
    "    Use this tool when you need to:\n",
    "    - Recall user preferences: \"What format does the user prefer?\"\n",
    "    - Remember past goals: \"What career path is the user interested in?\"\n",
    "    - Find previous interactions: \"What courses did we discuss before?\"\n",
    "    - Personalize recommendations: \"What are the user's interests?\"\n",
    "    \n",
    "    The search uses semantic matching to find relevant memories.\n",
    "    \n",
    "    Returns: List of relevant memories with content and metadata.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from agent_memory_client.filters import UserId\n",
    "        \n",
    "        # Search long-term memory\n",
    "        results = await memory_client.search_long_term_memory(\n",
    "            text=query,\n",
    "            user_id=UserId(eq=STUDENT_ID),\n",
    "            limit=limit\n",
    "        )\n",
    "        \n",
    "        if not results.memories or len(results.memories) == 0:\n",
    "            return \"No relevant memories found.\"\n",
    "        \n",
    "        output = []\n",
    "        for i, memory in enumerate(results.memories, 1):\n",
    "            output.append(f\"{i}. {memory.text}\")\n",
    "            if memory.topics:\n",
    "                output.append(f\"   Topics: {', '.join(memory.topics)}\")\n",
    "        \n",
    "        return \"\\n\".join(output)\n",
    "    except Exception as e:\n",
    "        return f\"Error searching memories: {str(e)}\"\n",
    "\n",
    "print(\"âœ… Tool 2 defined: search_memories\")\n",
    "print(\"   Purpose: Search long-term memory for user facts\")\n",
    "print(\"   Parameters: query (str), limit (int)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agent-state",
   "metadata": {},
   "source": [
    "### Tool 3: `store_memory`\n",
    "\n",
    "This tool saves important information to long-term memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "define-state",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T23:57:53.962062Z",
     "iopub.status.busy": "2025-10-31T23:57:53.961995Z",
     "iopub.status.idle": "2025-10-31T23:57:53.964832Z",
     "shell.execute_reply": "2025-10-31T23:57:53.964534Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Tool 3 defined: store_memory\n",
      "   Purpose: Save important facts to long-term memory\n",
      "   Parameters: text (str), memory_type (str), topics (List[str])\n"
     ]
    }
   ],
   "source": [
    "# Define input schema\n",
    "class StoreMemoryInput(BaseModel):\n",
    "    \"\"\"Input schema for storing memories.\"\"\"\n",
    "    text: str = Field(\n",
    "        description=\"The information to store. Should be a clear, factual statement. \"\n",
    "                    \"Examples: 'User prefers online courses', 'User's career goal is AI research'\"\n",
    "    )\n",
    "    memory_type: str = Field(\n",
    "        default=\"semantic\",\n",
    "        description=\"Type of memory: 'semantic' (facts/preferences), 'episodic' (events/interactions). \"\n",
    "                    \"Default is 'semantic'.\"\n",
    "    )\n",
    "    topics: List[str] = Field(\n",
    "        default=[],\n",
    "        description=\"Optional tags to categorize the memory, such as ['preferences', 'courses']\"\n",
    "    )\n",
    "\n",
    "# Define the tool\n",
    "@tool(\"store_memory\", args_schema=StoreMemoryInput)\n",
    "async def store_memory(text: str, memory_type: str = \"semantic\", topics: List[str] = []) -> str:\n",
    "    \"\"\"\n",
    "    Store important information to the user's long-term memory.\n",
    "    \n",
    "    Use this tool when the user shares:\n",
    "    - Preferences: \"I prefer online courses\", \"I like hands-on projects\"\n",
    "    - Goals: \"I want to work in AI\", \"I'm preparing for grad school\"\n",
    "    - Important facts: \"I have a part-time job\", \"I'm interested in startups\"\n",
    "    - Constraints: \"I can only take 2 courses per semester\"\n",
    "    \n",
    "    Do NOT store:\n",
    "    - Temporary information (use conversation context instead)\n",
    "    - Course details (already in course catalog)\n",
    "    - General questions\n",
    "    \n",
    "    Returns: Confirmation message.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from agent_memory_client.models import ClientMemoryRecord\n",
    "        \n",
    "        # Create memory record\n",
    "        memory = ClientMemoryRecord(\n",
    "            text=text,\n",
    "            user_id=STUDENT_ID,\n",
    "            memory_type=memory_type,\n",
    "            topics=topics or []\n",
    "        )\n",
    "        \n",
    "        # Store in long-term memory\n",
    "        await memory_client.create_long_term_memory([memory])\n",
    "        return f\"âœ… Stored to long-term memory: {text}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error storing memory: {str(e)}\"\n",
    "\n",
    "print(\"âœ… Tool 3 defined: store_memory\")\n",
    "print(\"   Purpose: Save important facts to long-term memory\")\n",
    "print(\"   Parameters: text (str), memory_type (str), topics (List[str])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graph-nodes",
   "metadata": {},
   "source": [
    "### Tools Summary\n",
    "\n",
    "Let's review our 3 tools:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "load-memory-node",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T23:57:53.966158Z",
     "iopub.status.busy": "2025-10-31T23:57:53.966078Z",
     "iopub.status.idle": "2025-10-31T23:57:53.968399Z",
     "shell.execute_reply": "2025-10-31T23:57:53.968046Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ðŸ› ï¸  AGENT TOOLS SUMMARY\n",
      "================================================================================\n",
      "\n",
      "1. search_courses\n",
      "   Description: Search for courses using semantic search based on topics, descriptions, or characteristics\n",
      "   Parameters: query, limit\n",
      "\n",
      "2. search_memories\n",
      "   Description: Search the user's long-term memory for relevant facts, preferences, and past interactions\n",
      "   Parameters: query, limit\n",
      "\n",
      "3. store_memory\n",
      "   Description: Store important information to the user's long-term memory\n",
      "   Parameters: text, memory_type, topics\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Collect all tools\n",
    "tools = [search_courses, search_memories, store_memory]\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ðŸ› ï¸  AGENT TOOLS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "for i, tool in enumerate(tools, 1):\n",
    "    print(f\"\\n{i}. {tool.name}\")\n",
    "    print(f\"   Description: {tool.description.split('.')[0]}\")\n",
    "    print(f\"   Parameters: {', '.join(tool.args_schema.model_fields.keys())}\")\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agent-node",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸŽ¨ Part 2: Define the Agent State\n",
    "\n",
    "In LangGraph, **state** is the shared data structure that flows through the graph. Each node can read from and write to the state.\n",
    "\n",
    "### What Goes in State?\n",
    "\n",
    "- **messages**: Conversation history (automatically managed by LangGraph)\n",
    "- **student_id**: Who we're helping\n",
    "- **session_id**: Current conversation session\n",
    "- **context**: Additional context (memories, preferences, etc.)\n",
    "\n",
    "**Note:** We use `Annotated[List[BaseMessage], add_messages]` for messages. The `add_messages` reducer automatically handles message deduplication and ordering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "save-memory-node",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T23:57:53.969443Z",
     "iopub.status.busy": "2025-10-31T23:57:53.969382Z",
     "iopub.status.idle": "2025-10-31T23:57:53.971457Z",
     "shell.execute_reply": "2025-10-31T23:57:53.971109Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agent state defined\n",
      "   Fields: messages, student_id, session_id, context\n"
     ]
    }
   ],
   "source": [
    "# Define the agent state\n",
    "class AgentState(BaseModel):\n",
    "    \"\"\"State for the course advisor agent.\"\"\"\n",
    "    messages: Annotated[List[BaseMessage], add_messages]\n",
    "    student_id: str\n",
    "    session_id: str\n",
    "    context: Dict[str, Any] = {}\n",
    "\n",
    "print(\"âœ… Agent state defined\")\n",
    "print(\"   Fields: messages, student_id, session_id, context\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "routing-logic",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ”— Part 3: Build the Agent Graph\n",
    "\n",
    "Now we'll build the LangGraph workflow. Our graph will have:\n",
    "\n",
    "1. **load_memory** - Load working memory (conversation history)\n",
    "2. **agent** - LLM decides what to do (call tools or respond)\n",
    "3. **tools** - Execute tool calls\n",
    "4. **save_memory** - Save updated conversation to working memory\n",
    "\n",
    "### Step 1: Define Node Functions\n",
    "\n",
    "Each node is a function that takes state and returns updated state.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "should-continue",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T23:57:53.972503Z",
     "iopub.status.busy": "2025-10-31T23:57:53.972440Z",
     "iopub.status.idle": "2025-10-31T23:57:53.974986Z",
     "shell.execute_reply": "2025-10-31T23:57:53.974616Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Node 1 defined: load_memory\n",
      "   Purpose: Load conversation history from working memory\n"
     ]
    }
   ],
   "source": [
    "# Node 1: Load working memory\n",
    "async def load_memory(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Load conversation history from working memory.\n",
    "    \n",
    "    This gives the agent context about previous interactions in this session.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get or create working memory for this session\n",
    "        _, working_memory = await memory_client.get_or_create_working_memory(\n",
    "            session_id=state.session_id,\n",
    "            user_id=state.student_id,\n",
    "            model_name=\"gpt-4o\"\n",
    "        )\n",
    "\n",
    "        if working_memory and working_memory.messages:\n",
    "            # Convert stored messages to LangChain message objects\n",
    "            loaded_messages = []\n",
    "            for msg in working_memory.messages:\n",
    "                if msg.role == 'user':\n",
    "                    loaded_messages.append(HumanMessage(content=msg.content))\n",
    "                elif msg.role == 'assistant':\n",
    "                    loaded_messages.append(AIMessage(content=msg.content))\n",
    "\n",
    "            # Add loaded messages to state (prepend to current messages)\n",
    "            state.messages = loaded_messages + state.messages\n",
    "            state.context['memory_loaded'] = True\n",
    "            print(f\"   Loaded {len(loaded_messages)} messages from working memory\")\n",
    "        else:\n",
    "            state.context['memory_loaded'] = False\n",
    "            print(\"   No previous conversation found (new session)\")\n",
    "    except Exception as e:\n",
    "        print(f\"   Warning: Could not load memory: {e}\")\n",
    "        state.context['memory_loaded'] = False\n",
    "    \n",
    "    return state\n",
    "\n",
    "print(\"âœ… Node 1 defined: load_memory\")\n",
    "print(\"   Purpose: Load conversation history from working memory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "build-graph",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T23:57:53.975927Z",
     "iopub.status.busy": "2025-10-31T23:57:53.975854Z",
     "iopub.status.idle": "2025-10-31T23:57:53.977825Z",
     "shell.execute_reply": "2025-10-31T23:57:53.977580Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Node 2 defined: agent_node\n",
      "   Purpose: LLM decides whether to call tools or respond\n"
     ]
    }
   ],
   "source": [
    "# Node 2: Agent (LLM with tools)\n",
    "async def agent_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    The agent decides what to do: call tools or respond to the user.\n",
    "    \n",
    "    This is where the LLM reasoning happens.\n",
    "    \"\"\"\n",
    "    # Create system message with instructions\n",
    "    system_message = SystemMessage(content=\"\"\"\n",
    "You are a helpful Redis University course advisor assistant.\n",
    "\n",
    "Your role:\n",
    "- Help students find courses that match their interests and goals\n",
    "- Remember student preferences and use them for personalized recommendations\n",
    "- Store important information about students for future conversations\n",
    "\n",
    "Guidelines:\n",
    "- Use search_courses to find relevant courses\n",
    "- Use search_memories to recall student preferences and past interactions\n",
    "- Use store_memory when students share important preferences, goals, or constraints\n",
    "- Be conversational and helpful\n",
    "- Provide specific course recommendations with details\n",
    "\"\"\")\n",
    "    \n",
    "    # Bind tools to LLM\n",
    "    llm_with_tools = llm.bind_tools(tools)\n",
    "    \n",
    "    # Call LLM with system message + conversation history\n",
    "    messages = [system_message] + state.messages\n",
    "    response = await llm_with_tools.ainvoke(messages)\n",
    "    \n",
    "    # Add response to state\n",
    "    state.messages.append(response)\n",
    "    \n",
    "    return state\n",
    "\n",
    "print(\"âœ… Node 2 defined: agent_node\")\n",
    "print(\"   Purpose: LLM decides whether to call tools or respond\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "construct-graph",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T23:57:53.978903Z",
     "iopub.status.busy": "2025-10-31T23:57:53.978835Z",
     "iopub.status.idle": "2025-10-31T23:57:53.981202Z",
     "shell.execute_reply": "2025-10-31T23:57:53.980864Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Node 3 defined: save_memory\n",
      "   Purpose: Save conversation to working memory\n"
     ]
    }
   ],
   "source": [
    "# Node 3: Save working memory\n",
    "async def save_memory(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Save the updated conversation to working memory.\n",
    "    \n",
    "    This ensures continuity across conversation turns.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get or create working memory\n",
    "        _, working_memory = await memory_client.get_or_create_working_memory(\n",
    "            session_id=state.session_id,\n",
    "            user_id=state.student_id,\n",
    "            model_name=\"gpt-4o\"\n",
    "        )\n",
    "\n",
    "        # Clear existing messages and add current conversation\n",
    "        working_memory.messages = []\n",
    "        for msg in state.messages:\n",
    "            if isinstance(msg, HumanMessage):\n",
    "                working_memory.messages.append(MemoryMessage(role='user', content=msg.content))\n",
    "            elif isinstance(msg, AIMessage):\n",
    "                # Only store text content, not tool calls\n",
    "                if msg.content:\n",
    "                    working_memory.messages.append(MemoryMessage(role='assistant', content=msg.content))\n",
    "\n",
    "        # Save to working memory\n",
    "        await memory_client.put_working_memory(\n",
    "            session_id=state.session_id,\n",
    "            memory=working_memory,\n",
    "            user_id=state.student_id,\n",
    "            model_name=\"gpt-4o\"\n",
    "        )\n",
    "\n",
    "        print(f\"   Saved {len(working_memory.messages)} messages to working memory\")\n",
    "    except Exception as e:\n",
    "        print(f\"   Warning: Could not save memory: {e}\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "print(\"âœ… Node 3 defined: save_memory\")\n",
    "print(\"   Purpose: Save conversation to working memory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualize-graph",
   "metadata": {},
   "source": [
    "### Step 2: Define Routing Logic\n",
    "\n",
    "We need a function to decide: should we call tools or end the conversation?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "show-graph",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T23:57:53.982174Z",
     "iopub.status.busy": "2025-10-31T23:57:53.982118Z",
     "iopub.status.idle": "2025-10-31T23:57:53.983908Z",
     "shell.execute_reply": "2025-10-31T23:57:53.983535Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Routing logic defined: should_continue\n",
      "   Routes to 'tools' if LLM wants to call tools, otherwise to 'save_memory'\n"
     ]
    }
   ],
   "source": [
    "# Routing function\n",
    "def should_continue(state: AgentState) -> str:\n",
    "    \"\"\"\n",
    "    Determine if we should continue to tools or end.\n",
    "    \n",
    "    If the last message has tool calls, route to tools.\n",
    "    Otherwise, we're done.\n",
    "    \"\"\"\n",
    "    last_message = state.messages[-1]\n",
    "    \n",
    "    # Check if there are tool calls\n",
    "    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    else:\n",
    "        return \"save_memory\"\n",
    "\n",
    "print(\"âœ… Routing logic defined: should_continue\")\n",
    "print(\"   Routes to 'tools' if LLM wants to call tools, otherwise to 'save_memory'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demo-section",
   "metadata": {},
   "source": [
    "### Step 3: Build the Graph\n",
    "\n",
    "Now we assemble all the pieces into a LangGraph workflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "run-agent-helper",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T23:57:53.984807Z",
     "iopub.status.busy": "2025-10-31T23:57:53.984751Z",
     "iopub.status.idle": "2025-10-31T23:57:53.990038Z",
     "shell.execute_reply": "2025-10-31T23:57:53.989670Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agent graph built and compiled!\n",
      "\n",
      "ðŸ“Š Graph structure:\n",
      "   START â†’ load_memory â†’ agent â†’ [tools â†’ agent]* â†’ save_memory â†’ END\n",
      "\n",
      "   * The agent can call tools multiple times before responding\n"
     ]
    }
   ],
   "source": [
    "# Create the graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"load_memory\", load_memory)\n",
    "workflow.add_node(\"agent\", agent_node)\n",
    "workflow.add_node(\"tools\", ToolNode(tools))\n",
    "workflow.add_node(\"save_memory\", save_memory)\n",
    "\n",
    "# Define edges\n",
    "workflow.set_entry_point(\"load_memory\")\n",
    "workflow.add_edge(\"load_memory\", \"agent\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"tools\": \"tools\",\n",
    "        \"save_memory\": \"save_memory\"\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(\"tools\", \"agent\")  # After tools, go back to agent\n",
    "workflow.add_edge(\"save_memory\", END)\n",
    "\n",
    "# Compile the graph\n",
    "agent_graph = workflow.compile()\n",
    "\n",
    "print(\"âœ… Agent graph built and compiled!\")\n",
    "print(\"\\nðŸ“Š Graph structure:\")\n",
    "print(\"   START â†’ load_memory â†’ agent â†’ [tools â†’ agent]* â†’ save_memory â†’ END\")\n",
    "print(\"\\n   * The agent can call tools multiple times before responding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demo-1",
   "metadata": {},
   "source": [
    "### Step 4: Visualize the Graph\n",
    "\n",
    "Let's see what our agent workflow looks like!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "demo-search",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T23:57:53.991081Z",
     "iopub.status.busy": "2025-10-31T23:57:53.991018Z",
     "iopub.status.idle": "2025-10-31T23:57:54.095976Z",
     "shell.execute_reply": "2025-10-31T23:57:54.095530Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Graph visualization displayed above\n"
     ]
    }
   ],
   "source": [
    "# Try to visualize the graph\n",
    "try:\n",
    "    from IPython.display import Image, display\n",
    "    \n",
    "    # Generate graph visualization\n",
    "    graph_image = agent_graph.get_graph().draw_mermaid_png()\n",
    "    display(Image(graph_image))\n",
    "    print(\"\\nâœ… Graph visualization displayed above\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸  Could not display graph visualization: {e}\")\n",
    "    print(\"\\nGraph structure (text):\")\n",
    "    print(\"\"\"    \n",
    "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "    â”‚   START     â”‚\n",
    "    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜\n",
    "           â”‚\n",
    "           â–¼\n",
    "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "    â”‚ load_memory â”‚\n",
    "    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜\n",
    "           â”‚\n",
    "           â–¼\n",
    "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "    â”‚    agent    â”‚ â—„â”€â”€â”€â”€â”€â”\n",
    "    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜       â”‚\n",
    "           â”‚              â”‚\n",
    "      â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”         â”‚\n",
    "      â”‚         â”‚         â”‚\n",
    "      â–¼         â–¼         â”‚\n",
    "   [tools]  [respond]     â”‚\n",
    "      â”‚                   â”‚\n",
    "      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                â”‚\n",
    "                â–¼\n",
    "         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "         â”‚ save_memory â”‚\n",
    "         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜\n",
    "                â”‚\n",
    "                â–¼\n",
    "         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "         â”‚     END     â”‚\n",
    "         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demo-2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸŽ¬ Part 4: Demo the Agent\n",
    "\n",
    "Now let's see our agent in action! We'll have a conversation with the agent and watch it:\n",
    "- Search for courses\n",
    "- Store memories about preferences\n",
    "- Recall information from previous interactions\n",
    "\n",
    "### Helper Function: Run Agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "demo-store",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T23:57:54.097563Z",
     "iopub.status.busy": "2025-10-31T23:57:54.097461Z",
     "iopub.status.idle": "2025-10-31T23:57:54.100763Z",
     "shell.execute_reply": "2025-10-31T23:57:54.100208Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Helper function defined: run_agent\n"
     ]
    }
   ],
   "source": [
    "async def run_agent(user_message: str, verbose: bool = True) -> str:\n",
    "    \"\"\"\n",
    "    Run the agent with a user message.\n",
    "    \n",
    "    Args:\n",
    "        user_message: The user's input\n",
    "        verbose: Whether to print detailed execution info\n",
    "    \n",
    "    Returns:\n",
    "        The agent's response\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"ðŸ‘¤ USER: {user_message}\")\n",
    "        print(\"=\" * 80)\n",
    "    \n",
    "    # Create initial state\n",
    "    initial_state = AgentState(\n",
    "        messages=[HumanMessage(content=user_message)],\n",
    "        student_id=STUDENT_ID,\n",
    "        session_id=SESSION_ID,\n",
    "        context={}\n",
    "    )\n",
    "    \n",
    "    # Run the graph\n",
    "    if verbose:\n",
    "        print(\"\\nðŸ¤– AGENT EXECUTION:\")\n",
    "    \n",
    "    final_state = await agent_graph.ainvoke(initial_state)\n",
    "\n",
    "    # Extract the final response\n",
    "    final_message = final_state[\"messages\"][-1]\n",
    "    response = final_message.content if hasattr(final_message, 'content') else str(final_message)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(f\"ðŸ¤– ASSISTANT: {response}\")\n",
    "        print(\"=\" * 80)\n",
    "    \n",
    "    return response\n",
    "\n",
    "print(\"âœ… Helper function defined: run_agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demo-3",
   "metadata": {},
   "source": [
    "### Demo 1: Search Courses\n",
    "\n",
    "Let's ask the agent to find machine learning courses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "demo-recall",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T23:57:54.102049Z",
     "iopub.status.busy": "2025-10-31T23:57:54.101962Z",
     "iopub.status.idle": "2025-10-31T23:57:58.356458Z",
     "shell.execute_reply": "2025-10-31T23:57:58.355667Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ðŸ‘¤ USER: What machine learning courses are available? I'm interested in intermediate level courses.\n",
      "================================================================================\n",
      "\n",
      "ðŸ¤– AGENT EXECUTION:\n",
      "19:57:54 httpx INFO   HTTP Request: GET http://localhost:8088/v1/working-memory/session_student_sarah_001_20251031_195753?user_id=student_sarah_001&namespace=redis_university&model_name=gpt-4o \"HTTP/1.1 404 Not Found\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:57:54 httpx INFO   HTTP Request: PUT http://localhost:8088/v1/working-memory/session_student_sarah_001_20251031_195753?user_id=student_sarah_001&model_name=gpt-4o \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   No previous conversation found (new session)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:57:54 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:57:55 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:57:58 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:57:58 httpx INFO   HTTP Request: GET http://localhost:8088/v1/working-memory/session_student_sarah_001_20251031_195753?user_id=student_sarah_001&namespace=redis_university&model_name=gpt-4o \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:57:58 httpx INFO   HTTP Request: PUT http://localhost:8088/v1/working-memory/session_student_sarah_001_20251031_195753?user_id=student_sarah_001&model_name=gpt-4o \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Saved 2 messages to working memory\n",
      "\n",
      "================================================================================\n",
      "ðŸ¤– ASSISTANT: Here are some intermediate-level courses related to machine learning that you might find interesting:\n",
      "\n",
      "1. **MATH022: Linear Algebra**\n",
      "   - **Credits:** 3\n",
      "   - **Format:** In-person\n",
      "   - **Description:** Covers vector spaces, matrices, eigenvalues, and linear transformations. This course is essential for data science and engineering, providing foundational knowledge for machine learning.\n",
      "\n",
      "2. **MATH023: Linear Algebra**\n",
      "   - **Credits:** 3\n",
      "   - **Format:** Hybrid\n",
      "   - **Description:** Similar to MATH022, this course also covers vector spaces, matrices, eigenvalues, and linear transformations, with a hybrid format for more flexibility.\n",
      "\n",
      "These courses focus on linear algebra, which is a crucial component of machine learning. If you're looking for more specific machine learning algorithms and applications, you might consider advanced courses like CS007: Machine Learning, which covers supervised and unsupervised learning, neural networks, and more.\n",
      "\n",
      "If you have any specific preferences or constraints, feel free to let me know!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Demo 1: Search for courses\n",
    "response1 = await run_agent(\n",
    "    \"What machine learning courses are available? I'm interested in intermediate level courses.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demo-4",
   "metadata": {},
   "source": [
    "### Demo 2: Store Preferences\n",
    "\n",
    "Now let's share some preferences and watch the agent store them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "demo-personalized",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T23:57:58.358447Z",
     "iopub.status.busy": "2025-10-31T23:57:58.358312Z",
     "iopub.status.idle": "2025-10-31T23:58:04.410189Z",
     "shell.execute_reply": "2025-10-31T23:58:04.409512Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ðŸ‘¤ USER: I prefer online courses because I have a part-time job. Also, I'm really interested in AI and want to work at a startup after graduation.\n",
      "================================================================================\n",
      "\n",
      "ðŸ¤– AGENT EXECUTION:\n",
      "19:57:58 httpx INFO   HTTP Request: GET http://localhost:8088/v1/working-memory/session_student_sarah_001_20251031_195753?user_id=student_sarah_001&namespace=redis_university&model_name=gpt-4o \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Loaded 2 messages from working memory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:57:59 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:57:59 httpx INFO   HTTP Request: POST http://localhost:8088/v1/long-term-memory/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:57:59 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:57:59 httpx INFO   HTTP Request: POST http://localhost:8088/v1/long-term-memory/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:58:01 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:58:02 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:58:04 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:58:04 httpx INFO   HTTP Request: GET http://localhost:8088/v1/working-memory/session_student_sarah_001_20251031_195753?user_id=student_sarah_001&namespace=redis_university&model_name=gpt-4o \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:58:04 httpx INFO   HTTP Request: PUT http://localhost:8088/v1/working-memory/session_student_sarah_001_20251031_195753?user_id=student_sarah_001&model_name=gpt-4o \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Saved 4 messages to working memory\n",
      "\n",
      "================================================================================\n",
      "ðŸ¤– ASSISTANT: Here are some intermediate-level machine learning-related courses that might interest you, especially considering your preference for online formats:\n",
      "\n",
      "1. **CS007: Machine Learning**\n",
      "   - **Credits:** 4\n",
      "   - **Format:** Hybrid\n",
      "   - **Level:** Advanced\n",
      "   - **Description:** This course introduces machine learning algorithms and applications, covering supervised and unsupervised learning, neural networks, and more. It's a great fit if you're looking to deepen your understanding of machine learning.\n",
      "\n",
      "2. **MATH023: Linear Algebra**\n",
      "   - **Credits:** 3\n",
      "   - **Format:** Hybrid\n",
      "   - **Level:** Intermediate\n",
      "   - **Description:** This course covers vector spaces, matrices, eigenvalues, and linear transformations, which are essential for data science and engineering. The hybrid format offers some flexibility.\n",
      "\n",
      "While CS007 is more advanced, it aligns well with your interest in AI. If you're looking for more online options, let me know, and I can help you find additional courses!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Demo 2: Store preferences\n",
    "response2 = await run_agent(\n",
    "    \"I prefer online courses because I have a part-time job. \"\n",
    "    \"Also, I'm really interested in AI and want to work at a startup after graduation.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inspect-memory",
   "metadata": {},
   "source": [
    "### Demo 3: Recall Memories\n",
    "\n",
    "Let's ask the agent to recall what it knows about us.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "check-memories",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T23:58:04.411898Z",
     "iopub.status.busy": "2025-10-31T23:58:04.411768Z",
     "iopub.status.idle": "2025-10-31T23:58:06.565467Z",
     "shell.execute_reply": "2025-10-31T23:58:06.564738Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ðŸ‘¤ USER: What do you remember about my preferences and goals?\n",
      "================================================================================\n",
      "\n",
      "ðŸ¤– AGENT EXECUTION:\n",
      "19:58:04 httpx INFO   HTTP Request: GET http://localhost:8088/v1/working-memory/session_student_sarah_001_20251031_195753?user_id=student_sarah_001&namespace=redis_university&model_name=gpt-4o \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Loaded 4 messages from working memory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:58:05 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:58:05 httpx INFO   HTTP Request: POST http://localhost:8088/v1/long-term-memory/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:58:06 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:58:06 httpx INFO   HTTP Request: GET http://localhost:8088/v1/working-memory/session_student_sarah_001_20251031_195753?user_id=student_sarah_001&namespace=redis_university&model_name=gpt-4o \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:58:06 httpx INFO   HTTP Request: PUT http://localhost:8088/v1/working-memory/session_student_sarah_001_20251031_195753?user_id=student_sarah_001&model_name=gpt-4o \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Saved 6 messages to working memory\n",
      "\n",
      "================================================================================\n",
      "ðŸ¤– ASSISTANT: I've noted your preference for online courses due to your part-time job and your interest in AI with a goal to work at a startup after graduation. If you need more information or have other preferences, feel free to let me know!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Demo 3: Recall memories\n",
    "response3 = await run_agent(\n",
    "    \"What do you remember about my preferences and goals?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison",
   "metadata": {},
   "source": [
    "### Demo 4: Personalized Recommendations\n",
    "\n",
    "Now let's ask for recommendations and see if the agent uses our stored preferences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "architecture-recap",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T23:58:06.567416Z",
     "iopub.status.busy": "2025-10-31T23:58:06.567279Z",
     "iopub.status.idle": "2025-10-31T23:58:11.047325Z",
     "shell.execute_reply": "2025-10-31T23:58:11.046775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ðŸ‘¤ USER: Can you recommend some courses for next semester based on what you know about me?\n",
      "================================================================================\n",
      "\n",
      "ðŸ¤– AGENT EXECUTION:\n",
      "19:58:06 httpx INFO   HTTP Request: GET http://localhost:8088/v1/working-memory/session_student_sarah_001_20251031_195753?user_id=student_sarah_001&namespace=redis_university&model_name=gpt-4o \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Loaded 6 messages from working memory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:58:07 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:58:07 httpx INFO   HTTP Request: POST http://localhost:8088/v1/long-term-memory/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:58:09 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:58:09 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:58:10 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:58:11 httpx INFO   HTTP Request: GET http://localhost:8088/v1/working-memory/session_student_sarah_001_20251031_195753?user_id=student_sarah_001&namespace=redis_university&model_name=gpt-4o \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:58:11 httpx INFO   HTTP Request: PUT http://localhost:8088/v1/working-memory/session_student_sarah_001_20251031_195753?user_id=student_sarah_001&model_name=gpt-4o \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Saved 8 messages to working memory\n",
      "\n",
      "================================================================================\n",
      "ðŸ¤– ASSISTANT: Here are some intermediate-level machine learning-related courses that might interest you, especially considering your preference for online formats:\n",
      "\n",
      "1. **CS007: Machine Learning**\n",
      "   - **Credits:** 4\n",
      "   - **Format:** Hybrid\n",
      "   - **Level:** Advanced\n",
      "   - **Description:** This course introduces machine learning algorithms and applications, covering supervised and unsupervised learning, neural networks, and more. It's a great fit if you're looking to deepen your understanding of machine learning.\n",
      "\n",
      "2. **MATH023: Linear Algebra**\n",
      "   - **Credits:** 3\n",
      "   - **Format:** Hybrid\n",
      "   - **Level:** Intermediate\n",
      "   - **Description:** This course covers vector spaces, matrices, eigenvalues, and linear transformations, which are essential for data science and engineering. The hybrid format offers some flexibility.\n",
      "\n",
      "While CS007 is more advanced, it aligns well with your interest in AI. If you're looking for more online options, let me know, and I can help you find additional courses!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Demo 4: Personalized recommendations\n",
    "response4 = await run_agent(\n",
    "    \"Can you recommend some courses for next semester based on what you know about me?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "key-takeaways",
   "metadata": {},
   "source": [
    "### Inspect Stored Memories\n",
    "\n",
    "Let's look at what's actually stored in long-term memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "next-steps",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T23:58:11.049386Z",
     "iopub.status.busy": "2025-10-31T23:58:11.049237Z",
     "iopub.status.idle": "2025-10-31T23:58:11.464715Z",
     "shell.execute_reply": "2025-10-31T23:58:11.464089Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:58:11 httpx INFO   HTTP Request: POST http://localhost:8088/v1/long-term-memory/search?optimize_query=false \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ðŸ’¾ LONG-TERM MEMORY CONTENTS\n",
      "================================================================================\n",
      "\n",
      "1. [MemoryTypeEnum.SEMANTIC] User prefers online courses because of their part-time job and is interested in AI, aiming to work at a startup after graduation.\n",
      "   Topics: preferences, goals, career goals\n",
      "   Created: 2025-10-31 23:34:56.348080+00:00\n",
      "\n",
      "2. [MemoryTypeEnum.SEMANTIC] User is interested in intermediate level machine learning courses\n",
      "   Topics: education, machine learning\n",
      "   Created: 2025-10-31 23:57:59.851662+00:00\n",
      "\n",
      "3. [MemoryTypeEnum.SEMANTIC] User is interested in intermediate-level machine learning courses.\n",
      "   Topics: education, machine learning\n",
      "   Created: 2025-10-31 23:41:07.649462+00:00\n",
      "\n",
      "4. [MemoryTypeEnum.SEMANTIC] User is interested in intermediate level machine learning courses.\n",
      "   Topics: education, machine learning\n",
      "   Created: 2025-10-31 23:38:59.455948+00:00\n",
      "\n",
      "5. [MemoryTypeEnum.SEMANTIC] User is interested in AI and wants to work at a startup after graduation.\n",
      "   Topics: career goals, interests\n",
      "   Created: 2025-10-31 23:34:51.334794+00:00\n",
      "\n",
      "6. [MemoryTypeEnum.SEMANTIC] User might be interested in CS007: Machine Learning, which covers supervised and unsupervised learning, neural networks, and more\n",
      "   Topics: education, machine learning\n",
      "   Created: 2025-10-31 23:57:59.851713+00:00\n",
      "\n",
      "7. [MemoryTypeEnum.SEMANTIC] User prefers online courses due to having a part-time job.\n",
      "   Topics: preferences, constraints\n",
      "   Created: 2025-10-31 23:34:50.400956+00:00\n",
      "\n",
      "8. [MemoryTypeEnum.SEMANTIC] User may consider advanced courses like CS007: Machine Learning, which covers supervised and unsupervised learning, and neural networks.\n",
      "   Topics: education, machine learning, course recommendations\n",
      "   Created: 2025-10-31 23:34:50.805480+00:00\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Check what's in long-term memory\n",
    "try:\n",
    "    from agent_memory_client.filters import UserId\n",
    "    \n",
    "    results = await memory_client.search_long_term_memory(\n",
    "        text=\"preferences goals interests\",\n",
    "        user_id=UserId(eq=STUDENT_ID),\n",
    "        limit=10\n",
    "    )\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"ðŸ’¾ LONG-TERM MEMORY CONTENTS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    if results.memories and len(results.memories) > 0:\n",
    "        for i, memory in enumerate(results.memories, 1):\n",
    "            print(f\"\\n{i}. [{memory.memory_type}] {memory.text}\")\n",
    "            if memory.topics:\n",
    "                print(f\"   Topics: {', '.join(memory.topics)}\")\n",
    "            if memory.created_at:\n",
    "                print(f\"   Created: {memory.created_at}\")\n",
    "    else:\n",
    "        print(\"\\nNo memories found.\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "except Exception as e:\n",
    "    print(f\"Error retrieving memories: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ“Š Part 5: RAG vs Agent Comparison\n",
    "\n",
    "Let's compare what we've built across the sections:\n",
    "\n",
    "### **Section 2: Basic RAG**\n",
    "```python\n",
    "# Simple flow\n",
    "query â†’ search_courses() â†’ generate_response()\n",
    "```\n",
    "- âœ… Can retrieve course information\n",
    "- âŒ No memory of previous interactions\n",
    "- âŒ Can't store user preferences\n",
    "- âŒ Single-step only\n",
    "\n",
    "### **Section 3: Memory-Enhanced RAG**\n",
    "```python\n",
    "# With memory\n",
    "load_memory() â†’ search_courses() â†’ generate_response() â†’ save_memory()\n",
    "```\n",
    "- âœ… Remembers conversation history\n",
    "- âœ… Can reference previous messages\n",
    "- âš ï¸  Limited to predefined flow\n",
    "- âŒ Can't decide when to store memories\n",
    "\n",
    "### **Section 4: Full Agent (This Notebook)**\n",
    "```python\n",
    "# Agent with tools and decision-making\n",
    "load_memory() â†’ agent_decides() â†’ [search_courses | search_memories | store_memory]* â†’ save_memory()\n",
    "```\n",
    "- âœ… Remembers conversation history\n",
    "- âœ… Decides when to search courses\n",
    "- âœ… Decides when to store memories\n",
    "- âœ… Decides when to recall memories\n",
    "- âœ… Can chain multiple operations\n",
    "- âœ… Adaptive to user needs\n",
    "\n",
    "### **Key Differences:**\n",
    "\n",
    "| Feature | RAG | Memory-RAG | Agent |\n",
    "|---------|-----|------------|-------|\n",
    "| **Retrieval** | âœ… | âœ… | âœ… |\n",
    "| **Conversation Memory** | âŒ | âœ… | âœ… |\n",
    "| **Long-term Memory** | âŒ | âš ï¸ (manual) | âœ… (automatic) |\n",
    "| **Decision Making** | âŒ | âŒ | âœ… |\n",
    "| **Multi-step Reasoning** | âŒ | âŒ | âœ… |\n",
    "| **Tool Selection** | âŒ | âŒ | âœ… |\n",
    "| **Complexity** | Low | Medium | High |\n",
    "| **Latency** | Low | Medium | Higher |\n",
    "| **Cost** | Low | Medium | Higher |\n",
    "\n",
    "**ðŸ’¡ Key Insight:** Agents add decision-making and multi-step reasoning to RAG systems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c8b43a1a04fff3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ—ï¸ Architecture Recap\n",
    "\n",
    "### **What We Built:**\n",
    "\n",
    "A complete course advisor agent with:\n",
    "\n",
    "**1. Tools (3 total)**\n",
    "- `search_courses` - Semantic search over course catalog\n",
    "- `search_memories` - Recall user preferences and facts\n",
    "- `store_memory` - Save important information\n",
    "\n",
    "**2. Memory Architecture**\n",
    "- **Working Memory** - Conversation history (session-scoped)\n",
    "- **Long-term Memory** - User preferences and facts (persistent)\n",
    "- **Graph State** - Current execution state (turn-scoped)\n",
    "\n",
    "**3. LangGraph Workflow**\n",
    "- **Nodes**: load_memory, agent, tools, save_memory\n",
    "- **Edges**: Conditional routing based on LLM decisions\n",
    "- **State**: Shared data structure flowing through the graph\n",
    "\n",
    "**4. Integration Points**\n",
    "- **Redis** - Course catalog storage and vector search\n",
    "- **Agent Memory Server** - Working and long-term memory\n",
    "- **OpenAI** - LLM for reasoning and tool selection\n",
    "- **LangGraph** - Workflow orchestration\n",
    "\n",
    "### **The Complete Context Engineering Stack:**\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    AGENT LAYER                          â”‚\n",
    "â”‚  (LangGraph orchestration + tool selection)             â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                     â”‚\n",
    "        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "        â”‚            â”‚            â”‚\n",
    "        â–¼            â–¼            â–¼\n",
    "   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "   â”‚ Tools  â”‚  â”‚ Memory  â”‚  â”‚   RAG   â”‚\n",
    "   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "        â”‚            â”‚            â”‚\n",
    "        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                     â”‚\n",
    "                     â–¼\n",
    "            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "            â”‚  Redis Stack    â”‚\n",
    "            â”‚  (Storage +     â”‚\n",
    "            â”‚   Vector Search)â”‚\n",
    "            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d4b563a3a30240",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸŽ“ Key Takeaways\n",
    "\n",
    "### **1. Agents = RAG + Tools + Decision-Making**\n",
    "- RAG retrieves information\n",
    "- Tools enable actions\n",
    "- Agents decide when to use each\n",
    "\n",
    "### **2. Memory is Critical for Personalization**\n",
    "- Working memory enables conversation continuity\n",
    "- Long-term memory enables personalization\n",
    "- Agents can decide when to store/recall memories\n",
    "\n",
    "### **3. LangGraph Simplifies Complex Workflows**\n",
    "- State management is automatic\n",
    "- Conditional routing is declarative\n",
    "- Visualization helps debugging\n",
    "\n",
    "### **4. Tool Design Matters**\n",
    "- Clear descriptions guide LLM selection\n",
    "- Well-defined schemas prevent errors\n",
    "- Focused tools are better than Swiss Army knives\n",
    "\n",
    "### **5. Trade-offs to Consider**\n",
    "- **Complexity**: Agents are more complex than RAG\n",
    "- **Latency**: Multiple tool calls add latency\n",
    "- **Cost**: More LLM calls = higher cost\n",
    "- **Value**: Worth it for complex, multi-step tasks\n",
    "\n",
    "### **6. When to Use Agents vs RAG**\n",
    "\n",
    "**Use RAG when:**\n",
    "- Simple question answering\n",
    "- Single-step retrieval\n",
    "- Low latency required\n",
    "- Predictable workflows\n",
    "\n",
    "**Use Agents when:**\n",
    "- Multi-step reasoning needed\n",
    "- Actions beyond retrieval\n",
    "- Personalization required\n",
    "- Complex decision-making\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fc05bfee7ece66",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸš€ Next Steps and Extensions\n",
    "\n",
    "### **Ideas to Extend This Agent:**\n",
    "\n",
    "1. **Add More Tools**\n",
    "   - `check_prerequisites` - Verify if student meets course requirements\n",
    "   - `get_course_details` - Get detailed info about a specific course\n",
    "   - `create_schedule` - Build a semester schedule\n",
    "   - `check_conflicts` - Detect time conflicts\n",
    "\n",
    "2. **Enhance Memory**\n",
    "   - Automatic memory extraction from conversations\n",
    "   - Memory summarization for long conversations\n",
    "   - Memory importance scoring\n",
    "   - Memory expiration policies\n",
    "\n",
    "3. **Improve Personalization**\n",
    "   - Learning style detection\n",
    "   - Career path recommendations\n",
    "   - Skill gap analysis\n",
    "   - Progress tracking\n",
    "\n",
    "4. **Add Guardrails**\n",
    "   - Input validation\n",
    "   - Output filtering\n",
    "   - Rate limiting\n",
    "   - Error handling\n",
    "\n",
    "5. **Production Considerations**\n",
    "   - Authentication and authorization\n",
    "   - Logging and monitoring\n",
    "   - Caching for performance\n",
    "   - Fallback strategies\n",
    "\n",
    "### **Reference Implementation:**\n",
    "\n",
    "Check out `reference-agent/` for a full production implementation with:\n",
    "- 7 tools (vs our 3)\n",
    "- Advanced memory management\n",
    "- Semantic tool selection\n",
    "- Comprehensive error handling\n",
    "- CLI interface\n",
    "- Full test suite\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437746891b606882",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸŽ‰ Congratulations!\n",
    "\n",
    "You've completed the Context Engineering course! You've learned:\n",
    "\n",
    "**Section 1:** Context Types\n",
    "- System, User, Conversation, Retrieved context\n",
    "- How context shapes LLM behavior\n",
    "\n",
    "**Section 2:** RAG Foundations\n",
    "- Semantic search with vector embeddings\n",
    "- Context assembly and generation\n",
    "- Building a course search system\n",
    "\n",
    "**Section 3:** Memory Architecture\n",
    "- Working memory for conversation continuity\n",
    "- Long-term memory for persistent knowledge\n",
    "- Memory-enhanced RAG systems\n",
    "\n",
    "**ðŸ”¬ Research Foundation:** Throughout this course, you've learned techniques validated by Context Rot research - prioritizing relevance over quantity, filtering distractors, and structuring context for optimal LLM performance. ([Context Rot paper](https://research.trychroma.com/context-rot))\n",
    "\n",
    "**Section 4:** Agents and Tools\n",
    "- Tool calling fundamentals\n",
    "- LangGraph workflow orchestration\n",
    "- Building a complete course advisor agent\n",
    "- Agents vs RAG trade-offs\n",
    "\n",
    "### **You Can Now:**\n",
    "- âœ… Design effective context strategies\n",
    "- âœ… Build RAG systems with Redis\n",
    "- âœ… Implement dual-memory architectures\n",
    "- âœ… Create agents with tools and decision-making\n",
    "- âœ… Choose the right approach for your use case\n",
    "\n",
    "### **Keep Learning:**\n",
    "- Explore the reference-agent implementation\n",
    "- Experiment with different tools\n",
    "- Try different LLMs and embeddings\n",
    "- Build your own agents!\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“š Additional Resources\n",
    "\n",
    "\n",
    "- [Agent Memory Server Documentation](https://github.com/redis/agent-memory-server) - Production-ready memory management\n",
    "- [Agent Memory Client](https://pypi.org/project/agent-memory-client/) - Python client for Agent Memory Server\n",
    "- [RedisVL Documentation](https://redisvl.com/) - Redis Vector Library\n",
    "- [Retrieval-Augmented Generation Paper](https://arxiv.org/abs/2005.11401) - Original RAG research\n",
    "- [LangChain RAG Tutorial](https://python.langchain.com/docs/use_cases/question_answering/) - Building RAG systems\n",
    "- [LangGraph Tutorials](https://langchain-ai.github.io/langgraph/tutorials/) - Building agents with LangGraph\n",
    "- [Agent Architectures](https://python.langchain.com/docs/modules/agents/) - Different agent patterns\n",
    "- [ReAct: Synergizing Reasoning and Acting](https://arxiv.org/abs/2210.03629) - Reasoning + acting in LLMs\n",
    "- [Anthropic's Guide to Building Effective Agents](https://www.anthropic.com/research/building-effective-agents) - Agent design patterns\n",
    "\n",
    "---\n",
    "\n",
    "**Thank you for completing this course! ðŸ™**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d495052317c67bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
