{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e21de5ad28ededc",
   "metadata": {},
   "source": [
    "![Redis](https://redis.io/wp-content/uploads/2024/04/Logotype.svg?auto=webp&quality=85,75&width=120)\n",
    "\n",
    "# üîó Section 3: Memory-Enhanced RAG and Agents\n",
    "\n",
    "**‚è±Ô∏è Estimated Time:** 60-75 minutes\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "\n",
    "1. **Build** a memory-enhanced RAG system that combines all four context types\n",
    "2. **Demonstrate** the benefits of memory for natural conversations\n",
    "3. **Convert** a simple RAG system into a LangGraph agent\n",
    "4. **Prepare** for Section 4 (adding tools and advanced agent capabilities)\n",
    "\n",
    "---\n",
    "\n",
    "## üîó Bridge from Previous Notebooks\n",
    "\n",
    "### **What You've Learned:**\n",
    "\n",
    "**Section 1:** Four Context Types\n",
    "- System Context (static instructions)\n",
    "- User Context (profile, preferences)\n",
    "- Conversation Context (enabled by working memory)\n",
    "- Retrieved Context (RAG results)\n",
    "\n",
    "**Section 2:** RAG Fundamentals\n",
    "- Semantic search with vector embeddings\n",
    "- Context assembly\n",
    "- LLM generation\n",
    "\n",
    "**Section 3 (Notebook 1):** Memory Fundamentals\n",
    "- Working memory for conversation continuity\n",
    "- Long-term memory for persistent knowledge\n",
    "- Memory types (semantic, episodic, message)\n",
    "- Memory lifecycle and persistence\n",
    "\n",
    "### **What We'll Build:**\n",
    "\n",
    "**Part 1:** Memory-Enhanced RAG\n",
    "- Integrate working memory + long-term memory + RAG\n",
    "- Show clear before/after comparisons\n",
    "- Demonstrate benefits of memory systems\n",
    "\n",
    "**Part 2:** LangGraph Agent (Separate Notebook)\n",
    "- Convert memory-enhanced RAG to LangGraph agent\n",
    "- Add state management and control flow\n",
    "- Prepare for Section 4 (tools and advanced capabilities)\n",
    "\n",
    "---\n",
    "\n",
    "## üìä The Complete Picture\n",
    "\n",
    "### **Memory-Enhanced RAG Flow:**\n",
    "\n",
    "```\n",
    "User Query\n",
    "    ‚Üì\n",
    "1. Load Working Memory (conversation history)\n",
    "2. Search Long-term Memory (user preferences, facts)\n",
    "3. RAG Search (relevant courses)\n",
    "4. Assemble Context (System + User + Conversation + Retrieved)\n",
    "5. Generate Response\n",
    "6. Save Working Memory (updated conversation)\n",
    "```\n",
    "\n",
    "### **All Four Context Types Working Together:**\n",
    "\n",
    "| Context Type | Source | Purpose |\n",
    "|-------------|--------|---------|\n",
    "| **System** | Static prompt | Role, instructions, guidelines |\n",
    "| **User** | Profile + Long-term Memory | Personalization, preferences |\n",
    "| **Conversation** | Working Memory | Reference resolution, continuity |\n",
    "| **Retrieved** | RAG Search | Relevant courses, information |\n",
    "\n",
    "**üí° Key Insight:** Memory transforms stateless RAG into stateful, personalized conversations.\n",
    "\n",
    "---\n",
    "\n",
    "## üì¶ Setup\n",
    "\n",
    "### **What We're Importing:**\n",
    "\n",
    "- **Section 2 components** - `redis_config`, `CourseManager`, models\n",
    "- **Agent Memory Server client** - `MemoryAPIClient` for memory operations\n",
    "- **LangChain** - `ChatOpenAI` for LLM interaction\n",
    "\n",
    "### **Why:**\n",
    "\n",
    "- Build on Section 2's RAG foundation\n",
    "- Add memory capabilities without rewriting everything\n",
    "- Use production-ready memory infrastructure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "264e6d5b346b6755",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T14:27:06.541458Z",
     "iopub.status.busy": "2025-10-31T14:27:06.541296Z",
     "iopub.status.idle": "2025-10-31T14:27:08.268475Z",
     "shell.execute_reply": "2025-10-31T14:27:08.268022Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Agent Memory Server client available\n",
      "‚úÖ OPENAI_API_KEY found\n",
      "\n",
      "üîß Environment Setup:\n",
      "   OPENAI_API_KEY: ‚úì Set\n",
      "   REDIS_URL: redis://localhost:6379\n",
      "   AGENT_MEMORY_URL: http://localhost:8088\n",
      "   Memory Server: ‚úì Available\n"
     ]
    }
   ],
   "source": [
    "# Setup: Import components\n",
    "import os\n",
    "import sys\n",
    "import asyncio\n",
    "from typing import List, Dict, Any, Optional\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment\n",
    "load_dotenv()\n",
    "sys.path.append('../../reference-agent')\n",
    "\n",
    "# Import Section 2 components\n",
    "from redis_context_course.redis_config import redis_config\n",
    "from redis_context_course.course_manager import CourseManager\n",
    "from redis_context_course.models import (\n",
    "    Course, StudentProfile, DifficultyLevel,\n",
    "    CourseFormat, Semester\n",
    ")\n",
    "\n",
    "# Import LangChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "# Import Agent Memory Server client\n",
    "try:\n",
    "    from agent_memory_client import MemoryAPIClient, MemoryClientConfig\n",
    "    from agent_memory_client.models import WorkingMemory, MemoryMessage, ClientMemoryRecord\n",
    "    MEMORY_SERVER_AVAILABLE = True\n",
    "    print(\"‚úÖ Agent Memory Server client available\")\n",
    "except ImportError:\n",
    "    MEMORY_SERVER_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è  Agent Memory Server not available\")\n",
    "    print(\"üìù Install with: pip install agent-memory-client\")\n",
    "    print(\"üöÄ Start server: See reference-agent/README.md\")\n",
    "\n",
    "# Verify environment\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"‚ùå OPENAI_API_KEY not found. Please set in .env file.\")\n",
    "else:\n",
    "    print(\"‚úÖ OPENAI_API_KEY found\")\n",
    "\n",
    "print(f\"\\nüîß Environment Setup:\")\n",
    "print(f\"   OPENAI_API_KEY: {'‚úì Set' if os.getenv('OPENAI_API_KEY') else '‚úó Not set'}\")\n",
    "print(f\"   REDIS_URL: {os.getenv('REDIS_URL', 'redis://localhost:6379')}\")\n",
    "print(f\"   AGENT_MEMORY_URL: {os.getenv('AGENT_MEMORY_URL', 'http://localhost:8088')}\")\n",
    "print(f\"   Memory Server: {'‚úì Available' if MEMORY_SERVER_AVAILABLE else '‚úó Not available'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedc66a54eb849c6",
   "metadata": {},
   "source": [
    "### üéØ What We Just Did\n",
    "\n",
    "**Successfully Imported:**\n",
    "- ‚úÖ **Section 2 RAG components** - `redis_config`, `CourseManager`, models\n",
    "- ‚úÖ **Agent Memory Server client** - Production-ready memory system\n",
    "- ‚úÖ **Environment verified** - OpenAI API key, Redis, Memory Server\n",
    "\n",
    "**Why This Matters:**\n",
    "- We're **building on Section 2's foundation** (not starting from scratch)\n",
    "- **Agent Memory Server** provides scalable, persistent memory\n",
    "- **Same Redis University domain** for consistency\n",
    "\n",
    "---\n",
    "\n",
    "## üîß Initialize Components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cd141310064ba82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T14:27:08.269735Z",
     "iopub.status.busy": "2025-10-31T14:27:08.269624Z",
     "iopub.status.idle": "2025-10-31T14:27:08.386857Z",
     "shell.execute_reply": "2025-10-31T14:27:08.386425Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:27:08 redisvl.index.index INFO   Index already exists, not overwriting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Memory Client Initialized\n",
      "   Base URL: http://localhost:8088\n",
      "   Namespace: redis_university\n",
      "\n",
      "üë§ Student Profile: Sarah Chen\n",
      "   Major: Computer Science\n",
      "   Interests: machine learning, data science, algorithms\n"
     ]
    }
   ],
   "source": [
    "# Initialize components\n",
    "course_manager = CourseManager()\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.0)\n",
    "\n",
    "# Initialize Memory Client\n",
    "if MEMORY_SERVER_AVAILABLE:\n",
    "    config = MemoryClientConfig(\n",
    "        base_url=os.getenv(\"AGENT_MEMORY_URL\", \"http://localhost:8088\"),\n",
    "        default_namespace=\"redis_university\"\n",
    "    )\n",
    "    memory_client = MemoryAPIClient(config=config)\n",
    "    print(\"üß† Memory Client Initialized\")\n",
    "    print(f\"   Base URL: {config.base_url}\")\n",
    "    print(f\"   Namespace: {config.default_namespace}\")\n",
    "else:\n",
    "    memory_client = None\n",
    "    print(\"‚ö†Ô∏è  Running without Memory Server (limited functionality)\")\n",
    "\n",
    "# Create a sample student profile (reusing Section 2 pattern)\n",
    "sarah = StudentProfile(\n",
    "    name=\"Sarah Chen\",\n",
    "    email=\"sarah.chen@university.edu\",\n",
    "    major=\"Computer Science\",\n",
    "    year=2,\n",
    "    interests=[\"machine learning\", \"data science\", \"algorithms\"],\n",
    "    completed_courses=[\"CS101\", \"CS201\"],\n",
    "    current_courses=[\"MATH301\"],\n",
    "    preferred_format=CourseFormat.ONLINE,\n",
    "    preferred_difficulty=DifficultyLevel.INTERMEDIATE\n",
    ")\n",
    "\n",
    "print(f\"\\nüë§ Student Profile: {sarah.name}\")\n",
    "print(f\"   Major: {sarah.major}\")\n",
    "print(f\"   Interests: {', '.join(sarah.interests)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d221bf3835cda63e",
   "metadata": {},
   "source": [
    "### üí° Key Insight\n",
    "\n",
    "We're reusing:\n",
    "- ‚úÖ **Same `CourseManager`** from Section 2\n",
    "- ‚úÖ **Same `StudentProfile`** model\n",
    "- ‚úÖ **Same Redis configuration**\n",
    "\n",
    "We're adding:\n",
    "- ‚ú® **Memory Client** for conversation history\n",
    "- ‚ú® **Working Memory** for session context\n",
    "- ‚ú® **Long-term Memory** for persistent knowledge\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Part 1: Memory-Enhanced RAG\n",
    "\n",
    "### **Goal:** Build a simple, inline memory-enhanced RAG system that demonstrates the benefits of memory.\n",
    "\n",
    "### **Approach:**\n",
    "- Start with Section 2's stateless RAG\n",
    "- Add working memory for conversation continuity\n",
    "- Add long-term memory for personalization\n",
    "- Show clear before/after comparisons\n",
    "\n",
    "---\n",
    "\n",
    "## üö´ Before: Stateless RAG (Section 2 Approach)\n",
    "\n",
    "Let's first recall how Section 2's stateless RAG worked.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18c01bfe255ff0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T14:27:08.387999Z",
     "iopub.status.busy": "2025-10-31T14:27:08.387932Z",
     "iopub.status.idle": "2025-10-31T14:27:19.029786Z",
     "shell.execute_reply": "2025-10-31T14:27:19.029077Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üö´ STATELESS RAG DEMO\n",
      "================================================================================\n",
      "\n",
      "üë§ User: I'm interested in machine learning courses\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:27:09 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:27:16 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Agent: Hi Sarah! It's great to hear about your interest in machine learning. Since you've already completed CS101 and CS201, you have a solid foundation in computer science, which will be beneficial as you dive into machine learning.\n",
      "\n",
      "Here are some course recommendations that align with your interests:\n",
      "\n",
      "1. **CS007: Machine Learning** - This course is a perfect fit for you as it focuses on the fundamentals of machine learning, including supervised and unsupervised learning techniques, model evaluation, and practical applications. It will build on your existing knowledge and introduce you to key machine learning concepts.\n",
      "\n",
      "2. **MATH022: Linear Algebra** - Linear algebra is a crucial mathematical foundation for understanding machine learning algorithms. This course will cover essential topics such as vector spaces, matrices, and eigenvalues, which are frequently used in machine learning.\n",
      "\n",
      "3. **MATH024: Linear Algebra** - If MATH022 is not available or if you're looking for a different perspective, MATH024 is another option. It may cover similar topics but with a different approach or additional applications.\n",
      "\n",
      "Additionally, you might want to explore courses in data science and algorithms, as they are closely related to machine learning:\n",
      "\n",
      "- **Data Science Courses**: These courses often cover data preprocessing, statistical analysis, and data visualization, which are important skills for a machine learning practitioner.\n",
      "\n",
      "- **Advanced Algorithms**: Understanding complex algorithms can help you design more efficient machine learning models.\n",
      "\n",
      "If you have any more questions or need further guidance, feel free to ask!\n",
      "\n",
      "\n",
      "üë§ User: What are the prerequisites for the first one?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:27:16 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:27:19 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Agent: For the course MATH028: Calculus I, the prerequisites typically include a solid understanding of high school algebra and trigonometry. Some institutions may require a placement test to ensure readiness for calculus. However, specific prerequisites can vary by institution, so it's always a good idea to check the course catalog or contact the mathematics department at your university for the most accurate information.\n",
      "\n",
      "‚ùå Agent can't resolve 'the first one' - no conversation history!\n"
     ]
    }
   ],
   "source": [
    "# Stateless RAG (Section 2 approach)\n",
    "async def stateless_rag_query(user_query: str, student_profile: StudentProfile, top_k: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    Section 2 stateless RAG approach.\n",
    "\n",
    "    Problems:\n",
    "    - No conversation history\n",
    "    - Can't resolve references (\"it\", \"that course\")\n",
    "    - Each query is independent\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Search courses\n",
    "    courses = await course_manager.search_courses(user_query, limit=top_k)\n",
    "\n",
    "    # Step 2: Assemble context (System + User + Retrieved only)\n",
    "    system_prompt = \"You are a helpful Redis University course advisor.\"\n",
    "\n",
    "    user_context = f\"\"\"Student: {student_profile.name}\n",
    "Major: {student_profile.major}\n",
    "Interests: {', '.join(student_profile.interests)}\n",
    "Completed: {', '.join(student_profile.completed_courses)}\"\"\"\n",
    "\n",
    "    retrieved_context = \"Relevant Courses:\\n\"\n",
    "    for i, course in enumerate(courses, 1):\n",
    "        retrieved_context += f\"{i}. {course.course_code}: {course.title}\\n\"\n",
    "\n",
    "    # Step 3: Generate response\n",
    "    messages = [\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content=f\"{user_context}\\n\\n{retrieved_context}\\n\\nQuery: {user_query}\")\n",
    "    ]\n",
    "\n",
    "    response = llm.invoke(messages).content\n",
    "\n",
    "    # ‚ùå No conversation history stored\n",
    "    # ‚ùå Next query won't remember this interaction\n",
    "\n",
    "    return response\n",
    "\n",
    "# Test stateless RAG\n",
    "print(\"=\" * 80)\n",
    "print(\"üö´ STATELESS RAG DEMO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "query_1 = \"I'm interested in machine learning courses\"\n",
    "print(f\"\\nüë§ User: {query_1}\")\n",
    "response_1 = await stateless_rag_query(query_1, sarah)\n",
    "print(f\"\\nü§ñ Agent: {response_1}\")\n",
    "\n",
    "# Try a follow-up with pronoun reference\n",
    "query_2 = \"What are the prerequisites for the first one?\"\n",
    "print(f\"\\n\\nüë§ User: {query_2}\")\n",
    "response_2 = await stateless_rag_query(query_2, sarah)\n",
    "print(f\"\\nü§ñ Agent: {response_2}\")\n",
    "print(\"\\n‚ùå Agent can't resolve 'the first one' - no conversation history!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb296c50e53337f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### üéØ What Just Happened?\n",
    "\n",
    "**Query 1:** \"I'm interested in machine learning courses\"\n",
    "- ‚úÖ Works fine - searches and returns ML courses\n",
    "\n",
    "**Query 2:** \"What are the prerequisites for **the first one**?\"\n",
    "- ‚ùå **Fails** - Agent doesn't know what \"the first one\" refers to\n",
    "- ‚ùå No conversation history stored\n",
    "- ‚ùå Each query is completely independent\n",
    "\n",
    "**The Problem:** Natural conversation requires context from previous turns.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ After: Memory-Enhanced RAG\n",
    "\n",
    "Now let's add memory to enable natural conversations.\n",
    "\n",
    "### **Step 1: Load Working Memory**\n",
    "\n",
    "Working memory stores conversation history for the current session.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5577d8576496593a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-31T14:27:19.031485Z",
     "iopub.status.busy": "2025-10-31T14:27:19.031347Z",
     "iopub.status.idle": "2025-10-31T14:27:19.324283Z",
     "shell.execute_reply": "2025-10-31T14:27:19.323806Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:27:19 httpx INFO   HTTP Request: GET http://localhost:8088/v1/working-memory/demo_session_001?user_id=sarah.chen&namespace=redis_university&model_name=gpt-4o \"HTTP/1.1 404 Not Found\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:27:19 httpx INFO   HTTP Request: PUT http://localhost:8088/v1/working-memory/demo_session_001?user_id=sarah.chen&model_name=gpt-4o \"HTTP/1.1 500 Internal Server Error\"\n"
     ]
    },
    {
     "ename": "MemoryServerError",
     "evalue": "HTTP 500: Internal Server Error",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPStatusError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.6/lib/python3.12/site-packages/agent_memory_client/client.py:291\u001b[39m, in \u001b[36mMemoryAPIClient.get_working_memory\u001b[39m\u001b[34m(self, session_id, user_id, namespace, model_name, context_window_max)\u001b[39m\n\u001b[32m    288\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.get(\n\u001b[32m    289\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m/v1/working-memory/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msession_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, params=params\n\u001b[32m    290\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m291\u001b[39m \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    293\u001b[39m \u001b[38;5;66;03m# Get the raw JSON response\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.6/lib/python3.12/site-packages/httpx/_models.py:829\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    828\u001b[39m message = message.format(\u001b[38;5;28mself\u001b[39m, error_type=error_type)\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request=request, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPStatusError\u001b[39m: Client error '404 Not Found' for url 'http://localhost:8088/v1/working-memory/demo_session_001?user_id=sarah.chen&namespace=redis_university&model_name=gpt-4o'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mMemoryNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.6/lib/python3.12/site-packages/agent_memory_client/client.py:359\u001b[39m, in \u001b[36mMemoryAPIClient.get_or_create_working_memory\u001b[39m\u001b[34m(self, session_id, user_id, namespace, model_name, context_window_max, long_term_memory_strategy)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    358\u001b[39m     \u001b[38;5;66;03m# Try to get existing working memory first\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m     existing_memory = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.get_working_memory(\n\u001b[32m    360\u001b[39m         session_id=session_id,\n\u001b[32m    361\u001b[39m         user_id=user_id,\n\u001b[32m    362\u001b[39m         namespace=namespace,\n\u001b[32m    363\u001b[39m         model_name=model_name,\n\u001b[32m    364\u001b[39m         context_window_max=context_window_max,\n\u001b[32m    365\u001b[39m     )\n\u001b[32m    367\u001b[39m     \u001b[38;5;66;03m# Check if this is an unsaved session (deprecated behavior for old clients)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.6/lib/python3.12/site-packages/agent_memory_client/client.py:299\u001b[39m, in \u001b[36mMemoryAPIClient.get_working_memory\u001b[39m\u001b[34m(self, session_id, user_id, namespace, model_name, context_window_max)\u001b[39m\n\u001b[32m    298\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m299\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_http_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.6/lib/python3.12/site-packages/agent_memory_client/client.py:161\u001b[39m, in \u001b[36mMemoryAPIClient._handle_http_error\u001b[39m\u001b[34m(self, response)\u001b[39m\n\u001b[32m    159\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MemoryNotFoundError\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MemoryNotFoundError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mResource not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m response.status_code >= \u001b[32m400\u001b[39m:\n",
      "\u001b[31mMemoryNotFoundError\u001b[39m: Resource not found: http://localhost:8088/v1/working-memory/demo_session_001?user_id=sarah.chen&namespace=redis_university&model_name=gpt-4o",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mHTTPStatusError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.6/lib/python3.12/site-packages/agent_memory_client/client.py:473\u001b[39m, in \u001b[36mMemoryAPIClient.put_working_memory\u001b[39m\u001b[34m(self, session_id, memory, user_id, model_name, context_window_max)\u001b[39m\n\u001b[32m    468\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.put(\n\u001b[32m    469\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m/v1/working-memory/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msession_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    470\u001b[39m     json=memory.model_dump(exclude_none=\u001b[38;5;28;01mTrue\u001b[39;00m, mode=\u001b[33m\"\u001b[39m\u001b[33mjson\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    471\u001b[39m     params=params,\n\u001b[32m    472\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m WorkingMemoryResponse(**response.json())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.6/lib/python3.12/site-packages/httpx/_models.py:829\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    828\u001b[39m message = message.format(\u001b[38;5;28mself\u001b[39m, error_type=error_type)\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request=request, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPStatusError\u001b[39m: Server error '500 Internal Server Error' for url 'http://localhost:8088/v1/working-memory/demo_session_001?user_id=sarah.chen&model_name=gpt-4o'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/500",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mMemoryServerError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m session_id = \u001b[33m\"\u001b[39m\u001b[33mdemo_session_001\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     18\u001b[39m student_id = sarah.email.split(\u001b[33m'\u001b[39m\u001b[33m@\u001b[39m\u001b[33m'\u001b[39m)[\u001b[32m0\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m working_memory = \u001b[38;5;28;01mawait\u001b[39;00m load_working_memory(session_id, student_id)\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m working_memory:\n\u001b[32m     23\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Loaded working memory for session: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msession_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mload_working_memory\u001b[39m\u001b[34m(session_id, student_id)\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m MEMORY_SERVER_AVAILABLE:\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m _, working_memory = \u001b[38;5;28;01mawait\u001b[39;00m memory_client.get_or_create_working_memory(\n\u001b[32m      9\u001b[39m     session_id=session_id,\n\u001b[32m     10\u001b[39m     user_id=student_id,\n\u001b[32m     11\u001b[39m     model_name=\u001b[33m\"\u001b[39m\u001b[33mgpt-4o\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     12\u001b[39m )\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m working_memory\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.6/lib/python3.12/site-packages/agent_memory_client/client.py:411\u001b[39m, in \u001b[36mMemoryAPIClient.get_or_create_working_memory\u001b[39m\u001b[34m(self, session_id, user_id, namespace, model_name, context_window_max, long_term_memory_strategy)\u001b[39m\n\u001b[32m    398\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_404:\n\u001b[32m    399\u001b[39m     \u001b[38;5;66;03m# Session doesn't exist, create it\u001b[39;00m\n\u001b[32m    400\u001b[39m     empty_memory = WorkingMemory(\n\u001b[32m    401\u001b[39m         session_id=session_id,\n\u001b[32m    402\u001b[39m         namespace=namespace \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.default_namespace,\n\u001b[32m   (...)\u001b[39m\u001b[32m    408\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m MemoryStrategyConfig(),\n\u001b[32m    409\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m     created_memory = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.put_working_memory(\n\u001b[32m    412\u001b[39m         session_id=session_id,\n\u001b[32m    413\u001b[39m         memory=empty_memory,\n\u001b[32m    414\u001b[39m         user_id=user_id,\n\u001b[32m    415\u001b[39m         model_name=model_name,\n\u001b[32m    416\u001b[39m         context_window_max=context_window_max,\n\u001b[32m    417\u001b[39m     )\n\u001b[32m    419\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, created_memory)\n\u001b[32m    420\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    421\u001b[39m     \u001b[38;5;66;03m# Re-raise other HTTP errors\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.6/lib/python3.12/site-packages/agent_memory_client/client.py:476\u001b[39m, in \u001b[36mMemoryAPIClient.put_working_memory\u001b[39m\u001b[34m(self, session_id, memory, user_id, model_name, context_window_max)\u001b[39m\n\u001b[32m    474\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m WorkingMemoryResponse(**response.json())\n\u001b[32m    475\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m476\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_http_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.6/lib/python3.12/site-packages/agent_memory_client/client.py:168\u001b[39m, in \u001b[36mMemoryAPIClient._handle_http_error\u001b[39m\u001b[34m(self, response)\u001b[39m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    167\u001b[39m         message = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mHTTP \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.text\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MemoryServerError(message, response.status_code)\n\u001b[32m    169\u001b[39m \u001b[38;5;66;03m# This should never be reached, but mypy needs to know this never returns\u001b[39;00m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m MemoryServerError(\n\u001b[32m    171\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnexpected status code: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, response.status_code\n\u001b[32m    172\u001b[39m )\n",
      "\u001b[31mMemoryServerError\u001b[39m: HTTP 500: Internal Server Error"
     ]
    }
   ],
   "source": [
    "# Step 1: Load working memory\n",
    "async def load_working_memory(session_id: str, student_id: str):\n",
    "    \"\"\"Load conversation history from working memory\"\"\"\n",
    "\n",
    "    if not MEMORY_SERVER_AVAILABLE:\n",
    "        return None\n",
    "\n",
    "    _, working_memory = await memory_client.get_or_create_working_memory(\n",
    "        session_id=session_id,\n",
    "        user_id=student_id,\n",
    "        model_name=\"gpt-4o\"\n",
    "    )\n",
    "\n",
    "    return working_memory\n",
    "\n",
    "# Test loading working memory\n",
    "session_id = \"demo_session_001\"\n",
    "student_id = sarah.email.split('@')[0]\n",
    "\n",
    "working_memory = await load_working_memory(session_id, student_id)\n",
    "\n",
    "if working_memory:\n",
    "    print(f\"‚úÖ Loaded working memory for session: {session_id}\")\n",
    "    print(f\"   Messages: {len(working_memory.messages)}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Memory Server not available\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f541ee37bd9e94b",
   "metadata": {},
   "source": [
    "### üéØ What We Just Did\n",
    "\n",
    "**Loaded Working Memory:**\n",
    "- Created or retrieved conversation history for this session\n",
    "- Session ID: `demo_session_001` (unique per conversation)\n",
    "- User ID: `sarah_chen` (from student email)\n",
    "\n",
    "**Why This Matters:**\n",
    "- Working memory persists across turns in the same session\n",
    "- Enables reference resolution (\"it\", \"that course\", \"the first one\")\n",
    "- Conversation context is maintained\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 2: Search Long-term Memory**\n",
    "\n",
    "Long-term memory stores persistent facts and preferences across sessions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff97c53e10f44716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Search long-term memory\n",
    "async def search_longterm_memory(query: str, student_id: str, limit: int = 5):\n",
    "    \"\"\"Search long-term memory for relevant facts\"\"\"\n",
    "\n",
    "    if not MEMORY_SERVER_AVAILABLE:\n",
    "        return []\n",
    "\n",
    "    results = await memory_client.search_long_term_memory(\n",
    "        text=query,\n",
    "        user_id=student_id,\n",
    "        limit=limit\n",
    "    )\n",
    "\n",
    "    return [m.text for m in results.memories] if results.memories else []\n",
    "\n",
    "# Test searching long-term memory\n",
    "query = \"What does the student prefer?\"\n",
    "memories = await search_longterm_memory(query, student_id)\n",
    "\n",
    "print(f\"üîç Query: '{query}'\")\n",
    "print(f\"üìö Found {len(memories)} relevant memories:\")\n",
    "for i, memory in enumerate(memories, 1):\n",
    "    print(f\"   {i}. {memory}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4fabcf00d1fdda",
   "metadata": {},
   "source": [
    "### üéØ What We Just Did\n",
    "\n",
    "**Searched Long-term Memory:**\n",
    "- Used semantic search to find relevant facts\n",
    "- Query: \"What does the student prefer?\"\n",
    "- Results: Memories about preferences, goals, academic info\n",
    "\n",
    "**Why This Matters:**\n",
    "- Long-term memory enables personalization\n",
    "- Facts persist across sessions (days, weeks, months)\n",
    "- Semantic search finds relevant memories without exact keyword matching\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 3: Assemble All Four Context Types**\n",
    "\n",
    "Now let's combine everything: System + User + Conversation + Retrieved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b6cc99aac5193e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Assemble all four context types\n",
    "async def assemble_context(\n",
    "    user_query: str,\n",
    "    student_profile: StudentProfile,\n",
    "    session_id: str,\n",
    "    top_k: int = 3\n",
    "):\n",
    "    \"\"\"\n",
    "    Assemble all four context types.\n",
    "\n",
    "    Returns:\n",
    "        - system_prompt: System Context\n",
    "        - user_context: User Context (profile + long-term memories)\n",
    "        - conversation_messages: Conversation Context (working memory)\n",
    "        - retrieved_context: Retrieved Context (RAG results)\n",
    "    \"\"\"\n",
    "\n",
    "    student_id = student_profile.email.split('@')[0]\n",
    "\n",
    "    # 1. System Context (static)\n",
    "    system_prompt = \"\"\"You are a Redis University course advisor.\n",
    "\n",
    "Your role:\n",
    "- Help students find and enroll in courses\n",
    "- Provide personalized recommendations\n",
    "- Answer questions about courses, prerequisites, schedules\n",
    "\n",
    "Guidelines:\n",
    "- Use conversation history to resolve references (\"it\", \"that course\")\n",
    "- Use long-term memories to personalize recommendations\n",
    "- Be helpful, supportive, and encouraging\"\"\"\n",
    "\n",
    "    # 2. User Context (profile + long-term memories)\n",
    "    user_context = f\"\"\"Student Profile:\n",
    "- Name: {student_profile.name}\n",
    "- Major: {student_profile.major}\n",
    "- Year: {student_profile.year}\n",
    "- Interests: {', '.join(student_profile.interests)}\n",
    "- Completed: {', '.join(student_profile.completed_courses)}\n",
    "- Current: {', '.join(student_profile.current_courses)}\n",
    "- Preferred Format: {student_profile.preferred_format.value}\n",
    "- Preferred Difficulty: {student_profile.preferred_difficulty.value}\"\"\"\n",
    "\n",
    "    # Search long-term memory\n",
    "    longterm_memories = await search_longterm_memory(user_query, student_id)\n",
    "    if longterm_memories:\n",
    "        user_context += f\"\\n\\nLong-term Memories:\\n\" + \"\\n\".join([f\"- {m}\" for m in longterm_memories])\n",
    "\n",
    "    # 3. Conversation Context (working memory)\n",
    "    working_memory = await load_working_memory(session_id, student_id)\n",
    "    conversation_messages = []\n",
    "    if working_memory:\n",
    "        for msg in working_memory.messages:\n",
    "            if msg.role == \"user\":\n",
    "                conversation_messages.append(HumanMessage(content=msg.content))\n",
    "            elif msg.role == \"assistant\":\n",
    "                conversation_messages.append(AIMessage(content=msg.content))\n",
    "\n",
    "\n",
    "    # 4. Retrieved Context (RAG)\n",
    "    courses = await course_manager.search_courses(user_query, limit=top_k)\n",
    "    retrieved_context = \"Relevant Courses:\\n\"\n",
    "    for i, course in enumerate(courses, 1):\n",
    "        retrieved_context += f\"\\n{i}. {course.course_code}: {course.title}\"\n",
    "        retrieved_context += f\"\\n   Description: {course.description}\"\n",
    "        retrieved_context += f\"\\n   Difficulty: {course.difficulty_level.value}\"\n",
    "        retrieved_context += f\"\\n   Format: {course.format.value}\"\n",
    "        if course.prerequisites:\n",
    "            prereqs = [p.course_code for p in course.prerequisites]\n",
    "            retrieved_context += f\"\\n   Prerequisites: {', '.join(prereqs)}\"\n",
    "\n",
    "    return system_prompt, user_context, conversation_messages, retrieved_context\n",
    "\n",
    "# Test assembling context\n",
    "system_prompt, user_context, conversation_messages, retrieved_context = await assemble_context(\n",
    "    user_query=\"machine learning courses\",\n",
    "    student_profile=sarah,\n",
    "    session_id=session_id,\n",
    "    top_k=3\n",
    ")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üìä ASSEMBLED CONTEXT\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\n1Ô∏è‚É£ System Context: {len(system_prompt)} chars\")\n",
    "print(f\"2Ô∏è‚É£ User Context: {len(user_context)} chars\")\n",
    "print(f\"3Ô∏è‚É£ Conversation Context: {len(conversation_messages)} messages\")\n",
    "print(f\"4Ô∏è‚É£ Retrieved Context: {len(retrieved_context)} chars\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f84446a6969a31",
   "metadata": {},
   "source": [
    "### üéØ What We Just Did\n",
    "\n",
    "**Assembled All Four Context Types:**\n",
    "\n",
    "1. **System Context** - Role, instructions, guidelines (static)\n",
    "2. **User Context** - Profile + long-term memories (dynamic, user-specific)\n",
    "3. **Conversation Context** - Working memory messages (dynamic, session-specific)\n",
    "4. **Retrieved Context** - RAG search results (dynamic, query-specific)\n",
    "\n",
    "**Why This Matters:**\n",
    "- All four context types from Section 1 are now working together\n",
    "- System knows WHO the user is (User Context)\n",
    "- System knows WHAT was discussed (Conversation Context)\n",
    "- System knows WHAT's relevant (Retrieved Context)\n",
    "- System knows HOW to behave (System Context)\n",
    "\n",
    "---\n",
    "\n",
    "### **Step 4: Generate Response and Save Memory**\n",
    "\n",
    "Now let's generate a response and save the updated conversation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9c424c857e0b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Generate response and save memory\n",
    "async def generate_and_save(\n",
    "    user_query: str,\n",
    "    student_profile: StudentProfile,\n",
    "    session_id: str,\n",
    "    top_k: int = 3\n",
    ") -> str:\n",
    "    \"\"\"Generate response and save to working memory\"\"\"\n",
    "\n",
    "    if not MEMORY_SERVER_AVAILABLE:\n",
    "        # Fallback to stateless RAG\n",
    "        return await stateless_rag_query(user_query, student_profile, top_k)\n",
    "\n",
    "    student_id = student_profile.email.split('@')[0]\n",
    "\n",
    "    # Assemble context\n",
    "    system_prompt, user_context, conversation_messages, retrieved_context = await assemble_context(\n",
    "        user_query, student_profile, session_id, top_k\n",
    "    )\n",
    "\n",
    "    # Build messages\n",
    "    messages = [SystemMessage(content=system_prompt)]\n",
    "    messages.extend(conversation_messages)  # Add conversation history\n",
    "    messages.append(HumanMessage(content=f\"{user_context}\\n\\n{retrieved_context}\\n\\nQuery: {user_query}\"))\n",
    "\n",
    "    # Generate response\n",
    "    response = llm.invoke(messages).content\n",
    "\n",
    "    # Save to working memory\n",
    "    working_memory = await load_working_memory(session_id, student_id)\n",
    "    if working_memory:\n",
    "        working_memory.messages.extend([\n",
    "            MemoryMessage(role=\"user\", content=user_query),\n",
    "            MemoryMessage(role=\"assistant\", content=response)\n",
    "        ])\n",
    "        await memory_client.put_working_memory(\n",
    "            session_id=session_id,\n",
    "            memory=working_memory,\n",
    "            user_id=student_id,\n",
    "            model_name=\"gpt-4o\"\n",
    "        )\n",
    "\n",
    "    return response\n",
    "\n",
    "# Test generating and saving\n",
    "query = \"I'm interested in machine learning courses\"\n",
    "response = await generate_and_save(query, sarah, session_id)\n",
    "\n",
    "print(f\"üë§ User: {query}\")\n",
    "print(f\"\\nü§ñ Agent: {response}\")\n",
    "print(f\"\\n‚úÖ Conversation saved to working memory\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f591bf327805dd",
   "metadata": {},
   "source": [
    "### üéØ What We Just Did\n",
    "\n",
    "**Generated Response:**\n",
    "- Assembled all four context types\n",
    "- Built message list with conversation history\n",
    "- Generated response using LLM\n",
    "- **Saved updated conversation to working memory**\n",
    "\n",
    "**Why This Matters:**\n",
    "- Next query will have access to this conversation\n",
    "- Reference resolution will work (\"it\", \"that course\")\n",
    "- Conversation continuity is maintained\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ Complete Demo: Memory-Enhanced RAG\n",
    "\n",
    "Now let's test the complete system with a multi-turn conversation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a129328fb75fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete memory-enhanced RAG demo\n",
    "async def memory_enhanced_rag_demo():\n",
    "    \"\"\"Demonstrate complete memory-enhanced RAG system\"\"\"\n",
    "\n",
    "    demo_session_id = \"complete_demo_session\"\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(\"üß™ MEMORY-ENHANCED RAG DEMO\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nüë§ Student: {sarah.name}\")\n",
    "    print(f\"üìß Session: {demo_session_id}\")\n",
    "\n",
    "    # Turn 1: Initial query\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üìç TURN 1: Initial Query\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    query_1 = \"I'm interested in machine learning courses\"\n",
    "    print(f\"\\nüë§ User: {query_1}\")\n",
    "\n",
    "    response_1 = await generate_and_save(query_1, sarah, demo_session_id)\n",
    "    print(f\"\\nü§ñ Agent: {response_1}\")\n",
    "\n",
    "    # Turn 2: Follow-up with pronoun reference\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üìç TURN 2: Follow-up with Pronoun Reference\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    query_2 = \"What are the prerequisites for the first one?\"\n",
    "    print(f\"\\nüë§ User: {query_2}\")\n",
    "\n",
    "    response_2 = await generate_and_save(query_2, sarah, demo_session_id)\n",
    "    print(f\"\\nü§ñ Agent: {response_2}\")\n",
    "    print(\"\\n‚úÖ Agent resolved 'the first one' using conversation history!\")\n",
    "\n",
    "\n",
    "    # Turn 3: Another follow-up\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üìç TURN 3: Another Follow-up\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    query_3 = \"Do I meet those prerequisites?\"\n",
    "    print(f\"\\nüë§ User: {query_3}\")\n",
    "\n",
    "    response_3 = await generate_and_save(query_3, sarah, demo_session_id)\n",
    "    print(f\"\\nü§ñ Agent: {response_3}\")\n",
    "    print(\"\\n‚úÖ Agent resolved 'those prerequisites' and checked student's transcript!\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"‚úÖ DEMO COMPLETE: Memory-enhanced RAG enables natural conversations!\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "# Run the complete demo\n",
    "await memory_enhanced_rag_demo()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e19c1f57084b6b1",
   "metadata": {},
   "source": [
    "### üéØ What Just Happened?\n",
    "\n",
    "**Turn 1:** \"I'm interested in machine learning courses\"\n",
    "- System searches courses\n",
    "- Finds ML-related courses\n",
    "- Responds with recommendations\n",
    "- **Saves conversation to working memory**\n",
    "\n",
    "**Turn 2:** \"What are the prerequisites for **the first one**?\"\n",
    "- System loads working memory (Turn 1)\n",
    "- Resolves \"the first one\" ‚Üí first course mentioned in Turn 1\n",
    "- Responds with prerequisites\n",
    "- **Saves updated conversation**\n",
    "\n",
    "**Turn 3:** \"Do I meet **those prerequisites**?\"\n",
    "- System loads working memory (Turns 1-2)\n",
    "- Resolves \"those prerequisites\" ‚Üí prerequisites from Turn 2\n",
    "- Checks student's completed courses (from profile)\n",
    "- Responds with personalized answer\n",
    "- **Saves updated conversation**\n",
    "\n",
    "**üí° Key Insight:** Memory + RAG = **Natural, stateful, personalized conversations**\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Before vs. After Comparison\n",
    "\n",
    "Let's visualize the difference between stateless and memory-enhanced RAG.\n",
    "\n",
    "### **Stateless RAG (Section 2):**\n",
    "\n",
    "```\n",
    "Query 1: \"I'm interested in ML courses\"\n",
    "  ‚Üí ‚úÖ Works (searches and returns courses)\n",
    "\n",
    "Query 2: \"What are the prerequisites for the first one?\"\n",
    "  ‚Üí ‚ùå Fails (no conversation history)\n",
    "  ‚Üí Agent: \"Which course are you referring to?\"\n",
    "```\n",
    "\n",
    "**Problems:**\n",
    "- ‚ùå No conversation continuity\n",
    "- ‚ùå Can't resolve references\n",
    "- ‚ùå Each query is independent\n",
    "- ‚ùå Poor user experience\n",
    "\n",
    "### **Memory-Enhanced RAG (This Notebook):**\n",
    "\n",
    "```\n",
    "Query 1: \"I'm interested in ML courses\"\n",
    "  ‚Üí ‚úÖ Works (searches and returns courses)\n",
    "  ‚Üí Saves to working memory\n",
    "\n",
    "Query 2: \"What are the prerequisites for the first one?\"\n",
    "  ‚Üí ‚úÖ Works (loads conversation history)\n",
    "  ‚Üí Resolves \"the first one\" ‚Üí first course from Query 1\n",
    "  ‚Üí Responds with prerequisites\n",
    "  ‚Üí Saves updated conversation\n",
    "\n",
    "Query 3: \"Do I meet those prerequisites?\"\n",
    "  ‚Üí ‚úÖ Works (loads conversation history)\n",
    "  ‚Üí Resolves \"those prerequisites\" ‚Üí prerequisites from Query 2\n",
    "  ‚Üí Checks student transcript\n",
    "  ‚Üí Responds with personalized answer\n",
    "```\n",
    "\n",
    "**Benefits:**\n",
    "- ‚úÖ Conversation continuity\n",
    "- ‚úÖ Reference resolution\n",
    "- ‚úÖ Personalization\n",
    "- ‚úÖ Natural user experience\n",
    "\n",
    "---\n",
    "\n",
    "## üéì Key Takeaways\n",
    "\n",
    "### **1. Memory Transforms RAG**\n",
    "\n",
    "**Without Memory (Section 2):**\n",
    "- Stateless queries\n",
    "- No conversation continuity\n",
    "- Limited to 3 context types (System, User, Retrieved)\n",
    "\n",
    "**With Memory (This Notebook):**\n",
    "- Stateful conversations\n",
    "- Reference resolution\n",
    "- All 4 context types (System, User, Conversation, Retrieved)\n",
    "\n",
    "### **2. Two Types of Memory Work Together**\n",
    "\n",
    "**Working Memory:**\n",
    "- Session-scoped conversation history\n",
    "- Enables reference resolution\n",
    "- TTL-based (expires after 24 hours)\n",
    "\n",
    "**Long-term Memory:**\n",
    "- User-scoped persistent facts\n",
    "- Enables personalization\n",
    "- Persists indefinitely\n",
    "\n",
    "### **3. Simple, Inline Approach**\n",
    "\n",
    "**What We Built:**\n",
    "- Small, focused functions\n",
    "- Inline code (no large classes)\n",
    "- Progressive learning\n",
    "- Clear demonstrations\n",
    "\n",
    "**Why This Matters:**\n",
    "- Easy to understand\n",
    "- Easy to modify\n",
    "- Easy to extend\n",
    "- Foundation for LangGraph agents (Part 2)\n",
    "\n",
    "### **4. All Four Context Types**\n",
    "\n",
    "**System Context:** Role, instructions, guidelines\n",
    "**User Context:** Profile + long-term memories\n",
    "**Conversation Context:** Working memory\n",
    "**Retrieved Context:** RAG results\n",
    "\n",
    "**Together:** Natural, stateful, personalized conversations\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ What's Next?\n",
    "\n",
    "### **Part 2: Converting to LangGraph Agent (Separate Notebook)**\n",
    "\n",
    "In the next notebook (`03_langgraph_agent_conversion.ipynb`), we'll:\n",
    "\n",
    "1. **Convert** memory-enhanced RAG to LangGraph agent\n",
    "2. **Add** state management and control flow\n",
    "3. **Prepare** for Section 4 (tools and advanced capabilities)\n",
    "4. **Build** a foundation for production-ready agents\n",
    "\n",
    "**Why LangGraph?**\n",
    "- Better state management\n",
    "- More control over agent flow\n",
    "- Easier to add tools (Section 4)\n",
    "- Production-ready architecture\n",
    "\n",
    "### **Section 4: Tools and Advanced Agents**\n",
    "\n",
    "After completing Part 2, you'll be ready for Section 4:\n",
    "- Adding tools (course enrollment, schedule management)\n",
    "- Multi-step reasoning\n",
    "- Error handling and recovery\n",
    "- Production deployment\n",
    "\n",
    "---\n",
    "\n",
    "## üèãÔ∏è Practice Exercises\n",
    "\n",
    "### **Exercise 1: Add Personalization**\n",
    "\n",
    "Modify the system to use long-term memories for personalization:\n",
    "\n",
    "1. Store student preferences in long-term memory\n",
    "2. Search long-term memory in `assemble_context()`\n",
    "3. Use memories to personalize recommendations\n",
    "\n",
    "**Hint:** Use `memory_client.create_long_term_memory()` and `memory_client.search_long_term_memory()`\n",
    "\n",
    "### **Exercise 2: Add Error Handling**\n",
    "\n",
    "Add error handling for memory operations:\n",
    "\n",
    "1. Handle case when Memory Server is unavailable\n",
    "2. Fallback to stateless RAG\n",
    "3. Log warnings appropriately\n",
    "\n",
    "**Hint:** Check `MEMORY_SERVER_AVAILABLE` flag\n",
    "\n",
    "### **Exercise 3: Add Conversation Summary**\n",
    "\n",
    "Add a function to summarize the conversation:\n",
    "\n",
    "1. Load working memory\n",
    "2. Extract key points from conversation\n",
    "3. Display summary to user\n",
    "\n",
    "**Hint:** Use LLM to generate summary from conversation history\n",
    "\n",
    "---\n",
    "\n",
    "## üìù Summary\n",
    "\n",
    "### **What You Learned:**\n",
    "\n",
    "1. ‚úÖ **Built** memory-enhanced RAG system\n",
    "2. ‚úÖ **Integrated** all four context types\n",
    "3. ‚úÖ **Demonstrated** benefits of memory\n",
    "4. ‚úÖ **Prepared** for LangGraph conversion\n",
    "\n",
    "### **Key Concepts:**\n",
    "\n",
    "- **Working Memory** - Session-scoped conversation history\n",
    "- **Long-term Memory** - User-scoped persistent facts\n",
    "- **Context Assembly** - Combining all four context types\n",
    "- **Reference Resolution** - Resolving pronouns and references\n",
    "- **Stateful Conversations** - Natural, continuous dialogue\n",
    "\n",
    "### **Next Steps:**\n",
    "\n",
    "1. Complete practice exercises\n",
    "2. Experiment with different queries\n",
    "3. Move to Part 2 (LangGraph agent conversion)\n",
    "4. Prepare for Section 4 (tools and advanced agents)\n",
    "\n",
    "**üéâ Congratulations!** You've built a complete memory-enhanced RAG system!\n",
    "\n",
    "---\n",
    "\n",
    "## üîó Resources\n",
    "\n",
    "- **Section 1:** Four Context Types\n",
    "- **Section 2:** RAG Fundamentals\n",
    "- **Section 3 (Notebook 1):** Memory Fundamentals\n",
    "- **Section 3 (Notebook 3):** LangGraph Agent Conversion (Next)\n",
    "- **Section 4:** Tools and Advanced Agents\n",
    "\n",
    "**Agent Memory Server:**\n",
    "- GitHub: `reference-agent/`\n",
    "- Documentation: See README.md\n",
    "- API Client: `agent-memory-client`\n",
    "\n",
    "**LangChain:**\n",
    "- Documentation: https://python.langchain.com/\n",
    "- LangGraph: https://langchain-ai.github.io/langgraph/\n",
    "\n",
    "---\n",
    "\n",
    "![Redis](https://redis.io/wp-content/uploads/2024/04/Logotype.svg?auto=webp&quality=85,75&width=120)\n",
    "\n",
    "**Redis University - Context Engineering Course**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
