{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a19be531208b364b",
   "metadata": {},
   "source": [
    "![Redis](https://redis.io/wp-content/uploads/2024/04/Logotype.svg?auto=webp&quality=85,75&width=120)\n",
    "\n",
    "# üß† Section 3: Memory Architecture - From Stateless RAG to Stateful Conversations\n",
    "\n",
    "**‚è±Ô∏è Estimated Time:** 45-60 minutes\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "\n",
    "1. **Understand** why memory is essential for context engineering\n",
    "2. **Implement** working memory for conversation continuity\n",
    "3. **Use** long-term memory for persistent user knowledge\n",
    "4. **Integrate** memory with your Section 2 RAG system\n",
    "5. **Build** a complete memory-enhanced course advisor\n",
    "\n",
    "---\n",
    "\n",
    "## üîó Recap\n",
    "\n",
    "### **Section 1: The Four Context Types**\n",
    "\n",
    "Recall the four context types from Section 1:\n",
    "\n",
    "1. **System Context** (Static) - Role, instructions, guidelines\n",
    "2. **User Context** (Dynamic, User-Specific) - Profile, preferences, goals\n",
    "3. **Conversation Context** (Dynamic, Session-Specific) - **‚Üê Memory enables this!**\n",
    "4. **Retrieved Context** (Dynamic, Query-Specific) - RAG results\n",
    "\n",
    "### **Section 2: Stateless RAG**\n",
    "\n",
    "Your Section 2 RAG system was **stateless**:\n",
    "\n",
    "```python\n",
    "async def rag_query(query, student_profile):\n",
    "    # 1. Search courses (Retrieved Context)\n",
    "    courses = await course_manager.search_courses(query)\n",
    "\n",
    "    # 2. Assemble context (System + User + Retrieved)\n",
    "    context = assemble_context(system_prompt, student_profile, courses)\n",
    "\n",
    "    # 3. Generate response\n",
    "    response = llm.invoke(context)\n",
    "\n",
    "    # ‚ùå No conversation history stored\n",
    "    # ‚ùå Each query is independent\n",
    "    # ‚ùå Can't reference previous messages\n",
    "```\n",
    "\n",
    "**The Problem:** Every query starts from scratch. No conversation continuity.\n",
    "\n",
    "---\n",
    "\n",
    "## üö® Why Agents Need Memory: The Grounding Problem\n",
    "\n",
    "Before diving into implementation, let's understand the fundamental problem that memory solves.\n",
    "\n",
    "**Grounding** means understanding what users are referring to. Natural conversation is full of references:\n",
    "\n",
    "### **Without Memory:**\n",
    "\n",
    "```\n",
    "User: \"Tell me about CS401\"\n",
    "Agent: \"CS401 is Machine Learning. It covers supervised learning...\"\n",
    "\n",
    "User: \"What are its prerequisites?\"\n",
    "Agent: ‚ùå \"What does 'it' refer to? Please specify which course.\"\n",
    "\n",
    "User: \"The course we just discussed!\"\n",
    "Agent: ‚ùå \"I don't have access to previous messages. Which course?\"\n",
    "```\n",
    "\n",
    "**This is a terrible user experience.**\n",
    "\n",
    "### Types of References That Need Grounding\n",
    "\n",
    "**Pronouns:**\n",
    "- \"it\", \"that course\", \"those\", \"this one\"\n",
    "- \"he\", \"she\", \"they\" (referring to people)\n",
    "\n",
    "**Descriptions:**\n",
    "- \"the easy one\", \"the online course\"\n",
    "- \"my advisor\", \"that professor\"\n",
    "\n",
    "**Implicit context:**\n",
    "- \"Can I take it?\" ‚Üí Take what?\n",
    "- \"When does it start?\" ‚Üí What starts?\n",
    "\n",
    "**Temporal references:**\n",
    "- \"you mentioned\", \"earlier\", \"last time\"\n",
    "\n",
    "### **With Memory:**\n",
    "\n",
    "```\n",
    "User: \"Tell me about CS401\"\n",
    "Agent: \"CS401 is Machine Learning. It covers...\"\n",
    "[Stores: User asked about CS401]\n",
    "\n",
    "User: \"What are its prerequisites?\"\n",
    "Agent: [Checks memory: \"its\" = CS401]\n",
    "Agent: ‚úÖ \"CS401 requires CS201 and MATH301\"\n",
    "\n",
    "User: \"Can I take it?\"\n",
    "Agent: [Checks memory: \"it\" = CS401, checks student transcript]\n",
    "Agent: ‚úÖ \"You've completed CS201 but still need MATH301\"\n",
    "```\n",
    "\n",
    "**Now the conversation flows naturally!**\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Two Types of Memory\n",
    "\n",
    "### **1. Working Memory (Session-Scoped)**\n",
    "\n",
    " - **What:** Conversation messages from the current session\n",
    " - **Purpose:** Reference resolution, conversation continuity\n",
    " - **Lifetime:** Session duration (24 hours TTL by default)\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "Session: session_123\n",
    "Messages:\n",
    "  1. User: \"Tell me about CS401\"\n",
    "  2. Agent: \"CS401 is Machine Learning...\"\n",
    "  3. User: \"What are its prerequisites?\"\n",
    "  4. Agent: \"CS401 requires CS201 and MATH301\"\n",
    "```\n",
    "\n",
    "### **2. Long-term Memory (Cross-Session)**\n",
    "\n",
    " - **What:** Persistent facts, preferences, goals\n",
    " - **Purpose:** Personalization across sessions and applications\n",
    " - **Lifetime:** Permanent (until explicitly deleted)\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "User: student_sarah\n",
    "Memories:\n",
    "  - \"Prefers online courses over in-person\"\n",
    "  - \"Major: Computer Science, focus on AI/ML\"\n",
    "  - \"Goal: Graduate Spring 2026\"\n",
    "  - \"Completed: CS101, CS201, MATH301\"\n",
    "```\n",
    "\n",
    "### **Comparison: Working vs. Long-term Memory**\n",
    "\n",
    "| Working Memory | Long-term Memory |\n",
    "|----------------|------------------|\n",
    "| **Session-scoped** | **User-scoped** |\n",
    "| Current conversation | Important facts |\n",
    "| TTL-based (expires) | Persistent |\n",
    "| Full message history | Extracted knowledge |\n",
    "| Loaded/saved each turn | Searched when needed |\n",
    "\n",
    "---\n",
    "\n",
    "## üì¶ Setup and Environment\n",
    "\n",
    "Let's set up our environment with the necessary dependencies and connections. We'll build on Section 2's RAG foundation and add memory capabilities.\n",
    "\n",
    "### ‚ö†Ô∏è Prerequisites\n",
    "\n",
    "**Before running this notebook, make sure you have:**\n",
    "\n",
    "1. **Docker Desktop running** - Required for Redis and Agent Memory Server\n",
    "\n",
    "2. **Environment variables** - Create a `.env` file in the `reference-agent` directory:\n",
    "   ```bash\n",
    "   # Copy the example file\n",
    "   cd ../../reference-agent\n",
    "   cp .env.example .env\n",
    "\n",
    "   # Edit .env and add your OpenAI API key\n",
    "   # OPENAI_API_KEY=your_actual_openai_api_key_here\n",
    "   ```\n",
    "\n",
    "3. **Run the setup script** - This will automatically start Redis and Agent Memory Server:\n",
    "   ```bash\n",
    "   cd ../../reference-agent\n",
    "   python setup_agent_memory_server.py\n",
    "   ```\n",
    "\n",
    "**Note:** The setup script will:\n",
    "- ‚úÖ Check if Docker is running\n",
    "- ‚úÖ Start Redis if not running (port 6379)\n",
    "- ‚úÖ Start Agent Memory Server if not running (port 8088)\n",
    "- ‚úÖ Verify Redis connection is working\n",
    "- ‚úÖ Handle any configuration issues automatically\n",
    "\n",
    "If the Memory Server is not available, the notebook will skip memory-related demos but will still run.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8736deb126c3f16",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56268deee3282f75",
   "metadata": {},
   "source": [
    "### Automated Setup Check\n",
    "\n",
    "Let's run the setup script to ensure all services are running properly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e2349a4bfd202d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T16:01:32.037128Z",
     "start_time": "2025-10-31T16:01:31.719782Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running automated setup check...\n",
      "\n",
      "\n",
      "üîß Agent Memory Server Setup\n",
      "===========================\n",
      "üìä Checking Redis...\n",
      "‚úÖ Redis is running\n",
      "üìä Checking Agent Memory Server...\n",
      "üîç Agent Memory Server container exists. Checking health...\n",
      "‚úÖ Agent Memory Server is running and healthy\n",
      "‚úÖ No Redis connection issues detected\n",
      "\n",
      "‚úÖ Setup Complete!\n",
      "=================\n",
      "üìä Services Status:\n",
      "   ‚Ä¢ Redis: Running on port 6379\n",
      "   ‚Ä¢ Agent Memory Server: Running on port 8088\n",
      "\n",
      "üéØ You can now run the notebooks!\n",
      "\n",
      "\n",
      "‚úÖ All services are ready!\n"
     ]
    }
   ],
   "source": [
    "# Run the setup script to ensure Redis and Agent Memory Server are running\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to setup script\n",
    "setup_script = Path(\"../../reference-agent/setup_agent_memory_server.py\")\n",
    "\n",
    "if setup_script.exists():\n",
    "    print(\"Running automated setup check...\\n\")\n",
    "    result = subprocess.run(\n",
    "        [sys.executable, str(setup_script)],\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    print(result.stdout)\n",
    "    if result.returncode != 0:\n",
    "        print(\"‚ö†Ô∏è  Setup check failed. Please review the output above.\")\n",
    "        print(result.stderr)\n",
    "    else:\n",
    "        print(\"\\n‚úÖ All services are ready!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Setup script not found. Please ensure services are running manually.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478ea9ac1a2f036",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdbc5b7728ae311",
   "metadata": {},
   "source": [
    "### Install Dependencies\n",
    "\n",
    "If you haven't already installed the reference-agent package, uncomment and run the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9a802c8b0c8d69aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T16:01:33.407203Z",
     "start_time": "2025-10-31T16:01:33.405271Z"
    }
   },
   "outputs": [],
   "source": [
    "# Uncomment to install reference-agent package\n",
    "# %pip install -q -e ../../reference-agent\n",
    "\n",
    "# Uncomment to install agent-memory-client\n",
    "# %pip install -q agent-memory-client\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f982dbbdf7348af",
   "metadata": {},
   "source": [
    "### Load Environment Variables\n",
    "\n",
    "We'll load environment variables from the `.env` file in the `reference-agent` directory.\n",
    "\n",
    "**Required variables:**\n",
    "- `OPENAI_API_KEY` - Your OpenAI API key\n",
    "- `REDIS_URL` - Redis connection URL (default: redis://localhost:6379)\n",
    "- `AGENT_MEMORY_URL` - Agent Memory Server URL (default: http://localhost:8088)\n",
    "\n",
    "If you haven't created the `.env` file yet, copy `.env.example` and add your OpenAI API key.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f08b853441918493",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T16:01:33.957278Z",
     "start_time": "2025-10-31T16:01:33.952517Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment variables loaded\n",
      "   REDIS_URL: redis://localhost:6379\n",
      "   AGENT_MEMORY_URL: http://localhost:8088\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from reference-agent directory\n",
    "env_path = Path(\"../../reference-agent/.env\")\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "# Verify required environment variables\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "REDIS_URL = os.getenv(\"REDIS_URL\", \"redis://localhost:6379\")\n",
    "AGENT_MEMORY_URL = os.getenv(\"AGENT_MEMORY_URL\", \"http://localhost:8088\")\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    print(f\"\"\"‚ùå OPENAI_API_KEY not found!\n",
    "\n",
    "    Please create a .env file at: {env_path.absolute()}\n",
    "\n",
    "    With the following content:\n",
    "    OPENAI_API_KEY=your_openai_api_key\n",
    "    REDIS_URL=redis://localhost:6379\n",
    "    AGENT_MEMORY_URL=http://localhost:8088\n",
    "    \"\"\")\n",
    "else:\n",
    "    print(\"‚úÖ Environment variables loaded\")\n",
    "    print(f\"   REDIS_URL: {REDIS_URL}\")\n",
    "    print(f\"   AGENT_MEMORY_URL: {AGENT_MEMORY_URL}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cc9a0e7f524393",
   "metadata": {},
   "source": [
    "### Import Core Libraries\n",
    "\n",
    "We'll import standard Python libraries and async support for our memory operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8d1a43786a58529a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T16:01:35.497349Z",
     "start_time": "2025-10-31T16:01:35.494811Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Core libraries imported\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from typing import List, Dict, Any, Optional\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"‚úÖ Core libraries imported\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a35f8385b5910f2",
   "metadata": {},
   "source": [
    "### Import Section 2 Components\n",
    "\n",
    "We're building on Section 2's RAG foundation, so we'll reuse the same components:\n",
    "- `redis_config` - Redis connection and configuration\n",
    "- `CourseManager` - Course search and management\n",
    "- `StudentProfile` and other models - Data structures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5fac5a16ef3467c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T16:01:36.260993Z",
     "start_time": "2025-10-31T16:01:36.258192Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Section 2 components imported\n",
      "   CourseManager: Available\n",
      "   Redis Config: Available\n",
      "   Models: Course, StudentProfile, etc.\n"
     ]
    }
   ],
   "source": [
    "# Import Section 2 components from reference-agent\n",
    "from redis_context_course.redis_config import redis_config\n",
    "from redis_context_course.course_manager import CourseManager\n",
    "from redis_context_course.models import (\n",
    "    Course, StudentProfile, DifficultyLevel,\n",
    "    CourseFormat, Semester\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Section 2 components imported\")\n",
    "print(f\"   CourseManager: Available\")\n",
    "print(f\"   Redis Config: Available\")\n",
    "print(f\"   Models: Course, StudentProfile, etc.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d596af861c1882",
   "metadata": {},
   "source": [
    "### Import LangChain Components\n",
    "\n",
    "We'll use LangChain for LLM interaction and message handling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d001a6a150cd8cc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T16:01:37.193910Z",
     "start_time": "2025-10-31T16:01:37.190383Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LangChain components imported\n",
      "   ChatOpenAI: Available\n",
      "   Message types: HumanMessage, SystemMessage, AIMessage\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "print(\"‚úÖ LangChain components imported\")\n",
    "print(f\"   ChatOpenAI: Available\")\n",
    "print(f\"   Message types: HumanMessage, SystemMessage, AIMessage\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80d8f9d4a4784a",
   "metadata": {},
   "source": [
    "### Import Agent Memory Server Client\n",
    "\n",
    "The Agent Memory Server provides production-ready memory management. If it's not available, we'll note that and continue with limited functionality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5518b93f06209cb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T16:01:38.702459Z",
     "start_time": "2025-10-31T16:01:38.699416Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Agent Memory Server client available\n",
      "   MemoryAPIClient: Ready\n",
      "   Memory models: WorkingMemory, MemoryMessage, ClientMemoryRecord\n"
     ]
    }
   ],
   "source": [
    "# Import Agent Memory Server client\n",
    "try:\n",
    "    from agent_memory_client import MemoryAPIClient, MemoryClientConfig\n",
    "    from agent_memory_client.models import WorkingMemory, MemoryMessage, ClientMemoryRecord\n",
    "    MEMORY_SERVER_AVAILABLE = True\n",
    "    print(\"‚úÖ Agent Memory Server client available\")\n",
    "    print(\"   MemoryAPIClient: Ready\")\n",
    "    print(\"   Memory models: WorkingMemory, MemoryMessage, ClientMemoryRecord\")\n",
    "except ImportError:\n",
    "    MEMORY_SERVER_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è  Agent Memory Server not available\")\n",
    "    print(\"   Install with: pip install agent-memory-client\")\n",
    "    print(\"   Start server: See reference-agent/README.md\")\n",
    "    print(\"   Note: Some demos will be skipped\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d78a586f3365b83",
   "metadata": {},
   "source": [
    "### What We Just Did\n",
    "\n",
    "We've successfully set up our environment with all the necessary components:\n",
    "\n",
    "**Imported:**\n",
    "- ‚úÖ Section 2 RAG components (`CourseManager`, `redis_config`, models)\n",
    "- ‚úÖ LangChain for LLM interaction\n",
    "- ‚úÖ Agent Memory Server client (if available)\n",
    "\n",
    "**Why This Matters:**\n",
    "- Building on Section 2's foundation (not starting from scratch)\n",
    "- Agent Memory Server provides scalable, persistent memory\n",
    "- Same Redis University domain for consistency\n",
    "\n",
    "---\n",
    "\n",
    "## üîß Initialize Components\n",
    "\n",
    "Now let's initialize the components we'll use throughout this notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1241314ec6df2f",
   "metadata": {},
   "source": [
    "### Initialize Course Manager\n",
    "\n",
    "The `CourseManager` handles course search and retrieval, just like in Section 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3f0dacdfabc8daae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T16:01:40.826554Z",
     "start_time": "2025-10-31T16:01:40.824362Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Course Manager initialized\n",
      "   Ready to search and retrieve courses\n"
     ]
    }
   ],
   "source": [
    "# Initialize Course Manager\n",
    "course_manager = CourseManager()\n",
    "\n",
    "print(\"‚úÖ Course Manager initialized\")\n",
    "print(\"   Ready to search and retrieve courses\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6183b28509fb438",
   "metadata": {},
   "source": [
    "### Initialize LLM\n",
    "\n",
    "We'll use GPT-4o with temperature=0.0 for consistent, deterministic responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4a18aede0c3a9d28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T16:01:41.920811Z",
     "start_time": "2025-10-31T16:01:41.918499Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20addef07a1c6bd",
   "metadata": {},
   "source": [
    "### Initialize Memory Client\n",
    "\n",
    "If the Agent Memory Server is available, we'll initialize the memory client. This client handles both working memory (conversation history) and long-term memory (persistent facts).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6540f51278904b66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T16:01:43.124529Z",
     "start_time": "2025-10-31T16:01:43.114843Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Memory Client initialized\n",
      "   Base URL: http://localhost:8088\n",
      "   Namespace: redis_university\n",
      "   Ready for working memory and long-term memory operations\n"
     ]
    }
   ],
   "source": [
    "# Initialize Memory Client\n",
    "if MEMORY_SERVER_AVAILABLE:\n",
    "    config = MemoryClientConfig(\n",
    "        base_url=AGENT_MEMORY_URL,\n",
    "        default_namespace=\"redis_university\"\n",
    "    )\n",
    "    memory_client = MemoryAPIClient(config=config)\n",
    "    print(\"‚úÖ Memory Client initialized\")\n",
    "    print(f\"   Base URL: {config.base_url}\")\n",
    "    print(f\"   Namespace: {config.default_namespace}\")\n",
    "    print(\"   Ready for working memory and long-term memory operations\")\n",
    "else:\n",
    "    memory_client = None\n",
    "    print(\"‚ö†Ô∏è  Memory Server not available\")\n",
    "    print(\"   Running with limited functionality\")\n",
    "    print(\"   Some demos will be skipped\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7d14857491bfe8",
   "metadata": {},
   "source": [
    "### Create Sample Student Profile\n",
    "\n",
    "We'll create a sample student profile to use throughout our demos. This follows the same pattern from Section 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d7accc8e193ee717",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T16:01:44.956173Z",
     "start_time": "2025-10-31T16:01:44.952762Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Student profile created\n",
      "   Name: Sarah Chen\n",
      "   Major: Computer Science\n",
      "   Year: 2\n",
      "   Interests: machine learning, data science, algorithms\n",
      "   Completed: CS101, CS201\n",
      "   Preferred Format: online\n"
     ]
    }
   ],
   "source": [
    "# Create sample student profile\n",
    "sarah = StudentProfile(\n",
    "    name=\"Sarah Chen\",\n",
    "    email=\"sarah.chen@university.edu\",\n",
    "    major=\"Computer Science\",\n",
    "    year=2,\n",
    "    interests=[\"machine learning\", \"data science\", \"algorithms\"],\n",
    "    completed_courses=[\"CS101\", \"CS201\"],\n",
    "    current_courses=[\"MATH301\"],\n",
    "    preferred_format=CourseFormat.ONLINE,\n",
    "    preferred_difficulty=DifficultyLevel.INTERMEDIATE\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Student profile created\")\n",
    "print(f\"   Name: {sarah.name}\")\n",
    "print(f\"   Major: {sarah.major}\")\n",
    "print(f\"   Year: {sarah.year}\")\n",
    "print(f\"   Interests: {', '.join(sarah.interests)}\")\n",
    "print(f\"   Completed: {', '.join(sarah.completed_courses)}\")\n",
    "print(f\"   Preferred Format: {sarah.preferred_format.value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "68ba2022815ad2e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T16:01:45.601901Z",
     "start_time": "2025-10-31T16:01:45.599017Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ INITIALIZATION SUMMARY\n",
      "\n",
      "‚úÖ Course Manager: Ready\n",
      "‚úÖ LLM (GPT-4o): Ready\n",
      "‚úÖ Memory Client: Ready\n",
      "‚úÖ Student Profile: Sarah Chen\n"
     ]
    }
   ],
   "source": [
    "print(\"üéØ INITIALIZATION SUMMARY\")\n",
    "print(f\"\\n‚úÖ Course Manager: Ready\")\n",
    "print(f\"‚úÖ LLM (GPT-4o): Ready\")\n",
    "print(f\"{'‚úÖ' if MEMORY_SERVER_AVAILABLE else '‚ö†Ô∏è '} Memory Client: {'Ready' if MEMORY_SERVER_AVAILABLE else 'Not Available'}\")\n",
    "print(f\"‚úÖ Student Profile: {sarah.name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8da5b64eb6b5e1",
   "metadata": {},
   "source": [
    "### Initialization Done\n",
    "üìã What We're Building On:\n",
    "-  Section 2's RAG foundation (CourseManager, redis_config)\n",
    "-  Same StudentProfile model\n",
    "-  Same Redis configuration\n",
    "\n",
    "‚ú® What We're Adding:\n",
    "-  Memory Client for conversation history\n",
    "-  Working Memory for session context\n",
    "-  Long-term Memory for persistent knowledge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bde21130868fd19",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö Part 1: Working Memory Fundamentals\n",
    "\n",
    "### **What is Working Memory?**\n",
    "\n",
    "Working memory stores **conversation messages** for the current session. It enables:\n",
    "\n",
    "- ‚úÖ **Reference resolution** - \"it\", \"that course\", \"the one you mentioned\"\n",
    "- ‚úÖ **Context continuity** - Each message builds on previous messages\n",
    "- ‚úÖ **Natural conversations** - Users don't repeat themselves\n",
    "\n",
    "### **How It Works:**\n",
    "\n",
    "```\n",
    "Turn 1: Load working memory (empty) ‚Üí Process query ‚Üí Save messages\n",
    "Turn 2: Load working memory (1 exchange) ‚Üí Process query ‚Üí Save messages\n",
    "Turn 3: Load working memory (2 exchanges) ‚Üí Process query ‚Üí Save messages\n",
    "```\n",
    "\n",
    "Each turn has access to all previous messages in the session.\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ Hands-On: Working Memory in Action\n",
    "\n",
    "Let's simulate a multi-turn conversation with working memory. We'll break this down step-by-step to see how working memory enables natural conversation flow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc71f00dd15b373",
   "metadata": {},
   "source": [
    "### Setup: Create Session and Student IDs\n",
    "\n",
    "Now that we have our components initialized, let's create session and student identifiers for our working memory demo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9359e3bf25eca598",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T16:01:50.077441Z",
     "start_time": "2025-10-31T16:01:50.074776Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Working Memory Demo Setup\n",
      "   Student ID: sarah.chen\n",
      "   Session ID: session_sarah.chen_demo\n",
      "   Ready to demonstrate multi-turn conversation\n"
     ]
    }
   ],
   "source": [
    "# Setup for working memory demo\n",
    "student_id = sarah.email.split('@')[0]  # \"sarah.chen\"\n",
    "session_id = f\"session_{student_id}_demo\"\n",
    "\n",
    "print(\"üéØ Working Memory Demo Setup\")\n",
    "print(f\"   Student ID: {student_id}\")\n",
    "print(f\"   Session ID: {session_id}\")\n",
    "print(\"   Ready to demonstrate multi-turn conversation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea67f3258827c67a",
   "metadata": {},
   "source": [
    "### Turn 1: Initial Query\n",
    "\n",
    "Let's start with a simple query about a course. This is the first turn, so working memory will be empty.\n",
    "\n",
    "We'll break this down into clear steps:\n",
    "1. We will use Memory Server\n",
    "2. Load working memory (will be empty on first turn)\n",
    "3. Search for the course\n",
    "4. Generate a response\n",
    "5. Save the conversation to working memory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af82e6eb4d49750",
   "metadata": {},
   "source": [
    "#### Step 1: Set up the user query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "709f9c69669862b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T16:07:57.803898Z",
     "start_time": "2025-10-31T16:07:57.802105Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üìç TURN 1: User asks about a course\n",
      "================================================================================\n",
      "\n",
      "üë§ User: Tell me about Data Structures and Algorithms\n"
     ]
    }
   ],
   "source": [
    "# Check if Memory Server is available\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üìç TURN 1: User asks about a course\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Define the user's query\n",
    "turn1_query = \"Tell me about Data Structures and Algorithms\"\n",
    "print(f\"\\nüë§ User: {turn1_query}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca7a35730407f29",
   "metadata": {},
   "source": [
    "#### Step 2: Load working memory\n",
    "\n",
    "On the first turn, working memory will be empty since this is a new session.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "eba535e7baa67844",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T16:07:59.132603Z",
     "start_time": "2025-10-31T16:07:59.121297Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:07:59 httpx INFO   HTTP Request: GET http://localhost:8088/v1/working-memory/session_sarah.chen_demo?user_id=sarah.chen&namespace=redis_university&model_name=gpt-4o \"HTTP/1.1 200 OK\"\n",
      "üìä Working Memory Status:\n",
      "   Messages in memory: 2\n",
      "   Status: Has history\n"
     ]
    }
   ],
   "source": [
    "# Load working memory (empty for first turn)\n",
    "_, turn1_working_memory = await memory_client.get_or_create_working_memory(\n",
    "    session_id=session_id,\n",
    "    user_id=student_id,\n",
    "    model_name=\"gpt-4o\"\n",
    ")\n",
    "\n",
    "print(f\"üìä Working Memory Status:\")\n",
    "print(f\"   Messages in memory: {len(turn1_working_memory.messages)}\")\n",
    "print(f\"   Status: {'Empty (first turn)' if len(turn1_working_memory.messages) == 0 else 'Has history'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3d4a8ed528aa8fe0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T16:07:59.761241Z",
     "start_time": "2025-10-31T16:07:59.758468Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WorkingMemoryResponse(messages=[MemoryMessage(role='user', content='Tell me about CS401', id='01K8XF2FBC4YDC5QNVQ8ZQKXNC', created_at=datetime.datetime(2025, 10, 31, 15, 44, 39, 788221, tzinfo=TzInfo(0)), persisted_at=None, discrete_memory_extracted='f'), MemoryMessage(role='assistant', content='CS009: Data Structures and Algorithms. Study of fundamental data structures and algorithms. Arrays, linked lists, trees, graphs, sorting, a...', id='01K8XF2FBC4YDC5QNVQ8ZQKXND', created_at=datetime.datetime(2025, 10, 31, 15, 44, 39, 788242, tzinfo=TzInfo(0)), persisted_at=None, discrete_memory_extracted='f')], memories=[], data={}, context=None, user_id='sarah.chen', tokens=0, session_id='session_sarah.chen_demo', namespace='redis_university', long_term_memory_strategy=MemoryStrategyConfig(strategy='discrete', config={}), ttl_seconds=None, last_accessed=datetime.datetime(2025, 10, 31, 15, 44, 39, tzinfo=TzInfo(0)), context_percentage_total_used=0.0296875, context_percentage_until_summarization=0.04241071428571429, new_session=False, unsaved=None)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# observe the object\n",
    "turn1_working_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66aab8077c35d988",
   "metadata": {},
   "source": [
    "#### Step 3: Search for the course\n",
    "\n",
    "Use the course manager to search for courses matching the query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bca2cd06e747dd30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T16:08:01.776194Z",
     "start_time": "2025-10-31T16:08:01.244875Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Searching for courses...\n",
      "12:08:01 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "   Found 1 course(s)\n",
      "   - CS009: Data Structures and Algorithms\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nüîç Searching for courses...\")\n",
    "turn1_courses = await course_manager.search_courses(turn1_query, limit=1)\n",
    "\n",
    "if turn1_courses:\n",
    "    print(f\"   Found {len(turn1_courses)} course(s)\")\n",
    "\n",
    "    # print the course details\n",
    "    for course in turn1_courses:\n",
    "        print(f\"   - {course.course_code}: {course.title}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9bff55ea668e6b",
   "metadata": {},
   "source": [
    "#### Step 4: Generate response using LLM\n",
    "\n",
    "Use the LLM to generate a natural response based on the retrieved course information.\n",
    "\n",
    "This follows the **RAG pattern**: Retrieve (done in Step 3) ‚Üí Augment (add to context) ‚Üí Generate (use LLM).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a3f1b52618ccea57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T16:10:51.324011Z",
     "start_time": "2025-10-31T16:10:51.321773Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Course context: Course Information:\n",
      "- Code: CS009\n",
      "- Title: Data Structures and Algorithms\n",
      "- Description: Study of fundamental data structures and algorithms. Arrays, linked lists, trees, graphs, sorting, and searching.\n",
      "- Prerequisites: CS001, CS001\n",
      "- Credits: 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "course = turn1_courses[0]\n",
    "\n",
    "course_context = f\"\"\"Course Information:\n",
    "- Code: {course.course_code}\n",
    "- Title: {course.title}\n",
    "- Description: {course.description}\n",
    "- Prerequisites: {', '.join([p.course_code for p in course.prerequisites]) if course.prerequisites else 'None'}\n",
    "- Credits: {course.credits}\n",
    "\"\"\"\n",
    "\n",
    "print(f\"   Course context: {course_context}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c2cef0a286c2498e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T16:11:03.157009Z",
     "start_time": "2025-10-31T16:10:57.981518Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí≠ Generating response using LLM...\n",
      "12:11:03 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\n",
      "ü§ñ Agent: The course \"Data Structures and Algorithms\" (CS009) is a 4-credit course that focuses on the study of fundamental data structures and algorithms. In this course, you will learn about various data structures such as arrays, linked lists, trees, and graphs. Additionally, the course covers essential algorithms related to sorting and searching. \n",
      "\n",
      "To enroll in this course, you must have completed the prerequisite course CS001. This foundational knowledge will help you understand and apply the concepts taught in CS009 effectively.\n"
     ]
    }
   ],
   "source": [
    "# Build messages for LLM\n",
    "turn1_messages = [\n",
    "    SystemMessage(content=\"You are a helpful course advisor. Answer questions about courses based on the provided information.\"),\n",
    "    HumanMessage(content=f\"{course_context}\\n\\nUser question: {turn1_query}\")\n",
    "]\n",
    "\n",
    "# Generate response using LLM\n",
    "print(f\"\\nüí≠ Generating response using LLM...\")\n",
    "turn1_response = llm.invoke(turn1_messages).content\n",
    "\n",
    "print(f\"\\nü§ñ Agent: {turn1_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7017ac79a9f5b8e",
   "metadata": {},
   "source": [
    "#### Step 5: Save to working memory\n",
    "\n",
    "Add both the user query and assistant response to working memory for future turns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f957e507de0b77ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T16:11:06.124034Z",
     "start_time": "2025-10-31T16:11:06.113522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:11:06 httpx INFO   HTTP Request: PUT http://localhost:8088/v1/working-memory/session_sarah.chen_demo?user_id=sarah.chen&model_name=gpt-4o \"HTTP/1.1 200 OK\"\n",
      "\n",
      "‚úÖ Saved to working memory\n",
      "   Messages now in memory: 6\n"
     ]
    }
   ],
   "source": [
    "if MEMORY_SERVER_AVAILABLE:\n",
    "    # Add messages to working memory\n",
    "    turn1_working_memory.messages.extend([\n",
    "        MemoryMessage(role=\"user\", content=turn1_query),\n",
    "        MemoryMessage(role=\"assistant\", content=turn1_response)\n",
    "    ])\n",
    "\n",
    "    # Save to Memory Server\n",
    "    await memory_client.put_working_memory(\n",
    "        session_id=session_id,\n",
    "        memory=turn1_working_memory,\n",
    "        user_id=student_id,\n",
    "        model_name=\"gpt-4o\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\n‚úÖ Saved to working memory\")\n",
    "    print(f\"   Messages now in memory: {len(turn1_working_memory.messages)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02ac18016d1bec2",
   "metadata": {},
   "source": [
    "### What Just Happened in Turn 1?\n",
    "\n",
    "**Initial State:**\n",
    "- Working memory was empty (first turn)\n",
    "- No conversation history available\n",
    "\n",
    "**Actions (RAG Pattern):**\n",
    "1. **Retrieve:** Searched for Data Structures and Algorithms in the course database\n",
    "2. **Augment:** Added course information to LLM context\n",
    "3. **Generate:** LLM created a natural language response\n",
    "4. **Save:** Stored conversation in working memory\n",
    "\n",
    "**Result:**\n",
    "- Working memory now contains 2 messages (1 user, 1 assistant)\n",
    "- This history will be available for the next turn\n",
    "\n",
    "**Key Insight:** Even the first turn uses the LLM to generate natural responses based on retrieved information.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb9cb241d57f6b2",
   "metadata": {},
   "source": [
    "### Turn 2: Follow-up with Pronoun Reference\n",
    "\n",
    "Now let's ask a follow-up question using \"its\" - a pronoun that requires context from Turn 1.\n",
    "\n",
    "We'll break this down into steps:\n",
    "1. Set up the query with pronoun reference\n",
    "2. Load working memory (now contains Turn 1)\n",
    "3. Build context with conversation history\n",
    "4. Generate response using LLM\n",
    "5. Save to working memory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9589179c5c3da16",
   "metadata": {},
   "source": [
    "#### Step 1: Set up the query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "afdae986f84bc666",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T16:11:10.864359Z",
     "start_time": "2025-10-31T16:11:10.861423Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìç TURN 2: User uses pronoun reference ('its')\n",
      "================================================================================\n",
      "\n",
      "üë§ User: What are its prerequisites?\n",
      "   Note: 'its' refers to Data Structures and Algorithms from Turn 1\n"
     ]
    }
   ],
   "source": [
    "if MEMORY_SERVER_AVAILABLE:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üìç TURN 2: User uses pronoun reference ('its')\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    turn2_query = \"What are its prerequisites?\"\n",
    "    print(f\"\\nüë§ User: {turn2_query}\")\n",
    "    print(f\"   Note: 'its' refers to Data Structures and Algorithms from Turn 1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b48f20026071368",
   "metadata": {},
   "source": [
    "#### Step 2: Load working memory\n",
    "\n",
    "This time, working memory will contain the conversation from Turn 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a979bc4af565ffc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T16:11:12.939612Z",
     "start_time": "2025-10-31T16:11:12.929347Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:11:12 httpx INFO   HTTP Request: GET http://localhost:8088/v1/working-memory/session_sarah.chen_demo?user_id=sarah.chen&namespace=redis_university&model_name=gpt-4o \"HTTP/1.1 200 OK\"\n",
      "\n",
      "üìä Working Memory Status:\n",
      "   Messages in memory: 6\n",
      "   Contains: Turn 1 conversation\n"
     ]
    }
   ],
   "source": [
    "if MEMORY_SERVER_AVAILABLE:\n",
    "    # Load working memory (now has 1 exchange from Turn 1)\n",
    "    _, turn2_working_memory = await memory_client.get_or_create_working_memory(\n",
    "        session_id=session_id,\n",
    "        user_id=student_id,\n",
    "        model_name=\"gpt-4o\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\nüìä Working Memory Status:\")\n",
    "    print(f\"   Messages in memory: {len(turn2_working_memory.messages)}\")\n",
    "    print(f\"   Contains: Turn 1 conversation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76554aaeb0e3cbbe",
   "metadata": {},
   "source": [
    "#### Step 3: Build context with conversation history\n",
    "\n",
    "To resolve the pronoun \"its\", we need to include the conversation history in the LLM context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bfb4ec94f0f8ac26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T16:11:14.247764Z",
     "start_time": "2025-10-31T16:11:14.244686Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Building context with conversation history...\n",
      "   Total messages in context: 8\n",
      "   Includes: System prompt + Turn 1 history + current query\n"
     ]
    }
   ],
   "source": [
    "if MEMORY_SERVER_AVAILABLE:\n",
    "    print(f\"\\nüîß Building context with conversation history...\")\n",
    "\n",
    "    # Start with system message\n",
    "    turn2_messages = [\n",
    "        SystemMessage(content=\"You are a helpful course advisor. Use conversation history to resolve references like 'it', 'that course', etc.\")\n",
    "    ]\n",
    "\n",
    "    # Add conversation history from working memory\n",
    "    for msg in turn2_working_memory.messages:\n",
    "        if msg.role == \"user\":\n",
    "            turn2_messages.append(HumanMessage(content=msg.content))\n",
    "        elif msg.role == \"assistant\":\n",
    "            turn2_messages.append(AIMessage(content=msg.content))\n",
    "\n",
    "    # Add current query\n",
    "    turn2_messages.append(HumanMessage(content=turn2_query))\n",
    "\n",
    "    print(f\"   Total messages in context: {len(turn2_messages)}\")\n",
    "    print(f\"   Includes: System prompt + Turn 1 history + current query\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cc54a84997e055",
   "metadata": {},
   "source": [
    "#### Step 4: Generate response using LLM\n",
    "\n",
    "The LLM can now resolve \"its\" by looking at the conversation history.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a086f086fa37da80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T16:11:18.369099Z",
     "start_time": "2025-10-31T16:11:16.670757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí≠ LLM resolving 'its' using conversation history...\n",
      "12:11:18 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\n",
      "ü§ñ Agent: The prerequisite for the \"Data Structures and Algorithms\" course (CS009) is CS001. You need to have completed CS001 to enroll in CS009, as it provides the foundational knowledge necessary for understanding the more advanced concepts covered in the course.\n"
     ]
    }
   ],
   "source": [
    "if MEMORY_SERVER_AVAILABLE:\n",
    "    print(f\"\\nüí≠ LLM resolving 'its' using conversation history...\")\n",
    "    turn2_response = llm.invoke(turn2_messages).content\n",
    "\n",
    "    print(f\"\\nü§ñ Agent: {turn2_response}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f186107902cd150a",
   "metadata": {},
   "source": [
    "#### Step 5: Save to working memory\n",
    "\n",
    "Add this turn's conversation to working memory for future turns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c68fbf3ce5198b43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T16:11:30.487163Z",
     "start_time": "2025-10-31T16:11:30.475678Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:11:30 httpx INFO   HTTP Request: PUT http://localhost:8088/v1/working-memory/session_sarah.chen_demo?user_id=sarah.chen&model_name=gpt-4o \"HTTP/1.1 200 OK\"\n",
      "\n",
      "‚úÖ Saved to working memory\n",
      "   Messages now in memory: 8\n"
     ]
    }
   ],
   "source": [
    "if MEMORY_SERVER_AVAILABLE:\n",
    "    # Add messages to working memory\n",
    "    turn2_working_memory.messages.extend([\n",
    "        MemoryMessage(role=\"user\", content=turn2_query),\n",
    "        MemoryMessage(role=\"assistant\", content=turn2_response)\n",
    "    ])\n",
    "\n",
    "    # Save to Memory Server\n",
    "    await memory_client.put_working_memory(\n",
    "        session_id=session_id,\n",
    "        memory=turn2_working_memory,\n",
    "        user_id=student_id,\n",
    "        model_name=\"gpt-4o\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\n‚úÖ Saved to working memory\")\n",
    "    print(f\"   Messages now in memory: {len(turn2_working_memory.messages)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f326d23a6ee980b3",
   "metadata": {},
   "source": [
    "### What Just Happened in Turn 2?\n",
    "\n",
    "**Initial State:**\n",
    "- Working memory contained Turn 1 conversation (2 messages)\n",
    "- User asked about \"its prerequisites\" - pronoun reference\n",
    "\n",
    "**Actions:**\n",
    "1. Loaded working memory with Turn 1 history\n",
    "2. Built context including conversation history\n",
    "3. LLM resolved \"its\" ‚Üí Data Structures and Algorithms (from Turn 1)\n",
    "4. Generated response about Data Structures and Algorithms's prerequisites\n",
    "5. Saved updated conversation to working memory\n",
    "\n",
    "**Result:**\n",
    "- Working memory now contains 4 messages (2 exchanges)\n",
    "- LLM successfully resolved pronoun reference using conversation history\n",
    "- Natural conversation flow maintained\n",
    "\n",
    "**Key Insight:** Without working memory, the LLM wouldn't know what \"its\" refers to!\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be825d46a5c61955",
   "metadata": {},
   "source": [
    "### Turn 3: Another Follow-up\n",
    "\n",
    "Let's ask one more follow-up question to demonstrate continued conversation continuity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd74fd54662fd1f",
   "metadata": {},
   "source": [
    "#### Step 1: Set up the query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "208fd300637bb36a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T16:12:49.572832Z",
     "start_time": "2025-10-31T16:12:49.571009Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìç TURN 3: User asks another follow-up\n",
      "================================================================================\n",
      "\n",
      "üë§ User: Can I take it next semester?\n",
      "   Note: 'it' refers to Data Structures and Algorithms from Turn 1\n"
     ]
    }
   ],
   "source": [
    "if MEMORY_SERVER_AVAILABLE:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üìç TURN 3: User asks another follow-up\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    turn3_query = \"Can I take it next semester?\"\n",
    "    print(f\"\\nüë§ User: {turn3_query}\")\n",
    "    print(f\"   Note: 'it' refers to Data Structures and Algorithms from Turn 1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86331ac55a6ecde2",
   "metadata": {},
   "source": [
    "#### Step 2: Load working memory with full conversation history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2e44ceccb6c97653",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T16:12:55.090836Z",
     "start_time": "2025-10-31T16:12:55.080957Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:12:55 httpx INFO   HTTP Request: GET http://localhost:8088/v1/working-memory/session_sarah.chen_demo?user_id=sarah.chen&namespace=redis_university&model_name=gpt-4o \"HTTP/1.1 200 OK\"\n",
      "\n",
      "üìä Working Memory Status:\n",
      "   Messages in memory: 8\n",
      "   Contains: Turns 1 and 2\n"
     ]
    }
   ],
   "source": [
    "if MEMORY_SERVER_AVAILABLE:\n",
    "    # Load working memory (now has 2 exchanges)\n",
    "    _, turn3_working_memory = await memory_client.get_or_create_working_memory(\n",
    "        session_id=session_id,\n",
    "        user_id=student_id,\n",
    "        model_name=\"gpt-4o\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\nüìä Working Memory Status:\")\n",
    "    print(f\"   Messages in memory: {len(turn3_working_memory.messages)}\")\n",
    "    print(f\"   Contains: Turns 1 and 2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a282014d4ae67ba8",
   "metadata": {},
   "source": [
    "#### Step 3: Build context and generate response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5e1b23372c5c1b00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T16:13:14.678278Z",
     "start_time": "2025-10-31T16:13:12.680180Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Total messages in context: 10\n",
      "12:13:14 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\n",
      "ü§ñ Agent: To determine if you can take \"Data Structures and Algorithms\" (CS009) next semester, you'll need to check the course schedule for the upcoming semester at your institution. Ensure that you have completed the prerequisite course, CS001, before enrolling. If you meet the prerequisite and the course is offered, you should be able to register for it. It's also a good idea to consult with your academic advisor to confirm your eligibility and to help with planning your course schedule.\n"
     ]
    }
   ],
   "source": [
    "if MEMORY_SERVER_AVAILABLE:\n",
    "    # Build context with full conversation history\n",
    "    turn3_messages = [\n",
    "        SystemMessage(content=\"You are a helpful course advisor. Use conversation history to resolve references.\")\n",
    "    ]\n",
    "\n",
    "    for msg in turn3_working_memory.messages:\n",
    "        if msg.role == \"user\":\n",
    "            turn3_messages.append(HumanMessage(content=msg.content))\n",
    "        elif msg.role == \"assistant\":\n",
    "            turn3_messages.append(AIMessage(content=msg.content))\n",
    "\n",
    "    turn3_messages.append(HumanMessage(content=turn3_query))\n",
    "\n",
    "    print(f\"   Total messages in context: {len(turn3_messages)}\")\n",
    "\n",
    "    # Generate response\n",
    "    turn3_response = llm.invoke(turn3_messages).content\n",
    "\n",
    "    print(f\"\\nü§ñ Agent: {turn3_response}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5661b86d35e4f97d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "‚úÖ DEMO COMPLETE: Working memory enabled natural conversation flow!\n",
    "\n",
    "---\n",
    "### Working Memory Demo Summary\n",
    "\n",
    "Let's review what we just demonstrated across three conversation turns.\n",
    "\n",
    "## üéØ Working Memory Demo Summary\n",
    "### üìä What Happened:\n",
    "**Turn 1:** 'Tell me about Data Structures and Algorithms'\n",
    "- Working memory: empty (first turn)\n",
    "- Stored query and response\n",
    "\n",
    "**Turn 2:** 'What are its prerequisites?'\n",
    "- Working memory: 1 exchange (Turn 1)\n",
    "- LLM resolved 'its' ‚Üí Data Structures and Algorithms using history\n",
    "- Generated accurate response\n",
    "\n",
    "**Turn 3:** 'Can I take it next semester?'\n",
    "- Working memory: 2 exchanges (Turns 1-2)\n",
    "- LLM resolved 'it' ‚Üí Data Structures and Algorithms using history\n",
    "- Maintained conversation continuity\n",
    "\n",
    "#### ‚úÖ Key Benefits:\n",
    "- Natural conversation flow\n",
    "- Pronoun reference resolution\n",
    "- No need to repeat context\n",
    "- Seamless user experience\n",
    "\n",
    "#### ‚ùå Without Working Memory:\n",
    "- 'What are its prerequisites?' ‚Üí 'What is its?' Or \"General information without data from the LLM's training\"\n",
    "- Each query is isolated\n",
    "- User must repeat context every time\n",
    "\n",
    "### Key Insight: Conversation Context Type\n",
    "\n",
    "Working memory provides the **Conversation Context** - the third context type from Section 1:\n",
    "\n",
    "1. **System Context** - Role and instructions (static)\n",
    "2. **User Context** - Profile and preferences (dynamic, user-specific)\n",
    "3. **Conversation Context** - Working memory (dynamic, session-specific) ‚Üê **We just demonstrated this!**\n",
    "4. **Retrieved Context** - RAG results (dynamic, query-specific)\n",
    "\n",
    "Without working memory, we only had 3 context types. Now we have all 4!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2a4b8f-ba91-49d0-8f24-ad49acb0eadb",
   "metadata": {},
   "source": [
    "---\n",
    "# üìö Long-term Memory for Context Engineering\n",
    "\n",
    "## What is Long-term Memory?\n",
    "\n",
    "Long-term memory enables AI agents to store **persistent facts, preferences, and goals** across sessions. This is crucial for context engineering because it allows agents to:\n",
    "\n",
    "- **Personalize** interactions by remembering user preferences\n",
    "- **Accumulate knowledge** about users over time\n",
    "- **Maintain continuity** across multiple conversations\n",
    "- **Search efficiently** using semantic vector search\n",
    "\n",
    "### How It Works\n",
    "\n",
    "```\n",
    "Session 1: User shares preferences ‚Üí Store in long-term memory\n",
    "Session 2: User asks for recommendations ‚Üí Search memory ‚Üí Personalized response\n",
    "Session 3: User updates preferences ‚Üí Update memory accordingly\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Three Types of Long-term Memory\n",
    "\n",
    "The Agent Memory Server supports three distinct memory types, each optimized for different kinds of information:\n",
    "\n",
    "### 1. Semantic Memory - Facts and Knowledge\n",
    "\n",
    "**Purpose:** Store timeless facts, preferences, and knowledge independent of when they were learned.\n",
    "\n",
    "**Examples:**\n",
    "- \"Student's major is Computer Science\"\n",
    "- \"Student prefers online courses\"\n",
    "- \"Student wants to graduate in Spring 2026\"\n",
    "- \"Student is interested in machine learning\"\n",
    "\n",
    "**When to use:** Information that remains true regardless of time context.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Episodic Memory - Events and Experiences\n",
    "\n",
    "**Purpose:** Store time-bound events and experiences where sequence matters.\n",
    "\n",
    "**Examples:**\n",
    "- \"Student enrolled in CS101 on 2024-09-15\"\n",
    "- \"Student completed CS101 with grade A on 2024-12-10\"\n",
    "- \"Student asked about machine learning courses on 2024-09-20\"\n",
    "\n",
    "**When to use:** Timeline-based information where timing or sequence is important.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Message Memory - Context-Rich Conversations\n",
    "\n",
    "**Purpose:** Store full conversation snippets where complete context is crucial.\n",
    "\n",
    "**Examples:**\n",
    "- Detailed career planning discussion with nuanced advice\n",
    "- Professor's specific guidance about research opportunities\n",
    "- Student's explanation of personal learning challenges\n",
    "\n",
    "**When to use:** When summary would lose important nuance, tone, or exact wording.\n",
    "\n",
    "**‚ö†Ô∏è Use sparingly** - Message memories are token-expensive!\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Choosing the Right Memory Type\n",
    "\n",
    "### Decision Framework\n",
    "\n",
    "**Ask yourself these questions:**\n",
    "\n",
    "1. **Can you extract a simple fact?** ‚Üí Use **Semantic**\n",
    "2. **Does timing matter?** ‚Üí Use **Episodic**\n",
    "3. **Is full context crucial?** ‚Üí Use **Message** (rarely)\n",
    "\n",
    "**Default strategy: Prefer Semantic** - they're compact, searchable, and efficient.\n",
    "\n",
    "---\n",
    "\n",
    "### Quick Reference Table\n",
    "\n",
    "| Information Type | Memory Type | Example |\n",
    "|-----------------|-------------|----------|\n",
    "| Preference | Semantic | \"Prefers morning classes\" |\n",
    "| Fact | Semantic | \"Major is Computer Science\" |\n",
    "| Goal | Semantic | \"Wants to graduate in 2026\" |\n",
    "| Event | Episodic | \"Enrolled in CS401 on 2024-09-15\" |\n",
    "| Timeline | Episodic | \"Completed CS101, then CS201\" |\n",
    "| Complex discussion | Message | [Full career planning conversation] |\n",
    "| Nuanced advice | Message | [Professor's detailed guidance] |\n",
    "\n",
    "---\n",
    "\n",
    "## Examples: Right vs. Wrong Choices\n",
    "\n",
    "### Scenario 1: Student States Preference\n",
    "\n",
    "**User says:** \"I prefer online courses because I work during the day.\"\n",
    "\n",
    "‚ùå **Wrong - Message memory (too verbose):**\n",
    "```python\n",
    "memory = \"Student said: 'I prefer online courses because I work during the day.'\"\n",
    "```\n",
    "\n",
    "‚úÖ **Right - Semantic memories (extracted facts):**\n",
    "```python\n",
    "memory1 = \"Student prefers online courses\"\n",
    "memory2 = \"Student works during the day\"\n",
    "```\n",
    "\n",
    "**Why:** Simple facts don't need verbatim storage.\n",
    "\n",
    "---\n",
    "\n",
    "### Scenario 2: Course Completion\n",
    "\n",
    "**User says:** \"I just finished CS101 last week!\"\n",
    "\n",
    "‚ùå **Wrong - Semantic (loses temporal context):**\n",
    "```python\n",
    "memory = \"Student completed CS101\"\n",
    "```\n",
    "\n",
    "‚úÖ **Right - Episodic (preserves timeline):**\n",
    "```python\n",
    "memory = \"Student completed CS101 on 2024-10-20\"\n",
    "```\n",
    "\n",
    "**Why:** Timeline matters for prerequisites and future planning.\n",
    "\n",
    "---\n",
    "\n",
    "### Scenario 3: Complex Career Advice\n",
    "\n",
    "**Context:** 20-message discussion about career path including nuanced advice about research vs. industry, application timing, and specific companies to target.\n",
    "\n",
    "‚ùå **Wrong - Semantic (loses too much context):**\n",
    "```python\n",
    "memory = \"Student discussed career planning\"\n",
    "```\n",
    "\n",
    "‚úÖ **Right - Message memory (preserves full context):**\n",
    "```python\n",
    "memory = [Full conversation thread with all nuance]\n",
    "```\n",
    "\n",
    "**Why:** Details and context are critical; summary would be inadequate.\n",
    "\n",
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "- **Most memories should be semantic** - efficient and searchable\n",
    "- **Use episodic when sequence matters** - track progress and timeline\n",
    "- **Use message rarely** - only when context cannot be summarized\n",
    "- **Effective memory selection improves personalization** and reduces token usage\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ Hands-On: Long-term Memory in Action\n",
    "\n",
    "Let's put these concepts into practice with code examples..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6211363411414ffa",
   "metadata": {},
   "source": [
    "### Setup: Student ID for Long-term Memory\n",
    "\n",
    "Long-term memories are user-scoped, so we need a student ID.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d50c55afc8fc7de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Long-term Memory Demo Setup\n",
      "   Student ID: sarah_chen\n",
      "   Ready to store and search persistent memories\n"
     ]
    }
   ],
   "source": [
    "# Setup for long-term memory demo\n",
    "lt_student_id = \"sarah_chen\"\n",
    "\n",
    "print(\"üéØ Long-term Memory Demo Setup\")\n",
    "print(f\"   Student ID: {lt_student_id}\")\n",
    "print(\"   Ready to store and search persistent memories\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f726e5d5efa27d7",
   "metadata": {},
   "source": [
    "### Step 1: Store Semantic Memories (Facts)\n",
    "\n",
    "Semantic memories are timeless facts about the student. Let's store several facts about Sarah's preferences and academic status.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1e9048102a2a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Store semantic memories\n",
    "async def store_semantic_memories():\n",
    "    \"\"\"Store semantic memories (facts) about the student\"\"\"\n",
    "\n",
    "    if not MEMORY_SERVER_AVAILABLE:\n",
    "        print(\"‚ö†Ô∏è  Memory Server not available. Skipping demo.\")\n",
    "        return\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(\"üìç STEP 1: Storing Semantic Memories (Facts)\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    semantic_memories = [\n",
    "        \"Student prefers online courses over in-person classes\",\n",
    "        \"Student's major is Computer Science with focus on AI/ML\",\n",
    "        \"Student wants to graduate in Spring 2026\",\n",
    "        \"Student prefers morning classes, no classes on Fridays\",\n",
    "        \"Student has completed CS101 and CS201\",\n",
    "        \"Student is currently taking MATH301\"\n",
    "    ]\n",
    "\n",
    "    print(f\"\\nüìù Storing {len(semantic_memories)} semantic memories...\")\n",
    "\n",
    "    for memory_text in semantic_memories:\n",
    "        memory_record = ClientMemoryRecord(\n",
    "            text=memory_text,\n",
    "            user_id=lt_student_id,\n",
    "            memory_type=\"semantic\",\n",
    "            topics=[\"preferences\", \"academic_info\"]\n",
    "        )\n",
    "        await memory_client.create_long_term_memory([memory_record])\n",
    "        print(f\"   ‚úÖ {memory_text}\")\n",
    "\n",
    "    print(f\"\\n‚úÖ Stored {len(semantic_memories)} semantic memories\")\n",
    "    print(\"   Memory type: semantic (timeless facts)\")\n",
    "    print(\"   Topics: preferences, academic_info\")\n",
    "\n",
    "# Run Step 1\n",
    "await store_semantic_memories()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e842c9e4ece988",
   "metadata": {},
   "source": [
    "### What We Just Did: Semantic Memories\n",
    "\n",
    "**Stored 6 semantic memories:**\n",
    "- Student preferences (online courses, morning classes)\n",
    "- Academic information (major, graduation date)\n",
    "- Course history (completed, current)\n",
    "\n",
    "**Why semantic?**\n",
    "- These are timeless facts\n",
    "- No specific date/time context needed\n",
    "- Compact and efficient\n",
    "\n",
    "**How they're stored:**\n",
    "- Vector-indexed for semantic search\n",
    "- Tagged with topics for organization\n",
    "- Automatically deduplicated\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac56855543c88db",
   "metadata": {},
   "source": [
    "### Step 2: Store Episodic Memories (Events)\n",
    "\n",
    "Episodic memories are time-bound events. Let's store some events from Sarah's academic timeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a447e552d130793d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Store episodic memories\n",
    "async def store_episodic_memories():\n",
    "    \"\"\"Store episodic memories (events) about the student\"\"\"\n",
    "\n",
    "    if not MEMORY_SERVER_AVAILABLE:\n",
    "        print(\"‚ö†Ô∏è  Memory Server not available. Skipping demo.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üìç STEP 2: Storing Episodic Memories (Events)\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    episodic_memories = [\n",
    "        \"Student enrolled in CS101 on 2024-09-01\",\n",
    "        \"Student completed CS101 with grade A on 2024-12-15\",\n",
    "        \"Student asked about machine learning courses on 2024-09-20\"\n",
    "    ]\n",
    "\n",
    "    print(f\"\\nüìù Storing {len(episodic_memories)} episodic memories...\")\n",
    "\n",
    "    for memory_text in episodic_memories:\n",
    "        memory_record = ClientMemoryRecord(\n",
    "            text=memory_text,\n",
    "            user_id=lt_student_id,\n",
    "            memory_type=\"episodic\",\n",
    "            topics=[\"enrollment\", \"courses\"]\n",
    "        )\n",
    "        await memory_client.create_long_term_memory([memory_record])\n",
    "        print(f\"   ‚úÖ {memory_text}\")\n",
    "\n",
    "    print(f\"\\n‚úÖ Stored {len(episodic_memories)} episodic memories\")\n",
    "    print(\"   Memory type: episodic (time-bound events)\")\n",
    "    print(\"   Topics: enrollment, courses\")\n",
    "\n",
    "# Run Step 2\n",
    "await store_episodic_memories()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b98104958320ca2",
   "metadata": {},
   "source": [
    "### What We Just Did: Episodic Memories\n",
    "\n",
    "**Stored 3 episodic memories:**\n",
    "- Enrollment event (CS101 on 2024-09-01)\n",
    "- Completion event (CS101 with grade A on 2024-12-15)\n",
    "- Interaction event (asked about ML courses on 2024-09-20)\n",
    "\n",
    "**Why episodic?**\n",
    "- These are time-bound events\n",
    "- Timing and sequence matter\n",
    "- Captures academic timeline\n",
    "\n",
    "**Difference from semantic:**\n",
    "- Semantic: \"Student has completed CS101\" (timeless fact)\n",
    "- Episodic: \"Student completed CS101 with grade A on 2024-12-15\" (specific event)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729b8ebf272c96a",
   "metadata": {},
   "source": [
    "### Step 3: Search Long-term Memory\n",
    "\n",
    "Now let's search our long-term memories using natural language queries. The system will use semantic search to find relevant memories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3061e6609af950e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Search long-term memory\n",
    "async def search_longterm_memories():\n",
    "    \"\"\"Search long-term memory with semantic queries\"\"\"\n",
    "\n",
    "    if not MEMORY_SERVER_AVAILABLE:\n",
    "        print(\"‚ö†Ô∏è  Memory Server not available. Skipping demo.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üìç STEP 3: Searching Long-term Memory\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    search_queries = [\n",
    "        \"What does the student prefer?\",\n",
    "        \"What courses has the student completed?\",\n",
    "        \"What is the student's major?\"\n",
    "    ]\n",
    "\n",
    "    for query in search_queries:\n",
    "        print(f\"\\nüîç Query: '{query}'\")\n",
    "        results = await memory_client.search_long_term_memory(\n",
    "            text=query,\n",
    "            user_id=lt_student_id,\n",
    "            limit=3\n",
    "        )\n",
    "\n",
    "        if results.memories:\n",
    "            print(f\"   üìö Found {len(results.memories)} relevant memories:\")\n",
    "            for i, memory in enumerate(results.memories[:3], 1):\n",
    "                print(f\"      {i}. {memory.text}\")\n",
    "        else:\n",
    "            print(\"   ‚ö†Ô∏è  No memories found\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"‚úÖ DEMO COMPLETE: Long-term memory enables persistent knowledge!\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "# Run Step 3\n",
    "await search_longterm_memories()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81623ed1f8e4fe3b",
   "metadata": {},
   "source": [
    "### Long-term Memory Demo Summary\n",
    "\n",
    "Let's review what we demonstrated with long-term memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a2a16698c66fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"üéØ LONG-TERM MEMORY DEMO SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nüìä What We Did:\")\n",
    "print(\"   Step 1: Stored 6 semantic memories (facts)\")\n",
    "print(\"           ‚Üí Student preferences, major, graduation date\")\n",
    "print(\"           ‚Üí Tagged with topics: preferences, academic_info\")\n",
    "print(\"\\n   Step 2: Stored 3 episodic memories (events)\")\n",
    "print(\"           ‚Üí Enrollment, completion, interaction events\")\n",
    "print(\"           ‚Üí Tagged with topics: enrollment, courses\")\n",
    "print(\"\\n   Step 3: Searched long-term memory\")\n",
    "print(\"           ‚Üí Used natural language queries\")\n",
    "print(\"           ‚Üí Semantic search found relevant memories\")\n",
    "print(\"           ‚Üí No exact keyword matching needed\")\n",
    "print(\"\\n‚úÖ Key Benefits:\")\n",
    "print(\"   ‚Ä¢ Persistent knowledge across sessions\")\n",
    "print(\"   ‚Ä¢ Semantic search (not keyword matching)\")\n",
    "print(\"   ‚Ä¢ Automatic deduplication\")\n",
    "print(\"   ‚Ä¢ Topic-based organization\")\n",
    "print(\"\\nüí° Key Insight:\")\n",
    "print(\"   Long-term memory enables personalization and knowledge\")\n",
    "print(\"   accumulation across sessions. It's the foundation for\")\n",
    "print(\"   building agents that remember and learn from users.\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7a247cc0c8fddf",
   "metadata": {},
   "source": [
    "### Key Insight: User Context Type\n",
    "\n",
    "Long-term memory provides part of the **User Context** - the second context type from Section 1:\n",
    "\n",
    "1. **System Context** - Role and instructions (static)\n",
    "2. **User Context** - Profile + long-term memories (dynamic, user-specific) ‚Üê **Long-term memories contribute here!**\n",
    "3. **Conversation Context** - Working memory (dynamic, session-specific)\n",
    "4. **Retrieved Context** - RAG results (dynamic, query-specific)\n",
    "\n",
    "Long-term memories enhance User Context by adding persistent knowledge about the user's preferences, history, and goals.\n",
    "\n",
    "---\n",
    "\n",
    "## üè∑Ô∏è Advanced: Topics and Filtering\n",
    "\n",
    "Topics help organize and filter memories. Let's explore how to use them effectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1257ba13cefc9c2",
   "metadata": {},
   "source": [
    "### Step 1: Store memories with topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dfb8e438774736",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MEMORY_SERVER_AVAILABLE:\n",
    "    topics_student_id = \"sarah_chen\"\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(\"üè∑Ô∏è  TOPICS AND FILTERING DEMO\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    print(\"\\nüìç Storing Memories with Topics\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # Define memories with their topics\n",
    "    memories_with_topics = [\n",
    "        (\"Student prefers online courses\", [\"preferences\", \"course_format\"]),\n",
    "        (\"Student's major is Computer Science\", [\"academic_info\", \"major\"]),\n",
    "        (\"Student wants to graduate in Spring 2026\", [\"goals\", \"graduation\"]),\n",
    "        (\"Student prefers morning classes\", [\"preferences\", \"schedule\"]),\n",
    "    ]\n",
    "\n",
    "    # Store each memory\n",
    "    for memory_text, topics in memories_with_topics:\n",
    "        memory_record = ClientMemoryRecord(\n",
    "            text=memory_text,\n",
    "            user_id=topics_student_id,\n",
    "            memory_type=\"semantic\",\n",
    "            topics=topics\n",
    "        )\n",
    "        await memory_client.create_long_term_memory([memory_record])\n",
    "        print(f\"   ‚úÖ {memory_text}\")\n",
    "        print(f\"      Topics: {', '.join(topics)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd16284999d3213",
   "metadata": {},
   "source": [
    "### Step 2: Filter memories by type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224aa7006183262",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MEMORY_SERVER_AVAILABLE:\n",
    "    print(\"\\nüìç Filtering by Memory Type: Semantic\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    from agent_memory_client.models import MemoryType\n",
    "\n",
    "    # Search for all semantic memories\n",
    "    results = await memory_client.search_long_term_memory(\n",
    "        text=\"\",  # Empty query returns all\n",
    "        user_id=topics_student_id,\n",
    "        memory_type=MemoryType(eq=\"semantic\"),\n",
    "        limit=10\n",
    "    )\n",
    "\n",
    "    print(f\"   Found {len(results.memories)} semantic memories:\")\n",
    "    for i, memory in enumerate(results.memories[:5], 1):\n",
    "        topics_str = ', '.join(memory.topics) if memory.topics else 'none'\n",
    "        print(f\"   {i}. {memory.text}\")\n",
    "        print(f\"      Topics: {topics_str}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"‚úÖ Topics enable organized, filterable memory management!\")\n",
    "    print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833010461c87f519",
   "metadata": {},
   "source": [
    "### üéØ Why Topics Matter\n",
    "\n",
    "**Organization:**\n",
    "- Group related memories together\n",
    "- Easy to find memories by category\n",
    "\n",
    "**Filtering:**\n",
    "- Search within specific topics\n",
    "- Filter by memory type (semantic, episodic, message)\n",
    "\n",
    "**Best Practices:**\n",
    "- Use consistent topic names\n",
    "- Keep topics broad enough to be useful\n",
    "- Common topics: `preferences`, `academic_info`, `goals`, `schedule`, `courses`\n",
    "\n",
    "---\n",
    "\n",
    "## üîÑ Cross-Session Memory Persistence\n",
    "\n",
    "Let's verify that memories persist across sessions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c98c46da71dcd1",
   "metadata": {},
   "source": [
    "### Step 1: Session 1 - Store memories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fa8b9da3288874",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MEMORY_SERVER_AVAILABLE:\n",
    "    cross_session_student_id = \"sarah_chen\"\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(\"üîÑ CROSS-SESSION MEMORY PERSISTENCE DEMO\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    print(\"\\nüìç SESSION 1: Storing Memories\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    memory_record = ClientMemoryRecord(\n",
    "        text=\"Student is interested in machine learning and AI\",\n",
    "        user_id=cross_session_student_id,\n",
    "        memory_type=\"semantic\",\n",
    "        topics=[\"interests\", \"AI\"]\n",
    "    )\n",
    "    await memory_client.create_long_term_memory([memory_record])\n",
    "    print(\"   ‚úÖ Stored: Student is interested in machine learning and AI\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d26f40c5997b028",
   "metadata": {},
   "source": [
    "### Step 2: Session 2 - Create new client and retrieve memories\n",
    "\n",
    "Simulate a new session by creating a new memory client.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa83e43fec2a253",
   "metadata": {},
   "outputs": [],
   "source": [
    "if MEMORY_SERVER_AVAILABLE:\n",
    "    print(\"\\nüìç SESSION 2: New Session, Same Student\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # Create a new memory client (simulating a new session)\n",
    "    new_session_config = MemoryClientConfig(\n",
    "        base_url=os.getenv(\"AGENT_MEMORY_URL\", \"http://localhost:8000\"),\n",
    "        default_namespace=\"redis_university\"\n",
    "    )\n",
    "    new_session_client = MemoryAPIClient(config=new_session_config)\n",
    "\n",
    "    print(\"   üîÑ New session started for the same student\")\n",
    "\n",
    "    # Search for memories from the new session\n",
    "    print(\"\\n   üîç Searching: 'What are the student's interests?'\")\n",
    "    cross_session_results = await new_session_client.search_long_term_memory(\n",
    "        text=\"What are the student's interests?\",\n",
    "        user_id=cross_session_student_id,\n",
    "        limit=3\n",
    "    )\n",
    "\n",
    "    if cross_session_results.memories:\n",
    "        print(f\"\\n   ‚úÖ Memories accessible from new session:\")\n",
    "        for i, memory in enumerate(cross_session_results.memories[:3], 1):\n",
    "            print(f\"      {i}. {memory.text}\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è  No memories found\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"‚úÖ Long-term memories persist across sessions!\")\n",
    "    print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e55992cb0e1184",
   "metadata": {},
   "source": [
    "### üéØ Cross-Session Persistence\n",
    "\n",
    "**What We Demonstrated:**\n",
    "- **Session 1:** Stored memories about student interests\n",
    "- **Session 2:** Created new client (simulating new session)\n",
    "- **Result:** Memories from Session 1 are accessible in Session 2\n",
    "\n",
    "**Why This Matters:**\n",
    "- Users don't have to repeat themselves\n",
    "- Personalization works across days, weeks, months\n",
    "- Knowledge accumulates over time\n",
    "\n",
    "**Contrast with Working Memory:**\n",
    "- Working memory: Session-scoped (expires after 24 hours)\n",
    "- Long-term memory: User-scoped (persists indefinitely)\n",
    "\n",
    "---\n",
    "\n",
    "## üîó What's Next: Memory-Enhanced RAG and Agents\n",
    "\n",
    "You've learned the fundamentals of memory architecture! Now it's time to put it all together.\n",
    "\n",
    "### **Next Notebook: `02_memory_enhanced_rag_and_agents.ipynb`**\n",
    "\n",
    "In the next notebook, you'll:\n",
    "\n",
    "1. **Build** a complete memory-enhanced RAG system\n",
    "   - Integrate working memory + long-term memory + RAG\n",
    "   - Combine all four context types\n",
    "   - Show clear before/after comparisons\n",
    "\n",
    "2. **Convert** to LangGraph agent (Part 2, separate notebook)\n",
    "   - Add state management\n",
    "   - Improve control flow\n",
    "   - Prepare for Section 4 (tools and advanced capabilities)\n",
    "\n",
    "**Why Continue?**\n",
    "- See memory in action with real conversations\n",
    "- Learn how to build production-ready agents\n",
    "- Prepare for Section 4 (adding tools like enrollment, scheduling)\n",
    "\n",
    "**üìö Continue to:** `02_memory_enhanced_rag_and_agents.ipynb`\n",
    "\n",
    "## ‚è∞ Memory Lifecycle & Persistence\n",
    "\n",
    "Understanding how long memories last and when they expire is crucial for building reliable systems.\n",
    "\n",
    "### **Working Memory TTL (Time-To-Live)**\n",
    "\n",
    "**Default TTL:** 24 hours\n",
    "\n",
    "**What this means:**\n",
    "- Working memory (conversation history) expires 24 hours after last activity\n",
    "- After expiration, conversation context is lost\n",
    "- Long-term memories extracted from the conversation persist\n",
    "\n",
    "**Timeline Example:**\n",
    "\n",
    "```\n",
    "Day 1, 10:00 AM - Session starts\n",
    "Day 1, 10:25 AM - Session ends\n",
    "    ‚Üì\n",
    "[24 hours later]\n",
    "    ‚Üì\n",
    "Day 2, 10:25 AM - Working memory still available ‚úÖ\n",
    "Day 2, 10:26 AM - Working memory expires ‚ùå\n",
    "```\n",
    "\n",
    "### **Long-term Memory Persistence**\n",
    "\n",
    "**Lifetime:** Indefinite (until manually deleted)\n",
    "\n",
    "**What this means:**\n",
    "- Long-term memories never expire automatically\n",
    "- Accessible across all sessions, forever\n",
    "- Must be explicitly deleted if no longer needed\n",
    "\n",
    "### **Why This Design?**\n",
    "\n",
    "**Working Memory (Short-lived):**\n",
    "- Conversations are temporary\n",
    "- Most context is only relevant during the session\n",
    "- Automatic cleanup prevents storage bloat\n",
    "- Privacy: Old conversations don't linger\n",
    "\n",
    "**Long-term Memory (Persistent):**\n",
    "- Important facts should persist\n",
    "- User preferences don't expire\n",
    "- Knowledge accumulates over time\n",
    "- Enables true personalization\n",
    "\n",
    "### **Important Implications**\n",
    "\n",
    "**1. Extract Before Expiration**\n",
    "\n",
    "If something important is said in conversation, it must be extracted to long-term memory before the 24-hour TTL expires.\n",
    "\n",
    "**Good news:** Agent Memory Server does this automatically!\n",
    "\n",
    "**2. Long-term Memories are Permanent**\n",
    "\n",
    "Once stored, long-term memories persist indefinitely. Be thoughtful about what you store.\n",
    "\n",
    "**3. Cross-Session Behavior**\n",
    "\n",
    "```\n",
    "Session 1 (Day 1):\n",
    "- User: \"I'm interested in machine learning\"\n",
    "- Working memory: Stores conversation\n",
    "- Long-term memory: Extracts \"Student interested in machine learning\"\n",
    "\n",
    "[30 hours later - Working memory expired]\n",
    "\n",
    "Session 2 (Day 3):\n",
    "- Working memory from Session 1: EXPIRED ‚ùå\n",
    "- Long-term memory: Still available ‚úÖ\n",
    "- Agent retrieves: \"Student interested in machine learning\"\n",
    "- Agent makes relevant recommendations ‚úÖ\n",
    "```\n",
    "\n",
    "### **Practical Multi-Day Conversation Example**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4dc88686624474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Day Conversation Simulation\n",
    "async def multi_day_simulation():\n",
    "    \"\"\"Simulate conversations across multiple days\"\"\"\n",
    "\n",
    "    if not MEMORY_SERVER_AVAILABLE:\n",
    "        print(\"‚ö†Ô∏è  Memory Server not available. Skipping demo.\")\n",
    "        return\n",
    "\n",
    "    student_id = \"sarah_chen\"\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(\"‚è∞ MULTI-DAY CONVERSATION SIMULATION\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Day 1: Initial conversation\n",
    "    print(\"\\nüìÖ DAY 1: Initial Conversation\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    session_1 = f\"session_{student_id}_day1\"\n",
    "\n",
    "    # Store a fact in long-term memory\n",
    "    memory_record = ClientMemoryRecord(\n",
    "        text=\"Student is preparing for a career in AI research\",\n",
    "        user_id=student_id,\n",
    "        memory_type=\"semantic\",\n",
    "        topics=[\"career\", \"goals\"]\n",
    "    )\n",
    "    await memory_client.create_long_term_memory([memory_record])\n",
    "    print(\"   ‚úÖ Stored in long-term memory: Career goal (AI research)\")\n",
    "\n",
    "    # Simulate working memory (would normally be conversation)\n",
    "    print(\"   üí¨ Working memory: Active for session_day1\")\n",
    "    print(\"   ‚è∞ TTL: 24 hours from now\")\n",
    "\n",
    "    # Day 3: New conversation (working memory expired)\n",
    "    print(\"\\nüìÖ DAY 3: New Conversation (48 hours later)\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    session_2 = f\"session_{student_id}_day3\"\n",
    "\n",
    "    print(\"   ‚ùå Working memory from Day 1: EXPIRED\")\n",
    "    print(\"   ‚úÖ Long-term memory: Still available\")\n",
    "\n",
    "    # Search long-term memory\n",
    "    results = await memory_client.search_long_term_memory(\n",
    "        text=\"What are the student's career goals?\",\n",
    "        user_id=student_id,\n",
    "        limit=3\n",
    "    )\n",
    "\n",
    "    if results.memories:\n",
    "        print(\"\\n   üîç Retrieved from long-term memory:\")\n",
    "        for memory in results.memories[:3]:\n",
    "            print(f\"      ‚Ä¢ {memory.text}\")\n",
    "        print(\"\\n   ‚úÖ Agent can still personalize recommendations!\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"‚úÖ Long-term memories persist, working memory expires\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "# Run the simulation\n",
    "await multi_day_simulation()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd48b3f8e02b6f5",
   "metadata": {},
   "source": [
    "### üéØ Memory Lifecycle Best Practices\n",
    "\n",
    "**1. Trust Automatic Extraction**\n",
    "- Agent Memory Server automatically extracts important facts\n",
    "- Don't manually store everything in long-term memory\n",
    "- Let the system decide what's important\n",
    "\n",
    "**2. Use Appropriate Memory Types**\n",
    "- Working memory: Current conversation only\n",
    "- Long-term memory: Facts that should persist\n",
    "\n",
    "**3. Monitor Memory Growth**\n",
    "- Long-term memories accumulate over time\n",
    "- Implement cleanup for outdated information\n",
    "- Consider archiving old memories\n",
    "\n",
    "**4. Plan for Expiration**\n",
    "- Working memory expires after 24 hours\n",
    "- Important context must be in long-term memory\n",
    "- Don't rely on working memory for cross-session data\n",
    "\n",
    "**5. Test Cross-Session Behavior**\n",
    "- Verify long-term memories are accessible\n",
    "- Ensure personalization works after TTL expiration\n",
    "- Test with realistic time gaps\n",
    "\n",
    "---\n",
    "\n",
    "## üéì Key Takeaways\n",
    "\n",
    "### **1. Memory Solves the Grounding Problem**\n",
    "\n",
    "Without memory, agents can't resolve references:\n",
    "- ‚ùå \"What are **its** prerequisites?\" ‚Üí Agent doesn't know what \"its\" refers to\n",
    "- ‚úÖ With working memory ‚Üí Agent resolves \"its\" from conversation history\n",
    "\n",
    "### **2. Two Types of Memory Serve Different Purposes**\n",
    "\n",
    "**Working Memory (Session-Scoped):**\n",
    "- Conversation messages from current session\n",
    "- Enables reference resolution and conversation continuity\n",
    "- TTL-based (expires after session ends)\n",
    "\n",
    "**Long-term Memory (Cross-Session):**\n",
    "- Persistent facts, preferences, goals\n",
    "- Enables personalization across sessions\n",
    "- Searchable via semantic vector search\n",
    "\n",
    "### **3. Memory Completes the Four Context Types**\n",
    "\n",
    "From Section 1, we learned about four context types. Memory enables two of them:\n",
    "\n",
    "1. **System Context** (Static) - ‚úÖ Section 2\n",
    "2. **User Context** (Dynamic, User-Specific) - ‚úÖ Section 2 + Long-term Memory\n",
    "3. **Conversation Context** (Dynamic, Session-Specific) - ‚ú® **Working Memory**\n",
    "4. **Retrieved Context** (Dynamic, Query-Specific) - ‚úÖ Section 2 RAG\n",
    "\n",
    "### **4. Memory + RAG = Complete Context Engineering**\n",
    "\n",
    "The integration pattern:\n",
    "```\n",
    "1. Load working memory (conversation history)\n",
    "2. Search long-term memory (user facts)\n",
    "3. RAG search (relevant documents)\n",
    "4. Assemble all context types\n",
    "5. Generate response\n",
    "6. Save working memory (updated conversation)\n",
    "```\n",
    "\n",
    "This gives us **stateful, personalized, context-aware conversations**.\n",
    "\n",
    "### **5. Agent Memory Server is Production-Ready**\n",
    "\n",
    "Why use Agent Memory Server instead of simple in-memory storage:\n",
    "- ‚úÖ **Scalable** - Redis-backed, handles thousands of users\n",
    "- ‚úÖ **Automatic** - Extracts important facts to long-term storage\n",
    "- ‚úÖ **Semantic search** - Vector-indexed memory retrieval\n",
    "- ‚úÖ **Deduplication** - Prevents redundant memories\n",
    "- ‚úÖ **TTL management** - Automatic expiration of old sessions\n",
    "\n",
    "### **6. LangChain is Sufficient for Memory + RAG**\n",
    "\n",
    "We didn't need LangGraph for this section because:\n",
    "- Simple linear flow (load ‚Üí search ‚Üí generate ‚Üí save)\n",
    "- No conditional branching or complex state management\n",
    "- No tool calling required\n",
    "\n",
    "**LangGraph becomes necessary in Section 4** when we add tools and multi-step workflows.\n",
    "\n",
    "### **7. Memory Management Best Practices**\n",
    "\n",
    "**Choose the Right Memory Type:**\n",
    "- **Semantic** for facts and preferences (most common)\n",
    "- **Episodic** for time-bound events and timeline\n",
    "- **Message** for context-rich conversations (use sparingly)\n",
    "\n",
    "**Understand Memory Lifecycle:**\n",
    "- **Working memory:** 24-hour TTL, session-scoped\n",
    "- **Long-term memory:** Indefinite persistence, user-scoped\n",
    "- **Automatic extraction:** Trust the system to extract important facts\n",
    "\n",
    "**Benefits of Proper Memory Management:**\n",
    "- ‚úÖ **Natural conversations** - Users don't repeat themselves\n",
    "- ‚úÖ **Cross-session personalization** - Knowledge persists over time\n",
    "- ‚úÖ **Efficient storage** - Automatic deduplication prevents bloat\n",
    "- ‚úÖ **Semantic search** - Find relevant memories without exact keywords\n",
    "- ‚úÖ **Scalable** - Redis-backed, production-ready architecture\n",
    "\n",
    "**Key Principle:** Memory transforms stateless RAG into stateful, personalized, context-aware conversations.\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ What's Next?\n",
    "\n",
    "### **Next Notebook: Memory-Enhanced RAG and Agents**\n",
    "\n",
    "**üìö Continue to: `02_memory_enhanced_rag_and_agents.ipynb`**\n",
    "\n",
    "In the next notebook, you'll:\n",
    "\n",
    "1. **Build** a complete memory-enhanced RAG system\n",
    "   - Integrate working memory + long-term memory + RAG\n",
    "   - Combine all four context types\n",
    "   - Show clear before/after comparisons\n",
    "\n",
    "2. **Convert** to LangGraph agent (Part 2, separate notebook)\n",
    "   - Add state management\n",
    "   - Improve control flow\n",
    "   - Prepare for Section 4 (tools and advanced capabilities)\n",
    "\n",
    "### **Then: Section 4 - Tools and Advanced Agents**\n",
    "\n",
    "After completing the next notebook, you'll be ready for Section 4:\n",
    "\n",
    "**Tools You'll Add:**\n",
    "- `search_courses` - Semantic search\n",
    "- `get_course_details` - Fetch specific course information\n",
    "- `check_prerequisites` - Verify student eligibility\n",
    "- `enroll_course` - Register student for a course\n",
    "- `store_memory` - Explicitly save important facts\n",
    "\n",
    "**The Complete Learning Path:**\n",
    "\n",
    "```\n",
    "Section 1: Context Engineering Fundamentals\n",
    "    ‚Üì\n",
    "Section 2: RAG (Retrieved Context)\n",
    "    ‚Üì\n",
    "Section 3 (Notebook 1): Memory Fundamentals ‚Üê You are here\n",
    "    ‚Üì\n",
    "Section 3 (Notebook 2): Memory-Enhanced RAG and Agents\n",
    "    ‚Üì\n",
    "Section 4: Tools + Agents (Complete Agentic System)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üí™ Practice Exercises\n",
    "\n",
    "### **Exercise 1: Cross-Session Personalization**\n",
    "\n",
    "Modify the `memory_enhanced_rag_query` function to:\n",
    "1. Store user preferences in long-term memory when mentioned\n",
    "2. Use those preferences in future sessions\n",
    "3. Test with two different sessions for the same student\n",
    "\n",
    "**Hint:** Look for phrases like \"I prefer...\", \"I like...\", \"I want...\" and store them as semantic memories.\n",
    "\n",
    "### **Exercise 2: Memory-Aware Filtering**\n",
    "\n",
    "Enhance the RAG search to use long-term memories as filters:\n",
    "1. Search long-term memory for preferences (format, difficulty, schedule)\n",
    "2. Apply those preferences as filters to `course_manager.search_courses()`\n",
    "3. Compare results with and without memory-aware filtering\n",
    "\n",
    "**Hint:** Use the `filters` parameter in `course_manager.search_courses()`.\n",
    "\n",
    "### **Exercise 3: Conversation Summarization**\n",
    "\n",
    "Implement a function that summarizes long conversations:\n",
    "1. When working memory exceeds 10 messages, summarize the conversation\n",
    "2. Store the summary in long-term memory\n",
    "3. Clear old messages from working memory (keep only recent 4)\n",
    "4. Test that reference resolution still works with summarized history\n",
    "\n",
    "**Hint:** Use the LLM to generate summaries, then store as semantic memories.\n",
    "\n",
    "### **Exercise 4: Multi-User Memory Management**\n",
    "\n",
    "Create a simple CLI that:\n",
    "1. Supports multiple students (different user IDs)\n",
    "2. Maintains separate working memory per session\n",
    "3. Maintains separate long-term memory per user\n",
    "4. Demonstrates cross-session continuity for each user\n",
    "\n",
    "**Hint:** Use different `session_id` and `user_id` for each student.\n",
    "\n",
    "### **Exercise 5: Memory Search Quality**\n",
    "\n",
    "Experiment with long-term memory search:\n",
    "1. Store 20+ diverse memories for a student\n",
    "2. Try different search queries\n",
    "3. Analyze which memories are retrieved\n",
    "4. Adjust memory text to improve search relevance\n",
    "\n",
    "**Hint:** More specific memory text leads to better semantic search results.\n",
    "\n",
    "---\n",
    "\n",
    "## üìù Summary\n",
    "\n",
    "### **What You Learned:**\n",
    "\n",
    "1. **The Grounding Problem** - Why agents need memory to resolve references\n",
    "2. **Working Memory** - Session-scoped conversation history for continuity\n",
    "3. **Long-term Memory** - Cross-session persistent knowledge for personalization\n",
    "4. **Memory Integration** - Combining memory with Section 2's RAG system\n",
    "5. **Complete Context Engineering** - All four context types working together\n",
    "6. **Production Architecture** - Using Agent Memory Server for scalable memory\n",
    "\n",
    "### **What You Built:**\n",
    "\n",
    "- ‚úÖ Working memory demo (multi-turn conversations)\n",
    "- ‚úÖ Long-term memory demo (persistent knowledge)\n",
    "- ‚úÖ Complete memory-enhanced RAG system\n",
    "- ‚úÖ Integration of all four context types\n",
    "\n",
    "### **Key Functions:**\n",
    "\n",
    "- `memory_enhanced_rag_query()` - Complete memory + RAG pipeline\n",
    "- `working_memory_demo()` - Demonstrates conversation continuity\n",
    "- `longterm_memory_demo()` - Demonstrates persistent knowledge\n",
    "- `complete_demo()` - End-to-end multi-turn conversation\n",
    "\n",
    "### **Architecture Pattern:**\n",
    "\n",
    "```\n",
    "User Query\n",
    "    ‚Üì\n",
    "Load Working Memory (conversation history)\n",
    "    ‚Üì\n",
    "Search Long-term Memory (user facts)\n",
    "    ‚Üì\n",
    "RAG Search (relevant courses)\n",
    "    ‚Üì\n",
    "Assemble Context (System + User + Conversation + Retrieved)\n",
    "    ‚Üì\n",
    "Generate Response\n",
    "    ‚Üì\n",
    "Save Working Memory (updated conversation)\n",
    "```\n",
    "\n",
    "### **From Section 2 to Section 3:**\n",
    "\n",
    "**Section 2 (Stateless RAG):**\n",
    "- ‚ùå No conversation history\n",
    "- ‚ùå Each query independent\n",
    "- ‚ùå Can't resolve references\n",
    "- ‚úÖ Retrieves relevant documents\n",
    "\n",
    "**Section 3 (Memory-Enhanced RAG):**\n",
    "- ‚úÖ Conversation history (working memory)\n",
    "- ‚úÖ Multi-turn conversations\n",
    "- ‚úÖ Reference resolution\n",
    "- ‚úÖ Persistent user knowledge (long-term memory)\n",
    "- ‚úÖ Personalization across sessions\n",
    "\n",
    "### **Next Steps:**\n",
    "\n",
    "**Section 4** will add **tools** and **agentic workflows** using **LangGraph**, completing your journey from context engineering fundamentals to production-ready AI agents.\n",
    "\n",
    "---\n",
    "\n",
    "## üéâ Congratulations!\n",
    "\n",
    "You've successfully built a **memory-enhanced RAG system** that:\n",
    "- Remembers conversations (working memory)\n",
    "- Accumulates knowledge (long-term memory)\n",
    "- Resolves references naturally\n",
    "- Personalizes responses\n",
    "- Integrates all four context types\n",
    "\n",
    "**You're now ready for Section 4: Tools & Agentic Workflows!** üöÄ\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34e3bc677c17172",
   "metadata": {},
   "source": [
    "### üéØ Memory Lifecycle Best Practices\n",
    "\n",
    "**1. Trust Automatic Extraction**\n",
    "- Agent Memory Server automatically extracts important facts\n",
    "- Don't manually store everything in long-term memory\n",
    "- Let the system decide what's important\n",
    "\n",
    "**2. Use Appropriate Memory Types**\n",
    "- Working memory: Current conversation only\n",
    "- Long-term memory: Facts that should persist\n",
    "\n",
    "**3. Monitor Memory Growth**\n",
    "- Long-term memories accumulate over time\n",
    "- Implement cleanup for outdated information\n",
    "- Consider archiving old memories\n",
    "\n",
    "**4. Plan for Expiration**\n",
    "- Working memory expires after 24 hours\n",
    "- Important context must be in long-term memory\n",
    "- Don't rely on working memory for cross-session data\n",
    "\n",
    "**5. Test Cross-Session Behavior**\n",
    "- Verify long-term memories are accessible\n",
    "- Ensure personalization works after TTL expiration\n",
    "- Test with realistic time gaps\n",
    "\n",
    "---\n",
    "\n",
    "## üéì Key Takeaways\n",
    "\n",
    "### **1. Memory Solves the Grounding Problem**\n",
    "\n",
    "Without memory, agents can't resolve references:\n",
    "- ‚ùå \"What are **its** prerequisites?\" ‚Üí Agent doesn't know what \"its\" refers to\n",
    "- ‚úÖ With working memory ‚Üí Agent resolves \"its\" from conversation history\n",
    "\n",
    "### **2. Two Types of Memory Serve Different Purposes**\n",
    "\n",
    "**Working Memory (Session-Scoped):**\n",
    "- Conversation messages from current session\n",
    "- Enables reference resolution and conversation continuity\n",
    "- TTL-based (expires after session ends)\n",
    "\n",
    "**Long-term Memory (Cross-Session):**\n",
    "- Persistent facts, preferences, goals\n",
    "- Enables personalization across sessions\n",
    "- Searchable via semantic vector search\n",
    "\n",
    "### **3. Memory Completes the Four Context Types**\n",
    "\n",
    "From Section 1, we learned about four context types. Memory enables two of them:\n",
    "\n",
    "1. **System Context** (Static) - ‚úÖ Section 2\n",
    "2. **User Context** (Dynamic, User-Specific) - ‚úÖ Section 2 + Long-term Memory\n",
    "3. **Conversation Context** (Dynamic, Session-Specific) - ‚ú® **Working Memory**\n",
    "4. **Retrieved Context** (Dynamic, Query-Specific) - ‚úÖ Section 2 RAG\n",
    "\n",
    "### **4. Memory + RAG = Complete Context Engineering**\n",
    "\n",
    "The integration pattern:\n",
    "```\n",
    "1. Load working memory (conversation history)\n",
    "2. Search long-term memory (user facts)\n",
    "3. RAG search (relevant documents)\n",
    "4. Assemble all context types\n",
    "5. Generate response\n",
    "6. Save working memory (updated conversation)\n",
    "```\n",
    "\n",
    "This gives us **stateful, personalized, context-aware conversations**.\n",
    "\n",
    "### **5. Agent Memory Server is Production-Ready**\n",
    "\n",
    "Why use Agent Memory Server instead of simple in-memory storage:\n",
    "- ‚úÖ **Scalable** - Redis-backed, handles thousands of users\n",
    "- ‚úÖ **Automatic** - Extracts important facts to long-term storage\n",
    "- ‚úÖ **Semantic search** - Vector-indexed memory retrieval\n",
    "- ‚úÖ **Deduplication** - Prevents redundant memories\n",
    "- ‚úÖ **TTL management** - Automatic expiration of old sessions\n",
    "\n",
    "### **6. LangChain is Sufficient for Memory + RAG**\n",
    "\n",
    "We didn't need LangGraph for this section because:\n",
    "- Simple linear flow (load ‚Üí search ‚Üí generate ‚Üí save)\n",
    "- No conditional branching or complex state management\n",
    "- No tool calling required\n",
    "\n",
    "**LangGraph becomes necessary in Section 4** when we add tools and multi-step workflows.\n",
    "\n",
    "### **7. Memory Management Best Practices**\n",
    "\n",
    "**Choose the Right Memory Type:**\n",
    "- **Semantic** for facts and preferences (most common)\n",
    "- **Episodic** for time-bound events and timeline\n",
    "- **Message** for context-rich conversations (use sparingly)\n",
    "\n",
    "**Understand Memory Lifecycle:**\n",
    "- **Working memory:** 24-hour TTL, session-scoped\n",
    "- **Long-term memory:** Indefinite persistence, user-scoped\n",
    "- **Automatic extraction:** Trust the system to extract important facts\n",
    "\n",
    "**Benefits of Proper Memory Management:**\n",
    "- ‚úÖ **Natural conversations** - Users don't repeat themselves\n",
    "- ‚úÖ **Cross-session personalization** - Knowledge persists over time\n",
    "- ‚úÖ **Efficient storage** - Automatic deduplication prevents bloat\n",
    "- ‚úÖ **Semantic search** - Find relevant memories without exact keywords\n",
    "- ‚úÖ **Scalable** - Redis-backed, production-ready architecture\n",
    "\n",
    "**Key Principle:** Memory transforms stateless RAG into stateful, personalized, context-aware conversations.\n",
    "\n",
    "---\n",
    "\n",
    "## üí™ Practice Exercises\n",
    "\n",
    "### **Exercise 1: Cross-Session Personalization**\n",
    "\n",
    "Modify the `memory_enhanced_rag_query` function to:\n",
    "1. Store user preferences in long-term memory when mentioned\n",
    "2. Use those preferences in future sessions\n",
    "3. Test with two different sessions for the same student\n",
    "\n",
    "**Hint:** Look for phrases like \"I prefer...\", \"I like...\", \"I want...\" and store them as semantic memories.\n",
    "\n",
    "### **Exercise 2: Memory-Aware Filtering**\n",
    "\n",
    "Enhance the RAG search to use long-term memories as filters:\n",
    "1. Search long-term memory for preferences (format, difficulty, schedule)\n",
    "2. Apply those preferences as filters to `course_manager.search_courses()`\n",
    "3. Compare results with and without memory-aware filtering\n",
    "\n",
    "**Hint:** Use the `filters` parameter in `course_manager.search_courses()`.\n",
    "\n",
    "### **Exercise 3: Conversation Summarization**\n",
    "\n",
    "Implement a function that summarizes long conversations:\n",
    "1. When working memory exceeds 10 messages, summarize the conversation\n",
    "2. Store the summary in long-term memory\n",
    "3. Clear old messages from working memory (keep only recent 4)\n",
    "4. Test that reference resolution still works with summarized history\n",
    "\n",
    "**Hint:** Use the LLM to generate summaries, then store as semantic memories.\n",
    "\n",
    "### **Exercise 4: Multi-User Memory Management**\n",
    "\n",
    "Create a simple CLI that:\n",
    "1. Supports multiple students (different user IDs)\n",
    "2. Maintains separate working memory per session\n",
    "3. Maintains separate long-term memory per user\n",
    "4. Demonstrates cross-session continuity for each user\n",
    "\n",
    "**Hint:** Use different `session_id` and `user_id` for each student.\n",
    "\n",
    "### **Exercise 5: Memory Search Quality**\n",
    "\n",
    "Experiment with long-term memory search:\n",
    "1. Store 20+ diverse memories for a student\n",
    "2. Try different search queries\n",
    "3. Analyze which memories are retrieved\n",
    "4. Adjust memory text to improve search relevance\n",
    "\n",
    "**Hint:** More specific memory text leads to better semantic search results.\n",
    "\n",
    "---\n",
    "\n",
    "## üìù Summary\n",
    "\n",
    "### **What You Learned:**\n",
    "\n",
    "1. **The Grounding Problem** - Why agents need memory to resolve references\n",
    "2. **Working Memory** - Session-scoped conversation history for continuity\n",
    "3. **Long-term Memory** - Cross-session persistent knowledge for personalization\n",
    "4. **Memory Integration** - Combining memory with Section 2's RAG system\n",
    "5. **Complete Context Engineering** - All four context types working together\n",
    "6. **Production Architecture** - Using Agent Memory Server for scalable memory\n",
    "\n",
    "### **What You Built:**\n",
    "\n",
    "- ‚úÖ Working memory demo (multi-turn conversations)\n",
    "- ‚úÖ Long-term memory demo (persistent knowledge)\n",
    "- ‚úÖ Complete memory-enhanced RAG system\n",
    "- ‚úÖ Integration of all four context types\n",
    "\n",
    "### **Key Functions:**\n",
    "\n",
    "- `memory_enhanced_rag_query()` - Complete memory + RAG pipeline\n",
    "- `working_memory_demo()` - Demonstrates conversation continuity\n",
    "- `longterm_memory_demo()` - Demonstrates persistent knowledge\n",
    "- `complete_demo()` - End-to-end multi-turn conversation\n",
    "\n",
    "### **Architecture Pattern:**\n",
    "\n",
    "```\n",
    "User Query\n",
    "    ‚Üì\n",
    "Load Working Memory (conversation history)\n",
    "    ‚Üì\n",
    "Search Long-term Memory (user facts)\n",
    "    ‚Üì\n",
    "RAG Search (relevant courses)\n",
    "    ‚Üì\n",
    "Assemble Context (System + User + Conversation + Retrieved)\n",
    "    ‚Üì\n",
    "Generate Response\n",
    "    ‚Üì\n",
    "Save Working Memory (updated conversation)\n",
    "```\n",
    "\n",
    "### **From Section 2 to Section 3:**\n",
    "\n",
    "**Section 2 (Stateless RAG):**\n",
    "- ‚ùå No conversation history\n",
    "- ‚ùå Each query independent\n",
    "- ‚ùå Can't resolve references\n",
    "- ‚úÖ Retrieves relevant documents\n",
    "\n",
    "**Section 3 (Memory-Enhanced RAG):**\n",
    "- ‚úÖ Conversation history (working memory)\n",
    "- ‚úÖ Multi-turn conversations\n",
    "- ‚úÖ Reference resolution\n",
    "- ‚úÖ Persistent user knowledge (long-term memory)\n",
    "- ‚úÖ Personalization across sessions\n",
    "\n",
    "### **Next Steps:**\n",
    "\n",
    "**Section 4** will add **tools** and **agentic workflows** using **LangGraph**, completing your journey from context engineering fundamentals to production-ready AI agents.\n",
    "\n",
    "---\n",
    "\n",
    "## üéâ Congratulations!\n",
    "\n",
    "You've successfully built a **memory-enhanced RAG system** that:\n",
    "- Remembers conversations (working memory)\n",
    "- Accumulates knowledge (long-term memory)\n",
    "- Resolves references naturally\n",
    "- Personalizes responses\n",
    "- Integrates all four context types\n",
    "\n",
    "**You're now ready for Section 4: Tools & Agentic Workflows!** üöÄ\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
