{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f38f7a74133d584d",
   "metadata": {},
   "source": [
    "![Redis](https://redis.io/wp-content/uploads/2024/04/Logotype.svg?auto=webp&quality=85,75&width=120)\n",
    "\n",
    "# RAG: Retrieved Context in Practice\n",
    "\n",
    "## From Context Engineering to Retrieval-Augmented Generation\n",
    "\n",
    "In Section 1, you learned about the four core context types:\n",
    "1. **System Context** - The AI's role and domain knowledge\n",
    "2. **User Context** - Personal profiles and preferences  \n",
    "3. **Conversation Context** - Dialogue history and flow\n",
    "4. **Retrieved Context** - Dynamic information from external sources\n",
    "\n",
    "This notebook focuses on **Retrieved Context** - the most powerful and complex context type. You'll learn how to build a production-ready RAG (Retrieval-Augmented Generation) system that dynamically fetches relevant information to enhance AI responses.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "**RAG Fundamentals:**\n",
    "- What RAG is and why it's essential for context engineering\n",
    "- How vector embeddings enable semantic search\n",
    "- Building a complete RAG pipeline with LangChain and Redis\n",
    "\n",
    "**Practical Implementation:**\n",
    "- Generate and ingest course data using existing utilities\n",
    "- Set up Redis vector store for semantic search\n",
    "- Implement retrieval and generation workflows\n",
    "- Combine retrieved context with user and system context\n",
    "\n",
    "**Foundation for Advanced Topics:**\n",
    "- This RAG system becomes the base for Section 3 (Memory Architecture)\n",
    "- You'll add LangGraph state management and tools in later sections\n",
    "- Focus here is purely on retrieval ‚Üí context assembly ‚Üí generation\n",
    "\n",
    "**Time to complete:** 30-35 minutes\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32f737633a8079d",
   "metadata": {},
   "source": [
    "## Why RAG Matters for Context Engineering\n",
    "\n",
    "### The Challenge: Static vs. Dynamic Knowledge\n",
    "\n",
    "In Section 1, we used **hardcoded** course information in the system context:\n",
    "\n",
    "```python\n",
    "system_context = \"\"\"You are a Redis University course advisor.\n",
    "\n",
    "Available Courses:\n",
    "- RU101: Introduction to Redis (Beginner, 4-6 hours)\n",
    "- RU201: Redis for Python (Intermediate, 6-8 hours)\n",
    "...\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "**Problems with this approach:**\n",
    "- ‚ùå **Doesn't scale** - Can't hardcode thousands of courses\n",
    "- ‚ùå **Wastes tokens** - Includes irrelevant courses in every request\n",
    "- ‚ùå **Hard to update** - Requires code changes to add/modify courses\n",
    "- ‚ùå **No personalization** - Same courses shown to everyone\n",
    "\n",
    "### The Solution: Retrieval-Augmented Generation (RAG)\n",
    "\n",
    "RAG solves these problems by **dynamically retrieving** only the most relevant information:\n",
    "\n",
    "```\n",
    "User Query: \"I want to learn about vector search\"\n",
    "     ‚Üì\n",
    "Semantic Search: Find courses matching \"vector search\"\n",
    "     ‚Üì\n",
    "Retrieved Context: RU301 - Vector Similarity Search with Redis\n",
    "     ‚Üì\n",
    "LLM Generation: Personalized recommendation using retrieved context\n",
    "```\n",
    "\n",
    "**Benefits:**\n",
    "- ‚úÖ **Scales infinitely** - Store millions of documents\n",
    "- ‚úÖ **Token efficient** - Only retrieve what's relevant\n",
    "- ‚úÖ **Easy to update** - Add/modify data without code changes\n",
    "- ‚úÖ **Personalized** - Different results for different queries\n",
    "\n",
    "### RAG as \"Retrieved Context\" from Section 1\n",
    "\n",
    "Remember the four context types? RAG is how we implement **Retrieved Context** in production:\n",
    "\n",
    "| Context Type | Storage | Retrieval Method | Example |\n",
    "|--------------|---------|------------------|---------|\n",
    "| System Context | Hardcoded | Always included | AI role, instructions |\n",
    "| User Context | Database | User ID lookup | Student profile |\n",
    "| Conversation Context | Session store | Session ID lookup | Chat history |\n",
    "| **Retrieved Context** | **Vector DB** | **Search** | **Relevant courses** |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6199337174405d39",
   "metadata": {},
   "source": [
    "## Setup and Environment\n",
    "\n",
    "Let's prepare our environment with the necessary dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b8643051fbc09a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment variables loaded\n",
      "   REDIS_URL: redis://localhost:6379\n",
      "   OPENAI_API_KEY: ‚úì Set\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Verify required environment variables\n",
    "required_vars = [\"OPENAI_API_KEY\"]\n",
    "missing_vars = [var for var in required_vars if not os.getenv(var)]\n",
    "\n",
    "if missing_vars:\n",
    "    print(f\"\"\"\n",
    "‚ö†Ô∏è  Missing required environment variables: {', '.join(missing_vars)}\n",
    "\n",
    "Please create a .env file with:\n",
    "OPENAI_API_KEY=your_openai_api_key\n",
    "REDIS_URL=redis://localhost:6379\n",
    "\n",
    "For Redis setup:\n",
    "- Local: docker run -d -p 6379:6379 redis/redis-stack-server:latest\n",
    "- Cloud: https://redis.com/try-free/\n",
    "\"\"\")\n",
    "    sys.exit(1)\n",
    "REDIS_URL='redis://localhost:6379'\n",
    "print(\"‚úÖ Environment variables loaded\")\n",
    "print(f\"   REDIS_URL: {REDIS_URL}\")\n",
    "print(f\"   OPENAI_API_KEY: {'‚úì Set' if os.getenv('OPENAI_API_KEY') else '‚úó Not set'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09c113f31cc9237",
   "metadata": {},
   "source": [
    "### Install Dependencies\n",
    "\n",
    "We'll use LangChain for RAG orchestration and Redis for vector storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a604197ba5bed3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dependencies ready\n"
     ]
    }
   ],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# %pip install -q langchain langchain-openai langchain-redis redisvl redis python-dotenv\n",
    "\n",
    "print(\"‚úÖ Dependencies ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa253a5a5fea56a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Step 1: Understanding Vector Embeddings\n",
    "\n",
    "Before building our RAG system, let's understand the core concept: **vector embeddings**.\n",
    "\n",
    "### What Are Embeddings?\n",
    "\n",
    "Embeddings convert text into numerical vectors that capture semantic meaning:\n",
    "\n",
    "```\n",
    "Text: \"Introduction to Redis\"\n",
    "  ‚Üì (embedding model)\n",
    "Vector: [0.23, -0.45, 0.67, ..., 0.12]  # 1536 dimensions for OpenAI\n",
    "```\n",
    "\n",
    "**Key insight:** Similar texts have similar vectors (measured by cosine similarity).\n",
    "\n",
    "### Why Embeddings Enable Semantic Search\n",
    "\n",
    "Traditional keyword search:\n",
    "- Query: \"machine learning courses\" \n",
    "- Matches: Only documents containing exact words \"machine learning\"\n",
    "- Misses: \"AI courses\", \"neural network classes\", \"deep learning programs\"\n",
    "\n",
    "Semantic search with embeddings:\n",
    "- Query: \"machine learning courses\"\n",
    "- Matches: All semantically similar content (AI, neural networks, deep learning, etc.)\n",
    "- Works across synonyms, related concepts, and different phrasings\n",
    "\n",
    "Let's see this in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f78bfe047e37e3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Generated embeddings for 3 texts\n",
      "   Vector dimensions: 1536\n",
      "   First vector preview: [-0.030, -0.013, 0.001, ...]\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Initialize embedding model\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Generate embeddings for similar and different texts\n",
    "texts = [\n",
    "    \"Introduction to machine learning and neural networks\",\n",
    "    \"Learn about AI and deep learning fundamentals\", \n",
    "    \"Database administration and SQL queries\",\n",
    "]\n",
    "\n",
    "# Get embeddings (this calls OpenAI API)\n",
    "vectors = embeddings.embed_documents(texts)\n",
    "\n",
    "print(f\"‚úÖ Generated embeddings for {len(texts)} texts\")\n",
    "print(f\"   Vector dimensions: {len(vectors[0])}\")\n",
    "print(f\"   First vector preview: [{vectors[0][0]:.3f}, {vectors[0][1]:.3f}, {vectors[0][2]:.3f}, ...]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8987e7214633221",
   "metadata": {},
   "source": [
    "### Measuring Semantic Similarity\n",
    "\n",
    "Let's calculate cosine similarity to see which texts are semantically related:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7963a05e261c914c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Similarity Scores (0=unrelated, 1=identical):\n",
      "   ML vs AI:       0.623 ‚Üê High similarity (related topics)\n",
      "   ML vs Database: 0.171 ‚Üê Low similarity (different topics)\n",
      "   AI vs Database: 0.177 ‚Üê Low similarity (different topics)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"Calculate cosine similarity between two vectors.\"\"\"\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "# Compare similarities\n",
    "sim_1_2 = cosine_similarity(vectors[0], vectors[1])  # ML vs AI (related)\n",
    "sim_1_3 = cosine_similarity(vectors[0], vectors[2])  # ML vs Database (unrelated)\n",
    "sim_2_3 = cosine_similarity(vectors[1], vectors[2])  # AI vs Database (unrelated)\n",
    "\n",
    "print(\"Semantic Similarity Scores (0=unrelated, 1=identical):\")\n",
    "print(f\"   ML vs AI:       {sim_1_2:.3f} ‚Üê High similarity (related topics)\")\n",
    "print(f\"   ML vs Database: {sim_1_3:.3f} ‚Üê Low similarity (different topics)\")\n",
    "print(f\"   AI vs Database: {sim_2_3:.3f} ‚Üê Low similarity (different topics)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830004ddb2bd656b",
   "metadata": {},
   "source": [
    "**üí° Key Takeaway:** Embeddings capture semantic meaning, allowing us to find relevant information even when exact keywords don't match.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be16970c9b44fcec",
   "metadata": {},
   "source": [
    "## üìö Step 2: Generate Course Data\n",
    "\n",
    "Now let's create realistic course data for our RAG system. We'll use the existing utilities from the reference agent.\n",
    "\n",
    "### Understanding the Course Generation Script\n",
    "\n",
    "The `generate_courses.py` script creates realistic course data with:\n",
    "- Multiple majors (CS, Data Science, Math, Business, Psychology)\n",
    "- Course templates with descriptions, prerequisites, schedules\n",
    "- Realistic metadata (instructors, enrollment, difficulty levels)\n",
    "\n",
    "Let's generate our course catalog:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d63e217969956023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Generating course catalog...\n",
      "\n",
      "‚úÖ Generated 5 majors:\n",
      "   - Computer Science (CS)\n",
      "   - Data Science (DS)\n",
      "   - Mathematics (MATH)\n",
      "   - Business Administration (BUS)\n",
      "   - Psychology (PSY)\n",
      "\n",
      "‚úÖ Generated 50 courses\n",
      "\n",
      "Sample Course:\n",
      "   Code: CS001\n",
      "   Title: Introduction to Programming\n",
      "   Department: Computer Science\n",
      "   Difficulty: beginner\n",
      "   Credits: 3\n",
      "   Description: Fundamental programming concepts using Python. Variables, control structures, functions, and basic d...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# IGNORE: Add reference-agent to Python path because I installed reference-agent with pip\n",
    "# IGNORE: sys.path.insert(0, os.path.join(os.getcwd(), 'python-recipes/context-engineering/reference-agent'))\n",
    "\n",
    "from redis_context_course.scripts.generate_courses import CourseGenerator\n",
    "\n",
    "# Initialize generator with a seed for reproducibility\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "# Create generator\n",
    "generator = CourseGenerator()\n",
    "\n",
    "print(\"üìö Generating course catalog...\")\n",
    "print()\n",
    "\n",
    "# Generate majors\n",
    "majors = generator.generate_majors()\n",
    "print(f\"‚úÖ Generated {len(majors)} majors:\")\n",
    "for major in majors:\n",
    "    print(f\"   - {major.name} ({major.code})\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Generate courses (10 per major)\n",
    "courses = generator.generate_courses(courses_per_major=10)\n",
    "print(f\"‚úÖ Generated {len(courses)} courses\")\n",
    "\n",
    "# Show a sample course\n",
    "sample_course = courses[0]\n",
    "print(f\"\"\"\n",
    "Sample Course:\n",
    "   Code: {sample_course.course_code}\n",
    "   Title: {sample_course.title}\n",
    "   Department: {sample_course.department}\n",
    "   Difficulty: {sample_course.difficulty_level.value}\n",
    "   Credits: {sample_course.credits}\n",
    "   Description: {sample_course.description[:100]}...\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95cd4b02364b072",
   "metadata": {},
   "source": [
    "### Save Course Catalog to JSON\n",
    "\n",
    "Let's save this data so we can ingest it into Redis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35eb083f18863411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 5 majors and 50 courses\n",
      "Data saved to course_catalog_section2.json\n",
      "‚úÖ Course catalog saved to course_catalog_section2.json\n",
      "   Ready for ingestion into Redis vector store\n"
     ]
    }
   ],
   "source": [
    "catalog_file = \"course_catalog_section2.json\"\n",
    "generator.save_to_json(catalog_file)\n",
    "\n",
    "print(f\"‚úÖ Course catalog saved to {catalog_file}\")\n",
    "print(f\"   Ready for ingestion into Redis vector store\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15d309043a79486",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîß Step 3: Set Up Redis Vector Store\n",
    "\n",
    "Now we'll configure Redis to store our course embeddings and enable semantic search.\n",
    "\n",
    "### Understanding Redis Vector Search\n",
    "\n",
    "Redis Stack provides vector similarity search capabilities:\n",
    "- **Storage:** Courses stored as Redis hashes with vector fields\n",
    "- **Indexing:** Vector index for fast similarity search (HNSW algorithm)\n",
    "- **Search:** Find top-k most similar courses to a query vector using cosine similarity\n",
    "\n",
    "### Using the Reference Agent Utilities\n",
    "\n",
    "Instead of configuring Redis from scratch, we'll use the **production-ready utilities** from the reference agent. These utilities are already configured and tested, allowing you to focus on context engineering concepts rather than Redis configuration details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429acdaadabaa392",
   "metadata": {},
   "source": [
    "### Import Redis Configuration\n",
    "\n",
    "Let's import the pre-configured Redis setup:\n",
    "\n",
    "What we're importing:\n",
    " - redis_config: A global singleton that manages all Redis connections\n",
    "\n",
    "What it provides (lazy-initialized properties):\n",
    " - redis_config.redis_client: Redis connection for data storage\n",
    " - redis_config.embeddings: OpenAI embeddings (text-embedding-3-small)\n",
    " - redis_config.vector_index: RedisVL SearchIndex with pre-configured schema\n",
    " - redis_config.checkpointer: RedisSaver for LangGraph (used in Section 3)\n",
    "\n",
    "Why use this:\n",
    " - Production-ready configuration (same as reference agent)\n",
    " - Proper schema with all course metadata fields\n",
    " - Vector field: 1536 dims, cosine distance, HNSW algorithm\n",
    " - No boilerplate - just import and use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64b05a2a034da925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Redis configuration imported\n",
      "   Redis URL: redis://localhost:6379\n",
      "   Vector index name: course_catalog\n"
     ]
    }
   ],
   "source": [
    "from redis_context_course.redis_config import redis_config\n",
    "\n",
    "print(\"‚úÖ Redis configuration imported\")\n",
    "print(f\"   Redis URL: {redis_config.redis_url}\")\n",
    "print(f\"   Vector index name: {redis_config.vector_index_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93784287e000173d",
   "metadata": {},
   "source": [
    "### Test Redis Connection\n",
    "\n",
    "Let's verify Redis is running and accessible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c2f11887561871f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Connected to Redis\n",
      "   Redis is healthy and ready\n"
     ]
    }
   ],
   "source": [
    "# Test connection using built-in health check\n",
    "if redis_config.health_check():\n",
    "    print(\"‚úÖ Connected to Redis\")\n",
    "    print(f\"   Redis is healthy and ready\")\n",
    "else:\n",
    "    print(\"‚ùå Redis connection failed\")\n",
    "    print(\"   Make sure Redis is running:\")\n",
    "    print(\"   - Local: docker run -d -p 6379:6379 redis/redis-stack-server:latest\")\n",
    "    print(\"   - Cloud: https://redis.com/try-free/\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154a875022180c9f",
   "metadata": {},
   "source": [
    "### Initialize Course Manager\n",
    "\n",
    "Now let's import the `CourseManager` - this handles all course operations, such as storage, retrieval, and search:\n",
    "\n",
    "What it provides:\n",
    " - store_course(): Store a course with vector embedding\n",
    " - search_courses(): Semantic search with filters\n",
    " - get_course(): Retrieve course by ID\n",
    " - get_course_by_code(): Retrieve course by course code\n",
    " - recommend_courses(): Generate personalized recommendations\n",
    "\n",
    "How it works:\n",
    " - Uses redis_config for connections (redis_client, vector_index, embeddings)\n",
    " - Automatically generates embeddings from course content\n",
    " - Uses RedisVL's VectorQuery for semantic search\n",
    " - Supports metadata filters (department, difficulty, format, etc.)\n",
    "\n",
    "Why use this:\n",
    " - Encapsulates all Redis/RedisVL complexity\n",
    " - Same code used in reference agent (Sections 3 & 4)\n",
    " - Focus on RAG concepts, not Redis implementation details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f89de1e20794eda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Course manager initialized\n",
      "   Ready for course storage and search\n",
      "   Using RedisVL for vector operations\n"
     ]
    }
   ],
   "source": [
    "from redis_context_course.course_manager import CourseManager\n",
    "\n",
    "# Initialize course manager\n",
    "course_manager = CourseManager()\n",
    "\n",
    "print(\"‚úÖ Course manager initialized\")\n",
    "print(f\"   Ready for course storage and search\")\n",
    "print(f\"   Using RedisVL for vector operations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa59e20137321967",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üì• Step 4: Ingest Courses into Redis\n",
    "\n",
    "Now we'll load our course catalog into Redis with vector embeddings for semantic search.\n",
    "\n",
    "### Understanding the Ingestion Process\n",
    "\n",
    "The ingestion pipeline:\n",
    "1. **Load** course data from JSON\n",
    "2. **Generate embeddings** for each course (title + description + tags)\n",
    "3. **Store** in Redis with metadata for filtering\n",
    "4. **Index** vectors for fast similarity search\n",
    "\n",
    "Let's use the existing ingestion utilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85ccf2cb80ad5e05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting course ingestion...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">üöÄ Starting Course Catalog Ingestion</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34müöÄ Starting Course Catalog Ingestion\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">‚úÖ Redis connection successful</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m‚úÖ Redis connection successful\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">üßπ Clearing existing data...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33müßπ Clearing existing data\u001b[0m\u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">‚úÖ Data cleared successfully</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m‚úÖ Data cleared successfully\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">‚úÖ Loaded catalog from course_catalog_section2.json</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m‚úÖ Loaded catalog from course_catalog_section2.json\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Majors: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   Majors: \u001b[1;36m5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Courses: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   Courses: \u001b[1;36m50\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "210b0d21357e488a8107aba0bf28ee38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">‚úÖ Ingested </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">5</span><span style=\"color: #008000; text-decoration-color: #008000\"> majors</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m‚úÖ Ingested \u001b[0m\u001b[1;32m5\u001b[0m\u001b[32m majors\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a3f7f8bc1b482985ae85864abdcc2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:33:51 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:33:52 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:33:52 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:33:53 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:33:54 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:33:54 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:33:54 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:33:55 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:33:55 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:33:55 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:33:55 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:33:56 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:33:56 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:33:56 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:33:56 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:33:57 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:33:58 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:33:58 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:33:58 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:33:58 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:33:58 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:33:59 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:33:59 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:34:00 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:34:00 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:34:01 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:34:01 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:34:01 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:34:02 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:34:02 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:34:02 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:34:02 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:34:03 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:34:03 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:34:03 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:34:03 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:34:04 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:34:04 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:34:04 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:34:04 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:34:04 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:34:05 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:34:05 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:34:05 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:34:05 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:34:06 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:34:06 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:34:06 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:34:06 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:34:06 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">‚úÖ Ingested </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">50</span><span style=\"color: #008000; text-decoration-color: #008000\"> courses</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m‚úÖ Ingested \u001b[0m\u001b[1;32m50\u001b[0m\u001b[32m courses\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">üìä Verification - Courses: </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">50</span><span style=\"color: #000080; text-decoration-color: #000080\">, Majors: </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">5</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34müìä Verification - Courses: \u001b[0m\u001b[1;34m50\u001b[0m\u001b[34m, Majors: \u001b[0m\u001b[1;34m5\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">üéâ Ingestion completed successfully!</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32müéâ Ingestion completed successfully!\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Course ingestion complete!\n",
      "   Courses in Redis: 50\n",
      "   Majors in Redis: 5\n"
     ]
    }
   ],
   "source": [
    "from redis_context_course.scripts.ingest_courses import CourseIngestionPipeline\n",
    "import asyncio\n",
    "\n",
    "# What we're importing:\n",
    "# - CourseIngestionPipeline: Handles bulk ingestion of course data\n",
    "#\n",
    "# What it does:\n",
    "# - Loads course catalog from JSON file\n",
    "# - For each course: generates embedding + stores in Redis\n",
    "# - Uses CourseManager internally for storage\n",
    "# - Provides progress tracking and verification\n",
    "#\n",
    "# Why use this:\n",
    "# - Handles batch ingestion efficiently\n",
    "# - Same utility used to populate reference agent\n",
    "# - Includes error handling and progress reporting\n",
    "\n",
    "# Initialize ingestion pipeline\n",
    "pipeline = CourseIngestionPipeline()\n",
    "\n",
    "print(\"üöÄ Starting course ingestion...\")\n",
    "print()\n",
    "\n",
    "# Run ingestion (clear existing data first)\n",
    "success = await pipeline.run_ingestion(\n",
    "    catalog_file=catalog_file,\n",
    "    clear_existing=True\n",
    ")\n",
    "\n",
    "if success:\n",
    "    print()\n",
    "    print(\"‚úÖ Course ingestion complete!\")\n",
    "\n",
    "    # Verify what was ingested\n",
    "    verification = pipeline.verify_ingestion()\n",
    "    print(f\"   Courses in Redis: {verification['courses']}\")\n",
    "    print(f\"   Majors in Redis: {verification['majors']}\")\n",
    "else:\n",
    "    print(\"‚ùå Ingestion failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9f4e00dcc39387",
   "metadata": {},
   "source": [
    "### What Just Happened?\n",
    "\n",
    "For each course, the ingestion pipeline:\n",
    "\n",
    "1. **Created searchable content:**\n",
    "   ```python\n",
    "   content = f\"{course.title} {course.description} {course.department} {' '.join(course.tags)}\"\n",
    "   ```\n",
    "\n",
    "2. **Generated embedding vector:**\n",
    "   ```python\n",
    "   embedding = await embeddings.aembed_query(content)  # 1536-dim vector\n",
    "   ```\n",
    "\n",
    "3. **Stored in Redis:**\n",
    "   ```python\n",
    "   redis_client.hset(f\"course_idx:{course.id}\", mapping={\n",
    "       \"course_code\": \"CS001\",\n",
    "       \"title\": \"Introduction to Programming\",\n",
    "       \"description\": \"...\",\n",
    "       \"content_vector\": embedding.tobytes()  # Binary vector\n",
    "   })\n",
    "   ```\n",
    "\n",
    "4. **Indexed for search:**\n",
    "   - Redis automatically indexes the vector field\n",
    "   - Enables fast k-NN (k-nearest neighbors) search\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4d3d17c5c3cdae",
   "metadata": {},
   "source": [
    "## üîç Step 5: Semantic Search - Finding Relevant Courses\n",
    "\n",
    "Now comes the magic: semantic search. Let's query our vector store to find relevant courses.\n",
    "\n",
    "### Basic Semantic Search\n",
    "\n",
    "Let's search for courses related to \"machine learning\".\n",
    "\n",
    "When this is called:\n",
    "```python\n",
    "await course_manager.search_courses(\n",
    "    query=query,\n",
    "    limit=3  # top_k parameter\n",
    ")\n",
    "```\n",
    "It is performing semantic search under the hood:\n",
    "1. Generates embedding for the query using OpenAI\n",
    "2. Performs vector similarity search in Redis (cosine distance)\n",
    "3. Returns top-k most similar courses\n",
    "4. Uses RedisVL's VectorQuery under the hood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d19cebdedbaec6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Searching for: 'machine learning and artificial intelligence'\n",
      "\n",
      "00:35:39 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "‚úÖ Found 3 relevant courses:\n",
      "\n",
      "1. CS007: Machine Learning\n",
      "   Department: Computer Science\n",
      "   Difficulty: advanced\n",
      "   Description: Introduction to machine learning algorithms and applications. Supervised and unsupervised learning, ...\n",
      "\n",
      "2. DS012: Statistics for Data Science\n",
      "   Department: Data Science\n",
      "   Difficulty: intermediate\n",
      "   Description: Statistical methods and probability theory for data analysis. Hypothesis testing, regression, and st...\n",
      "\n",
      "3. DS015: Statistics for Data Science\n",
      "   Department: Data Science\n",
      "   Difficulty: intermediate\n",
      "   Description: Statistical methods and probability theory for data analysis. Hypothesis testing, regression, and st...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We already initialized course_manager in Step 3\n",
    "# It's ready to use for semantic search\n",
    "\n",
    "# Search for machine learning courses\n",
    "query = \"machine learning and artificial intelligence\"\n",
    "print(f\"üîç Searching for: '{query}'\\n\")\n",
    "\n",
    "# Perform semantic search (returns top 3 most similar courses)\n",
    "results = await course_manager.search_courses(\n",
    "    query=query,\n",
    "    limit=3  # top_k parameter\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Found {len(results)} relevant courses:\\n\")\n",
    "\n",
    "for i, course in enumerate(results, 1):\n",
    "    print(f\"{i}. {course.course_code}: {course.title}\")\n",
    "    print(f\"   Department: {course.department}\")\n",
    "    print(f\"   Difficulty: {course.difficulty_level.value}\")\n",
    "    print(f\"   Description: {course.description[:100]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd46b1b7a140f91",
   "metadata": {},
   "source": [
    "### Search with Filters\n",
    "\n",
    "We can combine semantic search with metadata filters for more precise results:\n",
    "\n",
    "How filters work:\n",
    "\n",
    "```python\n",
    "results = await course_manager.search_courses(\n",
    "    query=query,\n",
    "    limit=3,\n",
    "    filters=filters\n",
    ")\n",
    "```\n",
    " - CourseManager._build_filters() converts dict to RedisVL filter expressions\n",
    " - Uses Tag filters for categorical fields (difficulty_level, format, department)\n",
    " - Uses Num filters for numeric fields (credits, year)\n",
    " - Combines filters with AND logic\n",
    " - Applied to vector search results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19e81b08ef0b24e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Searching for: 'machine learning'\n",
      "   Filters: {'difficulty_level': 'beginner', 'format': 'online'}\n",
      "\n",
      "00:39:02 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "‚úÖ Found 3 matching courses:\n",
      "1. DS020: Data Visualization\n",
      "   Format: online, Difficulty: beginner\n",
      "\n",
      "2. PSY043: Introduction to Psychology\n",
      "   Format: online, Difficulty: beginner\n",
      "\n",
      "3. PSY049: Introduction to Psychology\n",
      "   Format: online, Difficulty: beginner\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Search for beginner-level machine learning courses\n",
    "query = \"machine learning\"\n",
    "filters = {\n",
    "    \"difficulty_level\": \"beginner\",\n",
    "    \"format\": \"online\"\n",
    "}\n",
    "\n",
    "print(f\"üîç Searching for: '{query}'\\n   Filters: {filters}\\n\")\n",
    "# How filters work:\n",
    "# - CourseManager._build_filters() converts dict to RedisVL filter expressions\n",
    "# - Uses Tag filters for categorical fields (difficulty_level, format, department)\n",
    "# - Uses Num filters for numeric fields (credits, year)\n",
    "# - Combines filters with AND logic\n",
    "# - Applied to vector search results\n",
    "results = await course_manager.search_courses(\n",
    "    query=query,\n",
    "    limit=3,\n",
    "    filters=filters\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Found {len(results)} matching courses:\")\n",
    "for i, course in enumerate(results, 1):\n",
    "    print(f\"{i}. {course.course_code}: {course.title}\")\n",
    "    print(f\"   Format: {course.format.value}, Difficulty: {course.difficulty_level.value}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9406198195f5c4",
   "metadata": {},
   "source": [
    "**üí° Key Insight:** We can combine:\n",
    "- **Semantic search** (find courses about \"machine learning\")\n",
    "- **Metadata filters** (only beginner, online courses)\n",
    "\n",
    "This gives us precise, relevant results for any query. This will be a useful tool to build context for our RAG pipeline.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d2fedcf3efb590",
   "metadata": {},
   "source": [
    "## üîó Step 6: Building the RAG Pipeline\n",
    "\n",
    "Now let's combine everything into a complete RAG pipeline: Retrieval ‚Üí Context Assembly ‚Üí Generation.\n",
    "\n",
    "### The RAG Flow\n",
    "\n",
    "```\n",
    "User Query\n",
    "    ‚Üì\n",
    "1. Semantic Search (retrieve relevant courses)\n",
    "    ‚Üì\n",
    "2. Context Assembly (combine system + user + retrieved context)\n",
    "    ‚Üì\n",
    "3. LLM Generation (create personalized response)\n",
    "```\n",
    "\n",
    "Let's implement each step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b38da21b55f381ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LLM initialized (gpt-4o-mini)\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
    "\n",
    "print(\"‚úÖ LLM initialized (gpt-4o-mini)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3289098af7058a",
   "metadata": {},
   "source": [
    "### Step 6.1: Retrieval Function\n",
    "\n",
    "First, let's create a function to retrieve relevant courses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1206c431ffb4292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:40:03 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "üîç Retrieved 3 courses for: 'I want to learn about data structures'\n",
      "   - CS009: Data Structures and Algorithms\n",
      "   - CS001: Introduction to Programming\n",
      "   - CS005: Introduction to Programming\n"
     ]
    }
   ],
   "source": [
    "async def retrieve_courses(query: str, top_k: int = 3, filters: dict = None):\n",
    "    \"\"\"\n",
    "    Retrieve relevant courses using semantic search.\n",
    "\n",
    "    Args:\n",
    "        query: User's search query\n",
    "        top_k: Number of courses to retrieve\n",
    "        filters: Optional metadata filters\n",
    "\n",
    "    Returns:\n",
    "        List of relevant courses\n",
    "    \"\"\"\n",
    "    # Note: CourseManager.search_courses() uses 'limit' parameter, not 'top_k'\n",
    "    results = await course_manager.search_courses(\n",
    "        query=query,\n",
    "        limit=top_k,\n",
    "        filters=filters\n",
    "    )\n",
    "    return results\n",
    "\n",
    "# Test retrieval\n",
    "test_query = \"I want to learn about data structures\"\n",
    "retrieved_courses = await retrieve_courses(test_query, top_k=3)\n",
    "\n",
    "print(f\"üîç Retrieved {len(retrieved_courses)} courses for: '{test_query}'\")\n",
    "for course in retrieved_courses:\n",
    "    print(f\"   - {course.course_code}: {course.title}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef03683be57faf95",
   "metadata": {},
   "source": [
    "### Step 6.2: Context Assembly Function\n",
    "\n",
    "Now let's assemble context from multiple sources (system + user + retrieved):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a068ffa458f850f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Context assembled\n",
      "   Total length: 1537 characters\n",
      "   Includes: System + User + Retrieved context\n"
     ]
    }
   ],
   "source": [
    "def assemble_context(\n",
    "    user_query: str,\n",
    "    retrieved_courses: list,\n",
    "    user_profile: dict = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Assemble context from multiple sources for the LLM.\n",
    "\n",
    "    This implements the context engineering principles from Section 1:\n",
    "    - System Context: AI role and instructions\n",
    "    - User Context: Student profile and preferences\n",
    "    - Retrieved Context: Relevant courses from vector search\n",
    "    \"\"\"\n",
    "\n",
    "    # System Context: Define the AI's role\n",
    "    system_context = \"\"\"You are a Redis University course advisor.\n",
    "\n",
    "Your role:\n",
    "- Help students find courses that match their interests and goals\n",
    "- Provide personalized recommendations based on student profiles\n",
    "- Explain course prerequisites and learning paths\n",
    "- Be encouraging and supportive\n",
    "\n",
    "Guidelines:\n",
    "- Only recommend courses from the provided course list\n",
    "- Consider student's difficulty level preferences\n",
    "- Explain your reasoning for recommendations\n",
    "- Be concise but informative\n",
    "\"\"\"\n",
    "\n",
    "    # User Context: Student profile (if provided)\n",
    "    user_context = \"\"\n",
    "    if user_profile:\n",
    "        user_context = f\"\"\"\n",
    "Student Profile:\n",
    "- Name: {user_profile.get('name', 'Student')}\n",
    "- Major: {user_profile.get('major', 'Undeclared')}\n",
    "- Year: {user_profile.get('year', 'N/A')}\n",
    "- Interests: {', '.join(user_profile.get('interests', []))}\n",
    "- Preferred Difficulty: {user_profile.get('preferred_difficulty', 'any')}\n",
    "- Preferred Format: {user_profile.get('preferred_format', 'any')}\n",
    "\"\"\"\n",
    "\n",
    "    # Retrieved Context: Relevant courses from semantic search\n",
    "    retrieved_context = \"\\nRelevant Courses:\\n\"\n",
    "    for i, course in enumerate(retrieved_courses, 1):\n",
    "        retrieved_context += f\"\"\"\n",
    "{i}. {course.course_code}: {course.title}\n",
    "   Department: {course.department}\n",
    "   Difficulty: {course.difficulty_level.value}\n",
    "   Format: {course.format.value}\n",
    "   Credits: {course.credits}\n",
    "   Description: {course.description}\n",
    "   Prerequisites: {len(course.prerequisites)} required\n",
    "\"\"\"\n",
    "\n",
    "    # Combine all context\n",
    "    full_context = system_context\n",
    "    if user_context:\n",
    "        full_context += user_context\n",
    "    full_context += retrieved_context\n",
    "\n",
    "    return full_context\n",
    "\n",
    "# Test context assembly\n",
    "test_profile = {\n",
    "    \"name\": \"Sarah Chen\",\n",
    "    \"major\": \"Computer Science\",\n",
    "    \"year\": \"Junior\",\n",
    "    \"interests\": [\"machine learning\", \"data science\"],\n",
    "    \"preferred_difficulty\": \"intermediate\",\n",
    "    \"preferred_format\": \"online\"\n",
    "}\n",
    "\n",
    "assembled_context = assemble_context(\n",
    "    user_query=test_query,\n",
    "    retrieved_courses=retrieved_courses,\n",
    "    user_profile=test_profile\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Context assembled\")\n",
    "print(f\"   Total length: {len(assembled_context)} characters\")\n",
    "print(f\"   Includes: System + User + Retrieved context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16d6089b-7fe2-451d-b57d-436c49259216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observe the assembled context: \n",
      "\n",
      "You are a Redis University course advisor.\n",
      "\n",
      "Your role:\n",
      "- Help students find courses that match their interests and goals\n",
      "- Provide personalized recommendations based on student profiles\n",
      "- Explain course prerequisites and learning paths\n",
      "- Be encouraging and supportive\n",
      "\n",
      "Guidelines:\n",
      "- Only recommend courses from the provided course list\n",
      "- Consider student's difficulty level preferences\n",
      "- Explain your reasoning for recommendations\n",
      "- Be concise but informative\n",
      "\n",
      "Student Profile:\n",
      "- Name: Sarah Chen\n",
      "- Major: Computer Science\n",
      "- Year: Junior\n",
      "- Interests: machine learning, data science\n",
      "- Preferred Difficulty: intermediate\n",
      "- Preferred Format: online\n",
      "\n",
      "Relevant Courses:\n",
      "\n",
      "1. CS009: Data Structures and Algorithms\n",
      "   Department: Computer Science\n",
      "   Difficulty: intermediate\n",
      "   Format: in_person\n",
      "   Credits: 4\n",
      "   Description: Study of fundamental data structures and algorithms. Arrays, linked lists, trees, graphs, sorting, and searching.\n",
      "   Prerequisites: 2 required\n",
      "\n",
      "2. CS001: Introduction to Programming\n",
      "   Department: Computer Science\n",
      "   Difficulty: beginner\n",
      "   Format: hybrid\n",
      "   Credits: 3\n",
      "   Description: Fundamental programming concepts using Python. Variables, control structures, functions, and basic data structures.\n",
      "   Prerequisites: 0 required\n",
      "\n",
      "3. CS005: Introduction to Programming\n",
      "   Department: Computer Science\n",
      "   Difficulty: beginner\n",
      "   Format: hybrid\n",
      "   Credits: 3\n",
      "   Description: Fundamental programming concepts using Python. Variables, control structures, functions, and basic data structures.\n",
      "   Prerequisites: 0 required\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Observe the assembled context: \\n\\n{assembled_context}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9800d8dd-38ea-482f-9486-fc32ba9f1799",
   "metadata": {},
   "source": [
    "**üéÅ Bonus:** Can you identify the different parts of the context from what we learned in section 1 from above?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f28151926c3be5",
   "metadata": {},
   "source": [
    "**‚úÖ Answer:** Yes! Looking at the assembled context above, we can identify all three context types from Section 1:\n",
    "\n",
    "1. **System Context** (Static)\n",
    "   - The first section: \"You are a Redis University course advisor...\"\n",
    "   - Defines the AI's role, responsibilities, and guidelines\n",
    "   - Remains the same for all queries\n",
    "   - Sets behavioral instructions and constraints\n",
    "\n",
    "2. **User Context** (Dynamic, User-Specific)\n",
    "   - The \"Student Profile\" section\n",
    "   - Contains Sarah Chen's personal information: major, year, interests, preferences\n",
    "   - Changes based on who is asking the question\n",
    "   - Enables personalized recommendations\n",
    "\n",
    "3. **Retrieved Context** (Dynamic, Query-Specific)\n",
    "   - The \"Relevant Courses\" section\n",
    "   - Lists the 3 courses found via semantic search for \"data structures\"\n",
    "   - Changes based on the specific query\n",
    "   - Provides the factual information the LLM needs to answer\n",
    "\n",
    "Notice how all three work together: System Context tells the AI **how to behave**, User Context tells it **who it's helping**, and Retrieved Context provides **what information is relevant**. This is RAG in action!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c1be78f7cd3e20",
   "metadata": {},
   "source": [
    "### Step 6.3: Generation Function\n",
    "\n",
    "Finally, let's generate a response using the assembled context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e27332f-83d5-475f-9fcc-405525a25c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_response(user_query: str, context: str):\n",
    "    \"\"\"\n",
    "    Generate LLM response using assembled context.\n",
    "\n",
    "    Args:\n",
    "        user_query: User's question\n",
    "        context: Assembled context (system + user + retrieved)\n",
    "\n",
    "    Returns:\n",
    "        LLM response string\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        SystemMessage(content=context),\n",
    "        HumanMessage(content=user_query)\n",
    "    ]\n",
    "\n",
    "    response = await llm.ainvoke(messages)\n",
    "    return response.content\n",
    "\n",
    "# Test generation\n",
    "response = await generate_response(test_query, assembled_context)\n",
    "\n",
    "print(\"\\nü§ñ Generated Response:\\n\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba9e518ee7581c6",
   "metadata": {},
   "source": [
    "### üéØ Understanding the Generated Response\n",
    "\n",
    "Notice how the LLM's response demonstrates effective context engineering:\n",
    "\n",
    "**üë§ Personalization from User Context:**\n",
    "- Addresses Sarah by name\n",
    "- References her intermediate difficulty preference\n",
    "- Acknowledges her online format preference (even though the course is in-person)\n",
    "- Connects to her interests (machine learning and data science)\n",
    "\n",
    "**üìö Accuracy from Retrieved Context:**\n",
    "- Recommends CS009 (which was in the retrieved courses)\n",
    "- Provides correct course details (difficulty, format, credits, description)\n",
    "- Mentions prerequisites accurately (2 required)\n",
    "\n",
    "**ü§ñ Guidance from System Context:**\n",
    "- Acts as a supportive advisor (\"I'm here to help you succeed!\")\n",
    "- Explains reasoning for the recommendation\n",
    "- Acknowledges the format mismatch honestly\n",
    "- Stays within the provided course list\n",
    "\n",
    "This is the power of RAG: the LLM generates a response that is **personalized** (User Context), **accurate** (Retrieved Context), and **helpful** (System Context). Without RAG, the LLM would either hallucinate course details or provide generic advice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29793f2405eba89f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚ú® Step 7: Complete RAG Function\n",
    "\n",
    "Let's combine all three steps into a single, reusable RAG function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dff6ee-0f65-4875-b0ee-469a2afd26b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def rag_query(\n",
    "    user_query: str,\n",
    "    user_profile: dict = None,\n",
    "    top_k: int = 3,\n",
    "    filters: dict = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Complete RAG pipeline: Retrieve ‚Üí Assemble ‚Üí Generate\n",
    "\n",
    "    Args:\n",
    "        user_query: User's question\n",
    "        user_profile: Optional student profile\n",
    "        top_k: Number of courses to retrieve\n",
    "        filters: Optional metadata filters\n",
    "\n",
    "    Returns:\n",
    "        LLM response string\n",
    "    \"\"\"\n",
    "    # Step 1: Retrieve relevant courses\n",
    "    retrieved_courses = await retrieve_courses(user_query, top_k, filters)\n",
    "\n",
    "    # Step 2: Assemble context\n",
    "    context = assemble_context(user_query, retrieved_courses, user_profile)\n",
    "\n",
    "    # Step 3: Generate response\n",
    "    response = await generate_response(user_query, context)\n",
    "\n",
    "    return response, retrieved_courses\n",
    "\n",
    "# Test the complete RAG pipeline\n",
    "print(\"=\" * 60)\n",
    "print(\"COMPLETE RAG PIPELINE TEST\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "query = \"I'm interested in learning about databases and data management\"\n",
    "profile = {\n",
    "    \"name\": \"Alex Johnson\",\n",
    "    \"major\": \"Data Science\",\n",
    "    \"year\": \"Sophomore\",\n",
    "    \"interests\": [\"databases\", \"data analysis\", \"SQL\"],\n",
    "    \"preferred_difficulty\": \"intermediate\",\n",
    "    \"preferred_format\": \"hybrid\"\n",
    "}\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print()\n",
    "print(f\"Student: {profile['name']} ({profile['major']}, {profile['year']})\")\n",
    "print()\n",
    "\n",
    "response, courses = await rag_query(query, profile, top_k=3)\n",
    "\n",
    "print(\"Retrieved Courses:\")\n",
    "for i, course in enumerate(courses, 1):\n",
    "    print(f\"   {i}. {course.course_code}: {course.title}\")\n",
    "print()\n",
    "\n",
    "print(\"AI Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a079374b0fe92c",
   "metadata": {},
   "source": [
    "### üéØ Why This Complete RAG Function Matters\n",
    "\n",
    "The `rag_query()` function encapsulates the entire RAG pipeline in a single, reusable interface. This is important because:\n",
    "\n",
    "**1. Simplicity:** One function call handles retrieval ‚Üí assembly ‚Üí generation\n",
    "- No need to manually orchestrate the three steps\n",
    "- Clean API for building applications\n",
    "\n",
    "**2. Consistency:** Every query follows the same pattern\n",
    "- Ensures all three context types are always included\n",
    "- Reduces errors from missing context\n",
    "\n",
    "**3. Flexibility:** Easy to customize behavior\n",
    "- Adjust `top_k` for more/fewer retrieved courses\n",
    "- Add/remove user profile information\n",
    "- Modify filters for specific use cases\n",
    "\n",
    "**4. Production-Ready:** This pattern scales to real applications\n",
    "- In Section 3, we'll add memory (conversation history)\n",
    "- In Section 4, we'll add tools (course enrollment, prerequisites checking)\n",
    "- The core RAG pattern remains the same\n",
    "\n",
    "This is the foundation you'll build on throughout the rest of the course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f126f77dd7242ddb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üß™ Step 8: Try Different Queries\n",
    "\n",
    "Let's test our RAG system with various queries to see how it handles different scenarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d63b2d5a412a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 2: Advanced Machine Learning\n",
      "============================================================\n",
      "\n",
      "00:46:06 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:46:13 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\n",
      "Query: I want advanced courses in machine learning and AI\n",
      "\n",
      "\n",
      "AI Response:\n",
      "\n",
      "Hi David! Based on your major in Computer Science and your interests in machine learning and AI, I recommend the following course:\n",
      "\n",
      "**CS007: Machine Learning**\n",
      "- **Difficulty:** Advanced\n",
      "- **Format:** Hybrid (though not in-person, it involves some in-person elements)\n",
      "- **Credits:** 4\n",
      "- **Description:** This course covers machine learning algorithms and applications, including supervised and unsupervised learning as well as neural networks. \n",
      "\n",
      "While it would be ideal to have an exclusively in-person format, CS007 is the only advanced course listed that aligns with your interests and goals in machine learning. The hybrid format may still offer valuable in-person interaction.\n",
      "\n",
      "Unfortunately, there are no strictly in-person advanced courses focused on machine learning or AI in the current offerings. I encourage you to consider CS007 for a solid understanding of the subject, as it can significantly enhance your research capabilities in AI.\n",
      "\n",
      "If you have any further questions or need more assistance, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Beginner looking for programming courses\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 1: Beginner Programming\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "query1 = \"I'm new to programming and want to start learning\"\n",
    "profile1 = {\n",
    "    \"name\": \"Maria Garcia\",\n",
    "    \"major\": \"Undeclared\",\n",
    "    \"year\": \"Freshman\",\n",
    "    \"interests\": [\"programming\", \"technology\"],\n",
    "    \"preferred_difficulty\": \"beginner\",\n",
    "    \"preferred_format\": \"online\"\n",
    "}\n",
    "\n",
    "response1, courses1 = await rag_query(query1, profile1, top_k=2)\n",
    "print(f\"\\nQuery: {query1}\\n\")\n",
    "print(\"\\nAI Response:\\n\")\n",
    "print(response1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6d543a2d75022b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST 3: Business Analytics\n",
      "============================================================\n",
      "\n",
      "00:46:14 httpx INFO   HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "00:46:17 httpx INFO   HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\n",
      "Query: What courses can help me with business analytics and decision making?\n",
      "\n",
      "\n",
      "\n",
      "AI Response:\n",
      "\n",
      "Hi Jennifer! Given your interests in analytics and strategy, I recommend looking into the following course:\n",
      "\n",
      "**BUS033: Marketing Strategy**\n",
      "- **Department:** Business\n",
      "- **Difficulty:** Intermediate\n",
      "- **Format:** Hybrid\n",
      "- **Credits:** 3\n",
      "- **Description:** This course covers strategic marketing planning, market analysis, consumer behavior, and digital marketing techniques. \n",
      "\n",
      "This course aligns well with your major in Business Administration and your interest in analytics and strategy. It will provide you with valuable insights into decision-making processes in marketing, which is crucial for any business professional.\n",
      "\n",
      "Since you prefer a hybrid format, BUS033 is a great fit, allowing you to balance online learning with in-person engagement. Plus, its intermediate difficulty level matches your preferences perfectly.\n",
      "\n",
      "If you have any more questions or need further assistance, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Advanced student looking for specialized courses\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 2: Advanced Machine Learning\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "query2 = \"I want advanced courses in machine learning and AI\"\n",
    "profile2 = {\n",
    "    \"name\": \"David Kim\",\n",
    "    \"major\": \"Computer Science\",\n",
    "    \"year\": \"Senior\",\n",
    "    \"interests\": [\"machine learning\", \"AI\", \"research\"],\n",
    "    \"preferred_difficulty\": \"advanced\",\n",
    "    \"preferred_format\": \"in-person\"\n",
    "}\n",
    "\n",
    "response2, courses2 = await rag_query(query2, profile2, top_k=2)\n",
    "print(f\"\\nQuery: {query2}\\n\")\n",
    "print(\"\\nAI Response:\\n\")\n",
    "print(response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6430f264bc17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: Business student looking for relevant courses\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST 3: Business Analytics\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "query3 = \"What courses can help me with business analytics and decision making?\"\n",
    "profile3 = {\n",
    "    \"name\": \"Jennifer Lee\",\n",
    "    \"major\": \"Business Administration\",\n",
    "    \"year\": \"Junior\",\n",
    "    \"interests\": [\"analytics\", \"management\", \"strategy\"],\n",
    "    \"preferred_difficulty\": \"intermediate\",\n",
    "    \"preferred_format\": \"hybrid\"\n",
    "}\n",
    "\n",
    "response3, courses3 = await rag_query(query3, profile3, top_k=2)\n",
    "print(f\"\\nQuery: {query3}\\n\")\n",
    "print()\n",
    "print(\"\\nAI Response:\\n\")\n",
    "print(response3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38103b67a0624eb4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéì Key Takeaways\n",
    "\n",
    "### What You've Learned\n",
    "\n",
    "**1. RAG Fundamentals**\n",
    "- RAG dynamically retrieves relevant information instead of hardcoding knowledge\n",
    "- Vector embeddings enable semantic search (meaning-based, not keyword-based)\n",
    "- RAG solves the scalability and token efficiency problems of static context\n",
    "\n",
    "**2. The RAG Pipeline**\n",
    "```\n",
    "User Query ‚Üí Semantic Search ‚Üí Context Assembly ‚Üí LLM Generation\n",
    "```\n",
    "- **Retrieval:** Find relevant documents using vector similarity\n",
    "- **Assembly:** Combine system + user + retrieved context\n",
    "- **Generation:** LLM creates personalized response with full context\n",
    "\n",
    "**3. Context Engineering in Practice**\n",
    "- **System Context:** AI role and instructions (static)\n",
    "- **User Context:** Student profile and preferences (dynamic, user-specific)\n",
    "- **Retrieved Context:** Relevant courses from vector search (dynamic, query-specific)\n",
    "- **Integration:** All three context types work together\n",
    "\n",
    "**4. Technical Implementation with Reference Agent Utilities**\n",
    "- **redis_config**: Production-ready Redis configuration (RedisVL + LangChain)\n",
    "  - Manages connections, embeddings, vector index, checkpointer\n",
    "  - Same configuration used in reference agent\n",
    "- **CourseManager**: Handles all course operations\n",
    "  - Uses RedisVL's VectorQuery for semantic search\n",
    "  - Supports metadata filters with Tag and Num classes\n",
    "  - Automatically generates embeddings and stores courses\n",
    "- **CourseIngestionPipeline**: Bulk data ingestion\n",
    "  - Loads JSON, generates embeddings, stores in Redis\n",
    "  - Progress tracking and verification\n",
    "- **Benefits**: Focus on RAG concepts, not Redis implementation details\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "**Retrieval:**\n",
    "- Retrieve only what's needed (top-k results)\n",
    "- Use metadata filters to narrow results\n",
    "- Balance between too few (missing info) and too many (wasting tokens) results\n",
    "- **üí° Research Insight:** Context Rot research shows that distractors (similar-but-wrong information) have amplified negative impact in long contexts. Precision in retrieval matters more than recall. ([Context Rot paper](https://research.trychroma.com/context-rot))\n",
    "\n",
    "**Context Assembly:**\n",
    "- Structure context clearly (system ‚Üí user ‚Üí retrieved)\n",
    "- Include only relevant metadata\n",
    "- Keep descriptions concise but informative\n",
    "\n",
    "**Generation:**\n",
    "- Use appropriate temperature (0.7 for creative, 0.0 for factual)\n",
    "- Provide clear instructions in system context\n",
    "- Let the LLM explain its reasoning\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6994c097a695afdb",
   "metadata": {},
   "source": [
    "## üöÄ What's Next?\n",
    "\n",
    "### üß† Section 3: Memory Architecture\n",
    "\n",
    "In this section, you built a RAG system that retrieves relevant information for each query. But there's a problem: **it doesn't remember previous conversations**.\n",
    "\n",
    "In Section 3, you'll add memory to your RAG system:\n",
    "- **Working Memory:** Track conversation history within a session\n",
    "- **Long-term Memory:** Remember user preferences across sessions\n",
    "- **LangGraph Integration:** Manage stateful workflows with checkpointing\n",
    "- **Redis Agent Memory Server:** Automatic memory extraction and retrieval\n",
    "\n",
    "### Section 4: Tool Use and Agents\n",
    "\n",
    "After adding memory, you'll transform your RAG system into a full agent:\n",
    "- **Tool Calling:** Let the AI use functions (search, enroll, check prerequisites)\n",
    "- **LangGraph State Management:** Orchestrate complex multi-step workflows\n",
    "- **Agent Reasoning:** Plan and execute multi-step tasks\n",
    "- **Production Patterns:** Error handling, retries, and monitoring\n",
    "\n",
    "### The Journey\n",
    "\n",
    "```\n",
    "Section 1: Context Engineering Fundamentals\n",
    "    ‚Üì\n",
    "Section 2: RAG (Retrieved Context) ‚Üê You are here\n",
    "    ‚Üì\n",
    "Section 3: Memory Architecture (Conversation Context)\n",
    "    ‚Üì\n",
    "Section 4: Tool Use and Agents (Complete System)\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f445a3359501a4",
   "metadata": {},
   "source": [
    "## üí™ Practice Exercises\n",
    "\n",
    "Try these exercises to deepen your understanding:\n",
    "\n",
    "**Exercise 1: Custom Filters**\n",
    "- Modify the RAG query to filter by specific departments\n",
    "- Try combining multiple filters (difficulty + format + department)\n",
    "\n",
    "**Exercise 2: Adjust Retrieval**\n",
    "- Experiment with different `top_k` values (1, 3, 5, 10)\n",
    "- Observe how response quality changes with more/fewer retrieved courses\n",
    "\n",
    "**Exercise 3: Context Optimization**\n",
    "- Modify the `assemble_context` function to include more/less detail\n",
    "- Measure token usage and response quality trade-offs\n",
    "\n",
    "**Exercise 4: Different Domains**\n",
    "- Generate courses for a different domain (e.g., healthcare, finance)\n",
    "- Ingest and test RAG with your custom data\n",
    "\n",
    "**Exercise 5: Evaluation**\n",
    "- Create test queries with expected results\n",
    "- Measure retrieval accuracy (are the right courses retrieved?)\n",
    "- Measure generation quality (are responses helpful and accurate?)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9b8641f068666b",
   "metadata": {},
   "source": [
    "## üìù Summary\n",
    "\n",
    "You've built a complete RAG system that:\n",
    "- ‚úÖ Generates and ingests course data with vector embeddings\n",
    "- ‚úÖ Performs semantic search to find relevant courses\n",
    "- ‚úÖ Assembles context from multiple sources (system + user + retrieved)\n",
    "- ‚úÖ Generates personalized responses using LLMs\n",
    "- ‚úÖ Handles different query types and user profiles\n",
    "\n",
    "This RAG system is the foundation for the advanced topics in Sections 3 and 4. You'll build on this exact code to add memory, tools, and full agent capabilities.\n",
    "\n",
    "**Great work!** You've mastered Retrieved Context and built a production-ready RAG pipeline. üéâ\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Additional Resources\n",
    "\n",
    "### **RAG and Vector Search**\n",
    "- [Retrieval-Augmented Generation Paper](https://arxiv.org/abs/2005.11401) - Original RAG paper by Facebook AI\n",
    "- [Redis Vector Similarity Search](https://redis.io/docs/stack/search/reference/vectors/) - Official Redis VSS documentation\n",
    "- [RedisVL Documentation](https://redisvl.com/) - Redis Vector Library for Python\n",
    "- [LangChain RAG Tutorial](https://python.langchain.com/docs/tutorials/rag/) - Building RAG applications\n",
    "\n",
    "### **Embeddings and Semantic Search**\n",
    "- [OpenAI Embeddings Guide](https://platform.openai.com/docs/guides/embeddings) - Understanding text embeddings\n",
    "- [Sentence Transformers](https://www.sbert.net/) - Open-source embedding models\n",
    "- [HNSW Algorithm](https://arxiv.org/abs/1603.09320) - Hierarchical Navigable Small World graphs\n",
    "\n",
    "### **LangChain and Redis Integration**\n",
    "- [LangChain Documentation](https://python.langchain.com/docs/get_started/introduction) - Framework overview\n",
    "- [LangChain Redis Integration](https://python.langchain.com/docs/integrations/vectorstores/redis/) - Using Redis with LangChain\n",
    "- [Redis Python Client](https://redis-py.readthedocs.io/) - redis-py documentation\n",
    "\n",
    "### **Advanced RAG Techniques**\n",
    "- [Advanced RAG Patterns](https://blog.langchain.dev/deconstructing-rag/) - LangChain blog on RAG optimization\n",
    "- [Advanced Search with RedisVL](https://docs.redisvl.com/en/latest/user_guide/11_advanced_queries.html) - Vector, Hybrid, Text, and Keyword Search\n",
    "- [RAG Evaluation](https://arxiv.org/abs/2309.15217) - Measuring RAG system performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e31170-962f-4fe9-9209-a48f23a33400",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
