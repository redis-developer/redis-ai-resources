{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbba56a9",
   "metadata": {},
   "source": [
    "![Redis](https://redis.io/wp-content/uploads/2024/04/Logotype.svg?auto=webp&quality=85,75&width=120)\n",
    "# Routing Optimization\n",
    "\n",
    "Implementing a semantic router is a great light weight way to add branching logic to your application without taking on additional LLM calls. However, it can be tough to determine the optimal distance threshold values for your routes to maximize performance. This guide will walk through:\n",
    "\n",
    "- how to configure a semantic router\n",
    "- how to optimize the distance thresholds for the routes\n",
    "- a comparison between performing similar logic with an LLM versus a router\n",
    "\n",
    "## Let's Begin!\n",
    "<a href=\"https://colab.research.google.com/github/redis-developer/redis-ai-resources/blob/main/python-recipes/semantic-router/01_routing_optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bdc2a5-2192-4f5f-bd6e-7c956fd0e230",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "## Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c620286e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q sentence-transformers ranx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717284f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/redis/redis-vl-python.git@feat/RAAE-602/threshold-optimizer\n",
      "  Cloning https://github.com/redis/redis-vl-python.git (to revision feat/RAAE-602/threshold-optimizer) to /private/var/folders/_g/rr4lnxxx1_z7m78lz89dhvsm0000gp/T/pip-req-build-ykzynneq\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/redis/redis-vl-python.git /private/var/folders/_g/rr4lnxxx1_z7m78lz89dhvsm0000gp/T/pip-req-build-ykzynneq\n",
      "  Running command git checkout -b feat/RAAE-602/threshold-optimizer --track origin/feat/RAAE-602/threshold-optimizer\n",
      "  Switched to a new branch 'feat/RAAE-602/threshold-optimizer'\n",
      "  branch 'feat/RAAE-602/threshold-optimizer' set up to track 'origin/feat/RAAE-602/threshold-optimizer'.\n",
      "  Resolved https://github.com/redis/redis-vl-python.git to commit 18ff1008c5a40353c97c176d3d30028a87ff777a\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: coloredlogs<16.0,>=15.0 in /Users/robert.shelton/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from redisvl==0.4.1) (15.0.1)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from redisvl==0.4.1)\n",
      "  Using cached ml_dtypes-0.4.1-cp311-cp311-macosx_10_9_universal2.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/robert.shelton/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from redisvl==0.4.1) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=2 in /Users/robert.shelton/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from redisvl==0.4.1) (2.7.4)\n",
      "Collecting python-ulid<4.0.0,>=3.0.0 (from redisvl==0.4.1)\n",
      "  Using cached python_ulid-3.0.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.4 in /Users/robert.shelton/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from redisvl==0.4.1) (6.0.1)\n",
      "Requirement already satisfied: redis<6.0,>=5.0 in /Users/robert.shelton/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from redisvl==0.4.1) (5.0.5)\n",
      "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /Users/robert.shelton/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from redisvl==0.4.1) (0.9.0)\n",
      "Requirement already satisfied: tenacity>=8.2.2 in /Users/robert.shelton/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from redisvl==0.4.1) (8.3.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/robert.shelton/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from coloredlogs<16.0,>=15.0->redisvl==0.4.1) (10.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/robert.shelton/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from pydantic<3,>=2->redisvl==0.4.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /Users/robert.shelton/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from pydantic<3,>=2->redisvl==0.4.1) (2.18.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/robert.shelton/.pyenv/versions/3.11.8/lib/python3.11/site-packages (from pydantic<3,>=2->redisvl==0.4.1) (4.12.2)\n",
      "Using cached ml_dtypes-0.4.1-cp311-cp311-macosx_10_9_universal2.whl (397 kB)\n",
      "Using cached python_ulid-3.0.0-py3-none-any.whl (11 kB)\n",
      "Building wheels for collected packages: redisvl\n",
      "  Building wheel for redisvl (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for redisvl: filename=redisvl-0.4.1-py3-none-any.whl size=113401 sha256=973e3b34a10bf10547873947798f4c37f681a87bd1f53c7cf938f2b4bccd71a6\n",
      "  Stored in directory: /private/var/folders/_g/rr4lnxxx1_z7m78lz89dhvsm0000gp/T/pip-ephem-wheel-cache-ydmee1o_/wheels/7d/a2/98/dc1851263ac9752b79c06e42f079d0f4d7233faf3a0fba86f1\n",
      "Successfully built redisvl\n",
      "Installing collected packages: python-ulid, ml-dtypes, redisvl\n",
      "Successfully installed ml-dtypes-0.4.1 python-ulid-3.0.0 redisvl-0.4.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# install from branch since scheduled for 0.5.0\n",
    "%pip install git+https://github.com/redis/redis-vl-python.git@feat/RAAE-602/threshold-optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323aec7f",
   "metadata": {},
   "source": [
    "## Run a Redis instance\n",
    "\n",
    "#### For Colab\n",
    "Use the shell script below to download, extract, and install [Redis Stack](https://redis.io/docs/getting-started/install-stack/) directly from the Redis package archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb85a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_SKIP\n",
    "%%sh\n",
    "curl -fsSL https://packages.redis.io/gpg | sudo gpg --dearmor -o /usr/share/keyrings/redis-archive-keyring.gpg\n",
    "echo \"deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/redis.list\n",
    "sudo apt-get update  > /dev/null 2>&1\n",
    "sudo apt-get install redis-stack-server  > /dev/null 2>&1\n",
    "redis-stack-server --daemonize yes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5dbaaf",
   "metadata": {},
   "source": [
    "#### For Alternative Environments\n",
    "There are many ways to get the necessary redis-stack instance running\n",
    "1. On cloud, deploy a [FREE instance of Redis in the cloud](https://redis.com/try-free/). Or, if you have your\n",
    "own version of Redis Enterprise running, that works too!\n",
    "2. Per OS, [see the docs](https://redis.io/docs/latest/operate/oss_and_stack/install/install-stack/)\n",
    "3. With docker: `docker run -d --name redis-stack-server -p 6379:6379 redis/redis-stack-server:latest`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4499ae",
   "metadata": {},
   "source": [
    "### Define the Redis Connection URL\n",
    "\n",
    "By default this notebook connects to the local instance of Redis Stack. **If you have your own Redis Enterprise instance** - replace REDIS_PASSWORD, REDIS_HOST and REDIS_PORT values with your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aefda1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Replace values below with your own if using Redis Cloud instance\n",
    "REDIS_HOST = os.getenv(\"REDIS_HOST\", \"localhost\") # ex: \"redis-18374.c253.us-central1-1.gce.cloud.redislabs.com\"\n",
    "REDIS_PORT = os.getenv(\"REDIS_PORT\", \"6379\")      # ex: 18374\n",
    "REDIS_PASSWORD = os.getenv(\"REDIS_PASSWORD\", \"\")  # ex: \"1TNxTEdYRDgIDKM2gDfasupCADXXXX\"\n",
    "\n",
    "# If SSL is enabled on the endpoint, use rediss:// as the URL prefix\n",
    "REDIS_URL = f\"redis://:{REDIS_PASSWORD}@{REDIS_HOST}:{REDIS_PORT}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f4cb85",
   "metadata": {},
   "source": [
    "# Routing with multiple routes\n",
    "\n",
    "## Define the Routes\n",
    "\n",
    "Below we define 3 different routes. One for `technology`, one for `sports`, and\n",
    "another for `entertainment`. Now for this example, the goal here is\n",
    "surely topic \"classification\". But you can create routes and references for\n",
    "almost anything.\n",
    "\n",
    "Each route has a set of references that cover the \"semantic surface area\" of the\n",
    "route. The incoming query from a user needs to be semantically similar to one or\n",
    "more of the references in order to \"match\" on the route. Note that each route can have it's own distinct `distance_threshold` that defines what is considered a match for the particular query. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60ad280c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from redisvl.extensions.router import Route\n",
    "\n",
    "# Define routes for the semantic router\n",
    "technology = Route(\n",
    "    name=\"technology\",\n",
    "    references=[\n",
    "        \"what are the latest advancements in AI?\",\n",
    "        \"tell me about the newest gadgets\",\n",
    "        \"what's trending in tech?\"\n",
    "    ],\n",
    "    metadata={\"category\": \"tech\", \"priority\": 1},\n",
    "    distance_threshold=0.5\n",
    ")\n",
    "\n",
    "sports = Route(\n",
    "    name=\"sports\",\n",
    "    references=[\n",
    "        \"who won the game last night?\",\n",
    "        \"tell me about the upcoming sports events\",\n",
    "        \"what's the latest in the world of sports?\",\n",
    "        \"sports\",\n",
    "        \"basketball and football\"\n",
    "    ],\n",
    "    metadata={\"category\": \"sports\", \"priority\": 2},\n",
    "    distance_threshold=0.7\n",
    ")\n",
    "\n",
    "entertainment = Route(\n",
    "    name=\"entertainment\",\n",
    "    references=[\n",
    "        \"what are the top movies right now?\",\n",
    "        \"who won the best actor award?\",\n",
    "        \"what's new in the entertainment industry?\"\n",
    "    ],\n",
    "    metadata={\"category\": \"entertainment\", \"priority\": 3},\n",
    "    distance_threshold=0.6\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdbcbff",
   "metadata": {},
   "source": [
    "## Initialize the SemanticRouter\n",
    "\n",
    "Like before the ``SemanticRouter`` class will automatically create an index within Redis upon initialization for the route references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e80aaf84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robert.shelton/.pyenv/versions/3.11.8/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/robert.shelton/.pyenv/versions/3.11.8/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from redisvl.extensions.router import SemanticRouter\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Initialize the SemanticRouter\n",
    "multi_topic_router = SemanticRouter(\n",
    "    name=\"topic-router\",\n",
    "    routes=[technology, sports, entertainment],\n",
    "    redis_url=\"redis://localhost:6379\",\n",
    "    overwrite=True # Blow away any other routing index with this name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b199505",
   "metadata": {},
   "source": [
    "## View the created index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3caedb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Index Information:\n",
      "╭──────────────┬────────────────┬──────────────────┬─────────────────┬────────────╮\n",
      "│ Index Name   │ Storage Type   │ Prefixes         │ Index Options   │   Indexing │\n",
      "├──────────────┼────────────────┼──────────────────┼─────────────────┼────────────┤\n",
      "│ topic-router │ HASH           │ ['topic-router'] │ []              │          0 │\n",
      "╰──────────────┴────────────────┴──────────────────┴─────────────────┴────────────╯\n",
      "Index Fields:\n",
      "╭────────────┬─────────────┬────────┬────────────────┬────────────────┬────────────────┬────────────────┬────────────────┬────────────────┬─────────────────┬────────────────╮\n",
      "│ Name       │ Attribute   │ Type   │ Field Option   │ Option Value   │ Field Option   │ Option Value   │ Field Option   │   Option Value │ Field Option    │ Option Value   │\n",
      "├────────────┼─────────────┼────────┼────────────────┼────────────────┼────────────────┼────────────────┼────────────────┼────────────────┼─────────────────┼────────────────┤\n",
      "│ route_name │ route_name  │ TAG    │ SEPARATOR      │ ,              │                │                │                │                │                 │                │\n",
      "│ reference  │ reference   │ TEXT   │ WEIGHT         │ 1              │                │                │                │                │                 │                │\n",
      "│ vector     │ vector      │ VECTOR │ algorithm      │ FLAT           │ data_type      │ FLOAT32        │ dim            │            768 │ distance_metric │ COSINE         │\n",
      "╰────────────┴─────────────┴────────┴────────────────┴────────────────┴────────────────┴────────────────┴────────────────┴────────────────┴─────────────────┴────────────────╯\n"
     ]
    }
   ],
   "source": [
    "# look at the index specification created for the semantic router\n",
    "!rvl index info -i topic-router"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb95dde",
   "metadata": {},
   "source": [
    "## Test it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b0e3208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RouteMatch(name='technology', distance=0.419145862261)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query the router with a statement\n",
    "route_match = multi_topic_router(\"Can you tell me about the latest in artificial intelligence?\")\n",
    "route_match"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bc759b",
   "metadata": {},
   "source": [
    "## Optimize route distance thresholds with test data\n",
    "\n",
    "For optimization within redisvl you can create test data manually or make use of a model to generate some for you. In this case we will use a model to do it for us.\n",
    "\n",
    "Prompt for creating test data:\n",
    "> used claude sonnet 3.7 for generation of resource\n",
    "\n",
    "```txt\n",
    "You are a test data creation helper. \n",
    "\n",
    "Create test data of the form:\n",
    "\n",
    "{\n",
    "    \"query\": \"query about a topic\",\n",
    "    \"query_match\": \"topic-the-query-matches\"\n",
    "}\n",
    "\n",
    "The 3 available topics are: technology, sports, and entertainment. Generate many examples that map to these topics such that we can train a model to find the best thresholds for this classification task. Also make sure to include some examples that don't map to any of the topics to check the null case for these leave the query_match field empty.\n",
    "```\n",
    "\n",
    "The output of this call was saved to `./resources/test_data.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c03a117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"resources/train_data.json\", \"r\") as f:\n",
    "    train_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0c5c2a",
   "metadata": {},
   "source": [
    "## Run optimization with router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d2a15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robert.shelton/.pyenv/versions/3.11.8/lib/python3.11/site-packages/ranx/metrics/f1.py:36: NumbaTypeSafetyWarning: unsafe cast from uint64 to int64. Precision may be lost.\n",
      "  scores[i] = _f1(qrels[i], run[i], k, rel_lvl)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval metric F1: start 0.617, end 0.667 \n",
      "Ending thresholds: {'technology': 0.7242424242424242, 'sports': 0.4696969696969694, 'entertainment': 0.4666666666666667}\n"
     ]
    }
   ],
   "source": [
    "from redisvl.utils.optimize import RouterThresholdOptimizer\n",
    "\n",
    "optimizer = RouterThresholdOptimizer(multi_topic_router, train_data)\n",
    "optimizer.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343964ff",
   "metadata": {},
   "source": [
    "## Test classification against LLM\n",
    "\n",
    "Using the same prompt above we generated and stored another 20 questions to use as our `test_data` to compare against using an LLM model to perform this classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10c83f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"False\"\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\") or getpass.getpass(\"Enter your OpenAI API key: \")\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "def ask_openai(question: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    You are a classification bot. Your job is to classify the following query as either technology, sports, entertainment, or none. Return only the string label or an empty string if no match.\n",
    "\n",
    "    query: \"{question}\"\n",
    "    \"\"\"\n",
    "    response = client.completions.create(\n",
    "      model=\"gpt-3.5-turbo-instruct\",\n",
    "      prompt=prompt,\n",
    "      max_tokens=200\n",
    "    )\n",
    "    return response.choices[0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb25546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'technology'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"resources/test_data.json\", \"r\") as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "\n",
    "ask_openai(test_data[0][\"query\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e5c921b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def test_classifier(classifier, test_data, is_router=False):\n",
    "    correct = 0\n",
    "    times = []\n",
    "    for data in test_data:\n",
    "        start = time.time()\n",
    "        if is_router:\n",
    "            prediction = classifier(data[\"query\"]).name\n",
    "        else:\n",
    "            prediction = classifier(data[\"query\"])\n",
    "        \n",
    "        if not prediction or prediction.lower() == \"none\":\n",
    "            prediction = \"\"\n",
    "\n",
    "        times.append(time.time() - start)\n",
    "        print(f\"Expected | Observed: {data['query_match']} | {prediction.lower()}\")\n",
    "        if prediction.lower() == data[\"query_match\"]:\n",
    "            correct += 1\n",
    "    accuracy = correct / len(test_data)\n",
    "    avg_time = np.mean(times)\n",
    "    return accuracy, avg_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c6024e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected | Observed: technology | the string label for this query is technology, since it is discussing various areas of artificial intelligence, which classify as technology topics.\n",
      "Expected | Observed: technology | result: technology\n",
      "Expected | Observed: technology | technology\n",
      "Expected | Observed: technology | technology\n",
      "Expected | Observed: technology | technology\n",
      "Expected | Observed: sports | sports\n",
      "Expected | Observed: sports | sports\n",
      "Expected | Observed: sports | \n",
      "Expected | Observed: sports | sports\n",
      "Expected | Observed: sports | the label for this query is \"sports\".\n",
      "Expected | Observed: entertainment | entertainment\n",
      "Expected | Observed: entertainment | entertainment\n",
      "Expected | Observed: entertainment | possible match: entertainment\n",
      "Expected | Observed: entertainment | entertainment\n",
      "Expected | Observed: entertainment | entertainment\n",
      "Expected | Observed:  | \n",
      "Expected | Observed:  | \n",
      "Expected | Observed:  | \n",
      "Expected | Observed:  | \n",
      "Expected | Observed:  | technology\n"
     ]
    }
   ],
   "source": [
    "llm_accuracy, llm_avg_time = test_classifier(ask_openai, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c3362a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7, 0.4641483187675476)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_accuracy, llm_avg_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "40ddc05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected | Observed: technology | \n",
      "Expected | Observed: technology | \n",
      "Expected | Observed: technology | \n",
      "Expected | Observed: technology | \n",
      "Expected | Observed: technology | technology\n",
      "Expected | Observed: sports | sports\n",
      "Expected | Observed: sports | \n",
      "Expected | Observed: sports | sports\n",
      "Expected | Observed: sports | \n",
      "Expected | Observed: sports | sports\n",
      "Expected | Observed: entertainment | \n",
      "Expected | Observed: entertainment | entertainment\n",
      "Expected | Observed: entertainment | \n",
      "Expected | Observed: entertainment | entertainment\n",
      "Expected | Observed: entertainment | entertainment\n",
      "Expected | Observed:  | \n",
      "Expected | Observed:  | \n",
      "Expected | Observed:  | \n",
      "Expected | Observed:  | \n",
      "Expected | Observed:  | \n"
     ]
    }
   ],
   "source": [
    "router_accuracy, router_avg_time = test_classifier(multi_topic_router, test_data, is_router=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bec49e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6, 0.02554934024810791)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "router_accuracy, router_avg_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbec96f",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "The following outputs illustrate the tradeoffs with LLMs vs. using the router. As most likely expected the LLM outperforms in terms of accuracy however the router far outperforms the LLM in terms of average latency not to mention the costs incurred with each invocation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
