{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "![Redis](https://redis.io/wp-content/uploads/2024/04/Logotype.svg?auto=webp&quality=85,75&width=120)\n",
    "# Implementing hybrid search with Redis\n",
    "\n",
    "Hybrid search is all about combining lexical search with semantic vector search to improve result relevancy. This notebook will cover 3 different hybrid search strategies with Redis:\n",
    "\n",
    "1. Linear combination of scores from lexical search (BM25) and vector search (Cosine Distance)\n",
    "2. Reciprocal Rank Fusion (RRF)\n",
    "3. Client-Side Reranking with a cross encoder model\n",
    "\n",
    "The Redis Query Engine supports a unified interface for hybrid search with the [FT.HYBRID](https://redis.io/docs/latest/commands/ft.hybrid) command introduced in Redis Open Source 8.4.0, prior to which hybrid searches were only possible using [the aggregations API](https://redis.io/docs/latest/develop/ai/search-and-query/advanced-concepts/aggregations/). RedisVL added an interface for FT.HYBRID in 0.13.0 (via `HybridQuery`), and provided an interface for the aggregation approach for Redis prior to 8.4.0 (via `AggregateHybridQuery`). This notebook will demonstrate the usage of both approaches.\n",
    "\n",
    "## Requirements\n",
    "- Redis 8.4.0+\n",
    "- redisvl>=0.13.1\n",
    "- redispy>=7.1.0\n",
    "\n",
    "## Let's Begin!\n",
    "<a href=\"https://colab.research.google.com/github/redis-developer/redis-ai-resources/blob/main/python-recipes/vector-search/02_hybrid_search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Install Packages"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T08:03:51.826314Z",
     "start_time": "2025-12-19T08:03:51.784443Z"
    }
   },
   "cell_type": "code",
   "source": "%pip install \"redisvl>=0.13.1\" nltk pandas sentence-transformers",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Data/Index Preparation\n",
    " \n",
    "In this section:\n",
    "\n",
    "1. We prepare the data necessary for our hybrid search implementations by loading a collection of movies. Each movie object contains the following attributes:\n",
    "    - `title`\n",
    "    - `rating`\n",
    "    - `description`\n",
    "    - `genre`\n",
    " \n",
    "2. We generate vector embeddings from the movie descriptions. This allows users to perform searches that not only rely on exact matches but also on semantic relevance, helping them find movies that align closely with their interests.\n",
    "\n",
    "3. After preparing the data, we populate a search index with these movie records, enabling efficient querying based on both lexical and vector-based search techniques."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Running remotely or in collab? Run this cell to download the necessary dataset."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# NBVAL_SKIP\n",
    "!git clone https://github.com/redis-developer/redis-ai-resources.git temp_repo\n",
    "!mv temp_repo/python-recipes/vector-search/resources .\n",
    "!rm -rf temp_repo"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Install Redis\n",
    "\n",
    "For this tutorial you will need a running instance of Redis if you don't already have one.\n",
    "\n",
    "#### Local Redis\n",
    "Use the shell script below to download, extract, and install [Redis](https://redis.io/docs/latest/operate/oss_and_stack/install/install-stack/apt/) directly from the Redis package archive for a Linux environment."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# NBVAL_SKIP\n",
    "%%sh\n",
    "sudo apt-get install lsb-release curl gpg\n",
    "curl -fsSL https://packages.redis.io/gpg | sudo gpg --dearmor -o /usr/share/keyrings/redis-archive-keyring.gpg\n",
    "sudo chmod 644 /usr/share/keyrings/redis-archive-keyring.gpg\n",
    "echo \"deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/redis.list\n",
    "sudo apt-get update\n",
    "sudo apt-get install redis\n",
    "\n",
    "redis-server --version\n",
    "redis-server --daemonize yes --loadmodule /usr/lib/redis/modules/redisearch.so"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Alternative Redis Access (Cloud, Docker, other)\n",
    "There are many ways to get the necessary redis-stack instance running\n",
    "1. On cloud, deploy a [FREE instance of Redis in the cloud](https://redis.com/try-free/). Or, if you have your\n",
    "own version of Redis Enterprise running, that works too!\n",
    "2. Per OS, [see the docs](https://redis.io/docs/latest/operate/oss_and_stack/install/install-stack/)\n",
    "3. With docker: `docker run -d --name redis -p 6379:6379 redis:latest`"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from packaging.version import Version\n",
    "\n",
    "from redis import __version__ as redis_version\n",
    "from redisvl import __version__ as redisvl_version\n",
    "\n",
    "\n",
    "if Version(redis_version) < Version(\"7.1.0\"):\n",
    "    raise RuntimeError(\"redis-py version must be >= 7.1.0\")\n",
    "\n",
    "if Version(redisvl_version) < Version(\"0.13.0\"):\n",
    "    raise RuntimeError(\"redisvl version must be >= 0.13.0\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Define the Redis Connection URL\n",
    "\n",
    "By default this notebook connects to the local instance of Redis Stack. **If you have your own Redis Enterprise instance** - replace REDIS_PASSWORD, REDIS_HOST and REDIS_PORT values with your own."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Replace values below with your own if using Redis Cloud instance\n",
    "REDIS_HOST = os.getenv(\"REDIS_HOST\", \"localhost\") # ex: \"redis-18374.c253.us-central1-1.gce.cloud.redislabs.com\"\n",
    "REDIS_PORT = os.getenv(\"REDIS_PORT\", \"6379\")      # ex: 18374\n",
    "REDIS_PASSWORD = os.getenv(\"REDIS_PASSWORD\", \"\")  # ex: \"1TNxTEdYRDgIDKM2gDfasupCADXXXX\"\n",
    "\n",
    "# If SSL is enabled on the endpoint, use rediss:// as the URL prefix\n",
    "REDIS_URL = f\"redis://:{REDIS_PASSWORD}@{REDIS_HOST}:{REDIS_PORT}\""
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create redis client, load data, generate embeddings"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from redis import Redis\n",
    "from redisvl.redis.connection import RedisConnectionFactory\n",
    "\n",
    "client = Redis.from_url(REDIS_URL)\n",
    "client.ping()\n",
    "\n",
    "if Version(client.info()[\"redis_version\"]) < Version(\"8.4.0\"):\n",
    "    raise RuntimeError(\"Redis version must be >= 8.4.0\")\n",
    "\n",
    "installed_modules = RedisConnectionFactory.get_modules(client)\n",
    "if \"search\" not in installed_modules:\n",
    "    raise RuntimeError(\"Redisearch module is not installed\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import json\n",
    "\n",
    "with open(\"resources/movies.json\", 'r') as file:\n",
    "    movies = json.load(file)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from redisvl.utils.vectorize import HFTextVectorizer\n",
    "from redisvl.extensions.cache.embeddings import EmbeddingsCache\n",
    "\n",
    "\n",
    "# load model for embedding our movie descriptions\n",
    "model = HFTextVectorizer(\n",
    "    model='sentence-transformers/all-MiniLM-L6-v2',\n",
    "    cache=EmbeddingsCache(\n",
    "        name=\"embedcache\",\n",
    "        ttl=600,\n",
    "        redis_client=client,\n",
    "    )\n",
    ")\n",
    "\n",
    "# embed movie descriptions\n",
    "movie_data = [\n",
    "    {\n",
    "        **movie,\n",
    "        \"description_vector\": model.embed(movie[\"description\"], as_buffer=True)\n",
    "    } for movie in movies\n",
    "]"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "movie_data[:1]"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Define Redis index schema\n",
    "\n",
    "Below, we build a schema that represents our movie objects."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from redisvl.schema import IndexSchema\n",
    "from redisvl.index import SearchIndex\n",
    "\n",
    "\n",
    "schema = IndexSchema.from_dict({\n",
    "  \"index\": {\n",
    "    \"name\": \"movies\",\n",
    "    \"prefix\": \"movie\",\n",
    "    \"storage\": \"hash\"\n",
    "  },\n",
    "  \"fields\": [\n",
    "    { \"name\": \"title\", \"type\": \"text\" },\n",
    "    { \"name\": \"description\", \"type\": \"text\" },\n",
    "    { \"name\": \"genre\", \"type\": \"tag\", \"attrs\": {\"sortable\": True}},\n",
    "    { \"name\": \"rating\", \"type\": \"numeric\", \"attrs\": {\"sortable\": True}},\n",
    "    {\n",
    "        \"name\": \"description_vector\",\n",
    "        \"type\": \"vector\",\n",
    "        \"attrs\": {\n",
    "            \"dims\": 384,\n",
    "            \"distance_metric\": \"cosine\",\n",
    "            \"algorithm\": \"hnsw\",\n",
    "            \"datatype\": \"float32\"\n",
    "        }\n",
    "    }\n",
    "  ]\n",
    "})\n",
    "\n",
    "\n",
    "index = SearchIndex(schema, client, validate_on_load=True)\n",
    "index.create(overwrite=True, drop=True)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Populate index\n",
    "\n",
    "Load movie objects into Redis"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "index.load(movie_data)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Hybrid Search Approaches\n",
    "\n",
    "Now that our search index is populated and ready, we will build out a few different hybrid search techniques in Redis.\n",
    "\n",
    "To start, we will use the `HybridQuery` class that accepts a text string and vector to automatically combine text similarity and vector similarity scores.\n",
    "\n",
    "At a minimum, the `HybridQuery` class requires the following arguments:\n",
    "\n",
    "```python\n",
    "query = HybridQuery(\n",
    "    text=\"your query string here\",\n",
    "    text_field_name=\"<name of the text field in the index to do text search in>\",\n",
    "    vector=<bytes or numeric array, ex: [0.1, 0.2, 0.3]>,\n",
    "    vector_field_name=\"<name of the vector field in the index to compute vector similarity>\",\n",
    ")\n",
    "```\n",
    "\n",
    "This defaults to using the reciprocal rank fusion (RRF) method to combine scores, and only outputs the final keys and combined scores. A more common minimal usage might be:\n",
    "\n",
    "```python\n",
    "query = HybridQuery(\n",
    "    text=\"your query string here\",\n",
    "    text_field_name=\"<name of the text field in the index to do text search in>\",\n",
    "    vector=<bytes or numeric array, ex: [0.1, 0.2, 0.3]>,\n",
    "    vector_field_name=\"<name of the vector field in the index to compute vector similarity>\",\n",
    "    combination_method=\"RRF\",\n",
    "    rrf_window=20,\n",
    "    yield_text_score_as=\"text_score\",\n",
    "    yield_vsim_score_as=\"vector_similarity\",\n",
    "    yield_combined_score_as=\"hybrid_score\",\n",
    "    return_fields=[\"<list of fields to return>\"],\n",
    ")\n",
    "```"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Linear Combination\n",
    "\n",
    "The goal of this technique is to calculate a weighted sum of the text similarity score for our provided text search and the vector similarity score for our provided vector.\n",
    "\n",
    "The FT.HYBRID API introduced in Redis 8.4.0 supports a linear combination of text and vector scores (accessible as of RedisVL 0.13.0 in `HybridQuery`), and it is also possible with the aggregations API, as of `Redis 7.4.x` (search version `2.10.5` - accessible as of RedisVl 0.5.0 in `AggregateHybridQuery`)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Sample user query (can be changed for comparisons)\n",
    "user_query = \"action adventure movie with great fighting scenes against a dangerous criminal, crime busting, superheroes, and magic\""
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "\n",
    "from redisvl.query.hybrid import HybridQuery\n",
    "\n",
    "vector = model.embed(user_query, as_buffer=True)\n",
    "\n",
    "query = HybridQuery(\n",
    "\ttext=user_query,\n",
    "\ttext_field_name=\"description\",\n",
    "\tvector=vector,\n",
    "\tvector_field_name=\"description_vector\",\n",
    "\tcombination_method=\"LINEAR\",\n",
    "\tyield_text_score_as=\"text_score\",\n",
    "\tyield_vsim_score_as=\"vector_similarity\",\n",
    "\tyield_combined_score_as=\"hybrid_score\",\n",
    "\treturn_fields=[\"title\"],\n",
    ")\n",
    "\n",
    "results = index.query(query)\n",
    "pd.DataFrame(results[:3])"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Alternatively, for Redis versions prior to 8.4.0, we can use the aggregations API:"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from redisvl.query.aggregate import AggregateHybridQuery\n",
    "\n",
    "agg_query = AggregateHybridQuery(\n",
    "    text=user_query,\n",
    "    text_field_name=\"description\",\n",
    "    vector=vector,\n",
    "    vector_field_name=\"description_vector\",\n",
    "    return_fields=[\"title\"],\n",
    ")\n",
    "\n",
    "print(f\"Query being executed:\\n{agg_query._build_query_string()}\")\n",
    "\n",
    "results = index.query(agg_query)\n",
    "pd.DataFrame(results[:3])"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Choosing your stopwords for better queries\n",
    "You can see that the user query string has been tokenized and certain stopwords like 'and', 'for', 'with', 'but', have been removed, otherwise you would get matches on irrelevant words.\n",
    "RedisVL uses [NLTK](https://www.nltk.org/index.html) english stopwords as the the default. You can change which default language stopwords to use with the `stopwords` argument.\n",
    "You specify a language, like 'german', 'arabic', 'greek' and many others, provide your own list of stopwords, or set it to `None` to not remove any.\n",
    "\n",
    "Note that both `HybridQuery` and `AggregateHybridQuery` process stopwords identically."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# translate our user query to French and use nltk french stopwords\n",
    "french_query_text = \"Film d'action et d'aventure avec de superbes scènes de combat, des enquêtes criminelles, des super-héros et de la magie\"\n",
    "\n",
    "french_film_query = HybridQuery(\n",
    "    text=french_query_text,\n",
    "    text_field_name=\"description\",\n",
    "    vector=model.embed(french_query_text, as_buffer=True),\n",
    "    vector_field_name=\"description_vector\",\n",
    "    stopwords=\"french\",\n",
    ")\n",
    "\n",
    "print(french_film_query.query._search_query.query_string())\n",
    "\n",
    "# specify your own stopwords\n",
    "custom_stopwords = set([\n",
    "    \"a\", \"is\", \"the\", \"an\", \"and\", \"are\", \"as\", \"at\", \"be\", \"but\", \"by\", \"for\",\n",
    "    \"if\", \"in\", \"into\", \"it\", \"no\", \"not\", \"of\", \"on\", \"or\", \"such\", \"that\", \"their\",\n",
    "    \"then\", \"there\", \"these\", \"they\", \"this\", \"to\", \"was\", \"will\", \"with\"\n",
    "])\n",
    "\n",
    "stopwords_query = HybridQuery(\n",
    "    text=user_query,\n",
    "    text_field_name=\"description\",\n",
    "    vector=vector,\n",
    "    vector_field_name=\"description_vector\",\n",
    "    stopwords=custom_stopwords,\n",
    ")\n",
    "\n",
    "print(stopwords_query.query._search_query.query_string())\n",
    "\n",
    "# don't use any stopwords\n",
    "no_stopwords_query = HybridQuery(\n",
    "    text=user_query,\n",
    "    text_field_name=\"description\",\n",
    "    vector=vector,\n",
    "    vector_field_name=\"description_vector\",\n",
    "    stopwords=None,\n",
    ")\n",
    "\n",
    "print(no_stopwords_query.query._search_query.query_string())"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Choosing your text scoring function and weights\n",
    "There are different ways to calculate the similarity between sets of text. Options for text scoring functions are TFIDF, TFIDF.DOCNORM, BM25STD, BM25STD.NORM, BM25STD.TANH, DISMAX, DOCSCORE, and HAMMING; the default is BM25STD and is easy to configure with the `text_scorer` parameter. Just like changing you embedding model can change your vector similarity scores, changing your text similarity measure can change your text scores.\n",
    "\n",
    ">  For more information about supported scoring algorithms, see [the Redis documentation on scoring](https://redis.io/docs/latest/develop/ai/search-and-query/advanced-concepts/scoring/).\n",
    "\n",
    "When combining text and vector scores using a linear combination (`combination_method=\"LINEAR\"` in `HybridQuery` and the only option for `AggregateHybridQuery`), you can control the relative balance of these scores with tunable parameters.\n",
    "\n",
    "The FT.HYBRID API calculates the combined score as:\n",
    "\n",
    "```python\n",
    "hybrid_score = {alpha} * text_score + {beta} * vector_similarity\n",
    "```\n",
    "\n",
    "Where `alpha` can be provided to `HybridQuery` via the `linear_alpha` and `beta` is calculated as `1 - alpha`. FT.HYBRID defaults to `alpha=0.3`.\n",
    "\n",
    "`AggregateHybridQuery` defines the combined score in reverse as:\n",
    "\n",
    "```python\n",
    "hybrid_score = {1-alpha} * text_score + {alpha} * vector_similarity\n",
    "```\n",
    "\n",
    "Where the `alpha` parameter is configurable on the `AggregateHybridQuery` class. If not specified, it defaults to `0.7`.\n",
    "\n",
    "Try changing the `text_scorer` and `linear_alpha` parameters in the query below to see how results may change."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "tfidf_query = HybridQuery(\n",
    "    text=user_query,\n",
    "    text_field_name=\"description\",\n",
    "    vector=vector,\n",
    "    vector_field_name=\"description_vector\",\n",
    "    text_scorer=\"TFIDF\", # can be one of [TFIDF, TFIDF.DOCNORM, BM25, DISMAX, DOCSCORE, BM25STD]\n",
    "    stopwords=None,\n",
    "\tcombination_method=\"LINEAR\",\n",
    "    linear_alpha=0.75, # weight the text score higher\n",
    "    return_fields=[\"title\", \"description\"],\n",
    "\tyield_text_score_as=\"text_score\",\n",
    "    yield_vsim_score_as=\"vector_similarity\",\n",
    "    yield_combined_score_as=\"hybrid_score\",\n",
    ")\n",
    "\n",
    "results = index.query(tfidf_query)\n",
    "pd.DataFrame(results[:3])"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Reciprocal Rank Fusion (RRF)\n",
    "\n",
    "Instead of relying on document scores like cosine similarity and BM25/TFIDF, we can fetch items and focus on their rank. This rank can be utilized to create a new ranking metric known as [Reciprocal Rank Fusion (RRF)](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf). RRF is powerful because it can handle ranked lists of different length, scores of different scales, and other complexities.\n",
    "\n",
    "The FT.HYBRID API introduced in Redis 8.4.0 supports using RRF to combine results from text and vector queries (accessible as of RedisVL 0.13.0 in `HybridQuery`). Unless otherwise specified, RRF is the default combination method.\n",
    "\n",
    "The parameters available to customize the behaviour of RRF are `rrf_window` and `rrf_constant`. The `rrf_window` parameter controls the size of the window over which the RRF score is calculated, and the `rrf_constant` parameter controls the constant used in the RRF formula. Try changing these parameters to see how results may change."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "query = HybridQuery(\n",
    "\ttext=user_query,\n",
    "\ttext_field_name=\"description\",\n",
    "\tvector=vector,\n",
    "\tvector_field_name=\"description_vector\",\n",
    "\tcombination_method=\"RRF\",\n",
    "\trrf_window=20,\n",
    "\trrf_constant=60,\n",
    "\tyield_text_score_as=\"text_score\",\n",
    "\tyield_vsim_score_as=\"vector_similarity\",\n",
    "\tyield_combined_score_as=\"hybrid_score\",\n",
    "\treturn_fields=[\"title\", \"description\"],\n",
    ")\n",
    "\n",
    "results = index.query(query)\n",
    "pd.DataFrame(results[:3])"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Client-side RRF for older Redis versions\n",
    "\n",
    "When using Redis versions prior to 8.4.0, you can still perform RRF by fetching the top-k results from both the text and vector queries, and then fusing them together on the client-side."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def fuse_rankings_rrf(*ranked_lists, weights=None, k=60):\n",
    "    \"\"\"\n",
    "    Perform Weighted Reciprocal Rank Fusion on N number of ordered lists.\n",
    "    \"\"\"\n",
    "    item_scores = {}\n",
    "    \n",
    "    if weights is None:\n",
    "        weights = [1.0] * len(ranked_lists)\n",
    "    else:\n",
    "        assert len(weights) == len(ranked_lists), \"Number of weights must match number of ranked lists\"\n",
    "        assert all(0 <= w <= 1 for w in weights), \"Weights must be between 0 and 1\"\n",
    "    \n",
    "    for ranked_list, weight in zip(ranked_lists, weights):\n",
    "        for rank, item in enumerate(ranked_list, start=1):\n",
    "            if item not in item_scores:\n",
    "                item_scores[item] = 0\n",
    "            item_scores[item] += weight * (1 / (rank + k))\n",
    "    \n",
    "    # Sort items by their weighted RRF scores in descending order\n",
    "    return sorted(item_scores.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Below is a simple example of RRF over a few lists of numbers\n",
    "fuse_rankings_rrf([1, 2, 3], [2, 4, 6, 7, 8], [5, 6, 1, 2])"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We'll want some helper functions to  construct our individual text and vector queries"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Function to create a vector query using RedisVL helpers for ease of use\n",
    "from redisvl.query import VectorQuery, TextQuery\n",
    "\n",
    "\n",
    "def make_vector_query(user_query: str, num_results: int, filters = None) -> VectorQuery:\n",
    "    \"\"\"Generate a Redis vector query given user query string.\"\"\"\n",
    "    vector = model.embed(user_query, as_buffer=True)\n",
    "    query = VectorQuery(\n",
    "        vector=vector,\n",
    "        vector_field_name=\"description_vector\",\n",
    "        num_results=num_results,\n",
    "        return_fields=[\"title\", \"description\"]\n",
    "    )\n",
    "    if filters:\n",
    "        query.set_filter(filters)\n",
    "    return query\n",
    "\n",
    "\n",
    "def make_ft_query(text_field: str, user_query: str, num_results: int) -> TextQuery:\n",
    "    \"\"\"Generate a Redis full-text query given a user query string.\"\"\"\n",
    "    return TextQuery(\n",
    "        text=user_query,\n",
    "        text_field_name=text_field,\n",
    "        text_scorer=\"BM25\",\n",
    "        num_results=num_results,\n",
    "        return_fields=[\"title\", \"description\"],\n",
    "    )"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from typing import List, Dict, Any\n",
    "\n",
    "\n",
    "def weighted_rrf(\n",
    "    user_query: str,\n",
    "    alpha: float = 0.5,\n",
    "    num_results: int = 4,\n",
    "    k: int = 60,\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"Implemented client-side RRF after querying from Redis.\"\"\"\n",
    "    # Create the vector query\n",
    "    vector_query = make_vector_query(user_query, num_results=len(movie_data))\n",
    "\n",
    "    # Create the full-text query\n",
    "    full_text_query = make_ft_query(\"description\", user_query, num_results=len(movie_data))\n",
    "\n",
    "    # Run queries individually\n",
    "    vector_query_results = index.query(vector_query)\n",
    "    full_text_query_results = index.query(full_text_query)\n",
    "\n",
    "    # Extract titles from results\n",
    "    vector_titles = [movie[\"title\"] for movie in vector_query_results]\n",
    "    full_text_titles = [movie[\"title\"] for movie in full_text_query_results]\n",
    "\n",
    "    # Perform weighted RRF\n",
    "    return fuse_rankings_rrf(vector_titles, full_text_titles, weights=[alpha, 1-alpha], k=k)[:num_results]"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Test it out!\n",
    "weighted_rrf(user_query, num_results=6)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "But say we want to give more weight to the vector search rankings in this case to boost semantic similarities contribution to the final rank:"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "weighted_rrf(user_query, alpha=0.7, num_results=6)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Client-side reranking\n",
    "\n",
    "An alternative approach to RRF is to simply use an external reranker to order the final recommendations. RedisVL has built-in integrations to a few popular reranking modules."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from redisvl.utils.rerank import HFCrossEncoderReranker\n",
    "\n",
    "# Load the ms marco MiniLM cross encoder model from huggingface\n",
    "reranker = HFCrossEncoderReranker(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "\n",
    "\n",
    "def rerank(\n",
    "    user_query: str,\n",
    "    num_results: int = 4,\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"Rerank the candidates based on the user query with an external model/module.\"\"\"\n",
    "    # Create the vector query\n",
    "    vector_query = make_vector_query(user_query, num_results=num_results)\n",
    "\n",
    "    # Create the full-text query\n",
    "    full_text_query = make_ft_query(\"description\", user_query, num_results=num_results)\n",
    "\n",
    "    # Run queries individually\n",
    "    vector_query_results = index.query(vector_query)\n",
    "    full_text_query_results = index.query(full_text_query)\n",
    "\n",
    "    # Assemble list of potential movie candidates with their IDs\n",
    "    movie_map = {}\n",
    "    for movie in vector_query_results + full_text_query_results:\n",
    "        candidate = f\"Title: {movie['title']}. Description: {movie['description']}\"\n",
    "        if candidate not in movie_map:\n",
    "            movie_map[candidate] = movie\n",
    "\n",
    "    # Rerank candidates\n",
    "    reranked_movies, scores = reranker.rank(\n",
    "        query=user_query,\n",
    "        docs=list(movie_map.keys()),\n",
    "        limit=num_results,\n",
    "        return_score=True\n",
    "    )\n",
    "\n",
    "    # Fetch full movie objects for the reranked results\n",
    "    return [\n",
    "        (movie_map[movie['content']][\"title\"], score)\n",
    "        for movie, score in zip(reranked_movies, scores)\n",
    "    ]\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Test it out!\n",
    "rerank(user_query, num_results=6)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This technique is certainly much slower than simple RRF as it's running an additional cross-encoder model to rerank the results. This can be fairly computationally expensive, but tunable with enough clarity on the use case and focus (how many items to retrieve? how many items to rerank? model accleration via GPU?)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Post-processing configuration with FT.HYBRID\n",
    "\n",
    "The FT.HYBRID API also allows for post-processing of the results (e.g. aggregations and aliasing)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from redis.commands.search import reducers\n",
    "\n",
    "query = HybridQuery(\n",
    "\ttext=user_query,\n",
    "\ttext_field_name=\"description\",\n",
    "\tvector=vector,\n",
    "\tvector_field_name=\"description_vector\",\n",
    "\tcombination_method=\"RRF\",\n",
    "\trrf_window=20,\n",
    "\tyield_text_score_as=\"text_score\",\n",
    "\tyield_vsim_score_as=\"vector_similarity\",\n",
    "\tyield_combined_score_as=\"hybrid_score\",\n",
    "\treturn_fields=[\"title\", \"genre\", \"description\", \"rating\"],\n",
    "\tnum_results=20,\n",
    ")\n",
    "\n",
    "query.postprocessing_config.group_by(\n",
    "\t\"@genre\",\n",
    "\treducers.max(\"@hybrid_score\").alias(\"max_hybrid_score\"),\n",
    "\treducers.avg(\"@hybrid_score\").alias(\"avg_hybrid_score\"),\n",
    "\treducers.count().alias(\"count\"),\n",
    "\treducers.max(\"@rating\").alias(\"max_rating\"),\n",
    "\treducers.min(\"@rating\").alias(\"min_rating\"),\n",
    ").apply(\n",
    "\trating_range=\"@max_rating - @min_rating\",\n",
    ")\n",
    "\n",
    "results = index.query(query)\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Comparing Approaches\n",
    "\n",
    "While each approach has strengths and weaknesses, it's important to understand that each might work better in some use cases than others. Below we will run through a sample of user queries and generate matches for each using different hybrid search techniques."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "movie_user_queries = [\n",
    "    \"I'm in the mood for a high-rated action movie with a complex plot\",\n",
    "    \"What's a funny animated film about unlikely friendships?\",\n",
    "    \"Any movies featuring superheroes or extraordinary abilities\", \n",
    "    \"I want to watch a thrilling movie with spies or secret agents\",\n",
    "    \"Are there any comedies set in unusual locations or environments?\",\n",
    "    \"Find me an action-packed movie with car chases or explosions\",\n",
    "    \"What's a good family-friendly movie with talking animals?\",\n",
    "    \"I'm looking for a film that combines action and mind-bending concepts\",\n",
    "    \"Suggest a movie with a strong female lead character\",\n",
    "    \"What are some movies that involve heists or elaborate plans?\",\n",
    "    \"I need a feel-good movie about personal growth or transformation\",\n",
    "    \"Are there any films that blend comedy with action elements?\", \n",
    "    \"Show me movies set in dystopian or post-apocalyptic worlds\",\n",
    "    \"I'm interested in a movie with themes of revenge or justice\",\n",
    "    \"What are some visually stunning movies with impressive special effects?\"\n",
    "]"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from typing import Tuple\n",
    "\n",
    "\n",
    "def hybrid_query(text, num_results: int, **kwargs) -> List[Tuple[str, float]]:\n",
    "\n",
    "    query = HybridQuery(\n",
    "\t\ttext,\n",
    "\t\ttext_field_name=\"description\",\n",
    "\t\tvector=model.embed(text, as_buffer=True),\n",
    "\t\tvector_field_name=\"description_vector\",\n",
    "\t\tstopwords=\"english\",\n",
    "\t\tnum_results=num_results,\n",
    "\t\treturn_fields=[\"title\"],\n",
    "\t\tyield_combined_score_as=\"hybrid_score\",\n",
    "\t\t**kwargs,\n",
    "    )\n",
    "\n",
    "    results = index.query(query)\n",
    "\n",
    "    return [\n",
    "        (\n",
    "            movie[\"title\"],\n",
    "            movie[\"hybrid_score\"]\n",
    "        )\n",
    "        for movie in results\n",
    "    ]"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "rankings = pd.DataFrame()\n",
    "rankings[\"query\"] = movie_user_queries\n",
    "\n",
    "# First, add new columns to the DataFrame\n",
    "rankings[\"hf-cross-encoder\"] = \"\"\n",
    "rankings[\"rrf\"] = \"\"\n",
    "rankings[\"linear\"] = \"\""
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Now iterate through the queries and add results\n",
    "for i, user_query in enumerate(movie_user_queries):\n",
    "    rankings.at[i, \"hf-cross-encoder\"] = rerank(user_query, num_results=4)\n",
    "    rankings.at[i, \"rrf\"] = hybrid_query(user_query, num_results=4, combination_method=\"RRF\", rrf_window=20)\n",
    "    rankings.at[i, \"linear\"] = hybrid_query(user_query, num_results=4, combination_method=\"LINEAR\", linear_alpha=0.3)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "rankings.head()"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "rankings.loc[12].T"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Wrap up\n",
    "That's a wrap! Hopefully from this you were able to learn:\n",
    "- How to implement simple vector search queries in Redis\n",
    "- How to implement vector search queries with full-text filters\n",
    "- How to implement hybrid search queries using the Redis hybrid and aggregation APIs\n",
    "- How to perform client-side fusion and reranking techniques"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "redis-ai-res",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
